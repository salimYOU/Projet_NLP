{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Environ 3 minutes pour le rennuer entièrement\n",
    "\n",
    "idée : la fréquence des mots semble bien cacher les mots plus fins. Les études à la main on révelées d'autres mots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Import des constantes et de la base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/salimyoussfi/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/salimyoussfi/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/salimyoussfi/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "Using TensorFlow backend.\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/salimyoussfi/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/salimyoussfi/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package sentiwordnet to\n",
      "[nltk_data]     /Users/salimyoussfi/nltk_data...\n",
      "[nltk_data]   Package sentiwordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import des packages\n",
    "%matplotlib inline\n",
    "import time \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import marshal\n",
    "import io\n",
    "import ast\n",
    "import time \n",
    "\n",
    "#Tokenization \n",
    "import nltk\n",
    "from gensim.models.phrases import Phrases, Phraser\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from functools import reduce\n",
    "from operator import add\n",
    "import collections\n",
    "from collections import Counter\n",
    "\n",
    "#Word2Vec\n",
    "from gensim.models import Word2Vec\n",
    "from multiprocessing import cpu_count\n",
    "\n",
    "#TF-IDF\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Modèles de classifications\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "#BERT\n",
    "import torch\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertModel, BertForMaskedLM\n",
    "\n",
    "#Clustering \n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "#nltk\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk.corpus import wordnet\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "stopWords = set(stopwords.words('english'))\n",
    "\n",
    "# Keras \n",
    "import keras\n",
    "from keras.datasets import imdb\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "\n",
    "#LDA\n",
    "import gensim\n",
    "import nltk\n",
    "import time\n",
    "from nltk.corpus import wordnet\n",
    "import warnings\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "#SentiWordNet\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "from nltk.stem import PorterStemmer\n",
    "nltk.download('sentiwordnet')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import de la base intiale \n",
    "\n",
    "f = open('tweet_global_warming.txt', 'r',newline='', encoding='ISO-8859-1')\n",
    "content = f.read().split('\\r')\n",
    "\n",
    "content_new=[]\n",
    "for x in content : \n",
    "    if len(x)>0:\n",
    "        content_new.append(x)\n",
    "\n",
    "content_new=content_new[1:len(content_new)]\n",
    "\n",
    "##########################################################################################\n",
    "##########################################################################################\n",
    "\n",
    "# Création du dataframe\n",
    "\n",
    "col_tweet=[]\n",
    "col_existence=[]\n",
    "col_score=[]\n",
    "\n",
    "#Split tweet , Note\n",
    "\n",
    "for line in content_new:\n",
    "    if len(line.split('[link]'))==2:\n",
    "        (x,y)=line.split('[link]')\n",
    "        col_tweet.append(x)\n",
    "        col_existence.append(y)\n",
    "    else : \n",
    "        if len(line.split(',Yes,'))==2:\n",
    "            col_tweet.append(line.split(',Yes,')[0])\n",
    "            col_existence.append(',Yes,'+line.split(',Yes,')[1])\n",
    "        elif len(line.split(',No,'))==2:\n",
    "            col_tweet.append(line.split(',No,')[0])\n",
    "            col_existence.append(',No,'+line.split(',No,')[1])\n",
    "        elif len(line.split(',Y,'))==2:\n",
    "            col_tweet.append(line.split(',Y,')[0])\n",
    "            col_existence.append(',Yes,'+line.split(',Y,')[1])\n",
    "        elif len(line.split(',N/A,'))==2:\n",
    "            col_tweet.append(line.split(',N/A,')[0])\n",
    "            col_existence.append(',N/A,'+line.split(',N/A,')[1])\n",
    "        elif len(line.split(',NA,'))==2:\n",
    "            col_tweet.append(line.split(',NA,')[0])\n",
    "            col_existence.append(',NA,'+line.split(',NA,')[1])\n",
    "        elif len(line.split(',N,'))==2:\n",
    "            col_tweet.append(line.split(',N,')[0])\n",
    "            col_existence.append(',No,'+line.split(',N,')[1])\n",
    "\n",
    "col_tweet.append('I truly  Fat ASS Gore should get the Scam Artist Award of the decade with his Global Warming and Energy Credits worth close to Billion')\n",
    "col_existence.append(' ,NA')\n",
    "col_tweet.append('Despite Climategate, LEFT investing heavily in global warming hysteria as new way 2 impose nat\\'l & international controls on human freedom.')\n",
    "col_existence.append(' ,NA')\n",
    "        \n",
    "# Split Existence/Note\n",
    "col_existence_new=[]\n",
    "\n",
    "for x in col_existence:\n",
    "    if len(x.split(','))==3:\n",
    "        col_existence_new.append(x.split(',')[1])\n",
    "        col_score.append(x.split(',')[2])\n",
    "    else:\n",
    "        col_existence_new.append('NA')\n",
    "        col_score.append('NA')\n",
    "        \n",
    "#Nettoyage existence\n",
    "for avis in range(len(col_existence_new)):\n",
    "    if col_existence_new[avis]=='NA' or col_existence_new[avis]=='N/A' or col_existence_new[avis]=='':\n",
    "        col_existence_new[avis]=np.nan\n",
    "        \n",
    "#Nettoyage score\n",
    "for score in range(len(col_score)):\n",
    "    if 'NA' not in col_score[score]:\n",
    "        col_score[score]=col_score[score].split('\\t')[0]\n",
    "        if len(col_score[score].split('\"'))>1:\n",
    "            col_score[score]=float(col_score[score].split('\"')[0])\n",
    "        else: \n",
    "            col_score[score]=float(col_score[score])\n",
    "            \n",
    "    else : \n",
    "        col_score[score]=np.nan\n",
    "\n",
    "#Creation du DataFrame\n",
    "dic={'Tweet':col_tweet,'Existence':col_existence_new,'Score':col_score}\n",
    "df=pd.DataFrame(dic)\n",
    "\n",
    "df.drop_duplicates(['Tweet'], inplace=True)\n",
    "df.reset_index(inplace=True,drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv('my_file.csv.gz', compression='gzip')\n",
    "df = pd.read_csv('my_file.csv.gz', compression='gzip',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>7182</th>\n",
       "      <th>7183</th>\n",
       "      <th>7184</th>\n",
       "      <th>7185</th>\n",
       "      <th>7186</th>\n",
       "      <th>7187</th>\n",
       "      <th>7188</th>\n",
       "      <th>7189</th>\n",
       "      <th>7190</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5534</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5535</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5536</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5537</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5538</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5539 rows × 7192 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0    1    2    3    4    5    6    7    8    9  ...  7182  7183  7184  \\\n",
       "0     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
       "1     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
       "2     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
       "3     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
       "4     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
       "...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   ...   ...   ...   \n",
       "5534  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
       "5535  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
       "5536  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
       "5537  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
       "5538  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
       "\n",
       "      7185  7186  7187  7188  7189  7190  Labels  \n",
       "0      0.0   0.0   0.0   0.0   0.0   0.0     Yes  \n",
       "1      0.0   0.0   0.0   0.0   0.0   0.0     Yes  \n",
       "2      0.0   0.0   0.0   0.0   0.0   0.0     Yes  \n",
       "3      0.0   0.0   0.0   0.0   0.0   0.0     Yes  \n",
       "4      0.0   0.0   0.0   0.0   0.0   0.0     Yes  \n",
       "...    ...   ...   ...   ...   ...   ...     ...  \n",
       "5534   0.0   0.0   0.0   0.0   0.0   0.0     NaN  \n",
       "5535   0.0   0.0   0.0   0.0   0.0   0.0      No  \n",
       "5536   0.0   0.0   0.0   0.0   0.0   0.0      No  \n",
       "5537   0.0   0.0   0.0   0.0   0.0   0.0      No  \n",
       "5538   0.0   0.0   0.0   0.0   0.0   0.0     NaN  \n",
       "\n",
       "[5539 rows x 7192 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>7182</th>\n",
       "      <th>7183</th>\n",
       "      <th>7184</th>\n",
       "      <th>7185</th>\n",
       "      <th>7186</th>\n",
       "      <th>7187</th>\n",
       "      <th>7188</th>\n",
       "      <th>7189</th>\n",
       "      <th>7190</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5534</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5535</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5536</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5537</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5538</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5539 rows × 7192 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0    1    2    3    4    5    6    7    8    9  ...  7182  7183  7184  \\\n",
       "0     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
       "1     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
       "2     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
       "3     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
       "4     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
       "...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   ...   ...   ...   \n",
       "5534  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
       "5535  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
       "5536  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
       "5537  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
       "5538  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
       "\n",
       "      7185  7186  7187  7188  7189  7190  Labels  \n",
       "0      0.0   0.0   0.0   0.0   0.0   0.0     Yes  \n",
       "1      0.0   0.0   0.0   0.0   0.0   0.0     Yes  \n",
       "2      0.0   0.0   0.0   0.0   0.0   0.0     Yes  \n",
       "3      0.0   0.0   0.0   0.0   0.0   0.0     Yes  \n",
       "4      0.0   0.0   0.0   0.0   0.0   0.0     Yes  \n",
       "...    ...   ...   ...   ...   ...   ...     ...  \n",
       "5534   0.0   0.0   0.0   0.0   0.0   0.0     NaN  \n",
       "5535   0.0   0.0   0.0   0.0   0.0   0.0      No  \n",
       "5536   0.0   0.0   0.0   0.0   0.0   0.0      No  \n",
       "5537   0.0   0.0   0.0   0.0   0.0   0.0      No  \n",
       "5538   0.0   0.0   0.0   0.0   0.0   0.0     NaN  \n",
       "\n",
       "[5539 rows x 7192 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################\n",
      "####################\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>-0.034803</td>\n",
       "      <td>0.574692</td>\n",
       "      <td>-0.024320</td>\n",
       "      <td>0.084124</td>\n",
       "      <td>-0.007769</td>\n",
       "      <td>-0.043919</td>\n",
       "      <td>-0.212503</td>\n",
       "      <td>-0.187975</td>\n",
       "      <td>0.194824</td>\n",
       "      <td>-0.071464</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.061573</td>\n",
       "      <td>0.291551</td>\n",
       "      <td>-0.099408</td>\n",
       "      <td>-0.417668</td>\n",
       "      <td>0.114716</td>\n",
       "      <td>-0.070984</td>\n",
       "      <td>-0.140349</td>\n",
       "      <td>0.155909</td>\n",
       "      <td>0.387361</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>-0.045523</td>\n",
       "      <td>0.679620</td>\n",
       "      <td>0.000538</td>\n",
       "      <td>0.103425</td>\n",
       "      <td>-0.005931</td>\n",
       "      <td>-0.023181</td>\n",
       "      <td>-0.233011</td>\n",
       "      <td>-0.246731</td>\n",
       "      <td>0.277161</td>\n",
       "      <td>-0.078278</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.031663</td>\n",
       "      <td>0.376862</td>\n",
       "      <td>-0.074846</td>\n",
       "      <td>-0.527581</td>\n",
       "      <td>0.142178</td>\n",
       "      <td>-0.079401</td>\n",
       "      <td>-0.190756</td>\n",
       "      <td>0.178426</td>\n",
       "      <td>0.480519</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>-0.099174</td>\n",
       "      <td>0.598018</td>\n",
       "      <td>0.147960</td>\n",
       "      <td>-0.048949</td>\n",
       "      <td>-0.031430</td>\n",
       "      <td>-0.017491</td>\n",
       "      <td>-0.149470</td>\n",
       "      <td>-0.287509</td>\n",
       "      <td>0.368354</td>\n",
       "      <td>-0.136673</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.079986</td>\n",
       "      <td>0.281047</td>\n",
       "      <td>-0.051203</td>\n",
       "      <td>-0.427393</td>\n",
       "      <td>0.209120</td>\n",
       "      <td>0.037495</td>\n",
       "      <td>-0.045074</td>\n",
       "      <td>0.212375</td>\n",
       "      <td>0.501800</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>-0.032602</td>\n",
       "      <td>0.584073</td>\n",
       "      <td>-0.000475</td>\n",
       "      <td>0.022584</td>\n",
       "      <td>-0.020850</td>\n",
       "      <td>-0.066859</td>\n",
       "      <td>-0.207133</td>\n",
       "      <td>-0.080091</td>\n",
       "      <td>0.247074</td>\n",
       "      <td>-0.082756</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.103604</td>\n",
       "      <td>0.323825</td>\n",
       "      <td>-0.140997</td>\n",
       "      <td>-0.380847</td>\n",
       "      <td>0.117071</td>\n",
       "      <td>-0.048625</td>\n",
       "      <td>-0.109754</td>\n",
       "      <td>0.159889</td>\n",
       "      <td>0.402783</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>-0.122250</td>\n",
       "      <td>0.553165</td>\n",
       "      <td>0.123425</td>\n",
       "      <td>-0.024946</td>\n",
       "      <td>0.018299</td>\n",
       "      <td>0.033656</td>\n",
       "      <td>-0.132178</td>\n",
       "      <td>-0.334184</td>\n",
       "      <td>0.323884</td>\n",
       "      <td>-0.127449</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.058247</td>\n",
       "      <td>0.233620</td>\n",
       "      <td>0.048888</td>\n",
       "      <td>-0.392988</td>\n",
       "      <td>0.176985</td>\n",
       "      <td>0.028446</td>\n",
       "      <td>-0.054034</td>\n",
       "      <td>0.191555</td>\n",
       "      <td>0.447745</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5532</td>\n",
       "      <td>-0.061722</td>\n",
       "      <td>0.611638</td>\n",
       "      <td>0.056657</td>\n",
       "      <td>0.056770</td>\n",
       "      <td>0.013780</td>\n",
       "      <td>0.001569</td>\n",
       "      <td>-0.173358</td>\n",
       "      <td>-0.267492</td>\n",
       "      <td>0.287655</td>\n",
       "      <td>-0.122263</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.046790</td>\n",
       "      <td>0.328453</td>\n",
       "      <td>-0.031375</td>\n",
       "      <td>-0.454243</td>\n",
       "      <td>0.158813</td>\n",
       "      <td>-0.017741</td>\n",
       "      <td>-0.159698</td>\n",
       "      <td>0.198078</td>\n",
       "      <td>0.473690</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5533</td>\n",
       "      <td>-0.113981</td>\n",
       "      <td>0.498588</td>\n",
       "      <td>0.163165</td>\n",
       "      <td>-0.056748</td>\n",
       "      <td>-0.018788</td>\n",
       "      <td>0.026716</td>\n",
       "      <td>-0.103223</td>\n",
       "      <td>-0.277220</td>\n",
       "      <td>0.336499</td>\n",
       "      <td>-0.118409</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.064640</td>\n",
       "      <td>0.227641</td>\n",
       "      <td>0.007247</td>\n",
       "      <td>-0.337773</td>\n",
       "      <td>0.185337</td>\n",
       "      <td>0.024355</td>\n",
       "      <td>-0.009709</td>\n",
       "      <td>0.181260</td>\n",
       "      <td>0.392719</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5534</td>\n",
       "      <td>-0.077606</td>\n",
       "      <td>0.424907</td>\n",
       "      <td>0.097420</td>\n",
       "      <td>0.010471</td>\n",
       "      <td>0.008839</td>\n",
       "      <td>0.024059</td>\n",
       "      <td>-0.111279</td>\n",
       "      <td>-0.266572</td>\n",
       "      <td>0.203657</td>\n",
       "      <td>-0.083056</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.058557</td>\n",
       "      <td>0.180753</td>\n",
       "      <td>-0.014085</td>\n",
       "      <td>-0.332193</td>\n",
       "      <td>0.134709</td>\n",
       "      <td>-0.016538</td>\n",
       "      <td>-0.027659</td>\n",
       "      <td>0.144992</td>\n",
       "      <td>0.326755</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5535</td>\n",
       "      <td>-0.077740</td>\n",
       "      <td>0.501264</td>\n",
       "      <td>0.064616</td>\n",
       "      <td>0.010643</td>\n",
       "      <td>0.010023</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>-0.142786</td>\n",
       "      <td>-0.241226</td>\n",
       "      <td>0.250688</td>\n",
       "      <td>-0.096883</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.068197</td>\n",
       "      <td>0.217512</td>\n",
       "      <td>-0.031275</td>\n",
       "      <td>-0.362096</td>\n",
       "      <td>0.145170</td>\n",
       "      <td>-0.016336</td>\n",
       "      <td>-0.054055</td>\n",
       "      <td>0.157962</td>\n",
       "      <td>0.390158</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5536</td>\n",
       "      <td>-0.070640</td>\n",
       "      <td>0.583286</td>\n",
       "      <td>0.049536</td>\n",
       "      <td>0.040043</td>\n",
       "      <td>-0.001351</td>\n",
       "      <td>-0.011806</td>\n",
       "      <td>-0.183496</td>\n",
       "      <td>-0.253068</td>\n",
       "      <td>0.262121</td>\n",
       "      <td>-0.099735</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.074884</td>\n",
       "      <td>0.269492</td>\n",
       "      <td>-0.074751</td>\n",
       "      <td>-0.422344</td>\n",
       "      <td>0.149999</td>\n",
       "      <td>-0.040797</td>\n",
       "      <td>-0.087830</td>\n",
       "      <td>0.167525</td>\n",
       "      <td>0.426951</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5537 rows × 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5         6  \\\n",
       "0    -0.034803  0.574692 -0.024320  0.084124 -0.007769 -0.043919 -0.212503   \n",
       "1    -0.045523  0.679620  0.000538  0.103425 -0.005931 -0.023181 -0.233011   \n",
       "2    -0.099174  0.598018  0.147960 -0.048949 -0.031430 -0.017491 -0.149470   \n",
       "3    -0.032602  0.584073 -0.000475  0.022584 -0.020850 -0.066859 -0.207133   \n",
       "4    -0.122250  0.553165  0.123425 -0.024946  0.018299  0.033656 -0.132178   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "5532 -0.061722  0.611638  0.056657  0.056770  0.013780  0.001569 -0.173358   \n",
       "5533 -0.113981  0.498588  0.163165 -0.056748 -0.018788  0.026716 -0.103223   \n",
       "5534 -0.077606  0.424907  0.097420  0.010471  0.008839  0.024059 -0.111279   \n",
       "5535 -0.077740  0.501264  0.064616  0.010643  0.010023  0.000034 -0.142786   \n",
       "5536 -0.070640  0.583286  0.049536  0.040043 -0.001351 -0.011806 -0.183496   \n",
       "\n",
       "             7         8         9  ...        91        92        93  \\\n",
       "0    -0.187975  0.194824 -0.071464  ... -0.061573  0.291551 -0.099408   \n",
       "1    -0.246731  0.277161 -0.078278  ... -0.031663  0.376862 -0.074846   \n",
       "2    -0.287509  0.368354 -0.136673  ... -0.079986  0.281047 -0.051203   \n",
       "3    -0.080091  0.247074 -0.082756  ... -0.103604  0.323825 -0.140997   \n",
       "4    -0.334184  0.323884 -0.127449  ... -0.058247  0.233620  0.048888   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "5532 -0.267492  0.287655 -0.122263  ... -0.046790  0.328453 -0.031375   \n",
       "5533 -0.277220  0.336499 -0.118409  ... -0.064640  0.227641  0.007247   \n",
       "5534 -0.266572  0.203657 -0.083056  ... -0.058557  0.180753 -0.014085   \n",
       "5535 -0.241226  0.250688 -0.096883  ... -0.068197  0.217512 -0.031275   \n",
       "5536 -0.253068  0.262121 -0.099735  ... -0.074884  0.269492 -0.074751   \n",
       "\n",
       "            94        95        96        97        98        99  Labels  \n",
       "0    -0.417668  0.114716 -0.070984 -0.140349  0.155909  0.387361     Yes  \n",
       "1    -0.527581  0.142178 -0.079401 -0.190756  0.178426  0.480519     Yes  \n",
       "2    -0.427393  0.209120  0.037495 -0.045074  0.212375  0.501800     Yes  \n",
       "3    -0.380847  0.117071 -0.048625 -0.109754  0.159889  0.402783     Yes  \n",
       "4    -0.392988  0.176985  0.028446 -0.054034  0.191555  0.447745     Yes  \n",
       "...        ...       ...       ...       ...       ...       ...     ...  \n",
       "5532 -0.454243  0.158813 -0.017741 -0.159698  0.198078  0.473690     NaN  \n",
       "5533 -0.337773  0.185337  0.024355 -0.009709  0.181260  0.392719      No  \n",
       "5534 -0.332193  0.134709 -0.016538 -0.027659  0.144992  0.326755      No  \n",
       "5535 -0.362096  0.145170 -0.016336 -0.054055  0.157962  0.390158      No  \n",
       "5536 -0.422344  0.149999 -0.040797 -0.087830  0.167525  0.426951     NaN  \n",
       "\n",
       "[5537 rows x 101 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>-0.034803</td>\n",
       "      <td>0.574692</td>\n",
       "      <td>-0.024320</td>\n",
       "      <td>0.084124</td>\n",
       "      <td>-0.007769</td>\n",
       "      <td>-0.043919</td>\n",
       "      <td>-0.212503</td>\n",
       "      <td>-0.187975</td>\n",
       "      <td>0.194824</td>\n",
       "      <td>-0.071464</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.061573</td>\n",
       "      <td>0.291551</td>\n",
       "      <td>-0.099408</td>\n",
       "      <td>-0.417668</td>\n",
       "      <td>0.114716</td>\n",
       "      <td>-0.070984</td>\n",
       "      <td>-0.140349</td>\n",
       "      <td>0.155909</td>\n",
       "      <td>0.387361</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>-0.045523</td>\n",
       "      <td>0.679620</td>\n",
       "      <td>0.000538</td>\n",
       "      <td>0.103425</td>\n",
       "      <td>-0.005931</td>\n",
       "      <td>-0.023181</td>\n",
       "      <td>-0.233011</td>\n",
       "      <td>-0.246731</td>\n",
       "      <td>0.277161</td>\n",
       "      <td>-0.078278</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.031663</td>\n",
       "      <td>0.376862</td>\n",
       "      <td>-0.074846</td>\n",
       "      <td>-0.527581</td>\n",
       "      <td>0.142178</td>\n",
       "      <td>-0.079401</td>\n",
       "      <td>-0.190756</td>\n",
       "      <td>0.178426</td>\n",
       "      <td>0.480519</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>-0.099174</td>\n",
       "      <td>0.598018</td>\n",
       "      <td>0.147960</td>\n",
       "      <td>-0.048949</td>\n",
       "      <td>-0.031430</td>\n",
       "      <td>-0.017491</td>\n",
       "      <td>-0.149470</td>\n",
       "      <td>-0.287509</td>\n",
       "      <td>0.368354</td>\n",
       "      <td>-0.136673</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.079986</td>\n",
       "      <td>0.281047</td>\n",
       "      <td>-0.051203</td>\n",
       "      <td>-0.427393</td>\n",
       "      <td>0.209120</td>\n",
       "      <td>0.037495</td>\n",
       "      <td>-0.045074</td>\n",
       "      <td>0.212375</td>\n",
       "      <td>0.501800</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>-0.032602</td>\n",
       "      <td>0.584073</td>\n",
       "      <td>-0.000475</td>\n",
       "      <td>0.022584</td>\n",
       "      <td>-0.020850</td>\n",
       "      <td>-0.066859</td>\n",
       "      <td>-0.207133</td>\n",
       "      <td>-0.080091</td>\n",
       "      <td>0.247074</td>\n",
       "      <td>-0.082756</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.103604</td>\n",
       "      <td>0.323825</td>\n",
       "      <td>-0.140997</td>\n",
       "      <td>-0.380847</td>\n",
       "      <td>0.117071</td>\n",
       "      <td>-0.048625</td>\n",
       "      <td>-0.109754</td>\n",
       "      <td>0.159889</td>\n",
       "      <td>0.402783</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>-0.122250</td>\n",
       "      <td>0.553165</td>\n",
       "      <td>0.123425</td>\n",
       "      <td>-0.024946</td>\n",
       "      <td>0.018299</td>\n",
       "      <td>0.033656</td>\n",
       "      <td>-0.132178</td>\n",
       "      <td>-0.334184</td>\n",
       "      <td>0.323884</td>\n",
       "      <td>-0.127449</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.058247</td>\n",
       "      <td>0.233620</td>\n",
       "      <td>0.048888</td>\n",
       "      <td>-0.392988</td>\n",
       "      <td>0.176985</td>\n",
       "      <td>0.028446</td>\n",
       "      <td>-0.054034</td>\n",
       "      <td>0.191555</td>\n",
       "      <td>0.447745</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5532</td>\n",
       "      <td>-0.061722</td>\n",
       "      <td>0.611638</td>\n",
       "      <td>0.056657</td>\n",
       "      <td>0.056770</td>\n",
       "      <td>0.013780</td>\n",
       "      <td>0.001569</td>\n",
       "      <td>-0.173358</td>\n",
       "      <td>-0.267492</td>\n",
       "      <td>0.287655</td>\n",
       "      <td>-0.122263</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.046790</td>\n",
       "      <td>0.328453</td>\n",
       "      <td>-0.031375</td>\n",
       "      <td>-0.454243</td>\n",
       "      <td>0.158813</td>\n",
       "      <td>-0.017741</td>\n",
       "      <td>-0.159698</td>\n",
       "      <td>0.198078</td>\n",
       "      <td>0.473690</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5533</td>\n",
       "      <td>-0.113981</td>\n",
       "      <td>0.498588</td>\n",
       "      <td>0.163165</td>\n",
       "      <td>-0.056748</td>\n",
       "      <td>-0.018788</td>\n",
       "      <td>0.026716</td>\n",
       "      <td>-0.103223</td>\n",
       "      <td>-0.277220</td>\n",
       "      <td>0.336499</td>\n",
       "      <td>-0.118409</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.064640</td>\n",
       "      <td>0.227641</td>\n",
       "      <td>0.007247</td>\n",
       "      <td>-0.337773</td>\n",
       "      <td>0.185337</td>\n",
       "      <td>0.024355</td>\n",
       "      <td>-0.009709</td>\n",
       "      <td>0.181260</td>\n",
       "      <td>0.392719</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5534</td>\n",
       "      <td>-0.077606</td>\n",
       "      <td>0.424907</td>\n",
       "      <td>0.097420</td>\n",
       "      <td>0.010471</td>\n",
       "      <td>0.008839</td>\n",
       "      <td>0.024059</td>\n",
       "      <td>-0.111279</td>\n",
       "      <td>-0.266572</td>\n",
       "      <td>0.203657</td>\n",
       "      <td>-0.083056</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.058557</td>\n",
       "      <td>0.180753</td>\n",
       "      <td>-0.014085</td>\n",
       "      <td>-0.332193</td>\n",
       "      <td>0.134709</td>\n",
       "      <td>-0.016538</td>\n",
       "      <td>-0.027659</td>\n",
       "      <td>0.144992</td>\n",
       "      <td>0.326755</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5535</td>\n",
       "      <td>-0.077740</td>\n",
       "      <td>0.501264</td>\n",
       "      <td>0.064616</td>\n",
       "      <td>0.010643</td>\n",
       "      <td>0.010023</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>-0.142786</td>\n",
       "      <td>-0.241226</td>\n",
       "      <td>0.250688</td>\n",
       "      <td>-0.096883</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.068197</td>\n",
       "      <td>0.217512</td>\n",
       "      <td>-0.031275</td>\n",
       "      <td>-0.362096</td>\n",
       "      <td>0.145170</td>\n",
       "      <td>-0.016336</td>\n",
       "      <td>-0.054055</td>\n",
       "      <td>0.157962</td>\n",
       "      <td>0.390158</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5536</td>\n",
       "      <td>-0.070640</td>\n",
       "      <td>0.583286</td>\n",
       "      <td>0.049536</td>\n",
       "      <td>0.040043</td>\n",
       "      <td>-0.001351</td>\n",
       "      <td>-0.011806</td>\n",
       "      <td>-0.183496</td>\n",
       "      <td>-0.253068</td>\n",
       "      <td>0.262121</td>\n",
       "      <td>-0.099735</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.074884</td>\n",
       "      <td>0.269492</td>\n",
       "      <td>-0.074751</td>\n",
       "      <td>-0.422344</td>\n",
       "      <td>0.149999</td>\n",
       "      <td>-0.040797</td>\n",
       "      <td>-0.087830</td>\n",
       "      <td>0.167525</td>\n",
       "      <td>0.426951</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5537 rows × 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5         6  \\\n",
       "0    -0.034803  0.574692 -0.024320  0.084124 -0.007769 -0.043919 -0.212503   \n",
       "1    -0.045523  0.679620  0.000538  0.103425 -0.005931 -0.023181 -0.233011   \n",
       "2    -0.099174  0.598018  0.147960 -0.048949 -0.031430 -0.017491 -0.149470   \n",
       "3    -0.032602  0.584073 -0.000475  0.022584 -0.020850 -0.066859 -0.207133   \n",
       "4    -0.122250  0.553165  0.123425 -0.024946  0.018299  0.033656 -0.132178   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "5532 -0.061722  0.611638  0.056657  0.056770  0.013780  0.001569 -0.173358   \n",
       "5533 -0.113981  0.498588  0.163165 -0.056748 -0.018788  0.026716 -0.103223   \n",
       "5534 -0.077606  0.424907  0.097420  0.010471  0.008839  0.024059 -0.111279   \n",
       "5535 -0.077740  0.501264  0.064616  0.010643  0.010023  0.000034 -0.142786   \n",
       "5536 -0.070640  0.583286  0.049536  0.040043 -0.001351 -0.011806 -0.183496   \n",
       "\n",
       "             7         8         9  ...        91        92        93  \\\n",
       "0    -0.187975  0.194824 -0.071464  ... -0.061573  0.291551 -0.099408   \n",
       "1    -0.246731  0.277161 -0.078278  ... -0.031663  0.376862 -0.074846   \n",
       "2    -0.287509  0.368354 -0.136673  ... -0.079986  0.281047 -0.051203   \n",
       "3    -0.080091  0.247074 -0.082756  ... -0.103604  0.323825 -0.140997   \n",
       "4    -0.334184  0.323884 -0.127449  ... -0.058247  0.233620  0.048888   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "5532 -0.267492  0.287655 -0.122263  ... -0.046790  0.328453 -0.031375   \n",
       "5533 -0.277220  0.336499 -0.118409  ... -0.064640  0.227641  0.007247   \n",
       "5534 -0.266572  0.203657 -0.083056  ... -0.058557  0.180753 -0.014085   \n",
       "5535 -0.241226  0.250688 -0.096883  ... -0.068197  0.217512 -0.031275   \n",
       "5536 -0.253068  0.262121 -0.099735  ... -0.074884  0.269492 -0.074751   \n",
       "\n",
       "            94        95        96        97        98        99  Labels  \n",
       "0    -0.417668  0.114716 -0.070984 -0.140349  0.155909  0.387361     Yes  \n",
       "1    -0.527581  0.142178 -0.079401 -0.190756  0.178426  0.480519     Yes  \n",
       "2    -0.427393  0.209120  0.037495 -0.045074  0.212375  0.501800     Yes  \n",
       "3    -0.380847  0.117071 -0.048625 -0.109754  0.159889  0.402783     Yes  \n",
       "4    -0.392988  0.176985  0.028446 -0.054034  0.191555  0.447745     Yes  \n",
       "...        ...       ...       ...       ...       ...       ...     ...  \n",
       "5532 -0.454243  0.158813 -0.017741 -0.159698  0.198078  0.473690     NaN  \n",
       "5533 -0.337773  0.185337  0.024355 -0.009709  0.181260  0.392719      No  \n",
       "5534 -0.332193  0.134709 -0.016538 -0.027659  0.144992  0.326755      No  \n",
       "5535 -0.362096  0.145170 -0.016336 -0.054055  0.157962  0.390158      No  \n",
       "5536 -0.422344  0.149999 -0.040797 -0.087830  0.167525  0.426951     NaN  \n",
       "\n",
       "[5537 rows x 101 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################\n",
      "####################\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>191</th>\n",
       "      <th>192</th>\n",
       "      <th>193</th>\n",
       "      <th>194</th>\n",
       "      <th>195</th>\n",
       "      <th>196</th>\n",
       "      <th>197</th>\n",
       "      <th>198</th>\n",
       "      <th>199</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5534</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5535</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5536</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5537</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5538</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5539 rows × 201 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0  1  2  3  4  5  6  7  8  9  ...  191  192  193  194  195  196  197  \\\n",
       "0     0  0  0  1  0  0  0  0  0  0  ...    0    0    0    0    0    0    0   \n",
       "1     0  0  0  0  0  0  0  0  0  0  ...    0    0    0    0    0    0    0   \n",
       "2     0  0  0  0  0  0  0  0  0  0  ...    0    0    0    0    0    0    0   \n",
       "3     0  0  0  0  0  0  0  0  0  0  ...    0    0    0    0    0    0    0   \n",
       "4     0  0  0  0  0  0  0  0  0  0  ...    0    0    0    0    0    0    0   \n",
       "...  .. .. .. .. .. .. .. .. .. ..  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "5534  0  0  0  0  0  0  0  0  0  0  ...    0    0    0    0    0    0    0   \n",
       "5535  0  0  0  0  0  0  0  0  0  0  ...    0    0    0    0    0    0    0   \n",
       "5536  0  0  0  0  0  0  0  0  0  0  ...    0    0    0    0    0    0    0   \n",
       "5537  0  0  0  0  1  0  0  0  0  0  ...    0    0    0    0    0    0    0   \n",
       "5538  0  0  0  0  0  0  0  0  0  0  ...    0    0    0    0    0    0    0   \n",
       "\n",
       "      198  199  Labels  \n",
       "0       0    0     Yes  \n",
       "1       0    0     Yes  \n",
       "2       0    0     Yes  \n",
       "3       0    0     Yes  \n",
       "4       0    0     Yes  \n",
       "...   ...  ...     ...  \n",
       "5534    0    0     NaN  \n",
       "5535    0    0      No  \n",
       "5536    0    0      No  \n",
       "5537    0    0      No  \n",
       "5538    0    0     NaN  \n",
       "\n",
       "[5539 rows x 201 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>191</th>\n",
       "      <th>192</th>\n",
       "      <th>193</th>\n",
       "      <th>194</th>\n",
       "      <th>195</th>\n",
       "      <th>196</th>\n",
       "      <th>197</th>\n",
       "      <th>198</th>\n",
       "      <th>199</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5534</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5535</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5536</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5537</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5538</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5539 rows × 201 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0  1  2  3  4  5  6  7  8  9  ...  191  192  193  194  195  196  197  \\\n",
       "0     0  0  0  1  0  0  0  0  0  0  ...    0    0    0    0    0    0    0   \n",
       "1     0  0  0  0  0  0  0  0  0  0  ...    0    0    0    0    0    0    0   \n",
       "2     0  0  0  0  0  0  0  0  0  0  ...    0    0    0    0    0    0    0   \n",
       "3     0  0  0  0  0  0  0  0  0  0  ...    0    0    0    0    0    0    0   \n",
       "4     0  0  0  0  0  0  0  0  0  0  ...    0    0    0    0    0    0    0   \n",
       "...  .. .. .. .. .. .. .. .. .. ..  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "5534  0  0  0  0  0  0  0  0  0  0  ...    0    0    0    0    0    0    0   \n",
       "5535  0  0  0  0  0  0  0  0  0  0  ...    0    0    0    0    0    0    0   \n",
       "5536  0  0  0  0  0  0  0  0  0  0  ...    0    0    0    0    0    0    0   \n",
       "5537  0  0  0  0  1  0  0  0  0  0  ...    0    0    0    0    0    0    0   \n",
       "5538  0  0  0  0  0  0  0  0  0  0  ...    0    0    0    0    0    0    0   \n",
       "\n",
       "      198  199  Labels  \n",
       "0       0    0     Yes  \n",
       "1       0    0     Yes  \n",
       "2       0    0     Yes  \n",
       "3       0    0     Yes  \n",
       "4       0    0     Yes  \n",
       "...   ...  ...     ...  \n",
       "5534    0    0     NaN  \n",
       "5535    0    0      No  \n",
       "5536    0    0      No  \n",
       "5537    0    0      No  \n",
       "5538    0    0     NaN  \n",
       "\n",
       "[5539 rows x 201 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################\n",
      "####################\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.023414</td>\n",
       "      <td>0.005850</td>\n",
       "      <td>-0.041093</td>\n",
       "      <td>-0.032021</td>\n",
       "      <td>0.004571</td>\n",
       "      <td>0.005043</td>\n",
       "      <td>0.039657</td>\n",
       "      <td>0.020650</td>\n",
       "      <td>0.031514</td>\n",
       "      <td>-0.048857</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.033821</td>\n",
       "      <td>-0.002979</td>\n",
       "      <td>-0.011879</td>\n",
       "      <td>-0.015871</td>\n",
       "      <td>-0.042950</td>\n",
       "      <td>0.002714</td>\n",
       "      <td>0.093157</td>\n",
       "      <td>0.018993</td>\n",
       "      <td>-0.028171</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.021233</td>\n",
       "      <td>0.064300</td>\n",
       "      <td>-0.068433</td>\n",
       "      <td>0.039700</td>\n",
       "      <td>0.008767</td>\n",
       "      <td>0.032167</td>\n",
       "      <td>0.017867</td>\n",
       "      <td>0.007667</td>\n",
       "      <td>0.114133</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.038667</td>\n",
       "      <td>0.038833</td>\n",
       "      <td>-0.007900</td>\n",
       "      <td>0.012667</td>\n",
       "      <td>0.049933</td>\n",
       "      <td>-0.054100</td>\n",
       "      <td>0.070800</td>\n",
       "      <td>0.014133</td>\n",
       "      <td>-0.050967</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>-0.047160</td>\n",
       "      <td>0.005480</td>\n",
       "      <td>0.012520</td>\n",
       "      <td>-0.022360</td>\n",
       "      <td>-0.002520</td>\n",
       "      <td>-0.084140</td>\n",
       "      <td>-0.029600</td>\n",
       "      <td>-0.017000</td>\n",
       "      <td>0.055100</td>\n",
       "      <td>-0.033980</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003260</td>\n",
       "      <td>-0.014620</td>\n",
       "      <td>0.018440</td>\n",
       "      <td>-0.022480</td>\n",
       "      <td>0.009400</td>\n",
       "      <td>-0.023080</td>\n",
       "      <td>0.209880</td>\n",
       "      <td>0.079020</td>\n",
       "      <td>0.044420</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>-0.004100</td>\n",
       "      <td>0.014900</td>\n",
       "      <td>-0.017750</td>\n",
       "      <td>0.000950</td>\n",
       "      <td>-0.040650</td>\n",
       "      <td>-0.120650</td>\n",
       "      <td>-0.033950</td>\n",
       "      <td>0.036200</td>\n",
       "      <td>-0.010050</td>\n",
       "      <td>-0.011100</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.007550</td>\n",
       "      <td>-0.043650</td>\n",
       "      <td>0.019400</td>\n",
       "      <td>-0.031350</td>\n",
       "      <td>-0.021100</td>\n",
       "      <td>-0.049050</td>\n",
       "      <td>0.225300</td>\n",
       "      <td>0.009250</td>\n",
       "      <td>-0.010300</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.052200</td>\n",
       "      <td>0.022450</td>\n",
       "      <td>-0.183250</td>\n",
       "      <td>0.029650</td>\n",
       "      <td>-0.077250</td>\n",
       "      <td>-0.056450</td>\n",
       "      <td>-0.046750</td>\n",
       "      <td>-0.042300</td>\n",
       "      <td>0.083000</td>\n",
       "      <td>-0.031850</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>-0.058650</td>\n",
       "      <td>0.013300</td>\n",
       "      <td>-0.014750</td>\n",
       "      <td>-0.095300</td>\n",
       "      <td>-0.062300</td>\n",
       "      <td>0.187300</td>\n",
       "      <td>-0.010800</td>\n",
       "      <td>0.036300</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5534</td>\n",
       "      <td>0.012700</td>\n",
       "      <td>0.068600</td>\n",
       "      <td>0.007980</td>\n",
       "      <td>0.049280</td>\n",
       "      <td>-0.011000</td>\n",
       "      <td>0.042040</td>\n",
       "      <td>0.105280</td>\n",
       "      <td>-0.005640</td>\n",
       "      <td>0.039080</td>\n",
       "      <td>-0.023800</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.099220</td>\n",
       "      <td>0.037980</td>\n",
       "      <td>0.084960</td>\n",
       "      <td>-0.065920</td>\n",
       "      <td>0.066540</td>\n",
       "      <td>-0.000320</td>\n",
       "      <td>0.015800</td>\n",
       "      <td>0.041500</td>\n",
       "      <td>-0.024940</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5535</td>\n",
       "      <td>-0.096400</td>\n",
       "      <td>-0.005040</td>\n",
       "      <td>-0.030640</td>\n",
       "      <td>-0.004840</td>\n",
       "      <td>0.003840</td>\n",
       "      <td>-0.017080</td>\n",
       "      <td>0.009400</td>\n",
       "      <td>-0.070480</td>\n",
       "      <td>0.013000</td>\n",
       "      <td>0.011100</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.085400</td>\n",
       "      <td>0.056460</td>\n",
       "      <td>0.015820</td>\n",
       "      <td>-0.029300</td>\n",
       "      <td>-0.073400</td>\n",
       "      <td>-0.051820</td>\n",
       "      <td>0.199580</td>\n",
       "      <td>-0.021740</td>\n",
       "      <td>-0.001900</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5536</td>\n",
       "      <td>0.013713</td>\n",
       "      <td>-0.016407</td>\n",
       "      <td>-0.069427</td>\n",
       "      <td>-0.011700</td>\n",
       "      <td>0.005907</td>\n",
       "      <td>0.010667</td>\n",
       "      <td>0.012180</td>\n",
       "      <td>0.028887</td>\n",
       "      <td>-0.005393</td>\n",
       "      <td>0.038313</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043380</td>\n",
       "      <td>-0.026667</td>\n",
       "      <td>0.035780</td>\n",
       "      <td>-0.004920</td>\n",
       "      <td>-0.018840</td>\n",
       "      <td>-0.004713</td>\n",
       "      <td>0.126353</td>\n",
       "      <td>0.048653</td>\n",
       "      <td>-0.038813</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5537</td>\n",
       "      <td>-0.007162</td>\n",
       "      <td>0.026894</td>\n",
       "      <td>-0.014887</td>\n",
       "      <td>0.013413</td>\n",
       "      <td>0.022212</td>\n",
       "      <td>-0.037306</td>\n",
       "      <td>0.027094</td>\n",
       "      <td>-0.007219</td>\n",
       "      <td>0.005625</td>\n",
       "      <td>0.003894</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.029994</td>\n",
       "      <td>-0.009288</td>\n",
       "      <td>0.019863</td>\n",
       "      <td>0.012325</td>\n",
       "      <td>0.002912</td>\n",
       "      <td>0.004813</td>\n",
       "      <td>0.145725</td>\n",
       "      <td>0.043256</td>\n",
       "      <td>-0.017325</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5538</td>\n",
       "      <td>-0.003313</td>\n",
       "      <td>0.019009</td>\n",
       "      <td>-0.007722</td>\n",
       "      <td>-0.007883</td>\n",
       "      <td>-0.022217</td>\n",
       "      <td>-0.039978</td>\n",
       "      <td>0.031226</td>\n",
       "      <td>0.013878</td>\n",
       "      <td>-0.010235</td>\n",
       "      <td>-0.038139</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005626</td>\n",
       "      <td>-0.020522</td>\n",
       "      <td>0.007996</td>\n",
       "      <td>0.011543</td>\n",
       "      <td>-0.023609</td>\n",
       "      <td>0.002535</td>\n",
       "      <td>0.129130</td>\n",
       "      <td>0.011243</td>\n",
       "      <td>0.011800</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5539 rows × 301 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5         6  \\\n",
       "0     0.023414  0.005850 -0.041093 -0.032021  0.004571  0.005043  0.039657   \n",
       "1     0.021233  0.064300 -0.068433  0.039700  0.008767  0.032167  0.017867   \n",
       "2    -0.047160  0.005480  0.012520 -0.022360 -0.002520 -0.084140 -0.029600   \n",
       "3    -0.004100  0.014900 -0.017750  0.000950 -0.040650 -0.120650 -0.033950   \n",
       "4     0.052200  0.022450 -0.183250  0.029650 -0.077250 -0.056450 -0.046750   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "5534  0.012700  0.068600  0.007980  0.049280 -0.011000  0.042040  0.105280   \n",
       "5535 -0.096400 -0.005040 -0.030640 -0.004840  0.003840 -0.017080  0.009400   \n",
       "5536  0.013713 -0.016407 -0.069427 -0.011700  0.005907  0.010667  0.012180   \n",
       "5537 -0.007162  0.026894 -0.014887  0.013413  0.022212 -0.037306  0.027094   \n",
       "5538 -0.003313  0.019009 -0.007722 -0.007883 -0.022217 -0.039978  0.031226   \n",
       "\n",
       "             7         8         9  ...       291       292       293  \\\n",
       "0     0.020650  0.031514 -0.048857  ... -0.033821 -0.002979 -0.011879   \n",
       "1     0.007667  0.114133  0.016667  ... -0.038667  0.038833 -0.007900   \n",
       "2    -0.017000  0.055100 -0.033980  ... -0.003260 -0.014620  0.018440   \n",
       "3     0.036200 -0.010050 -0.011100  ... -0.007550 -0.043650  0.019400   \n",
       "4    -0.042300  0.083000 -0.031850  ...  0.003200 -0.058650  0.013300   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "5534 -0.005640  0.039080 -0.023800  ... -0.099220  0.037980  0.084960   \n",
       "5535 -0.070480  0.013000  0.011100  ... -0.085400  0.056460  0.015820   \n",
       "5536  0.028887 -0.005393  0.038313  ...  0.043380 -0.026667  0.035780   \n",
       "5537 -0.007219  0.005625  0.003894  ... -0.029994 -0.009288  0.019863   \n",
       "5538  0.013878 -0.010235 -0.038139  ... -0.005626 -0.020522  0.007996   \n",
       "\n",
       "           294       295       296       297       298       299  Labels  \n",
       "0    -0.015871 -0.042950  0.002714  0.093157  0.018993 -0.028171     Yes  \n",
       "1     0.012667  0.049933 -0.054100  0.070800  0.014133 -0.050967     Yes  \n",
       "2    -0.022480  0.009400 -0.023080  0.209880  0.079020  0.044420     Yes  \n",
       "3    -0.031350 -0.021100 -0.049050  0.225300  0.009250 -0.010300     Yes  \n",
       "4    -0.014750 -0.095300 -0.062300  0.187300 -0.010800  0.036300     Yes  \n",
       "...        ...       ...       ...       ...       ...       ...     ...  \n",
       "5534 -0.065920  0.066540 -0.000320  0.015800  0.041500 -0.024940     NaN  \n",
       "5535 -0.029300 -0.073400 -0.051820  0.199580 -0.021740 -0.001900      No  \n",
       "5536 -0.004920 -0.018840 -0.004713  0.126353  0.048653 -0.038813      No  \n",
       "5537  0.012325  0.002912  0.004813  0.145725  0.043256 -0.017325      No  \n",
       "5538  0.011543 -0.023609  0.002535  0.129130  0.011243  0.011800     NaN  \n",
       "\n",
       "[5539 rows x 301 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.023414</td>\n",
       "      <td>0.005850</td>\n",
       "      <td>-0.041093</td>\n",
       "      <td>-0.032021</td>\n",
       "      <td>0.004571</td>\n",
       "      <td>0.005043</td>\n",
       "      <td>0.039657</td>\n",
       "      <td>0.020650</td>\n",
       "      <td>0.031514</td>\n",
       "      <td>-0.048857</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.033821</td>\n",
       "      <td>-0.002979</td>\n",
       "      <td>-0.011879</td>\n",
       "      <td>-0.015871</td>\n",
       "      <td>-0.042950</td>\n",
       "      <td>0.002714</td>\n",
       "      <td>0.093157</td>\n",
       "      <td>0.018993</td>\n",
       "      <td>-0.028171</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.021233</td>\n",
       "      <td>0.064300</td>\n",
       "      <td>-0.068433</td>\n",
       "      <td>0.039700</td>\n",
       "      <td>0.008767</td>\n",
       "      <td>0.032167</td>\n",
       "      <td>0.017867</td>\n",
       "      <td>0.007667</td>\n",
       "      <td>0.114133</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.038667</td>\n",
       "      <td>0.038833</td>\n",
       "      <td>-0.007900</td>\n",
       "      <td>0.012667</td>\n",
       "      <td>0.049933</td>\n",
       "      <td>-0.054100</td>\n",
       "      <td>0.070800</td>\n",
       "      <td>0.014133</td>\n",
       "      <td>-0.050967</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>-0.047160</td>\n",
       "      <td>0.005480</td>\n",
       "      <td>0.012520</td>\n",
       "      <td>-0.022360</td>\n",
       "      <td>-0.002520</td>\n",
       "      <td>-0.084140</td>\n",
       "      <td>-0.029600</td>\n",
       "      <td>-0.017000</td>\n",
       "      <td>0.055100</td>\n",
       "      <td>-0.033980</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003260</td>\n",
       "      <td>-0.014620</td>\n",
       "      <td>0.018440</td>\n",
       "      <td>-0.022480</td>\n",
       "      <td>0.009400</td>\n",
       "      <td>-0.023080</td>\n",
       "      <td>0.209880</td>\n",
       "      <td>0.079020</td>\n",
       "      <td>0.044420</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>-0.004100</td>\n",
       "      <td>0.014900</td>\n",
       "      <td>-0.017750</td>\n",
       "      <td>0.000950</td>\n",
       "      <td>-0.040650</td>\n",
       "      <td>-0.120650</td>\n",
       "      <td>-0.033950</td>\n",
       "      <td>0.036200</td>\n",
       "      <td>-0.010050</td>\n",
       "      <td>-0.011100</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.007550</td>\n",
       "      <td>-0.043650</td>\n",
       "      <td>0.019400</td>\n",
       "      <td>-0.031350</td>\n",
       "      <td>-0.021100</td>\n",
       "      <td>-0.049050</td>\n",
       "      <td>0.225300</td>\n",
       "      <td>0.009250</td>\n",
       "      <td>-0.010300</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.052200</td>\n",
       "      <td>0.022450</td>\n",
       "      <td>-0.183250</td>\n",
       "      <td>0.029650</td>\n",
       "      <td>-0.077250</td>\n",
       "      <td>-0.056450</td>\n",
       "      <td>-0.046750</td>\n",
       "      <td>-0.042300</td>\n",
       "      <td>0.083000</td>\n",
       "      <td>-0.031850</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>-0.058650</td>\n",
       "      <td>0.013300</td>\n",
       "      <td>-0.014750</td>\n",
       "      <td>-0.095300</td>\n",
       "      <td>-0.062300</td>\n",
       "      <td>0.187300</td>\n",
       "      <td>-0.010800</td>\n",
       "      <td>0.036300</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5534</td>\n",
       "      <td>0.012700</td>\n",
       "      <td>0.068600</td>\n",
       "      <td>0.007980</td>\n",
       "      <td>0.049280</td>\n",
       "      <td>-0.011000</td>\n",
       "      <td>0.042040</td>\n",
       "      <td>0.105280</td>\n",
       "      <td>-0.005640</td>\n",
       "      <td>0.039080</td>\n",
       "      <td>-0.023800</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.099220</td>\n",
       "      <td>0.037980</td>\n",
       "      <td>0.084960</td>\n",
       "      <td>-0.065920</td>\n",
       "      <td>0.066540</td>\n",
       "      <td>-0.000320</td>\n",
       "      <td>0.015800</td>\n",
       "      <td>0.041500</td>\n",
       "      <td>-0.024940</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5535</td>\n",
       "      <td>-0.096400</td>\n",
       "      <td>-0.005040</td>\n",
       "      <td>-0.030640</td>\n",
       "      <td>-0.004840</td>\n",
       "      <td>0.003840</td>\n",
       "      <td>-0.017080</td>\n",
       "      <td>0.009400</td>\n",
       "      <td>-0.070480</td>\n",
       "      <td>0.013000</td>\n",
       "      <td>0.011100</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.085400</td>\n",
       "      <td>0.056460</td>\n",
       "      <td>0.015820</td>\n",
       "      <td>-0.029300</td>\n",
       "      <td>-0.073400</td>\n",
       "      <td>-0.051820</td>\n",
       "      <td>0.199580</td>\n",
       "      <td>-0.021740</td>\n",
       "      <td>-0.001900</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5536</td>\n",
       "      <td>0.013713</td>\n",
       "      <td>-0.016407</td>\n",
       "      <td>-0.069427</td>\n",
       "      <td>-0.011700</td>\n",
       "      <td>0.005907</td>\n",
       "      <td>0.010667</td>\n",
       "      <td>0.012180</td>\n",
       "      <td>0.028887</td>\n",
       "      <td>-0.005393</td>\n",
       "      <td>0.038313</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043380</td>\n",
       "      <td>-0.026667</td>\n",
       "      <td>0.035780</td>\n",
       "      <td>-0.004920</td>\n",
       "      <td>-0.018840</td>\n",
       "      <td>-0.004713</td>\n",
       "      <td>0.126353</td>\n",
       "      <td>0.048653</td>\n",
       "      <td>-0.038813</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5537</td>\n",
       "      <td>-0.007162</td>\n",
       "      <td>0.026894</td>\n",
       "      <td>-0.014887</td>\n",
       "      <td>0.013413</td>\n",
       "      <td>0.022212</td>\n",
       "      <td>-0.037306</td>\n",
       "      <td>0.027094</td>\n",
       "      <td>-0.007219</td>\n",
       "      <td>0.005625</td>\n",
       "      <td>0.003894</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.029994</td>\n",
       "      <td>-0.009288</td>\n",
       "      <td>0.019863</td>\n",
       "      <td>0.012325</td>\n",
       "      <td>0.002912</td>\n",
       "      <td>0.004813</td>\n",
       "      <td>0.145725</td>\n",
       "      <td>0.043256</td>\n",
       "      <td>-0.017325</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5538</td>\n",
       "      <td>-0.003313</td>\n",
       "      <td>0.019009</td>\n",
       "      <td>-0.007722</td>\n",
       "      <td>-0.007883</td>\n",
       "      <td>-0.022217</td>\n",
       "      <td>-0.039978</td>\n",
       "      <td>0.031226</td>\n",
       "      <td>0.013878</td>\n",
       "      <td>-0.010235</td>\n",
       "      <td>-0.038139</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005626</td>\n",
       "      <td>-0.020522</td>\n",
       "      <td>0.007996</td>\n",
       "      <td>0.011543</td>\n",
       "      <td>-0.023609</td>\n",
       "      <td>0.002535</td>\n",
       "      <td>0.129130</td>\n",
       "      <td>0.011243</td>\n",
       "      <td>0.011800</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5539 rows × 301 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5         6  \\\n",
       "0     0.023414  0.005850 -0.041093 -0.032021  0.004571  0.005043  0.039657   \n",
       "1     0.021233  0.064300 -0.068433  0.039700  0.008767  0.032167  0.017867   \n",
       "2    -0.047160  0.005480  0.012520 -0.022360 -0.002520 -0.084140 -0.029600   \n",
       "3    -0.004100  0.014900 -0.017750  0.000950 -0.040650 -0.120650 -0.033950   \n",
       "4     0.052200  0.022450 -0.183250  0.029650 -0.077250 -0.056450 -0.046750   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "5534  0.012700  0.068600  0.007980  0.049280 -0.011000  0.042040  0.105280   \n",
       "5535 -0.096400 -0.005040 -0.030640 -0.004840  0.003840 -0.017080  0.009400   \n",
       "5536  0.013713 -0.016407 -0.069427 -0.011700  0.005907  0.010667  0.012180   \n",
       "5537 -0.007162  0.026894 -0.014887  0.013413  0.022212 -0.037306  0.027094   \n",
       "5538 -0.003313  0.019009 -0.007722 -0.007883 -0.022217 -0.039978  0.031226   \n",
       "\n",
       "             7         8         9  ...       291       292       293  \\\n",
       "0     0.020650  0.031514 -0.048857  ... -0.033821 -0.002979 -0.011879   \n",
       "1     0.007667  0.114133  0.016667  ... -0.038667  0.038833 -0.007900   \n",
       "2    -0.017000  0.055100 -0.033980  ... -0.003260 -0.014620  0.018440   \n",
       "3     0.036200 -0.010050 -0.011100  ... -0.007550 -0.043650  0.019400   \n",
       "4    -0.042300  0.083000 -0.031850  ...  0.003200 -0.058650  0.013300   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "5534 -0.005640  0.039080 -0.023800  ... -0.099220  0.037980  0.084960   \n",
       "5535 -0.070480  0.013000  0.011100  ... -0.085400  0.056460  0.015820   \n",
       "5536  0.028887 -0.005393  0.038313  ...  0.043380 -0.026667  0.035780   \n",
       "5537 -0.007219  0.005625  0.003894  ... -0.029994 -0.009288  0.019863   \n",
       "5538  0.013878 -0.010235 -0.038139  ... -0.005626 -0.020522  0.007996   \n",
       "\n",
       "           294       295       296       297       298       299  Labels  \n",
       "0    -0.015871 -0.042950  0.002714  0.093157  0.018993 -0.028171     Yes  \n",
       "1     0.012667  0.049933 -0.054100  0.070800  0.014133 -0.050967     Yes  \n",
       "2    -0.022480  0.009400 -0.023080  0.209880  0.079020  0.044420     Yes  \n",
       "3    -0.031350 -0.021100 -0.049050  0.225300  0.009250 -0.010300     Yes  \n",
       "4    -0.014750 -0.095300 -0.062300  0.187300 -0.010800  0.036300     Yes  \n",
       "...        ...       ...       ...       ...       ...       ...     ...  \n",
       "5534 -0.065920  0.066540 -0.000320  0.015800  0.041500 -0.024940     NaN  \n",
       "5535 -0.029300 -0.073400 -0.051820  0.199580 -0.021740 -0.001900      No  \n",
       "5536 -0.004920 -0.018840 -0.004713  0.126353  0.048653 -0.038813      No  \n",
       "5537  0.012325  0.002912  0.004813  0.145725  0.043256 -0.017325      No  \n",
       "5538  0.011543 -0.023609  0.002535  0.129130  0.011243  0.011800     NaN  \n",
       "\n",
       "[5539 rows x 301 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################\n",
      "####################\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>759</th>\n",
       "      <th>760</th>\n",
       "      <th>761</th>\n",
       "      <th>762</th>\n",
       "      <th>763</th>\n",
       "      <th>764</th>\n",
       "      <th>765</th>\n",
       "      <th>766</th>\n",
       "      <th>767</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>-0.194920</td>\n",
       "      <td>-0.112881</td>\n",
       "      <td>0.388437</td>\n",
       "      <td>-0.109874</td>\n",
       "      <td>0.041914</td>\n",
       "      <td>-0.137204</td>\n",
       "      <td>0.109907</td>\n",
       "      <td>0.556634</td>\n",
       "      <td>-0.304503</td>\n",
       "      <td>-0.419192</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.042977</td>\n",
       "      <td>-0.004823</td>\n",
       "      <td>-0.049975</td>\n",
       "      <td>0.218379</td>\n",
       "      <td>-0.276184</td>\n",
       "      <td>0.220082</td>\n",
       "      <td>-0.796053</td>\n",
       "      <td>0.144477</td>\n",
       "      <td>-0.509098</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>-0.174782</td>\n",
       "      <td>-0.099447</td>\n",
       "      <td>-0.468011</td>\n",
       "      <td>0.108068</td>\n",
       "      <td>-0.028635</td>\n",
       "      <td>-0.427431</td>\n",
       "      <td>0.169761</td>\n",
       "      <td>0.651794</td>\n",
       "      <td>-0.305934</td>\n",
       "      <td>-0.692678</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.023003</td>\n",
       "      <td>-0.002153</td>\n",
       "      <td>-0.354740</td>\n",
       "      <td>0.397673</td>\n",
       "      <td>-0.244706</td>\n",
       "      <td>0.033439</td>\n",
       "      <td>-0.483247</td>\n",
       "      <td>-0.173934</td>\n",
       "      <td>-0.337515</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.039530</td>\n",
       "      <td>-0.073837</td>\n",
       "      <td>-0.087995</td>\n",
       "      <td>0.360194</td>\n",
       "      <td>0.181992</td>\n",
       "      <td>-0.366591</td>\n",
       "      <td>0.008656</td>\n",
       "      <td>0.453784</td>\n",
       "      <td>-0.260378</td>\n",
       "      <td>-0.490275</td>\n",
       "      <td>...</td>\n",
       "      <td>0.075246</td>\n",
       "      <td>0.057701</td>\n",
       "      <td>-0.087006</td>\n",
       "      <td>0.320335</td>\n",
       "      <td>-0.269148</td>\n",
       "      <td>0.119730</td>\n",
       "      <td>-0.637774</td>\n",
       "      <td>0.000480</td>\n",
       "      <td>-0.097225</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>-0.264160</td>\n",
       "      <td>-0.126185</td>\n",
       "      <td>-0.099923</td>\n",
       "      <td>0.301749</td>\n",
       "      <td>0.262108</td>\n",
       "      <td>-0.213265</td>\n",
       "      <td>0.108956</td>\n",
       "      <td>0.407808</td>\n",
       "      <td>-0.187299</td>\n",
       "      <td>-0.148701</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.155414</td>\n",
       "      <td>-0.248788</td>\n",
       "      <td>-0.342570</td>\n",
       "      <td>0.218711</td>\n",
       "      <td>-0.174955</td>\n",
       "      <td>-0.092277</td>\n",
       "      <td>-0.557828</td>\n",
       "      <td>-0.256308</td>\n",
       "      <td>-0.358489</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.078526</td>\n",
       "      <td>0.177795</td>\n",
       "      <td>0.488374</td>\n",
       "      <td>0.213472</td>\n",
       "      <td>0.312748</td>\n",
       "      <td>-0.280140</td>\n",
       "      <td>0.397646</td>\n",
       "      <td>0.429720</td>\n",
       "      <td>-0.310175</td>\n",
       "      <td>-0.554000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.093388</td>\n",
       "      <td>-0.008426</td>\n",
       "      <td>0.207753</td>\n",
       "      <td>0.094225</td>\n",
       "      <td>-0.148403</td>\n",
       "      <td>0.101668</td>\n",
       "      <td>-0.530785</td>\n",
       "      <td>0.069791</td>\n",
       "      <td>-0.241589</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5534</td>\n",
       "      <td>-0.400154</td>\n",
       "      <td>-0.256461</td>\n",
       "      <td>-0.183564</td>\n",
       "      <td>0.033262</td>\n",
       "      <td>0.159400</td>\n",
       "      <td>-0.255320</td>\n",
       "      <td>0.377321</td>\n",
       "      <td>0.061936</td>\n",
       "      <td>-0.094525</td>\n",
       "      <td>-0.187200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.181568</td>\n",
       "      <td>0.113463</td>\n",
       "      <td>-0.217428</td>\n",
       "      <td>-0.007062</td>\n",
       "      <td>-0.436011</td>\n",
       "      <td>-0.095360</td>\n",
       "      <td>-0.296756</td>\n",
       "      <td>0.257059</td>\n",
       "      <td>-0.234672</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5535</td>\n",
       "      <td>0.051658</td>\n",
       "      <td>-0.054771</td>\n",
       "      <td>0.298856</td>\n",
       "      <td>0.032705</td>\n",
       "      <td>0.214817</td>\n",
       "      <td>-0.419218</td>\n",
       "      <td>-0.005545</td>\n",
       "      <td>0.701181</td>\n",
       "      <td>-0.368737</td>\n",
       "      <td>-0.288521</td>\n",
       "      <td>...</td>\n",
       "      <td>0.209300</td>\n",
       "      <td>-0.141448</td>\n",
       "      <td>-0.260576</td>\n",
       "      <td>0.385859</td>\n",
       "      <td>-0.042413</td>\n",
       "      <td>-0.044953</td>\n",
       "      <td>-0.381793</td>\n",
       "      <td>0.155324</td>\n",
       "      <td>-0.293402</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5536</td>\n",
       "      <td>-0.120506</td>\n",
       "      <td>0.175940</td>\n",
       "      <td>0.014781</td>\n",
       "      <td>-0.156842</td>\n",
       "      <td>0.175269</td>\n",
       "      <td>0.039736</td>\n",
       "      <td>0.083392</td>\n",
       "      <td>0.751514</td>\n",
       "      <td>0.105191</td>\n",
       "      <td>-0.167486</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.151757</td>\n",
       "      <td>-0.134946</td>\n",
       "      <td>-0.152878</td>\n",
       "      <td>-0.033997</td>\n",
       "      <td>-0.350957</td>\n",
       "      <td>-0.388650</td>\n",
       "      <td>-0.116329</td>\n",
       "      <td>0.089427</td>\n",
       "      <td>-0.230295</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5537</td>\n",
       "      <td>0.073636</td>\n",
       "      <td>0.110835</td>\n",
       "      <td>0.429038</td>\n",
       "      <td>0.118876</td>\n",
       "      <td>0.007961</td>\n",
       "      <td>-0.031842</td>\n",
       "      <td>-0.030791</td>\n",
       "      <td>0.188152</td>\n",
       "      <td>-0.325286</td>\n",
       "      <td>-0.172276</td>\n",
       "      <td>...</td>\n",
       "      <td>0.337875</td>\n",
       "      <td>-0.096466</td>\n",
       "      <td>-0.481865</td>\n",
       "      <td>0.066156</td>\n",
       "      <td>-0.208680</td>\n",
       "      <td>0.082813</td>\n",
       "      <td>-0.188787</td>\n",
       "      <td>0.365409</td>\n",
       "      <td>0.169572</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5538</td>\n",
       "      <td>-0.029584</td>\n",
       "      <td>0.114278</td>\n",
       "      <td>0.226568</td>\n",
       "      <td>0.230094</td>\n",
       "      <td>-0.027433</td>\n",
       "      <td>-0.308322</td>\n",
       "      <td>0.019580</td>\n",
       "      <td>0.600823</td>\n",
       "      <td>-0.277417</td>\n",
       "      <td>-0.068723</td>\n",
       "      <td>...</td>\n",
       "      <td>0.241541</td>\n",
       "      <td>0.066769</td>\n",
       "      <td>-0.011381</td>\n",
       "      <td>0.492085</td>\n",
       "      <td>-0.038748</td>\n",
       "      <td>0.007048</td>\n",
       "      <td>-0.074291</td>\n",
       "      <td>0.399871</td>\n",
       "      <td>-0.195889</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5539 rows × 769 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5         6  \\\n",
       "0    -0.194920 -0.112881  0.388437 -0.109874  0.041914 -0.137204  0.109907   \n",
       "1    -0.174782 -0.099447 -0.468011  0.108068 -0.028635 -0.427431  0.169761   \n",
       "2     0.039530 -0.073837 -0.087995  0.360194  0.181992 -0.366591  0.008656   \n",
       "3    -0.264160 -0.126185 -0.099923  0.301749  0.262108 -0.213265  0.108956   \n",
       "4     0.078526  0.177795  0.488374  0.213472  0.312748 -0.280140  0.397646   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "5534 -0.400154 -0.256461 -0.183564  0.033262  0.159400 -0.255320  0.377321   \n",
       "5535  0.051658 -0.054771  0.298856  0.032705  0.214817 -0.419218 -0.005545   \n",
       "5536 -0.120506  0.175940  0.014781 -0.156842  0.175269  0.039736  0.083392   \n",
       "5537  0.073636  0.110835  0.429038  0.118876  0.007961 -0.031842 -0.030791   \n",
       "5538 -0.029584  0.114278  0.226568  0.230094 -0.027433 -0.308322  0.019580   \n",
       "\n",
       "             7         8         9  ...       759       760       761  \\\n",
       "0     0.556634 -0.304503 -0.419192  ... -0.042977 -0.004823 -0.049975   \n",
       "1     0.651794 -0.305934 -0.692678  ... -0.023003 -0.002153 -0.354740   \n",
       "2     0.453784 -0.260378 -0.490275  ...  0.075246  0.057701 -0.087006   \n",
       "3     0.407808 -0.187299 -0.148701  ... -0.155414 -0.248788 -0.342570   \n",
       "4     0.429720 -0.310175 -0.554000  ... -0.093388 -0.008426  0.207753   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "5534  0.061936 -0.094525 -0.187200  ...  0.181568  0.113463 -0.217428   \n",
       "5535  0.701181 -0.368737 -0.288521  ...  0.209300 -0.141448 -0.260576   \n",
       "5536  0.751514  0.105191 -0.167486  ... -0.151757 -0.134946 -0.152878   \n",
       "5537  0.188152 -0.325286 -0.172276  ...  0.337875 -0.096466 -0.481865   \n",
       "5538  0.600823 -0.277417 -0.068723  ...  0.241541  0.066769 -0.011381   \n",
       "\n",
       "           762       763       764       765       766       767  Labels  \n",
       "0     0.218379 -0.276184  0.220082 -0.796053  0.144477 -0.509098     Yes  \n",
       "1     0.397673 -0.244706  0.033439 -0.483247 -0.173934 -0.337515     Yes  \n",
       "2     0.320335 -0.269148  0.119730 -0.637774  0.000480 -0.097225     Yes  \n",
       "3     0.218711 -0.174955 -0.092277 -0.557828 -0.256308 -0.358489     Yes  \n",
       "4     0.094225 -0.148403  0.101668 -0.530785  0.069791 -0.241589     Yes  \n",
       "...        ...       ...       ...       ...       ...       ...     ...  \n",
       "5534 -0.007062 -0.436011 -0.095360 -0.296756  0.257059 -0.234672     NaN  \n",
       "5535  0.385859 -0.042413 -0.044953 -0.381793  0.155324 -0.293402      No  \n",
       "5536 -0.033997 -0.350957 -0.388650 -0.116329  0.089427 -0.230295      No  \n",
       "5537  0.066156 -0.208680  0.082813 -0.188787  0.365409  0.169572      No  \n",
       "5538  0.492085 -0.038748  0.007048 -0.074291  0.399871 -0.195889     NaN  \n",
       "\n",
       "[5539 rows x 769 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>759</th>\n",
       "      <th>760</th>\n",
       "      <th>761</th>\n",
       "      <th>762</th>\n",
       "      <th>763</th>\n",
       "      <th>764</th>\n",
       "      <th>765</th>\n",
       "      <th>766</th>\n",
       "      <th>767</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>-0.194920</td>\n",
       "      <td>-0.112881</td>\n",
       "      <td>0.388437</td>\n",
       "      <td>-0.109874</td>\n",
       "      <td>0.041914</td>\n",
       "      <td>-0.137204</td>\n",
       "      <td>0.109907</td>\n",
       "      <td>0.556634</td>\n",
       "      <td>-0.304503</td>\n",
       "      <td>-0.419192</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.042977</td>\n",
       "      <td>-0.004823</td>\n",
       "      <td>-0.049975</td>\n",
       "      <td>0.218379</td>\n",
       "      <td>-0.276184</td>\n",
       "      <td>0.220082</td>\n",
       "      <td>-0.796053</td>\n",
       "      <td>0.144477</td>\n",
       "      <td>-0.509098</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>-0.174782</td>\n",
       "      <td>-0.099447</td>\n",
       "      <td>-0.468011</td>\n",
       "      <td>0.108068</td>\n",
       "      <td>-0.028635</td>\n",
       "      <td>-0.427431</td>\n",
       "      <td>0.169761</td>\n",
       "      <td>0.651794</td>\n",
       "      <td>-0.305934</td>\n",
       "      <td>-0.692678</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.023003</td>\n",
       "      <td>-0.002153</td>\n",
       "      <td>-0.354740</td>\n",
       "      <td>0.397673</td>\n",
       "      <td>-0.244706</td>\n",
       "      <td>0.033439</td>\n",
       "      <td>-0.483247</td>\n",
       "      <td>-0.173934</td>\n",
       "      <td>-0.337515</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.039530</td>\n",
       "      <td>-0.073837</td>\n",
       "      <td>-0.087995</td>\n",
       "      <td>0.360194</td>\n",
       "      <td>0.181992</td>\n",
       "      <td>-0.366591</td>\n",
       "      <td>0.008656</td>\n",
       "      <td>0.453784</td>\n",
       "      <td>-0.260378</td>\n",
       "      <td>-0.490275</td>\n",
       "      <td>...</td>\n",
       "      <td>0.075246</td>\n",
       "      <td>0.057701</td>\n",
       "      <td>-0.087006</td>\n",
       "      <td>0.320335</td>\n",
       "      <td>-0.269148</td>\n",
       "      <td>0.119730</td>\n",
       "      <td>-0.637774</td>\n",
       "      <td>0.000480</td>\n",
       "      <td>-0.097225</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>-0.264160</td>\n",
       "      <td>-0.126185</td>\n",
       "      <td>-0.099923</td>\n",
       "      <td>0.301749</td>\n",
       "      <td>0.262108</td>\n",
       "      <td>-0.213265</td>\n",
       "      <td>0.108956</td>\n",
       "      <td>0.407808</td>\n",
       "      <td>-0.187299</td>\n",
       "      <td>-0.148701</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.155414</td>\n",
       "      <td>-0.248788</td>\n",
       "      <td>-0.342570</td>\n",
       "      <td>0.218711</td>\n",
       "      <td>-0.174955</td>\n",
       "      <td>-0.092277</td>\n",
       "      <td>-0.557828</td>\n",
       "      <td>-0.256308</td>\n",
       "      <td>-0.358489</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.078526</td>\n",
       "      <td>0.177795</td>\n",
       "      <td>0.488374</td>\n",
       "      <td>0.213472</td>\n",
       "      <td>0.312748</td>\n",
       "      <td>-0.280140</td>\n",
       "      <td>0.397646</td>\n",
       "      <td>0.429720</td>\n",
       "      <td>-0.310175</td>\n",
       "      <td>-0.554000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.093388</td>\n",
       "      <td>-0.008426</td>\n",
       "      <td>0.207753</td>\n",
       "      <td>0.094225</td>\n",
       "      <td>-0.148403</td>\n",
       "      <td>0.101668</td>\n",
       "      <td>-0.530785</td>\n",
       "      <td>0.069791</td>\n",
       "      <td>-0.241589</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5534</td>\n",
       "      <td>-0.400154</td>\n",
       "      <td>-0.256461</td>\n",
       "      <td>-0.183564</td>\n",
       "      <td>0.033262</td>\n",
       "      <td>0.159400</td>\n",
       "      <td>-0.255320</td>\n",
       "      <td>0.377321</td>\n",
       "      <td>0.061936</td>\n",
       "      <td>-0.094525</td>\n",
       "      <td>-0.187200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.181568</td>\n",
       "      <td>0.113463</td>\n",
       "      <td>-0.217428</td>\n",
       "      <td>-0.007062</td>\n",
       "      <td>-0.436011</td>\n",
       "      <td>-0.095360</td>\n",
       "      <td>-0.296756</td>\n",
       "      <td>0.257059</td>\n",
       "      <td>-0.234672</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5535</td>\n",
       "      <td>0.051658</td>\n",
       "      <td>-0.054771</td>\n",
       "      <td>0.298856</td>\n",
       "      <td>0.032705</td>\n",
       "      <td>0.214817</td>\n",
       "      <td>-0.419218</td>\n",
       "      <td>-0.005545</td>\n",
       "      <td>0.701181</td>\n",
       "      <td>-0.368737</td>\n",
       "      <td>-0.288521</td>\n",
       "      <td>...</td>\n",
       "      <td>0.209300</td>\n",
       "      <td>-0.141448</td>\n",
       "      <td>-0.260576</td>\n",
       "      <td>0.385859</td>\n",
       "      <td>-0.042413</td>\n",
       "      <td>-0.044953</td>\n",
       "      <td>-0.381793</td>\n",
       "      <td>0.155324</td>\n",
       "      <td>-0.293402</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5536</td>\n",
       "      <td>-0.120506</td>\n",
       "      <td>0.175940</td>\n",
       "      <td>0.014781</td>\n",
       "      <td>-0.156842</td>\n",
       "      <td>0.175269</td>\n",
       "      <td>0.039736</td>\n",
       "      <td>0.083392</td>\n",
       "      <td>0.751514</td>\n",
       "      <td>0.105191</td>\n",
       "      <td>-0.167486</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.151757</td>\n",
       "      <td>-0.134946</td>\n",
       "      <td>-0.152878</td>\n",
       "      <td>-0.033997</td>\n",
       "      <td>-0.350957</td>\n",
       "      <td>-0.388650</td>\n",
       "      <td>-0.116329</td>\n",
       "      <td>0.089427</td>\n",
       "      <td>-0.230295</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5537</td>\n",
       "      <td>0.073636</td>\n",
       "      <td>0.110835</td>\n",
       "      <td>0.429038</td>\n",
       "      <td>0.118876</td>\n",
       "      <td>0.007961</td>\n",
       "      <td>-0.031842</td>\n",
       "      <td>-0.030791</td>\n",
       "      <td>0.188152</td>\n",
       "      <td>-0.325286</td>\n",
       "      <td>-0.172276</td>\n",
       "      <td>...</td>\n",
       "      <td>0.337875</td>\n",
       "      <td>-0.096466</td>\n",
       "      <td>-0.481865</td>\n",
       "      <td>0.066156</td>\n",
       "      <td>-0.208680</td>\n",
       "      <td>0.082813</td>\n",
       "      <td>-0.188787</td>\n",
       "      <td>0.365409</td>\n",
       "      <td>0.169572</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5538</td>\n",
       "      <td>-0.029584</td>\n",
       "      <td>0.114278</td>\n",
       "      <td>0.226568</td>\n",
       "      <td>0.230094</td>\n",
       "      <td>-0.027433</td>\n",
       "      <td>-0.308322</td>\n",
       "      <td>0.019580</td>\n",
       "      <td>0.600823</td>\n",
       "      <td>-0.277417</td>\n",
       "      <td>-0.068723</td>\n",
       "      <td>...</td>\n",
       "      <td>0.241541</td>\n",
       "      <td>0.066769</td>\n",
       "      <td>-0.011381</td>\n",
       "      <td>0.492085</td>\n",
       "      <td>-0.038748</td>\n",
       "      <td>0.007048</td>\n",
       "      <td>-0.074291</td>\n",
       "      <td>0.399871</td>\n",
       "      <td>-0.195889</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5539 rows × 769 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5         6  \\\n",
       "0    -0.194920 -0.112881  0.388437 -0.109874  0.041914 -0.137204  0.109907   \n",
       "1    -0.174782 -0.099447 -0.468011  0.108068 -0.028635 -0.427431  0.169761   \n",
       "2     0.039530 -0.073837 -0.087995  0.360194  0.181992 -0.366591  0.008656   \n",
       "3    -0.264160 -0.126185 -0.099923  0.301749  0.262108 -0.213265  0.108956   \n",
       "4     0.078526  0.177795  0.488374  0.213472  0.312748 -0.280140  0.397646   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "5534 -0.400154 -0.256461 -0.183564  0.033262  0.159400 -0.255320  0.377321   \n",
       "5535  0.051658 -0.054771  0.298856  0.032705  0.214817 -0.419218 -0.005545   \n",
       "5536 -0.120506  0.175940  0.014781 -0.156842  0.175269  0.039736  0.083392   \n",
       "5537  0.073636  0.110835  0.429038  0.118876  0.007961 -0.031842 -0.030791   \n",
       "5538 -0.029584  0.114278  0.226568  0.230094 -0.027433 -0.308322  0.019580   \n",
       "\n",
       "             7         8         9  ...       759       760       761  \\\n",
       "0     0.556634 -0.304503 -0.419192  ... -0.042977 -0.004823 -0.049975   \n",
       "1     0.651794 -0.305934 -0.692678  ... -0.023003 -0.002153 -0.354740   \n",
       "2     0.453784 -0.260378 -0.490275  ...  0.075246  0.057701 -0.087006   \n",
       "3     0.407808 -0.187299 -0.148701  ... -0.155414 -0.248788 -0.342570   \n",
       "4     0.429720 -0.310175 -0.554000  ... -0.093388 -0.008426  0.207753   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "5534  0.061936 -0.094525 -0.187200  ...  0.181568  0.113463 -0.217428   \n",
       "5535  0.701181 -0.368737 -0.288521  ...  0.209300 -0.141448 -0.260576   \n",
       "5536  0.751514  0.105191 -0.167486  ... -0.151757 -0.134946 -0.152878   \n",
       "5537  0.188152 -0.325286 -0.172276  ...  0.337875 -0.096466 -0.481865   \n",
       "5538  0.600823 -0.277417 -0.068723  ...  0.241541  0.066769 -0.011381   \n",
       "\n",
       "           762       763       764       765       766       767  Labels  \n",
       "0     0.218379 -0.276184  0.220082 -0.796053  0.144477 -0.509098     Yes  \n",
       "1     0.397673 -0.244706  0.033439 -0.483247 -0.173934 -0.337515     Yes  \n",
       "2     0.320335 -0.269148  0.119730 -0.637774  0.000480 -0.097225     Yes  \n",
       "3     0.218711 -0.174955 -0.092277 -0.557828 -0.256308 -0.358489     Yes  \n",
       "4     0.094225 -0.148403  0.101668 -0.530785  0.069791 -0.241589     Yes  \n",
       "...        ...       ...       ...       ...       ...       ...     ...  \n",
       "5534 -0.007062 -0.436011 -0.095360 -0.296756  0.257059 -0.234672     NaN  \n",
       "5535  0.385859 -0.042413 -0.044953 -0.381793  0.155324 -0.293402      No  \n",
       "5536 -0.033997 -0.350957 -0.388650 -0.116329  0.089427 -0.230295      No  \n",
       "5537  0.066156 -0.208680  0.082813 -0.188787  0.365409  0.169572      No  \n",
       "5538  0.492085 -0.038748  0.007048 -0.074291  0.399871 -0.195889     NaN  \n",
       "\n",
       "[5539 rows x 769 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################\n",
      "####################\n"
     ]
    }
   ],
   "source": [
    "dic_representations_init=['tfidf','word2vec','fast2vec_cluster','fast2vec_mean', 'bert'] \n",
    "for name_representation in dic_representations_init:\n",
    "    df = pd.read_csv('representations/df_{}.csv'.format(name_representation),index_col=0)\n",
    "    display(df)\n",
    "    df.to_csv('representations/{}.csv.gz'.format(name_representation), compression='gzip')\n",
    "    df = pd.read_csv('representations/{}.csv.gz'.format(name_representation), compression='gzip',index_col=0)\n",
    "    display(df)\n",
    "    print('#'*20)\n",
    "    print('#'*20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quelques exemples de tweets : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exemples de tweets qui croient au réchauffement climatique : \n",
      " \n",
      "Global warming report urges governments to act|BRUSSELS, Belgium (AP) - The world faces increased hunger and .. \n",
      " \n",
      "Fighting poverty and global warming in Africa \n",
      " \n",
      "Carbon offsets: How a Vatican forest failed to reduce global warming \n",
      " \n",
      "URUGUAY: Tools Needed for Those Most Vulnerable to Climate Change \n",
      " \n",
      "RT @sejorg: RT @JaymiHeimbuch: Ocean Saltiness Shows Global Warming Is Intensifying Our Water Cycle \n",
      " \n",
      "##################################################\n",
      "##################################################\n",
      " \n",
      "Exemples de tweets qui doutent du réchauffement climatique : \n",
      " \n",
      "Wait here's an idea: it's natural climate change, not human induced global warming. \n",
      " \n",
      "@New_federalists  i have it on good auth tht global warming also causes toe fungus.  We R all fortunate tht thr IS no global warming! #tcot\n",
      " \n",
      "Illegal war and the myth of global warming|My main campaign platform for this election will be the illegal .. \n",
      " \n",
      "the scientific community was scamed by global green  gov warming scam.\n",
      " \n",
      "40 degrees in NYC. please urinate on next liberal global warming /climate change scum you see.\n",
      " \n"
     ]
    }
   ],
   "source": [
    "# Exemples de tweets\n",
    "\n",
    "print('Exemples de tweets qui croient au réchauffement climatique : ')\n",
    "print(' ')\n",
    "for k in range(5):\n",
    "    print(df[df.Existence=='Yes'].reset_index().iloc[k]['Tweet'])\n",
    "    print(' ')\n",
    "    \n",
    "print('#'*50)\n",
    "print('#'*50)\n",
    "print(' ')\n",
    "print('Exemples de tweets qui doutent du réchauffement climatique : ')\n",
    "print(' ')\n",
    "for k in range(5):\n",
    "    print(df[df.Existence=='No'].reset_index().iloc[k]['Tweet'])\n",
    "    print(' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Une petite description de la base : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On dispose de 5539 tweets.\n",
      " \n",
      "On a 1683 données manquantes sur le label de l'avis du tweet (Yes, No) .\n",
      " \n",
      "On a 2821 tweets qui croit au Changement climatique.\n",
      "On a 1035 tweets qui remettent en doute le Changement climatique.\n"
     ]
    }
   ],
   "source": [
    "print('On dispose de {} tweets.'.format(df.shape[0]))\n",
    "print(' ')\n",
    "print('On a {} données manquantes sur le label de l\\'avis du tweet (Yes, No) .'.format(str(df.isnull().sum()['Existence'])))\n",
    "print(' ')\n",
    "print('On a {} tweets qui croit au Changement climatique.'.format(str(df[df.Existence=='Yes'].shape[0])))\n",
    "print('On a {} tweets qui remettent en doute le Changement climatique.'.format(str(df[df.Existence=='No'].shape[0])))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Nettoyage des données et représentations des tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization des tweets et nettoyage des tokens "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def get_wordnet_pos(word):\n",
    "    tag = nltk.pos_tag([word])[0][1][0].lower()\n",
    "    tag_return = {\"j\": wordnet.ADJ,\n",
    "                \"n\": wordnet.NOUN,\n",
    "                \"v\": wordnet.VERB,\n",
    "                \"r\": wordnet.ADV}\n",
    "    return tag_return.get(tag, wordnet.NOUN)\n",
    "\n",
    "#On prend toutes les phrases de touts les texts, et on les concatène dans une liste, en les traitant auparavant\n",
    "\n",
    "sent_detector = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "\n",
    "def remove_hashtags(tokens):\n",
    "    tokens= map(lambda x : x.replace('#',''),tokens) #map : parcours tout les tokens\n",
    "    return list(tokens)\n",
    "\n",
    "def remove_url(tokens): #pb pour https\n",
    "    tokens= filter(lambda x: \"http\" not in x, tokens) #filter : garde là où il y a True\n",
    "    return list(tokens)\n",
    "\n",
    "def remove_html(tokens):\n",
    "    tokens= filter(lambda x: x[0]+x[-1]!='<>',tokens)\n",
    "    return list(tokens)\n",
    "\n",
    "def remove_www(tokens):\n",
    "    tokens= filter(lambda x: \"www\" not in x, tokens) #filter : garde là où il y a True\n",
    "    return list(tokens)\n",
    "\n",
    "def remove_contraction(sample):\n",
    "    sample = sample.lower()\n",
    "    sample = sample.replace('won\\'t', ' will not')    \n",
    "    sample = sample.replace('n\\'t',' not')\n",
    "    sample = sample.replace('\\'ll',' will') \n",
    "    sample = sample.replace('it\\'s','it is')    \n",
    "    sample = sample.replace('he\\'s','he is')    \n",
    "    sample = sample.replace('she\\'s','she is')    \n",
    "    sample = sample.replace('\\'re', ' are')\n",
    "    sample = sample.replace('that\\'s', 'that is')\n",
    "    return sample\n",
    "\n",
    "\n",
    "def RepresentsInt(s):\n",
    "    try: \n",
    "        int(s)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "def clean_ponctuation(text_tokens): # Nettoyage de la ponctuation\n",
    "\n",
    "    list_word_clean_ponctuation=[]\n",
    "    for tweet in text_tokens:\n",
    "        list_tweet=[]\n",
    "        for word in tweet:\n",
    "            if len(word)<2:\n",
    "                if (word=='a') or (word=='i') or (word=='u'):\n",
    "                    list_tweet.append(word)\n",
    "                if RepresentsInt(word):\n",
    "                    list_tweet.append(word)\n",
    "            else :\n",
    "                if (word!='..') & (word!='...') & (word!='rt'):\n",
    "                    list_tweet.append(word)\n",
    "        list_word_clean_ponctuation.append(list_tweet)\n",
    "    \n",
    "    return(list_word_clean_ponctuation)\n",
    "\n",
    "def remove_arobase(text_tokens):\n",
    "    \n",
    "    list_new_tokens=[]\n",
    "    for tweet in text_tokens:\n",
    "        new_tweet=[]\n",
    "        for word in tweet: \n",
    "            if '@' not in word:\n",
    "                new_tweet.append(word)\n",
    "        list_new_tokens.append(new_tweet)\n",
    "    \n",
    "    return(list_new_tokens)\n",
    "\n",
    "###############################################################\n",
    "###############################################################\n",
    "###############################################################\n",
    "\n",
    "def clean_text_first(corpus):\n",
    "    \n",
    "    tok=TweetTokenizer()\n",
    "    tokens=[]\n",
    "    for sample in corpus:\n",
    "        sample = remove_contraction(sample)\n",
    "        token=tok.tokenize(sample)\n",
    "        token=remove_url(token)\n",
    "        token=remove_html(token)\n",
    "        token=remove_hashtags(token)\n",
    "        token=remove_www(token)\n",
    "        token2 = []\n",
    "        for elt in token:\n",
    "            if elt != '':\n",
    "                if elt != \"warming\":\n",
    "                    token2.append(lemmatizer.lemmatize(elt, get_wordnet_pos(elt)))\n",
    "                else:\n",
    "                    token2.append(\"warming\")\n",
    "        token=list(map(lambda x : x.lower(),token2)) #.lower() : met les majuscules en minuscules\n",
    "        tokens.append(token) #ajout du token à l'ensemble des phrases\n",
    "    \n",
    "    #Nettoyage de la ponctuation\n",
    "    tokens=clean_ponctuation(tokens)\n",
    "    \n",
    "    #Nettoyage des arobase : pour la plupart, se sont des noms propres\n",
    "    tokens=remove_arobase(tokens)\n",
    "    \n",
    "    return tokens\n",
    "\n",
    "def clean_text_second(corpus,threshold=10, stopwords_out = False): #On rajoute l'association des mots qui vont ensembles\n",
    "    \n",
    "    #clean les textes\n",
    "    tokens=clean_text_first(corpus)\n",
    "    \n",
    "    #associer les mots\n",
    "    phrases=Phrases(tokens,threshold=threshold) #On fait apprendre le modèle d'association sur tout les mots\n",
    "    phraser=Phraser(phrases) #Outil pour associer\n",
    "    \n",
    "    clean_tokens=[]\n",
    "    for token in tokens: #On parcours les phrases et on associe les mots\n",
    "        new_tokens=phraser[token]\n",
    "        if stopwords_out :\n",
    "            new_tokens2 = []\n",
    "            for elt in new_tokens:\n",
    "                if elt not in stopWords:\n",
    "                    new_tokens2.append(elt)\n",
    "            clean_tokens.append(new_tokens2)\n",
    "        else:\n",
    "            clean_tokens.append(new_tokens)\n",
    "    \n",
    "    return(clean_tokens)\n",
    "\n",
    "\"\"\"\n",
    "# Sauvegarde des tokens nettoyés\n",
    "clean_text=clean_text_second(df.Tweet)\n",
    "data=pd.DataFrame([clean_text]).T\n",
    "data.to_csv('clean_text.csv')\n",
    "\n",
    "df_yes=df[df.Existence=='Yes'].reset_index()\n",
    "clean_text_yes=clean_text_second(df_yes.Tweet)\n",
    "data=pd.DataFrame([clean_text_yes]).T\n",
    "data.to_csv('clean_text_yes.csv')\n",
    "\n",
    "df_no=df[df.Existence=='No'].reset_index()\n",
    "clean_text_no=clean_text_second(df_no.Tweet)\n",
    "data=pd.DataFrame([clean_text_no]).T\n",
    "data.to_csv('clean_text_no.csv')\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Fonction pour l'importée\n",
    "def import_clean_text(option='all'):\n",
    "\n",
    "    if option=='all':\n",
    "        clean_new=[]\n",
    "        clean_text=pd.read_csv('clean_text.csv',index_col=0)\n",
    "        for tweet in list(clean_text['0']):\n",
    "            clean_new.append(ast.literal_eval(tweet))\n",
    "        clean_text=clean_new\n",
    "\n",
    "    if option=='yes':\n",
    "        clean_new=[]\n",
    "        clean_text=pd.read_csv('clean_text_yes.csv',index_col=0)\n",
    "        for tweet in list(clean_text['0']):\n",
    "            clean_new.append(ast.literal_eval(tweet))\n",
    "        clean_text=clean_new\n",
    "        \n",
    "    if option=='no':\n",
    "        clean_new=[]\n",
    "        clean_text=pd.read_csv('clean_text_no.csv',index_col=0)\n",
    "        for tweet in list(clean_text['0']):\n",
    "            clean_new.append(ast.literal_eval(tweet))\n",
    "        clean_text=clean_new\n",
    "    \n",
    "    return(clean_text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mots les plus fréquents après le nettoyage des tweets : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les 10 mots qui apparaissent le plus sont (par ordre décroissant) :\n",
      " \n",
      "climate_change (2936) \n",
      "global_warming (2709) \n",
      "the (2275) \n",
      "be (1801) \n",
      "to (1443) \n",
      "of (1328) \n",
      "a (1193) \n",
      "on (962) \n",
      "and (869) \n",
      "in (845) \n"
     ]
    }
   ],
   "source": [
    "#Mots les plus fréquents après nettoyage des tokens\n",
    "\n",
    "list_words=import_clean_text()\n",
    "\n",
    "counter=collections.Counter(reduce(add, list_words))\n",
    "\n",
    "#10 mots les plus fréquents \n",
    "number_word=10\n",
    "print('Les {} mots qui apparaissent le plus sont (par ordre décroissant) :'.format(number_word))\n",
    "print(' ')\n",
    "for word in counter.most_common(number_word):\n",
    "    print(word[0]+' ('+str(word[1])+') ') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "En moyenne, on a retenu 12.0 mots par tweet \n"
     ]
    }
   ],
   "source": [
    "# Taille moyenne des tweet : \n",
    "list_words\n",
    "mean=0\n",
    "for tweet in list_words:\n",
    "    mean=mean+len(tweet)\n",
    "    \n",
    "print('En moyenne, on a retenu {} mots par tweet '.format(str(round(mean/len(list_words),0))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Représentation TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Pour chaque mot, on a un vecteur le représentant. Pour réprésenter un tweet, on fait la moyenne des vecteurs correspondant à chacun de ces mots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialisation des mots TF-IDF\n",
    "cv = CountVectorizer()\n",
    "tfidf_transformer=TfidfTransformer(smooth_idf=True,use_idf=True)\n",
    "\n",
    "# Formatage de la base pour la méthode TF-IDF\n",
    "corpus=clean_text_second(df.Tweet,threshold=20, stopwords_out = True)\n",
    "corpus_new=[]\n",
    "for tweet in corpus: \n",
    "    tweet_sentence=''\n",
    "    for word in tweet:\n",
    "        tweet_sentence=tweet_sentence+' '+word\n",
    "    corpus_new.append(tweet_sentence)\n",
    "    \n",
    "# Caclul des scores TF-IDF de chaque mot\n",
    "word_count_vector=cv.fit_transform(corpus_new)\n",
    "tfidf_transformer.fit(word_count_vector)\n",
    "\n",
    "count_vector=cv.transform(corpus_new)\n",
    "tf_idf_vector=tfidf_transformer.transform(count_vector)\n",
    "feature_names = cv.get_feature_names()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "Tweet initial : Global warming report urges governments to act|BRUSSELS, Belgium (AP) - The world faces increased hunger and .. \n",
      " \n",
      "Tweet nettoyé :  global warming report urge government act brussels belgium ap world face increase hunger\n",
      " \n",
      "Scores TF-IDF : \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>belgium</td>\n",
       "      <td>0.382666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>brussels</td>\n",
       "      <td>0.382666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>hunger</td>\n",
       "      <td>0.359726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>urge</td>\n",
       "      <td>0.320411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>face</td>\n",
       "      <td>0.287450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>exclusive</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>excite</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>exchange</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>excess</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>à_the</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7191 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           first_tweet\n",
       "belgium       0.382666\n",
       "brussels      0.382666\n",
       "hunger        0.359726\n",
       "urge          0.320411\n",
       "face          0.287450\n",
       "...                ...\n",
       "exclusive     0.000000\n",
       "excite        0.000000\n",
       "exchange      0.000000\n",
       "excess        0.000000\n",
       "à_the         0.000000\n",
       "\n",
       "[7191 rows x 1 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exemple de représentation du premier tweet \n",
    "\n",
    "#get tfidf vector for first document\n",
    "first_document_vector=tf_idf_vector[0]\n",
    "\n",
    "#print du tweet\n",
    "print(' ')\n",
    "print('Tweet initial : '+df.iloc[0]['Tweet'])\n",
    "print(' ')\n",
    "\n",
    "#print du tweet nettoyé\n",
    "print('Tweet nettoyé : '+corpus_new[0])\n",
    "print(' ')\n",
    "print('Scores TF-IDF : ')\n",
    "#print des scores \n",
    "pd.DataFrame(first_document_vector.T.todense(), index=feature_names, columns=[\"first_tweet\"]).sort_values(by=[\"first_tweet\"],ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndf_tfidf = pd.DataFrame(tf_idf_vector.T.todense(),index=feature_names)\\ndf_tfidf=df_tfidf.T\\ndf_tfidf.columns=[x for x in range(df_tfidf.shape[1])]\\ndf_tfidf['Labels']=df.Existence\\ndf_tfidf.to_csv('representations/df_tfidf.csv')\\ndf_tfidf\\n\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Représentation de tout les tweets \n",
    "\n",
    "\"\"\"\n",
    "df_tfidf = pd.DataFrame(tf_idf_vector.T.todense(),index=feature_names)\n",
    "df_tfidf=df_tfidf.T\n",
    "df_tfidf.columns=[x for x in range(df_tfidf.shape[1])]\n",
    "df_tfidf['Labels']=df.Existence\n",
    "df_tfidf.to_csv('representations/df_tfidf.csv')\n",
    "df_tfidf\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>7182</th>\n",
       "      <th>7183</th>\n",
       "      <th>7184</th>\n",
       "      <th>7185</th>\n",
       "      <th>7186</th>\n",
       "      <th>7187</th>\n",
       "      <th>7188</th>\n",
       "      <th>7189</th>\n",
       "      <th>7190</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5534</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5535</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5536</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5537</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5538</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5539 rows × 7192 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0    1    2    3    4    5    6    7    8    9  ...  7182  7183  7184  \\\n",
       "0     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
       "1     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
       "2     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
       "3     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
       "4     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
       "...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   ...   ...   ...   \n",
       "5534  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
       "5535  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
       "5536  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
       "5537  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
       "5538  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
       "\n",
       "      7185  7186  7187  7188  7189  7190  Labels  \n",
       "0      0.0   0.0   0.0   0.0   0.0   0.0     Yes  \n",
       "1      0.0   0.0   0.0   0.0   0.0   0.0     Yes  \n",
       "2      0.0   0.0   0.0   0.0   0.0   0.0     Yes  \n",
       "3      0.0   0.0   0.0   0.0   0.0   0.0     Yes  \n",
       "4      0.0   0.0   0.0   0.0   0.0   0.0     Yes  \n",
       "...    ...   ...   ...   ...   ...   ...     ...  \n",
       "5534   0.0   0.0   0.0   0.0   0.0   0.0     NaN  \n",
       "5535   0.0   0.0   0.0   0.0   0.0   0.0      No  \n",
       "5536   0.0   0.0   0.0   0.0   0.0   0.0      No  \n",
       "5537   0.0   0.0   0.0   0.0   0.0   0.0      No  \n",
       "5538   0.0   0.0   0.0   0.0   0.0   0.0     NaN  \n",
       "\n",
       "[5539 rows x 7192 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tfidf=pd.read_csv('representations/df_tfidf.csv',index_col=0)\n",
    "df_tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Représentation Word2Vec entrainé sur la base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On utilise tout d'abord l'algorithme Word2Vec pour représenter ces tweets. Chaque mot à une représentation vectorielle. Pour chaque tweet, on fait la moyenne des vecteurs (chaque mot) inclut dans ce tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrainement du modèle Word2Vec ...\n"
     ]
    }
   ],
   "source": [
    "#Cleaning des tweets\n",
    "clean_text=import_clean_text()\n",
    "\n",
    "print(\"Entrainement du modèle Word2Vec ...\")\n",
    "model = Word2Vec(clean_text, size=100, window=5, min_count=3, workers=4) \n",
    "\n",
    "model.train(clean_text, total_examples=len(clean_text), epochs=10) #réseau de neuronne du Word2Vec\n",
    "model_wv = model.wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/salimyoussfi/opt/anaconda3/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3257: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/Users/salimyoussfi/opt/anaconda3/lib/python3.7/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "# Représentation des tweets en moyennant les mots\n",
    "\n",
    "def tokens2vectors(tokenCorpus):\n",
    "    ''' transforms our X into a list of list of vec (2D array) '''\n",
    "    new_sample = list()\n",
    "    i=0\n",
    "    labels=[]\n",
    "    for sample in tokenCorpus:\n",
    "        tweetVecs = list()\n",
    "        for token in sample:\n",
    "            try : \n",
    "                tweetVecs.append(model_wv.get_vector(token)  )\n",
    "            except: \n",
    "                i=i+1\n",
    "                tweetVecs.append( np.zeros(100) ) \n",
    "        new_sample.append(np.mean(tweetVecs, axis=0))\n",
    "    \n",
    "    return np.array(new_sample)\n",
    "\n",
    "\n",
    "X= tokens2vectors(clean_text)\n",
    "\n",
    "Y=[]\n",
    "labels=[]\n",
    "index_label=0\n",
    "for x in list(X):\n",
    "    try: \n",
    "        Y.append(list(x))\n",
    "        labels.append(df.Existence[index_label])\n",
    "        index_label=index_label+1\n",
    "    except : \n",
    "        index_label=index_label+1\n",
    "        pass\n",
    "    \n",
    "df_word2vec= pd.DataFrame(Y,columns=[str(x) for x in range(len(Y[0]))])\n",
    "df_word2vec['Labels']=labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>-0.034803</td>\n",
       "      <td>0.574692</td>\n",
       "      <td>-0.024320</td>\n",
       "      <td>0.084124</td>\n",
       "      <td>-0.007769</td>\n",
       "      <td>-0.043919</td>\n",
       "      <td>-0.212503</td>\n",
       "      <td>-0.187975</td>\n",
       "      <td>0.194824</td>\n",
       "      <td>-0.071464</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.061573</td>\n",
       "      <td>0.291551</td>\n",
       "      <td>-0.099408</td>\n",
       "      <td>-0.417668</td>\n",
       "      <td>0.114716</td>\n",
       "      <td>-0.070984</td>\n",
       "      <td>-0.140349</td>\n",
       "      <td>0.155909</td>\n",
       "      <td>0.387361</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>-0.045523</td>\n",
       "      <td>0.679620</td>\n",
       "      <td>0.000538</td>\n",
       "      <td>0.103425</td>\n",
       "      <td>-0.005931</td>\n",
       "      <td>-0.023181</td>\n",
       "      <td>-0.233011</td>\n",
       "      <td>-0.246731</td>\n",
       "      <td>0.277161</td>\n",
       "      <td>-0.078278</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.031663</td>\n",
       "      <td>0.376862</td>\n",
       "      <td>-0.074846</td>\n",
       "      <td>-0.527581</td>\n",
       "      <td>0.142178</td>\n",
       "      <td>-0.079401</td>\n",
       "      <td>-0.190756</td>\n",
       "      <td>0.178426</td>\n",
       "      <td>0.480519</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>-0.099174</td>\n",
       "      <td>0.598018</td>\n",
       "      <td>0.147960</td>\n",
       "      <td>-0.048949</td>\n",
       "      <td>-0.031430</td>\n",
       "      <td>-0.017491</td>\n",
       "      <td>-0.149470</td>\n",
       "      <td>-0.287509</td>\n",
       "      <td>0.368354</td>\n",
       "      <td>-0.136673</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.079986</td>\n",
       "      <td>0.281047</td>\n",
       "      <td>-0.051203</td>\n",
       "      <td>-0.427393</td>\n",
       "      <td>0.209120</td>\n",
       "      <td>0.037495</td>\n",
       "      <td>-0.045074</td>\n",
       "      <td>0.212375</td>\n",
       "      <td>0.501800</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>-0.032602</td>\n",
       "      <td>0.584073</td>\n",
       "      <td>-0.000475</td>\n",
       "      <td>0.022584</td>\n",
       "      <td>-0.020850</td>\n",
       "      <td>-0.066859</td>\n",
       "      <td>-0.207133</td>\n",
       "      <td>-0.080091</td>\n",
       "      <td>0.247074</td>\n",
       "      <td>-0.082756</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.103604</td>\n",
       "      <td>0.323825</td>\n",
       "      <td>-0.140997</td>\n",
       "      <td>-0.380847</td>\n",
       "      <td>0.117071</td>\n",
       "      <td>-0.048625</td>\n",
       "      <td>-0.109754</td>\n",
       "      <td>0.159889</td>\n",
       "      <td>0.402783</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>-0.122250</td>\n",
       "      <td>0.553165</td>\n",
       "      <td>0.123425</td>\n",
       "      <td>-0.024946</td>\n",
       "      <td>0.018299</td>\n",
       "      <td>0.033656</td>\n",
       "      <td>-0.132178</td>\n",
       "      <td>-0.334184</td>\n",
       "      <td>0.323884</td>\n",
       "      <td>-0.127449</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.058247</td>\n",
       "      <td>0.233620</td>\n",
       "      <td>0.048888</td>\n",
       "      <td>-0.392988</td>\n",
       "      <td>0.176985</td>\n",
       "      <td>0.028446</td>\n",
       "      <td>-0.054034</td>\n",
       "      <td>0.191555</td>\n",
       "      <td>0.447745</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5532</td>\n",
       "      <td>-0.061722</td>\n",
       "      <td>0.611638</td>\n",
       "      <td>0.056657</td>\n",
       "      <td>0.056770</td>\n",
       "      <td>0.013780</td>\n",
       "      <td>0.001569</td>\n",
       "      <td>-0.173358</td>\n",
       "      <td>-0.267492</td>\n",
       "      <td>0.287655</td>\n",
       "      <td>-0.122263</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.046790</td>\n",
       "      <td>0.328453</td>\n",
       "      <td>-0.031375</td>\n",
       "      <td>-0.454243</td>\n",
       "      <td>0.158813</td>\n",
       "      <td>-0.017741</td>\n",
       "      <td>-0.159698</td>\n",
       "      <td>0.198078</td>\n",
       "      <td>0.473690</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5533</td>\n",
       "      <td>-0.113981</td>\n",
       "      <td>0.498588</td>\n",
       "      <td>0.163165</td>\n",
       "      <td>-0.056748</td>\n",
       "      <td>-0.018788</td>\n",
       "      <td>0.026716</td>\n",
       "      <td>-0.103223</td>\n",
       "      <td>-0.277220</td>\n",
       "      <td>0.336499</td>\n",
       "      <td>-0.118409</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.064640</td>\n",
       "      <td>0.227641</td>\n",
       "      <td>0.007247</td>\n",
       "      <td>-0.337773</td>\n",
       "      <td>0.185337</td>\n",
       "      <td>0.024355</td>\n",
       "      <td>-0.009709</td>\n",
       "      <td>0.181260</td>\n",
       "      <td>0.392719</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5534</td>\n",
       "      <td>-0.077606</td>\n",
       "      <td>0.424907</td>\n",
       "      <td>0.097420</td>\n",
       "      <td>0.010471</td>\n",
       "      <td>0.008839</td>\n",
       "      <td>0.024059</td>\n",
       "      <td>-0.111279</td>\n",
       "      <td>-0.266572</td>\n",
       "      <td>0.203657</td>\n",
       "      <td>-0.083056</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.058557</td>\n",
       "      <td>0.180753</td>\n",
       "      <td>-0.014085</td>\n",
       "      <td>-0.332193</td>\n",
       "      <td>0.134709</td>\n",
       "      <td>-0.016538</td>\n",
       "      <td>-0.027659</td>\n",
       "      <td>0.144992</td>\n",
       "      <td>0.326755</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5535</td>\n",
       "      <td>-0.077740</td>\n",
       "      <td>0.501264</td>\n",
       "      <td>0.064616</td>\n",
       "      <td>0.010643</td>\n",
       "      <td>0.010023</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>-0.142786</td>\n",
       "      <td>-0.241226</td>\n",
       "      <td>0.250688</td>\n",
       "      <td>-0.096883</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.068197</td>\n",
       "      <td>0.217512</td>\n",
       "      <td>-0.031275</td>\n",
       "      <td>-0.362096</td>\n",
       "      <td>0.145170</td>\n",
       "      <td>-0.016336</td>\n",
       "      <td>-0.054055</td>\n",
       "      <td>0.157962</td>\n",
       "      <td>0.390158</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5536</td>\n",
       "      <td>-0.070640</td>\n",
       "      <td>0.583286</td>\n",
       "      <td>0.049536</td>\n",
       "      <td>0.040043</td>\n",
       "      <td>-0.001351</td>\n",
       "      <td>-0.011806</td>\n",
       "      <td>-0.183496</td>\n",
       "      <td>-0.253068</td>\n",
       "      <td>0.262121</td>\n",
       "      <td>-0.099735</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.074884</td>\n",
       "      <td>0.269492</td>\n",
       "      <td>-0.074751</td>\n",
       "      <td>-0.422344</td>\n",
       "      <td>0.149999</td>\n",
       "      <td>-0.040797</td>\n",
       "      <td>-0.087830</td>\n",
       "      <td>0.167525</td>\n",
       "      <td>0.426951</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5537 rows × 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5         6  \\\n",
       "0    -0.034803  0.574692 -0.024320  0.084124 -0.007769 -0.043919 -0.212503   \n",
       "1    -0.045523  0.679620  0.000538  0.103425 -0.005931 -0.023181 -0.233011   \n",
       "2    -0.099174  0.598018  0.147960 -0.048949 -0.031430 -0.017491 -0.149470   \n",
       "3    -0.032602  0.584073 -0.000475  0.022584 -0.020850 -0.066859 -0.207133   \n",
       "4    -0.122250  0.553165  0.123425 -0.024946  0.018299  0.033656 -0.132178   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "5532 -0.061722  0.611638  0.056657  0.056770  0.013780  0.001569 -0.173358   \n",
       "5533 -0.113981  0.498588  0.163165 -0.056748 -0.018788  0.026716 -0.103223   \n",
       "5534 -0.077606  0.424907  0.097420  0.010471  0.008839  0.024059 -0.111279   \n",
       "5535 -0.077740  0.501264  0.064616  0.010643  0.010023  0.000034 -0.142786   \n",
       "5536 -0.070640  0.583286  0.049536  0.040043 -0.001351 -0.011806 -0.183496   \n",
       "\n",
       "             7         8         9  ...        91        92        93  \\\n",
       "0    -0.187975  0.194824 -0.071464  ... -0.061573  0.291551 -0.099408   \n",
       "1    -0.246731  0.277161 -0.078278  ... -0.031663  0.376862 -0.074846   \n",
       "2    -0.287509  0.368354 -0.136673  ... -0.079986  0.281047 -0.051203   \n",
       "3    -0.080091  0.247074 -0.082756  ... -0.103604  0.323825 -0.140997   \n",
       "4    -0.334184  0.323884 -0.127449  ... -0.058247  0.233620  0.048888   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "5532 -0.267492  0.287655 -0.122263  ... -0.046790  0.328453 -0.031375   \n",
       "5533 -0.277220  0.336499 -0.118409  ... -0.064640  0.227641  0.007247   \n",
       "5534 -0.266572  0.203657 -0.083056  ... -0.058557  0.180753 -0.014085   \n",
       "5535 -0.241226  0.250688 -0.096883  ... -0.068197  0.217512 -0.031275   \n",
       "5536 -0.253068  0.262121 -0.099735  ... -0.074884  0.269492 -0.074751   \n",
       "\n",
       "            94        95        96        97        98        99  Labels  \n",
       "0    -0.417668  0.114716 -0.070984 -0.140349  0.155909  0.387361     Yes  \n",
       "1    -0.527581  0.142178 -0.079401 -0.190756  0.178426  0.480519     Yes  \n",
       "2    -0.427393  0.209120  0.037495 -0.045074  0.212375  0.501800     Yes  \n",
       "3    -0.380847  0.117071 -0.048625 -0.109754  0.159889  0.402783     Yes  \n",
       "4    -0.392988  0.176985  0.028446 -0.054034  0.191555  0.447745     Yes  \n",
       "...        ...       ...       ...       ...       ...       ...     ...  \n",
       "5532 -0.454243  0.158813 -0.017741 -0.159698  0.198078  0.473690     NaN  \n",
       "5533 -0.337773  0.185337  0.024355 -0.009709  0.181260  0.392719      No  \n",
       "5534 -0.332193  0.134709 -0.016538 -0.027659  0.144992  0.326755      No  \n",
       "5535 -0.362096  0.145170 -0.016336 -0.054055  0.157962  0.390158      No  \n",
       "5536 -0.422344  0.149999 -0.040797 -0.087830  0.167525  0.426951     NaN  \n",
       "\n",
       "[5537 rows x 101 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_word2vec.to_csv('representations/df_word2vec.csv')\n",
    "df_word2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Représentation Fast2vec pre-trained "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_text=import_clean_text()\n",
    "\n",
    "def load_vectors(fname, amount):\n",
    "    fin = io.open(fname, 'r', encoding ='utf-8', newline = '\\n', errors = 'ignore')\n",
    "    n, d = map(int, fin.readline().split())\n",
    "    data = {}\n",
    "    i = 0\n",
    "    for line in fin:\n",
    "        i += 1 \n",
    "        print(\"Done : \", i/amount * 100, \"%\")\n",
    "        if i < amount:\n",
    "            tokens = line.rstrip().split(' ')\n",
    "            data[tokens[0]] = tokens[1:]\n",
    "        else:\n",
    "            break\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfastext = load_vectors('wiki-news-300d-1M.vec', 500000)\\n\\n\\nclean_text=clean_text_first(df.Tweet)\\n\\ndic_words = {}\\nunknown_list = []\\n\\nunknown = 0\\ncount_word = 0\\n\\nfor tweet in clean_text:\\n    for word in tweet:\\n        count_word += 1\\n        if word in fastext.keys():\\n            dic_words[word] = fastext[word]\\n        else:\\n            unknown += 1\\n            unknown_list.append(word)\\n\\nmarshal.dump(dic_words, open('dic_words.dat', 'wb'))\\n\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "fastext = load_vectors('wiki-news-300d-1M.vec', 500000)\n",
    "\n",
    "\n",
    "clean_text=clean_text_first(df.Tweet)\n",
    "\n",
    "dic_words = {}\n",
    "unknown_list = []\n",
    "\n",
    "unknown = 0\n",
    "count_word = 0\n",
    "\n",
    "for tweet in clean_text:\n",
    "    for word in tweet:\n",
    "        count_word += 1\n",
    "        if word in fastext.keys():\n",
    "            dic_words[word] = fastext[word]\n",
    "        else:\n",
    "            unknown += 1\n",
    "            unknown_list.append(word)\n",
    "\n",
    "marshal.dump(dic_words, open('dic_words.dat', 'wb'))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "inf = open('dic_words.dat', 'rb')\n",
    "dic_words = marshal.load(inf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### En clusterisant la sortie de Fast2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_ft = pd.DataFrame(data=dic_words)\n",
    "dataset_ft = dataset_ft.T\n",
    "clustering = AgglomerativeClustering(200).fit(dataset_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le Cluster numéro :  0 contient  40  mots\n",
      " \n",
      " \n",
      "['talk', 'admin', 'data', 'article', 'pic', 'environment', 'photo', 'link', 'overview', 'lede', 'user', 'cn', 'slideshow', 'ip', 'image', 'material', 'content', 'poster', 'tag', 'info', 'collage', 'page', 'bio', 'brochure', 'summary', 'nutshell', 'information', 'cleanup', 'text', 'picture', 'msg', 'section', 'enviroment', 'click', 'caption', 'blurb', 'detail', 'bios', 'photograph', 'intro']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  1 contient  52  mots\n",
      " \n",
      " \n",
      "['angus', 'harry', 'ken', 'heather', 'mont', 'wor', 'dy', 'bobby', 'redd', 'abu', 'ira', 'ny', 'marc', 'dan', 'sh', 'ker', 'ted', 'turner', 'wy', 'wi', 'noel', 'doe', 'sally', 'boer', 'teamster', 'ed', 'holt', 'no1', 'drudge', 'wh', 'stan', 'ty', 'smith', 'ford', 'cud', 'batman', 'beck', 'penn', 'glen', 'twain', 'miller', 'ck', 'ing', 'lorraine', 'ned', 'mak', 'porter', 'colin', 'ling', 'bec', 'dana', 'whi']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  2 contient  32  mots\n",
      " \n",
      " \n",
      "['season', 'toon', 'tale', 'film', 'animation', 'remake', 'trek', 'voyage', 'journey', 'epic', 'story', 'cartoon', 'adventure', 'character', 'adventurer', 'song', 'narrative', 'hero', 'odyssey', 'expedition', 'episode', 'plot', 'chronicle', 'flashback', 'trip', 'sequel', 'cartoonist', 'movie', 'novel', 'album', 'homer', 'explorer']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  3 contient  74  mots\n",
      " \n",
      " \n",
      "['government', 'county', 'community', 'group', 'fellow', 'student', 'city', 'administration', 'frontier', 'official', 'state', 'professor', 'league', 'team', 'society', 'member', 'institute', 'college', 'staff', 'council', 'province', 'locality', 'prof', 'university', 'alumnus', 'teacher', 'school', 'emirate', 'town', 'senior', 'capitol', 'instruction', 'game', 'veteran', 'center', 'club', 'parent', 'federal', 'participation', 'capital', 'area', 'field', 'union', 'separation', 'elite', 'resident', 'high-school', 'dean', 'organization', 'network', 'education', 'representative', 'division', 'homeland', 'unit', 'volunteer', 'region', 'metro', 'institution', 'centre', 'beneficiary', 'hotbed', 'statewide', 'frontline', 'association', 'campus', 'graduate', 'participant', 'educational', 'academy', 'municipal', 'emeritus', 'heartland', 'hub']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  4 contient  69  mots\n",
      " \n",
      " \n",
      "['natural', 'life', 'miracle', 'mind', 'real', 'nature', 'limbo', 'grand', 'hapless', 'live', 'heart', 'namesake', 'death', 'beauty', 'counterpart', 'wild', 'living', 'runaway', 'gift', 'destiny', 'dead', 'giant', 'monster', 'imaginary', 'soul', 'identity', 'twin', 'body', 'name', 'supreme', 'creator', 'homegrown', 'actual', 'head', 'creation', 'reality', 'nick', 'lone', 'hybrid', 'die', 'existence', 'fantasy', 'politic', 'unreal', 'ghost', 'grace', 'phantom', 'grave', 'mystery', 'brain', 'pre-eminently', 'nightmare', 'master', 'disappearance', 'non-reality', 'allure', 'brilliance', 'ultimate', 'everyday', 'pesky', 'genius', 'predecessor', 'toll', 'big-time', 'epitome', 'dream', 'paradise', 'conscience', 'title']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  5 contient  33  mots\n",
      " \n",
      " \n",
      "['bell', 'bomb', 'early-warning', 'plane', 'explosive', 'satellite', 'weapon', 'gun', 'ring', 'ballistic', 'missile', 'trainer', 'boxing', 'train', 'contrail', 'pilot', 'timer', 'blast', 'clock', 'fly-by', 'ammo', 'bout', 'training', 'aviation', 'flight', 'sabre', 'cannon', 'dagger', 'knife', 'clockwork', 'explosion', 'airport', 'barrel']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  6 contient  27  mots\n",
      " \n",
      " \n",
      "['fiction', 'tradition', 'culture', 'politics', 'economy', 'capitalism', 'filmmaker', 'economics', 'history', 'socialist', 'libertarian', 'documentary', 'realism', 'journalism', 'literature', 'philosophy', 'bestseller', 'nonfiction', 'medicine', 'realist', 'journalistic', 'liberalism', 'marxism', 'romanticism', 'psychology', 'photojournalism', 'documentarian']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  7 contient  39  mots\n",
      " \n",
      " \n",
      "['usa', 'american', 'europe', 'japan', 'canadian', 'asian', 'european', 'china', 'america', 'sydney', 'asia', 'italy', 'olympic', 'uk', 'canada', 'australian', 'england', 'germany', 'armenia', 'spain', 'chinese', 'mexico', 'german', 'russia', 'vancouver', 'ottawa', 'olympics', 'montreal', 'australia', 'british', 'melbourne', 'portugal', 'bulgaria', 'taiwan', 'japanese', 'greece', 'poland', 'brit', 'britain']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  8 contient  20  mots\n",
      " \n",
      " \n",
      "['meat', 'agriculture', 'farmer', 'pastoralists', 'pastoralist', 'rural', 'cow', 'sheep', 'slaughter', 'milk', 'ag', 'goat', 'grazing', 'farm', 'dairy', 'hog', 'livestock', 'beef', 'bull', 'agricultural']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  9 contient  48  mots\n",
      " \n",
      " \n",
      "['wheat', 'rice', 'peanut', 'plant', 'leaf', 'cherry', 'blossom', 'bloom', 'ash', 'tree', 'tulip', 'crop', 'greenhouse', 'flower', 'tea', 'hydroponics', 'weaver', 'root', 'vegetable', 'blooming', 'bush', 'seed', 'tomato', 'monkey', 'chocolate', 'maple', 'syrup', 'bud', 'onion', 'coffee', 'rat', 'bonsai', 'wood', 'prairie', 'grass', 'acorn', 'quilt', 'carrot', 'hothouse', 'olive', 'nit', 'banana', 'oak', 'guinea', 'nursery', 'candy', 'loom', 'palm']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  10 contient  26  mots\n",
      " \n",
      " \n",
      "['will', 'could', 'must', 'may', 'might', 'wont', 'should', 'wouldnt', 'don', 'haven', 'can', 'doesn', 'would', 'cannot', 'isn', 'dont', 'doesnt', 'gotta', 'wouldn', 'cant', 'lemme', 'gonna', 'wil', 'shall', 'didnt', 'wld']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  11 contient  22  mots\n",
      " \n",
      " \n",
      "['migratory', 'migration', 'immigration', 'dispersal', 'relocation', 'long-distance', 'transportation', 'traffic', 'transport', 'trucking', 'immigrant', 'freight', 'refugee', 'congestion', 'humanitarian', 'transit', 'airlift', 'long-haul', 'short-haul', 'influx', 'evacuation', 'gridlock']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  12 contient  30  mots\n",
      " \n",
      " \n",
      "['digg', 'thoreau', 'time.com', 'wired.com', 'examiner.com', 'npr', 'nytimes.com', 'alt', 'gawker', 'stormfront', 'usatoday.com', 'guardian.co.uk', 'webby', 'artikel', 'orkut', 'msnbc.com', 'hannity', 'cbc.ca', 'drupal', 'oped', 'latimes.com', 'forbes.com', 'dailykos', 'blip.tv', 'dramatica', 'allafrica.com', 'wikipedia', 'telegraph.co.uk', 'diff', 'encyclopedia']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  13 contient  108  mots\n",
      " \n",
      " \n",
      "['a', 'those', 'most', 'our', 'all', 'new', 'preliminary', 'little', 'an', 'any', 'no', 'my', 'main', 'next', 'these', 'one', 'their', 'vary', 'present', 'basic', 'third', 'many', 'general', 'certain', 'future', 'whole', 'another', 'familiar', 'same', 'few', 'past', 'traditional', 'your', 'special', 'first', 'popular', 'other', 'universal', 'major', 'without', 'single', 'entire', 'exclusive', 'such', 'multiple', 'every', 'several', 'recent', 'last', 'current', 'core', 'his', 'earlier', 'central', 'some', 'own', 'principal', 'separate', 'different', 'available', 'long-term', 'favorite', 'standard', 'both', 'various', 'opposite', 'old', 'classic', 'modern', 'chief', 'former', 'final', 'complementary', 'independent', 'exactly', 'abnormal', 'comparable', 'her', 'each', 'fundamental', 'complex', 'additional', 'second', 'upcoming', 'spontaneous', 'secondary', 'obligatory', 'limited', 'unaltered', 'usual', 'previous', 'original', 'normal', 'primary', 'long-standing', 'abundant', 'common', 'correlative', 'congruent', 'varied', 'random', 'specific', 'superior', 'mixed', 'norm', 'roughly', 'so-called', 'unchanging']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  14 contient  46  mots\n",
      " \n",
      " \n",
      "['silly', 'scary', 'off-the-charts', 'ridiculous', 'out-of-touch', 'stupid', 'weird', 'bizarre', 'strange', 'industry-friendly', 'scaled-back', 'outdated', 'hypocritical', 'worthless', 'unclear', 'vague', 'rusty', 'skeptical', 'idiotic', 'freaky', 'dishonest', 'laughable', 'untrustworthy', 'oddball', 'inane', 'sloppy', 'subpar', 'off-the-mark', 'senseless', 'pathetic', 'certifiably', 'sceptical', 'out-of-step', 'crappy', 'incomprehensible', 'offbeat', 'disingenuous', 'revenue-neutral', 'wait-and-see', 'deficient', 'lousy', 'fuzzy', 'shabby', 'unpersuaded', 'inconclusive', 'creepy']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  15 contient  27  mots\n",
      " \n",
      " \n",
      "['explore', 'monitor', 'regulate', 'update', 'fix', 'examine', 'monitoring', 'suspend', 'revise', 'upgrade', 'investigate', 'cancel', 'supervise', 'reassess', 'rewrite', 'alignment', 'reschedule', 'defer', 'tweak', 'align', 'postpone', 'televise', 'recalculate', 'assess', 'determine', 'inspect', 'coordinate']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  16 contient  45  mots\n",
      " \n",
      " \n",
      "['ap', 'ac', 'ca', 'lo', 'mich', 'sen', 'ben', 'dc', 'mit', 'vol', 'iv', 'tr', 'az', 'ar', 'ii', 'fe', 'fab', 'cont', 'em', 'id', 'ab', 'meg', 'bi', 'sm', 'ch', 'xi', 'ob', 'mac', 'dem', 'ter', 'el', 'va', 'van', 'com', 'ir', 'fr', 'trans', 'dow', 'ist', 'fl', 'vi', 'ff', 'vo', 'ea', 'han']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  17 contient  23  mots\n",
      " \n",
      " \n",
      "['confirm', 'refute', 'implicate', 'exonerate', 'downplay', 'discredit', 'ignore', 'absolve', 'disproves', 'contradict', 'verify', 'disprove', 'falsify', 'disbelieve', 'debunk', 'debunks', 'embarrass', 'debunked', 'dismiss', 'vindicate', 'refutes', 'validate', 'bode']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  18 contient  29  mots\n",
      " \n",
      " \n",
      "['home', 'mountain', 'house', 'property', 'resort', 'land', 'oceanfront', 'summit', 'hill', 'family', 'vacation', 'subterranean', 'retreat', 'climb', 'estate', 'cave', 'peak', 'underwater', 'mansion', 'ruin', 'elevation', 'cliff', 'hideaway', 'mire', 'hotel', 'ridge', 'ocean-view', 'villa', 'wreck']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  19 contient  20  mots\n",
      " \n",
      " \n",
      "['accountability', 'subjectivity', 'legitimacy', 'stewardship', 'crony', 'policymaking', 'corrupt', 'credibility', 'bureaucracy', 'politicization', 'credibilty', 'distortion', 'credence', 'crooked', 'corruption', 'manipulation', 'accountable', 'deniability', 'egotism', 'governance']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  20 contient  74  mots\n",
      " \n",
      " \n",
      "['urge', 'fail', 'need', 'believe', 'belive', 'enjoy', 'want', 'argue', 'agree', 'guess', 'accept', 'invitation', 'consider', 'love', 'understand', 'like', 'hate', 'favor', 'feel', 'doubt', 'recommend', 'think', 'advise', 'conclude', 'wonder', 'wish', 'oppose', 'sense', 'dare', 'predict', 'suspect', 'forgot', 'flunk', 'fails', 'suggest', 'assume', 'try', 'favour', 'suppose', 'refuse', 'expect', 'appreciate', 'forget', 'remember', 'forgotten', 'regard', 'invite', 'disagree', 'realise', 'attempt', 'propose', 'admit', 'acknowledge', 'foresee', 'respect', 'contend', 'grasp', 'imagine', 'despise', 'contemplate', 'accepted', 'reject', 'approve', 'concede', 'accepts', 'comprehend', 'insist', 'prefer', 'recall', 'concur', 'tend', 'endorse', 'realize', 'disagreed']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  21 contient  76  mots\n",
      " \n",
      " \n",
      "['auth', 'int', 'ct', 'temp', 'dr', 'pb', 'alpha', 'phi', 'co2', 'conf', 'uw', 'nw', 'rds', 'hr', 'sec', 'nat', 'cst', 'max', 'thurs', 'min', 'pr', 'gt', 'cl', 'bp', 'lt', 'comp', 'pf', 'md', 'gr', 'nite', 'sr', 'kb', 'tx', 'ht', 'nj', 'vp', 'wks', 'gl', 'mil', 'datetime', 'rb', 'xtra', 'celsius', '12h', 'fm', 'mag', 'wk', 'ph', 'colo', 'jr', 'mr', 'beta', 'br', 'nh', 'sci', 'mk', 'mth', 'op', 'warner', '2day', 'luv', 'co', 'cal', '30min', 'g77', 'reg', 'gf', 'st', 'rad', 'str', 'maj', 'sc', 'exp', 'tp', 'std', 'assoc']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  22 contient  30  mots\n",
      " \n",
      " \n",
      "['bird', 'phoenix', 'lizard', 'gecko', 'snake', 'thrush', 'fox', 'iguana', 'eagle', 'egg', 'wolf', 'lemming', 'griffin', 'robin', 'blackbird', 'wolverine', 'chicken', 'panda', 'newt', 'waterfowl', 'swan', 'lion', 'duck', 'groundhog', 'bunny', 'panther', 'chick', 'penguin', 'beaver', 'hibernate']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  23 contient  19  mots\n",
      " \n",
      " \n",
      "['800,000', '30000', '3,000', '6bn', '3k', '500k', '50million', '7,500', '8000', '10,000', '30,000', '4000', '3000', '25,000', '43m', '200,000', '7,000', '15k', '1,000']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  24 contient  18  mots\n",
      " \n",
      " \n",
      "['please', 'praise', 'thanks', 'plz', 'pls', 'bye', 'dear', 'thanx', 'thank', 'thx', 'goody', 'compliment', 'kudos', 'hello', 'sir', 'thnx', 'oy', 'amen']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  25 contient  38  mots\n",
      " \n",
      " \n",
      "['hack', 'stall', 'pat', 'bet', 'flounder', 'stunner', 'boffin', 'kibosh', 'sideline', 'flip-flop', 'crunch', 'ass', 'hash', 'freak', 'right-winger', 'nerd', 'hug', 'clunker', 'winger', 'underbelly', 'bust', 'butt', 'upside', 'barney', 'hugger', 'shocker', 'groupie', 'loser', 'dud', 'hacker', 'pervert', 'livewire', 'fudge', 'flipflop', 'cutie', 'ups', 'lowdown', 'flop']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  26 contient  13  mots\n",
      " \n",
      " \n",
      "['reopen', 'awaken', 'close', 'opening', 'closure', 'open', 'closer', 'wakeup', 'shuts', 'shut', 'wake', 'door', 'woken']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  27 contient  28  mots\n",
      " \n",
      " \n",
      "['glacier', 'artic', 'melt', 'arctic', 'antarctica', 'ski', 'ice', 'thaw', 'snowy', 'glacial', 'frozen', 'freeze', 'hockey', 'cream', 'kayak', 'iceberg', 'polar', 'igloo', 'tundra', 'snow-laden', 'snowless', 'iced', 'antarctic', 'sled', 'glaciologists', 'ice-covered', 'snowman', 'skiing']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  28 contient  14  mots\n",
      " \n",
      " \n",
      "['cafe', 'grape', 'wine', 'vino', 'bottle', 'brewer', 'starbucks', 'beer', 'mead', 'margarita', 'partyers', 'speakeasy', 'partiers', 'caf']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  29 contient  46  mots\n",
      " \n",
      " \n",
      "['vulnerable', 'high', 'serious', 'strong', 'hugh', 'sizable', 'large', 'small', 'long', 'vast', 'extreme', 'hard', 'poor', 'big', 'hardest', 'delicate', 'low', 'moderate', 'broad', 'rich', 'lean', 'huge', 'powerful', 'weak', 'massive', 'tough', 'super', 'sensitive', 'slim', 'intense', 'tiny', 'tepid', 'heavy', 'short', 'soft', 'susceptible', 'deep', 'severe', 'mild', 'ginormous', 'solid', 'thin', 'steady', 'harder', 'poorer', 'toughest']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  30 contient  29  mots\n",
      " \n",
      " \n",
      "['deal', 'accord', 'hope', 'sign', 'stake', 'denial', 'renewal', 'signing', 'affirmation', 'negotiate', 'renew', 'compromise', 'dedication', 'promise', 'agreement', 'negotiation', 'pledge', 'sacrifice', 'acceptance', 'behest', 'sake', 'commitment', 'unwillingness', 'inability', 'co-signing', 'reaffirmation', 'honor', 'plea', 'willingness']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  31 contient  20  mots\n",
      " \n",
      " \n",
      "['peruvian', 'tibetan', 'irish', 'cisco', 'hispanic', 'inuit', 'scottish', 'mayan', 'eskimo', 'scot', 'tibet', 'austrian', 'latin', 'trad', 'dalai', 'lama', 'latino', 'spanish', 'scotsman', 'brazilian']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  32 contient  28  mots\n",
      " \n",
      " \n",
      "['forest', 'ecosystem', 'environmentalist', 'eco', 'environmental', 'sustainability', 'biodiversity', 'environmentalism', 'renewable', 'wildlife', 'conservation', 'habitat', 'greenpeace', 'sustainable', 'tropical', 'enviro', 'ecology', 'deforestation', 'ecologic', 'conservationist', 'rainforest', 'conservancy', 'reforestation', 'wetland', 'hydrology', 'forestry', 'ecological', 'greenway']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  33 contient  39  mots\n",
      " \n",
      " \n",
      "['driver', 'park', 'pew', 'car', 'lane', 'tire', 'aisle', 'automotive', 'motorsports', 'nascar', 'ferris', 'cart', 'tudor', 'elevator', 'limo', 'slush', 'legged', 'auto', 'hood', 'toolshed', 'snowdrift', 'parking', 'brake', 'sidewalk', 'driveway', 'blower', 'ride', 'pothole', 'bike', 'amusement', 'carpool', '2ft', 'yard', 'backyard', 'snowplow', 'weatherboarding', 'horse', 'tipper', 'wheel']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  34 contient  62  mots\n",
      " \n",
      " \n",
      "['honest', 'simple', 'cute', 'active', 'creative', 'porous', 'medium', 'clever', 'elliptical', 'fun', 'frank', 'brave', 'fancy', 'hostile', 'expensive', 'fluent', 'tolerant', 'glossy', 'raw', 'lucrative', 'tart', 'verdant', 'attractive', 'neutral', 'humble', 'dynamic', 'rugged', 'delicious', 'rough', 'jolly', 'profitable', 'smart', 'interpretive', 'fragrant', 'interactive', 'niche', 'cheaply', 'flammable', 'plain', 'productive', 'nicer', 'slick', 'fresh', 'transformative', 'crude', 'malleable', 'stubborn', 'healthy', 'steep', 'partisan', 'aromatic', 'cheap', 'truthful', 'passive', 'ardent', 'digital', 'loyal', 'blitz', 'quiet', 'respectful', 'visual', 'dumb']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  35 contient  42  mots\n",
      " \n",
      " \n",
      "['18', '25', '14', '40', '26', '12', '30', '22', '24', '10', '11', '21', '20', '15', '13', '33', '16', '52', '44', '39', '27', '28', '29', '31', '32', '34', '35', '36', '59', '09', '37', '55', '50', '19', '17', '43', '08', '07', '02', '45', '48', '23']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  36 contient  71  mots\n",
      " \n",
      " \n",
      "['bite', 'push', 'pour', 'poison', 'cleaner', 'clean', 'cut', 'sink', 'trigger', 'bury', 'kick', 'pull', 'reset', 'wear', 'hang', 'drawn', 'sting', 'tie', 'bump', 'sweep', 'shave', 'swallow', 'ditch', 'rip', 'shake', 'smack', 'slap', 'boost', 'stick', 'slam', 'dump', 'shed', 'rid', 'shred', 'pinch', 'grip', 'wash', 'drain', 'whack', 'contact', 'sever', 'dig', 'knock', 'shovel', 'pack', 'beat', 'scoop', 'punch', 'sprinkle', 'brush', 'stuck', 'jolt', 'snarl', 'scratch', 'tear', 'chop', 'pummel', 'puncture', 'scar', 'touch', 'wipe', 'chunk', 'lash', 'perk', 'draw', 'tap', 'drown', 'snap', 'shove', 'swamp', 'slice']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  37 contient  6  mots\n",
      " \n",
      " \n",
      "['chiller', 'conditioner', 'refrigerant', 'buster', 'yin', 'yang']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  38 contient  52  mots\n",
      " \n",
      " \n",
      "['computer', 'schedule', 'pen', 'lesson', 'gear', 'tv', 'test', 'curve', 'software', 'technology', 'discovery', 'innovation', 'diary', 'supercomputer', 'experiment', 'desk', 'console', 'television', 'quiz', 'visualization', 'mobile', 'phone', 'machine', 'load', 'timeline', 'radio', 'graph', 'synching', 'logbook', 'pencil', 'ink', 'homework', 'calculator', 'application', 'invention', 'app', 'patent', 'teleprompter', 'tech', 'sync', 'exploration', 'lab', 'chart', 'installation', 'cell', 'setup', 'laboratory', 'broadcasting', 'device', 'math', 'newsdesk', 'calendar']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  39 contient  74  mots\n",
      " \n",
      " \n",
      "['evidence', 'measurable', 'bad', 'good', 'illegal', 'proof', 'wrong', 'true', 'right', 'effective', 'key', 'prove', 'false', 'important', 'comprehensive', 'necessary', 'best', 'reliable', 'safe', 'secure', 'possible', 'full', 'timely', 'logic', 'proper', 'perfect', 'ok', 'truth', 'commonsense', 'related', 'useful', 'significant', 'fair', 'complete', 'rational', 'logical', 'prominent', 'precise', 'valid', 'baseless', 'consistent', 'informative', 'unsubstantiated', 'helpful', 'practical', 'relevant', 'well-founded', 'decent', 'fine', 'okay', 'credible', 'proven', 'legit', 'robust', 'integral', 'valuable', 'visible', 'observable', 'prompt', 'definitive', 'critical', 'accurate', 'vital', 'essential', 'better', 'realistic', 'logically', 'legitimate', 'tangible', 'reasonable', 'sensible', 'handy', 'legal', 'worthwhile']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  40 contient  24  mots\n",
      " \n",
      " \n",
      "['human', 'gore', 'race', 'class', 'animal', 'codex', 'labor', 'labour', 'canine', 'uncensored', 'gender', 'sex', 'male', 'censor', 'abstinence', 'waterboarding', 'slavery', 'prostitution', 'abortion', 'anatomy', 'masturbation', 'onanism', 'redaction', 'prostitute']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  41 contient  25  mots\n",
      " \n",
      " \n",
      "['fight', 'war', 'combat', 'struggle', 'attack', 'petition', 'battle', 'boycott', 'sortie', 'anti-union', 'engagement', 'rally', 'skirmish', 'opposition', 'protest', 'march', 'fortress', 'snub', 'picket', 'battling', 'conflict', 'invasion', 'siege', 'assault', 'ambush']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  42 contient  27  mots\n",
      " \n",
      " \n",
      "['senate', 'congress', 'politician', 'lawmaker', 'democracy', 'republican', 'governor', 'legislative', 'bipartisan', 'senator', 'citizen', 'democrat', 'democratic', 'monarchy', 'mayor', 'parliament', 'republic', 'recess', 'commerce', 'chamber', 'legislature', 'patriot', 'caucus', 'congressman', 'bipartisanship', 'legislator', 'congressional']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  43 contient  10  mots\n",
      " \n",
      " \n",
      "['biofuel', 'bioethicists', 'ethanol', 'cleantech', 'public-policy', 'think-tanks', 'biofuels', 'bioscience', 'biotech', 'biotechnology']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  44 contient  79  mots\n",
      " \n",
      " \n",
      "['how', 'this', 'thing', 'that', 'it', 'because', 'there', 'if', 'here', 'so', 'well', 'when', 'least', 'what', 'or', 'perhaps', 'then', 'either', 'due', 'once', 'nothing', 'before', 'why', 'though', 'anymore', 'after', 'later', 'lot', 'but', 'since', 'despite', 'instead', 'kind', 'enough', 'something', 'which', 'where', 'too', 'while', 'ago', 'as', 'unless', 'regardless', 'amid', 'except', 'maybe', 'everything', 'plus', 'otherwise', 'during', 'midst', 'again', 'type', 'bunch', 'although', 'however', 'sort', 'whether', 'wherever', 'whenever', 'anyway', 'stuff', 'itself', 'bit', 'kinda', 'else', 'nowhere', 'slightly', 'anything', 'spite', 'everywhere', 'dispite', 'directly', 'thus', 'anywhere', 'whatever', 'everytime', 'whose', 'besides']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  45 contient  99  mots\n",
      " \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "['henderson', 'graham', 'klein', 'rogers', 'hansen', 'cahill', 'denis', 'hayes', 'goldberg', 'barrett', 'stevens', 'milton', 'jacob', 'webb', 'sebastian', 'jones', 'clive', 'thompson', 'simpson', 'armstrong', 'mann', 'jenkins', 'kyle', 'levin', 'stein', 'benjamin', 'phillips', 'knott', 'kemp', 'joseph', 'colbert', 'walter', 'williams', 'dixon', 'goodman', 'justin', 'wv', 'ross', 'elliott', 'turnbull', 'thomas', 'malcolm', 'mccarthy', 'richardson', 'perkins', 'brennan', 'adam', 'norris', 'clarkson', 'abraham', 'lincoln', 'winston', 'churchill', 'shannon', 'arnold', 'ian', 'katz', 'locke', 'kennedy', 'floyd', 'reagan', 'margaret', 'roosevelt', 'peterson', 'katrina', 'alan', 'bryan', 'walsh', 'dylan', 'robinson', 'brandon', 'noah', 'ark', 'wayne', 'benny', 'russell', 'giles', 'coleman', 'terry', 'gardner', 'garrett', 'chavez', 'harris', 'adler', 'morton', 'charlie', 'cohen', 'weber', 'henry', 'bieber', 'roy', 'spencer', 'gregory', 'hopkins', 'alec', 'alexander', 'haiti', 'carter', 'johnson']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  46 contient  32  mots\n",
      " \n",
      " \n",
      "['kar', 'ge', 'ma', 'pa', 'har', 'bo', 'ga', 'om', 'jeg', 'og', 'wa', 'aap', 'ni', 'mo', 'pri', 'jo', 'cha', 'bho', 'hum', 'hon', 'po', 'ba', 'bal', 'ho', 'ki', 'hu', 'ding', 'som', 'ri', 'nan', 'gb', 'ko']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  47 contient  24  mots\n",
      " \n",
      " \n",
      "['more', 'than', 'faster', 'much', 'browner', 'less', 'greener', 'warmer', 'wetter', 'rather', 'pricier', 'longer', 'greenest', 'hotter', 'cooler', 'cheaper', 'heavier', 'colder', 'thatn', 'shorter', 'smellier', 'weirder', 'lighter', 'funnier']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  48 contient  31  mots\n",
      " \n",
      " \n",
      "['presentation', 'conference', 'meeting', 'panelist', 'podcast', 'gathering', 'lecture', 'sponsorship', 'host', 'sponsor', 'co-host', 'sermon', 'confab', 'guest', 'webcast', 'speech', 'capstone', 'assembly', 'fete', 'webinar', 'hustings', 'colloquium', 'internship', 'tea-party', 'cosponsor', 'briefing', 'mini-grants', 'session', 'speaker', 'co-op', 'workshop']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  49 contient  15  mots\n",
      " \n",
      " \n",
      "['activist', 'investor', 'advocate', 'protester', 'advocacy', 'stakeholder', 'anti-poverty', 'campaigner', 'activism', 'lobbyist', 'shareholder', 'lobby', 'taxpayer', 'grassroots', 'dividend']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  50 contient  14  mots\n",
      " \n",
      " \n",
      "['preview', 'near-record', 'launch', 'long-awaited', 'premiere', 'blast-off', 'celebrity-filled', 'ballyhooed', 'appearance', 'record-breaking', 'debut', 'never-before-seen', 'record-setting', 'heatwave']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  51 contient  25  mots\n",
      " \n",
      " \n",
      "['mercury', 'lake', 'mine', 'valley', 'coal', 'drill', 'drilling', 'steam', 'mining', 'rig', 'tungsten', 'acupuncture', 'river', 'engine', 'hydropower', 'pond', 'basin', 'turbine', 'generator', 'off-shore', 'tugboat', 'dam', 'offshore', 'refinery', 'miner']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  52 contient  37  mots\n",
      " \n",
      " \n",
      "['mental', 'science', 'scientific', 'academic', 'clinical', 'commercial', 'economic', 'service', 'industrial', 'military', 'financial', 'social', 'utility', 'public', 'technical', 'political', 'private', 'mainstream', 'emotional', 'meta', 'psychological', 'finacial', 'intellectual', 'civil', 'abstract', 'physical', 'fringe', 'professional', 'pseudo-scientific', 'mechanistic', 'psychic', 'institutional', 'observational', 'behavioral', 'unforseen', 'data-driven', 'peer-reviewed']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  53 contient  34  mots\n",
      " \n",
      " \n",
      "['production', 'buyer', 'buying', 'demand', 'price', 'trade', 'merchant', 'broker', 'clearinghouse', 'bank', 'shopping', 'market', 'swap', 'retail', 'stock', 'product', 'retailer', 'trading', 'consumer', 'home-improvement', 'supply', 'transaction', 'manufacture', 'exchange', 'store', 'shop', 'banker', 'purchasing', 'commodity', 'distribution', 'delivery', 'mall', 'one-stop-shop', 'one-stop']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  54 contient  26  mots\n",
      " \n",
      " \n",
      "['p2', 'g8', '0', '2c', '8p', 'e2', 'c3', '2.89', '912', '6.30', 'pm', '873', '1010', 'n2', '93.5', '11a', '2p', '1001', '4.10', '2132', '2b', '91.3', '756', 'a5', '26.95', '33,700']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  55 contient  33  mots\n",
      " \n",
      " \n",
      "['al', 'ha', 'per', 'la', 'un', 'et', 'dio', 'se', 'ani', 'ne', 'en', 'ex', 'sa', 'asa', 'pas', 'contra', 'mi', 'de', 'non', 'con', 'di', 'pe', 'versus', 'ai', 'est', 'cu', 'ou', 'pro', 'aka', 'au', 'da', 'su', 'tu']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  56 contient  57  mots\n",
      " \n",
      " \n",
      "['upper', 'platform', 'spin', 'discus', 'brace', 'round', 'bat', 'yorkers', 'wire', 'floor', 'strand', 'ground', 'front', 'top', 'telegraph', 'party', 'groove', 'drum', 'line', 'shield', 'side', 'bottom', 'flag', 'ball', 'corner', 'string', 'base', 'jam', 'quarter', 'wing', 'pole', 'column', 'x2', 'rope', 'lid', 'jack', 'coin', 'middle', 'row', 'pitch', 'trap', 'foundation', 'compass', 'bronze', 'roof', 'anchor', 'gold', 'square', 'midway', 'circle', 'seal', 'snare', 'rim', 'vertical', 'plate', 'dial', 'jig']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  57 contient  35  mots\n",
      " \n",
      " \n",
      "['fuck', 'screw', 'doodoo', 'ya', 'damn', 'workin', 'suck', 'dis', 'sic', 'backstabbed', 'heck', 'darn', 'ye', 'ol', 'lyin', 'dang', 'piss', 'effed', 'goddammit', 'dat', 'stfu', 'hell', 'fuckin', 'doin', 'eff', 'yo', 'assed', 'stoopid', 'shitload', 'gon', 'lil', 'gettin', 'smarta', 'dickens', 'wised']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  58 contient  20  mots\n",
      " \n",
      " \n",
      "['ft', 'million', 'kuna', 'billion', 'mole', 'dollar', 'ton', 'cc', 'pound', 'mile', 'trillion', 'mol', 'euro', 'inch', 'meter', 'gallon', 'lb', 'mm', 'oz', 'watt']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  59 contient  36  mots\n",
      " \n",
      " \n",
      "['crazy', 'ignorant', 'hysteria', 'impotent', 'panic', 'insane', 'unwashed', 'ill', 'mad', 'chaotic', 'toothless', 'blind', 'knee-jerk', 'reckless', 'desperate', 'chaos', 'hysterical', 'frenzy', 'blindness', 'clueless', 'numb', 'sore', 'orderly', 'sick', 'illiterate', 'demented', 'suicidal', 'hysteric', 'thoughtless', 'paranoid', 'delusional', 'drunk', 'drunken', 'uninformed', 'madness', 'one-eyed']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  60 contient  27  mots\n",
      " \n",
      " \n",
      "['surprise', 'sigh', 'wrath', 'horror', 'shock', 'unrest', 'backlash', 'relief', 'furor', 'rage', 'turmoil', 'instability', 'solitude', 'mockery', 'scrutiny', 'comfort', 'attention', 'scorn', 'ridicule', 'outrage', 'joy', 'disappointment', 'pain', 'discontent', 'warmth', 'solace', 'anger']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  61 contient  26  mots\n",
      " \n",
      " \n",
      "['blog', 'researcher', 'scientist', 'correspondent', 'economist', 'biologist', 'author', 'writer', 'letter-writer', 'blogosphere', 'politico', 'editor', 'wonk', 'columnist', 'commentator', 'reader', 'ecologist', 'physicist', 'journalist', 'theologian', 'blogger', 'reporter', 'contributor', 'pundit', 'analyst', 'scholar']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  62 contient  32  mots\n",
      " \n",
      " \n",
      "['toe', 'hair', 'foot', 'eye', 'ear', 'glove', 'teeth', 'smile', 'hand', 'fingernail', 'rectum', 'kidney', 'camera', 'lip', 'bald', 'beard', 'eyeball', 'grin', 'mouth', 'vagina', 'lens', 'shank', 'finger', 'arm', 'boot', 'shoe', 'shin', 'nail', 'tooth', 'thumb', 'throat', 'gaze']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  63 contient  17  mots\n",
      " \n",
      " \n",
      "['syed', 'meena', 'ramesh', 'delhi', 'rohit', 'shyam', 'raj', 'varanasi', 'noida', 'uttar', 'pradesh', 'pune', 'dubey', 'menon', 'kolkata', 'krishna', 'islamabad']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  64 contient  45  mots\n",
      " \n",
      " \n",
      "['u', 'abt', 'i', 'tht', 'thr', 'th', 'ur', 're', 'tha', 'althoug', 'itz', 'ppl', 'fro', 'cuz', 'yr', 'b4', 'etc', 'forbiden', 'mabye', 'agre', 'soo', 'bc', 'newsflash', 'imo', 'htink', 'fwiw', 'ot', 'esp', 'ike', 'btw', 'teh', 'ie', 'everythin', 'believ', 'somethings', 'vry', 'secondly', 'altho', 'fyi', 'tho', 'fo', 'ppls', 'wht', 'changin', 'thi']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  65 contient  21  mots\n",
      " \n",
      " \n",
      "['vatican', 'jesus', 'angel', 'carol', 'thanksgiving', 'god', 'christian', 'evil', 'lord', 'methodist', 'christianity', 'bible', 'nazism', 'islam', 'pope', 'prophet', 'hitler', 'catholic', 'devil', 'karma', 'easter']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  66 contient  19  mots\n",
      " \n",
      " \n",
      "['recycle', 'waste', 'trash', 'single-use', 'plastic', 'bag', 'junk', 'stack', 'packaging', 'manila', 'package', 'pile', 'bin', 'envelope', 'accumulation', 'garbage', 'tupperware', 'heap', 'accumulate']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  67 contient  23  mots\n",
      " \n",
      " \n",
      "['intensify', 'impact', 'affect', 'effect', 'intensified', 'influence', 'alter', 'affected', 'exaggerated', 'exaggerates', 'underestimated', 'underway', 'outweigh', 'negate', 'hurt', 'weighs', 'misread', 'alters', 'negates', 'overrate', 'outnumbers', 'weigh', 'exaggerate']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  68 contient  29  mots\n",
      " \n",
      " \n",
      "['flaw', 'solution', 'damage', 'peril', 'threat', 'vulnerability', 'danger', 'problem', 'risk', 'harm', 'proble', 'hazard', 'distraction', 'roadblock', 'dilemma', 'setback', 'nuisance', 'quandry', 'curse', 'menace', 'disruption', 'jigsaw', 'puzzle', 'barrier', 'bane', 'interference', 'hiccup', 'unsolved', 'lifeline']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  69 contient  14  mots\n",
      " \n",
      " \n",
      "['climate', 'storm', 'tornado', 'weather', 'prediction', 'meteorology', 'meteorologist', 'climatologist', 'forecast', 'hurricane', 'weathercasters', 'weatherman', 'forecasting', 'forecaster']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  70 contient  34  mots\n",
      " \n",
      " \n",
      "['patient', 'business', 'industry', 'health', 'corporation', 'company', 'architect', 'care', 'audit', 'sector', 'doc', 'insurance', 'manufacturer', 'enterprise', 'corporate', 'healthcare', 'engineering', 'maker', 'sanitation', 'firm', 'foundry', 'profession', 'accountancy', 'engineer', 'vet', 'academia', 'e-health', 'career', 'insurer', 'architecture', 're-insurance', 'industy', 'doctor', 'med']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  71 contient  30  mots\n",
      " \n",
      " \n",
      "['sun', 'green', 'fairy', 'white', 'blinking', 'wave', 'black', 'dim', 'red', 'light', 'yellow', 'dark', 'brown', 'domino', 'rainbow', 'sky', 'bright', 'ray', 'blue', 'ripple', 'fading', 'fleeting', 'gray', 'grey', 'shadow', 'violet', 'unicorn', 'moon', 'flash', 'sunset']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  72 contient  77  mots\n",
      " \n",
      " \n",
      "['act', 'show', 'track', 'lead', 'support', 'play', 'notice', 'way', 'place', 'billing', 'lose', 'stretch', 'toward', 'end', 'help', 'win', 'trouble', 'credit', 'listing', 'call', 'cost', 'time', 'benefit', 'part', 'loss', 'advance', 'series', 'return', 'spot', 'loses', 'worth', 'rescue', 'order', 'set', 'towards', 'date', 'fit', 'advantage', 'free', 'aid', 'list', 'merit', 'worthiness', 'note', 'retuning', 'rank', 'pay', 'advancement', 'turn', 'yield', 'progress', 'sing', 'victory', 'card', 'ranked', 'record', 'backing', 'form', 'gain', 'tune', 'rent', 'course', 'expense', 'bother', 'role', 'charge', 'justify', 'warrant', 'match', 'feature', 'paid', 'fee', 'advanced', 'fold', 'backup', 'rating', 'assist']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  73 contient  35  mots\n",
      " \n",
      " \n",
      "['report', 'analysis', 'study', 'reporting', 'expert', 'morale', 'review', 'work', 'research', 'adviser', 'conduct', 'knowledge', 'panel', 'guru', 'advisory', 'advisor', 'advice', 'guidance', 'insider', 'board', 'wisdom', 'inquiry', 'request', 'chair', 'commission', 'investigation', 'bulletin', 'specialist', 'committee', 'intel', 'assessment', 'experience', 'probe', 'insight', 'intelligence']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  74 contient  17  mots\n",
      " \n",
      " \n",
      "['minister', 'bishop', 'episcopal', 'earl', 'admiral', 'royal', 'sultan', 'clergy', 'church', 'king', 'palace', 'duchess', 'imperial', 'navy', 'queen', 'prince', 'kingdom']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  75 contient  24  mots\n",
      " \n",
      " \n",
      "['wed', 'mother', 'age', 'birthday', 'grandson', 'wife', 'lover', 'wedding', 'married', 'uncle', 'sister', 'father', 'marriage', 'friend', 'born', 'neighbor', 'birth', 'colleague', 'pal', 'roommate', 'grandchild', 'daughter', 'brother', 'couple']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  76 contient  18  mots\n",
      " \n",
      " \n",
      "['brilliant', 'great', 'beautiful', 'nice', 'excellent', 'world-famous', 'superb', 'awesome', 'famous', 'unbelievable', 'tremendous', 'wonderful', 'terrific', 'lovely', 'eminent', 'renowned', 'world-renowned', 'famed']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  77 contient  8  mots\n",
      " \n",
      " \n",
      "['geopolitics', 'intergovernmental', 'non-proliferation', 'diplomatic', 'diplomacy', 'geopolitical', 'inter-governmental', 'inter-agency']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  78 contient  104  mots\n",
      " \n",
      " \n",
      "['look', 'compete', 'bring', 'do', 'say', 'attribute', 'read', 'see', 'learn', 'put', 'check', 'make', 'give', 'qualify', 'find', 'take', 'join', 'get', 'know', 'display', 'ask', 'marked', 'mention', 'explain', 'tell', 'watch', 'include', 'compare', 'treat', 'raise', 'seek', 'contain', 'offer', 'remind', 'warn', 'reading', 'follow', 'meet', 'receive', 'write', 'reach', 'pick', 'carry', 'cover', 'provide', 'teach', 'choose', 'visit', 'attend', 'displayed', 'testify', 'select', 'enter', 'mark', 'add', 'introduce', 'substitute', 'satisfy', 'ensure', 'pursue', 'share', 'speak', 'afford', 'send', 'repeat', 'fill', 'behave', 'alert', 'witness', 'remove', 'highlight', 'showcase', 'forewarn', 'imply', 'insure', 'dispatch', 'hire', 'discuss', 'clarify', 'achieve', 'beware', 'appoint', 'echo', 'communicate', 'specify', 'represent', 'sent', 'assure', 'connote', 'juxtapose', 'elect', 'distinguish', 'indicate', 'herald', 'replace', 'duplicate', 'inform', 'deliver', 'observe', 'insert', 'express', 'nominate', 'chosen', 'serve']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  79 contient  51  mots\n",
      " \n",
      " \n",
      "['nyc', 'mississippi', 'california', 'virginia', 'washington', 'colorado', 'york', 'alaska', 'florida', 'paris', 'maine', 'connecticut', 'chicago', 'wisconsin', 'brooklyn', 'montana', 'arkansas', 'nevada', 'hollywood', 'milwaukee', 'vermont', 'michigan', 'ohio', 'utah', 'houston', 'oregon', 'denver', 'dallas', 'philly', 'mid-atlantic', 'seattle', 'texas', 'orleans', 'massachusetts', 'baltimore', 'illinois', 'cali', 'montgomery', 'orlando', 'manitoba', 'midwest', 'atlanta', 'minnesota', 'maryland', 'newark', 'hawaii', 'berlin', 'jerusalem', 'pittsburgh', 'cincinnati', 'minneapolis']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  80 contient  39  mots\n",
      " \n",
      " \n",
      "['killer', 'culprit', 'conspiracy', 'rebel', 'abuse', 'racist', 'guilty', 'crime', 'cover-up', 'racism', 'drug', 'victim', 'steroid', 'wrongdoing', 'mafia-style', 'terrorism', 'guerrilla', 'violent', 'neglect', 'terrorist', 'suicide', 'gang', 'mob', 'guilt', 'homosexuality', 'homophobic', 'punishment', 'breakaway', 'rebellious', 'offense', 'abuser', 'predator', 'treason', 'substance', 'malpractice', 'serial', 'prescription', 'apex', 'violence']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le Cluster numéro :  81 contient  13  mots\n",
      " \n",
      " \n",
      "['50-50', 'award', 'roulette', 'probability', 'nobel', 'laureate', 'reward', 'odds', 'contest', 'lottery', 'competition', 'pulitzer', 'prize']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  82 contient  49  mots\n",
      " \n",
      " \n",
      "['rate', 'degree', 'tip', 'level', 'average', 'estimate', 'compute', 'sheet', 'ease', 'count', 'relative', 'limit', 'pressure', 'concentration', 'momentum', 'traction', 'assortment', 'glue', 'tension', 'number', 'coverage', 'centrifugal', 'balance', 'amount', 'projection', 'camp', 'variety', 'breakdown', 'binding', 'mass', 'figure', 'counting', 'percent', 'overall', 'minimum', 'magnitude', 'imbalance', 'extent', 'weight', 'diversity', 'absolute', 'aggregate', 'sum', 'build-up', 'exposure', 'calculation', 'lock-in', 'stickiness', 'gravity']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  83 contient  28  mots\n",
      " \n",
      " \n",
      "['global', 'national', 'indigenous', 'alien', 'stranger', 'foreign', 'local', 'sacred', 'international', 'small-scale', 'daily', 'regional', 'native', 'ancient', 'ceremony', 'two-day', 'ceremonial', 'annual', 'cross-cultural', 'quadrennial', 'ancestral', 'ritual', 'scale', 'tribal', 'one-man', 'holy', 'tribe', 'weekly']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  84 contient  16  mots\n",
      " \n",
      " \n",
      "['reform', 'development', 'mitigation', 'expansion', 'reduction', 'adaption', 'removal', 'prevention', 'adaptation', 'growth', 'abatement', 'stimulus', 'restoration', 'reorganization', 'modification', 'conversion']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  85 contient  15  mots\n",
      " \n",
      " \n",
      "['2010', '2009', '2000', '1992', '2008', '2007', '1971', '1905', '1995', '1978', '1953', '1772', '1816', '2011', '2003']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  86 contient  17  mots\n",
      " \n",
      " \n",
      "['scream', 'peep', 'whisper', 'boing', 'hurrah', 'bleat', 'cheer', 'shout', 'cry', 'coo', 'mutter', 'yack', 'squawk', 'yap', 'whine', 'boo', 'hoot']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  87 contient  27  mots\n",
      " \n",
      " \n",
      "['cap', 'clothing', 'hat', 'jacket', 'cape', 'jean', 'clothes', 'sleeve', 'cloth', 'shower', 'furniture', 'bed', 'bath', 'undies', 'nakedness', 'shirt', 'waist', 'naked', 'bunk', 'swimsuit', 'strap-on', 'coat', 'jersey', 'plaid', 'twill', 'pant', 'closet']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  88 contient  18  mots\n",
      " \n",
      " \n",
      "['angry', 'mocked', 'concerned', 'upset', 'duped', 'worried', 'annoyed', 'swayed', 'disturbed', 'slimmed', 'tricked', 'alarmed', 'displeased', 'surprised', 'undone', 're-thought', 'remade', 'challenged']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  89 contient  22  mots\n",
      " \n",
      " \n",
      "['campaign', 'election', 'office', 'post', 'electoral', 're-election', 'job', 'position', 'candidate', 'referendum', 'nomination', 'ballot', 'vote', 'nom', 'voting', 'vacancy', 'ticket', 'presidency', 'seat', 'voter', 'employment', 'candidacy']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  90 contient  17  mots\n",
      " \n",
      " \n",
      "['hunger', 'poverty', 'scarcity', 'shortage', 'famine', 'depletion', 'seasonal', 'drought', 'unemployment', 'downswing', 'homelessness', 'rebound', 'illiteracy', 'exhaustion', 'recession', 'unemployed', 'cyclical']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  91 contient  27  mots\n",
      " \n",
      " \n",
      "['speed', 'variability', 'efficiency', 'peace', 'justice', 'independence', 'freedom', 'persistence', 'fairness', 'sensitivity', 'equality', 'transparency', 'resilience', 'confidence', 'skepticism', 'trust', 'clarity', 'equity', 'scepticism', 'accuracy', 'adaptability', 'prudence', 'caution', 'uncertainty', 'prosperity', 'certainty', 'openness']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  92 contient  22  mots\n",
      " \n",
      " \n",
      "['forensics', 'trial', 'attorney', 'regulator', 'counsel', 'cop', 'watchdog', 'police', 'court', 'ombudsman', 'judge', 'suit', 'bail', 'officer', 'inspection', 'detective', 'jail', 'examiner', 'lawsuit', 'prison', 'inspector', 'lawyer']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  93 contient  11  mots\n",
      " \n",
      " \n",
      "['southern', 'south', 'west', 'southernmost', 'east', 'northeast', 'western', 'north', 'eastern', 'northern', 'west-northwest']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  94 contient  35  mots\n",
      " \n",
      " \n",
      "['invasive', 'hazardous', 'catastrophic', 'deadly', 'temper', 'difficult', 'dangerous', 'inconvenient', 'positive', 'untenable', 'disastrous', 'dire', 'fickle', 'temperamental', 'negative', 'ominous', 'negatively', 'destructive', 'hurtful', 'terrible', 'unbearable', 'bloody', 'impossible', 'cruel', 'harsh', 'horrible', 'blunt', 'unpredictable', 'draconian', 'bitter', 'precarious', 'harmful', 'cranky', 'nasty', 'awful']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  95 contient  38  mots\n",
      " \n",
      " \n",
      "['water', 'temperature', 'gas', 'chemistry', 'air', 'tube', 'energy', 'heat', 'organic', 'food', 'atmospheric', 'cloud', 'fuel', 'ozone', 'layer', 'oil', 'heating', 'stratosphere', 'emission', 'nuclear', 'solar', 'wind', 'atmosphere', 'thermal', 'channel', 'flow', 'absorption', 'stream', 'electric', 'electrical', 'magnetic', 'stratospheric', 'vapor', 'chemical', 'hole', 'vaporization', 'flux', 'radiation']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  96 contient  23  mots\n",
      " \n",
      " \n",
      "['opponent', 'foe', 'icon', 'athlete', 'star', 'fanatic', 'zealot', 'worship', 'celebrity', 'believer', 'ideologue', 'supporter', 'follower', 'actress', 'proponent', 'fan', 'worshiper', 'backer', 'critic', 'idol', 'zeal', 'watcher', 'detractor']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  97 contient  46  mots\n",
      " \n",
      " \n",
      "['change', 'urinate', 'fall', 'move', 'pass', 'leap', 'slide', 'rise', 'sneak', 'travel', 'switch', 'miss', 'throw', 'drop', 'rob', 'shift', 'decline', 'passing', 'stole', 'jump', 'caught', 'navigate', 'walk', 'buck', 'shot', 'reverse', 'steal', 'fly', 'chase', 'skip', 'catch', 'chuck', 'bandwagon', 'warp', 'orient', 'transfer', 'drift', 'swim', 'jot', 'shoot', 'flip', 'grab', 'drag', 'arrest', 'teleport', 'capture']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  98 contient  15  mots\n",
      " \n",
      " \n",
      "['population', 'extinct', 'apocalypse', 'annihilation', 'genocidal', 'overpopulation', 'doomsday', 'rapture', 'urbanism', 'extinction', 'populus', 'survivalist', 'populaton', 'genocide', 'ecocide']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  99 contient  11  mots\n",
      " \n",
      " \n",
      "['spark', 'burner', 'kindle', 'fire', 'burning', 'torch', 'burn', 'combustion', 'ignite', 'candle', 'bulb']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  100 contient  58  mots\n",
      " \n",
      " \n",
      "['peter', 'bob', 'james', 'tim', 'fred', 'john', 'richard', 'larry', 'vic', 'jackson', 'matt', 'charles', 'steven', 'daniel', 'brian', 'joe', 'paul', 'michael', 'jeff', 'tom', 'david', 'kevin', 'glenn', 'neil', 'jim', 'george', 'andrew', 'madison', 'jason', 'patrick', 'chris', 'stephen', 'robert', 'jon', 'matthew', 'jake', 'gordon', 'sean', 'steve', 'simon', 'christopher', 'scott', 'mike', 'stewart', 'pete', 'alex', 'dennis', 'rick', 'phil', 'greg', 'jerry', 'monty', 'keith', 'brad', 'lewis', 'doug', 'jimmy', 'martin']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  101 contient  35  mots\n",
      " \n",
      " \n",
      "['money', 'net', 'redistribution', 'alms', 'budget', 'fortune', 'fund', 'allocation', 'funding', 'profiteer', 'profit', 'tax', 'greed', 'fame', 'grant', 'outgo', 'glory', 'cash', 'wealth', 'philanthropy', 'excess', 'income', 'spending', 'entitlement', 'debt', 'subsidy', 'revenge', 'lust', 'deficit', 'pocket', 'windfall', 'loot', 'wallet', 'surplus', 'charity']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  102 contient  9  mots\n",
      " \n",
      " \n",
      "['denier', 'doubter', 'denialist', 'climategate', 'warmist', 'sceptic', 'skeptic', 'denialists', 'denialism']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  103 contient  12  mots\n",
      " \n",
      " \n",
      "['evolution', 'evo', 'evolutionary', 'young-earth', 'creationists', 'creationist', 'fossile', 'fossil', 'dinosaur', 'megafauna', 'homo', 'hominid']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  104 contient  33  mots\n",
      " \n",
      " \n",
      "['contribute', 'heard', 'interview', 'listen', 'briefed', 'contributes', 'told', 'sits', 'accuse', 'overheard', 'amazes', 'complains', 'listens', 'deny', 'spoke', 'speaks', 'interviewed', 'respond', 'belongs', 'complain', 'accuses', 'hear', 'responds', 'refer', 'partakes', 'denies', 'deserves', 'annoys', 'described', 'describes', 'frightens', 'refers', 'joked']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  105 contient  20  mots\n",
      " \n",
      " \n",
      "['imperils', 'threatens', 'exacerbate', 'disrupt', 'worsen', 'threaten', 'endanger', 'devastate', 'paralyze', 'cripple', 'undermine', 'imperil', 'weaken', 'destabilize', 'degrade', 'derail', 'endangers', 'stabilize', 'impede', 'mar']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  106 contient  32  mots\n",
      " \n",
      " \n",
      "['very', 'increasingly', 'primarily', 'unusually', 'environmentally', 'nearly', 'heavily', 'equally', 'fairly', 'almost', 'completely', 'significantly', 'pretty', 'strongly', 'utterly', 'totally', 'largely', 'relatively', 'greatly', 'entirely', 'exclusively', 'practically', 'economically', 'quite', 'widely', 'absolutely', 'especially', 'particularly', 'highly', 'extremely', 'mostly', 'scientifically']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  107 contient  10  mots\n",
      " \n",
      " \n",
      "['fat', 'exercise', 'fitness', 'treadmill', 'workout', 'cardio', 'excercise', 'obesity', 'bmi', 'obese']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  108 contient  11  mots\n",
      " \n",
      " \n",
      "['street-corner', 'retro', 'space-age', 'disco', 'well-worn', 'corny', 'hipster', 'trite', 'twee', 'hippie', 'feel-good']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  109 contient  68  mots\n",
      " \n",
      " \n",
      "['create', 'sue', 'kill', 'use', 'absorb', 'save', 'prepare', 'eat', 'mobilize', 'consume', 'manipulate', 'buy', 'adapt', 'activate', 'protect', 'mobilise', 'convince', 'maintain', 'commit', 'produce', 'publish', 'invest', 'impose', 'perpetrate', 'sell', 'fabricate', 'integrate', 'adopt', 'gather', 'utilize', 'organize', 'pollute', 'destroy', 'forge', 'perpetuate', 'promote', 'prosecute', 'develop', 'incorporate', 'rely', 'distribute', 'connect', 'enact', 'engage', 'defend', 'combine', 'operate', 'build', 'embrace', 'orchestrate', 'transform', 'foster', 'establish', 'abandon', 'adjust', 'enlist', 'invent', 'implement', 'concoct', 'outbid', 'poach', 'sustain', 'convene', 'initiate', 'dedicate', 'exploit', 'donate', 'emit']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  110 contient  11  mots\n",
      " \n",
      " \n",
      "['carbon', 'oxygen', 'methane', 'nitrous', 'oxide', 'ammonia', 'nitrogen', 'dihydrogen', 'monoxide', 'dioxide', 'glucose']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  111 contient  24  mots\n",
      " \n",
      " \n",
      "['be', 'have', 'induced', 'exist', 'remain', 'occur', 'seem', 'require', 'allow', 'involve', 'become', 'happen', 'erupt', 'involves', 'remains', 'exists', 'appear', 'enable', 'happens', 'persists', 'arises', 'becomes', 'ensue', 'induce']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  112 contient  13  mots\n",
      " \n",
      " \n",
      "['cool', 'cold', 'hot', 'dry', 'cloudy', 'warm', 'humid', 'cozy', 'sunny', 'toasty', 'wet', 'chill', 'unseasonably']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  113 contient  14  mots\n",
      " \n",
      " \n",
      "['world', 'country', 'earth', 'nation', 'continent', 'subcontinent', 'planet', 'globe', 'humanity', 'cosmos', 'planetary', 'hemisphere', 'universe', 'mankind']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  114 contient  92  mots\n",
      " \n",
      " \n",
      "['tool', 'cycle', 'strategy', 'perspective', 'symptom', 'myth', 'model', 'view', 'action', 'effort', 'motion', 'element', 'plan', 'account', 'contribution', 'step', 'point', 'event', 'resource', 'revolution', 'awareness', 'pattern', 'activity', 'approach', 'building', 'perception', 'regime', 'scenario', 'programme', 'system', 'fashion', 'program', 'period', 'scheme', 'habit', 'consciousness', 'landscape', 'process', 'sight', 'portfolio', 'diet', 'project', 'structure', 'stage', 'style', 'initiative', 'era', 'guide', 'movement', 'vogue', 'phenomenon', 'transition', 'attitude', 'appetite', 'footprint', 'impression', 'frame', 'dimension', 'factor', 'angle', 'trend', 'background', 'mood', 'profile', 'illusion', 'outcome', 'vision', 'shape', 'resolution', 'hearing', 'epoch', 'behaviour', 'manual', 'aspect', 'method', 'technique', 'phase', 'scene', 'redux', 'mechanism', 'slant', 'severity', 'screen', 'condition', 'occurrence', 'framework', 'radar', 'bias', 'sea-change', 'design', 'behavior', 'horizon']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  115 contient  17  mots\n",
      " \n",
      " \n",
      "['indicator', 'stats', 'measure', 'poll', 'benchmarking', 'survey', 'gauge', 'census', 'measurement', 'statistic', 'barometer', 'benchmark', 'scorecard', 'pollster', 'statistician', 'gallup', 'statistical']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le Cluster numéro :  116 contient  28  mots\n",
      " \n",
      " \n",
      "['ecotone', 'clinique', 'nanofibers', 'inseparability', 'degrowth', 'mid-continent', 'geosphere', 'commercial-grade', 'guar', 'gazelle', 'freeriding', 'data-crunching', 'soy-based', 'mosquitofish', 'nyala', 'natgas', 'carbon-based', 'pika', 'co-benefits', 'redeye', 'himalayan', 'no-take', 'vegan', 'anti-allergy', 'pollack', 'gearless', 'remineralization', 'topi']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  117 contient  37  mots\n",
      " \n",
      " \n",
      "['seriously', 'soon', 'publically', 'rapidly', 'effectively', 'politely', 'finally', 'responsibly', 'suavely', 'conveniently', 'gently', 'quietly', 'endlessly', 'easily', 'sensibly', 'slowly', 'boldly', 'suddenly', 'eventually', 'bold', 'unequally', 'quickly', 'wryly', 'concisely', 'sweetly', 'officially', 'formally', 'sincerely', 'inadvertently', 'incorrectly', 'purposely', 'belatedly', 'strategically', 'incessantly', 'publicly', 'innovatively', 'badly']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  118 contient  19  mots\n",
      " \n",
      " \n",
      "['scam', 'hoax', 'fraud', 'bluff', 'fradulent', 'swindle', 'phony', 'ruse', 'fake', 'mock', 'bogus', 'bluffing', 'pretense', 'fool', 'pretend', 'hoaxster', 'fraudster', 'scamsters', 'dummy']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  119 contient  17  mots\n",
      " \n",
      " \n",
      "['celebrate', 'laud', 'rejoice', 'preach', 'tout', 'criticize', 'dissect', 'worry', 'chide', 'proselytize', 'fret', 'fear', 'opine', 'gloat', 'scold', 'overreact', 'criticise']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  120 contient  14  mots\n",
      " \n",
      " \n",
      "['org', 'gov', 'ceo', 'pres', 'dept', 'biz', 'govt', 'exec', 'department', 'corp', 'orgs', 'hq', 'govts', 'rep']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  121 contient  23  mots\n",
      " \n",
      " \n",
      "['ocean', 'coastal', 'whale', 'sea', 'oceanic', 'waterfront', 'shore', 'marine', 'bay', 'island', 'coast', 'ship', 'fishing', 'boat', 'shark', 'turtle', 'leatherback', 'ridley', 'fish', 'beach', 'shrimp', 'fishery', 'squid']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  122 contient  22  mots\n",
      " \n",
      " \n",
      "['sediment', 'fungus', 'frost', 'collagen', 'microbe', 'soil', 'insect', 'organism', 'pollen', 'clot', 'bacteria', 'algae', 'bee', 'fertilizer', 'moisture', 'flake', 'coral', 'bug', 'protein', 'mulch', 'hive', 'gene']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  123 contient  12  mots\n",
      " \n",
      " \n",
      "['26th', '27th', '40th', '2nd', '5th', '4th', '1st', '48th', '13th', '20th', '21st', '18th']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  124 contient  17  mots\n",
      " \n",
      " \n",
      "['tsunami', 'flood', 'spill', 'earthquake', 'landslide', 'crisis', 'leak', 'disaster', 'collapse', 'tragedy', 'meltdown', 'destruction', 'quake', 'deluge', 'devastation', 'aftermath', 'catastrophe']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  125 contient  36  mots\n",
      " \n",
      " \n",
      "['nasa', 'ipcc', 'sachs', 'pentagon', 'conn', 'g20', 'oxfam', 'motorola', 'wwf', 'nationa', 'siemens', 'goldman', 'soylent', 'gmo', 'gove', 'intl', 'tribbles', 'exxon', 'toyota', 'prius', 'saturn', 'nwo', 'chems', 'verizon', 'x-men', 'mythbusters', 'audi', 'todate', 'gw', 'gobal', 'wmd', 'gps', 'suv', 'documentry', 'kyoto', 'pluto']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  126 contient  35  mots\n",
      " \n",
      " \n",
      "['art', 'archive', 'artist', 'crowd', 'audience', 'rock', 'tour', 'music', 'library', 'festival', 'studio', 'museum', 'pop', 'theater', 'viola', 'room', 'space', 'exhibition', 'folk', 'facility', 'harp', 'jazz', 'auditorium', 'entertainment', 'gig', 'collection', 'venue', 'spectator', 'circuit', 'painting', 'dance', 'location', 'tribune', 'storage', 'instrument']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  127 contient  20  mots\n",
      " \n",
      " \n",
      "['ventura', 'san', 'francisco', 'lopez', 'sierra', 'diego', 'carlos', 'nino', 'santiago', 'ivan', 'pablo', 'juan', 'vega', 'amer', 'romero', 'luis', 'rojas', 'fidel', 'castro', 'rio']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  128 contient  20  mots\n",
      " \n",
      " \n",
      "['suggests', 'confirms', 'writes', 'declares', 'warns', 'agrees', 'asks', 'predicts', 'reminds', 'recommends', 'argues', 'reveals', 'proposes', 'insists', 'indicates', 'explains', 'admits', 'presumes', 'discovers', 'contends']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  129 contient  13  mots\n",
      " \n",
      " \n",
      "['youtube', 'amazon', 'fb', 'uploaded', 'tweet', 'twitter', 'facebook', 'linkedin', 'unfollow', 'ebook', 'itunes', 'favorited', 'flickr']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  130 contient  55  mots\n",
      " \n",
      " \n",
      "['to', 'the', 'and', 'in', 'for', 'around', 'of', 'far', 'from', 'on', 'across', 'by', 'back', 'with', 'into', 'at', 'between', 'out', 'over', 'up', 'about', 'apart', 'via', 'against', 'under', 'off', 'down', 'among', 'locally', 'below', 'above', 'away', 'forth', 'together', 'ahead', 'through', 'behind', 'forward', 'worldwide', 'outside', 'along', 'straight', 'abroad', 'beyond', 'beside', 'unnoticed', 'near', 'within', 'indoors', 'inside', 'onto', 'thru', 'globally', 'upwards', 'upon']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  131 contient  7  mots\n",
      " \n",
      " \n",
      "['thursday', 'monday', 'wednesday', 'sunday', 'friday', 'tuesday', 'saturday']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  132 contient  74  mots\n",
      " \n",
      " \n",
      "['message', 'blame', 'cause', 'issue', 'difference', 'explanation', 'focus', 'chance', 'connection', 'fact', 'force', 'alarm', 'fault', 'interest', 'consideration', 'case', 'warning', 'voice', 'power', 'reason', 'alternative', 'hint', 'goal', 'consequence', 'matter', 'option', 'reminder', 'lack', 'example', 'concern', 'target', 'control', 'choice', 'opinion', 'decision', 'result', 'landmark', 'priority', 'topic', 'subject', 'authority', 'aim', 'task', 'possibility', 'opportunity', 'clue', 'command', 'sound', 'prospect', 'inaction', 'importance', 'significance', 'purpose', 'majority', 'relationship', 'potential', 'responsibility', 'loud', 'success', 'excuse', 'distinction', 'failure', 'intention', 'historic', 'absent', 'historical', 'absence', 'reliance', 'potentially', 'relation', 'by-product', 'intent', 'emphasis', 'signal']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  133 contient  47  mots\n",
      " \n",
      " \n",
      "['hey', 'huh', 'yes', 'urgh', 'bleh', 'hmmmm', 'hmmm', 'eh', 'wtf', 'er', 'lol', 'yeah', 'oh', 'mmmm', 'hahah', 'hmm', 'hahaha', 'yikes', 'haha', 'omg', 'ohhhh', 'wow', 'errr', 'noooooo', 'uh-oh', 'crikey', 'um', 'uh', 'ugh', 'smh', 'yea', 'yup', 'lmao', 'noooo', 'hah', 'woot', 'oops', 'yay', 'whoa', 'aww', 'duh', 'argh', 'yuck', 'grrr', 'nah', 'grrrr', 'nope']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  134 contient  21  mots\n",
      " \n",
      " \n",
      "['seclude', 'nationalize', 'reinvent', 'unplug', 'steamroll', 'whiten', 'brighten', 'overturn', 'reclaim', 'convolute', 'reinvigorate', 'decarbonise', 'innovate', 'scuttle', 'hunker', 'regain', 'retrain', 'desiccate', 'depreciate', 'upend', 'rehabilitate']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  135 contient  12  mots\n",
      " \n",
      " \n",
      "['dwindles', 'soar', 'disappear', 'skyrocket', 'unravel', 'plummet', 'dwindle', 'shrink', 'unravels', 'disappears', 'reappear', 'vanished']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  136 contient  64  mots\n",
      " \n",
      " \n",
      "['calif', 'pli', 'foll', 'afp', 'harte', 'sourc', 'worldnews', 'usc', 'spr', 'cli', 'cir', 'macbeth', 'clo', 'tole', 'mlb', 'nyu', 'clima', 'supp', 'cfr', 'acad', 'prc', 'doa', 'nih', 'htt', 'fac', 'edm', 'chron', 'yid', 'dhs', 'rcp', 'syracuse', 'resp', 'ict', 'ste', 'twp', 'byu', 'spe', 'xc', 'fonda', 'glo', 'mkt', 'sundance', 'brr', '2u', 'chg', 'accel', 'cre', 'bx', 'smithsonian', 'bos', 'whiche', 'cymru', 'sociali', 'ernst', 'lars', 'usw', 'rls', 'pgm', 'curr', 'archiv', 'issu', 'edt', 'tol', 'hrd']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  137 contient  35  mots\n",
      " \n",
      " \n",
      "['rapid', 'rare', 'fast', 'irreversible', 'unequivocal', 'slow', 'likely', 'imminent', 'unprecedented', 'immediate', 'exceptional', 'unlikely', 'automatic', 'sudden', 'quick', 'clear', 'surprising', 'dramatic', 'willful', 'obvious', 'imperative', 'emergency', 'unusual', 'intentional', 'inevitable', 'instant', 'easy', 'undeniable', 'plausible', 'unexpected', 'necessity', 'accidental', 'deliberate', 'abrupt', 'urgent']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  138 contient  34  mots\n",
      " \n",
      " \n",
      "['spring', 'late', 'year', 'day', 'tonight', 'morning', 'week', 'early', 'weekend', 'until', 'winter', 'decade', '1970s', 'minute', 'afternoon', 'noon', 'hour', 'summer', 'month', 'till', 'yesterday', 'autumn', 'mid', 'tomorrow', 'asap', 'midnight', 'til', 'night', 'mid-day', 'sooner', 'century', 'eve', 'overnight', 'tommorow']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  139 contient  27  mots\n",
      " \n",
      " \n",
      "['chat', 'debate', 'discussion', 'buzz', 'dialogue', 'conversation', 'consensus', 'controversy', 'discourse', 'dispute', 'argument', 'thread', 'rhetoric', 'forum', 'dialectic', 'bashing', 'vent', 'monologue', 'froth', 'fodder', 'arguement', 'discusson', 'hype', 'chatter', 'spar', 'grist', 'rant']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  140 contient  5  mots\n",
      " \n",
      " \n",
      "['7pm', '3pm', '1pm', '2pm', '10pm']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  141 contient  24  mots\n",
      " \n",
      " \n",
      "['specie', 'cara', 'humani', 'veritas', 'alexia', 'maria', 'los', 'angeles', 'alba', 'imperforate', 'costa', 'buen', 'vivir', 'prima', 'fascia', 'mierda', 'nova', 'pena', 'terra', 'cambio', 'riba', 'paz', 'scintilla', 'ahora']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  142 contient  16  mots\n",
      " \n",
      " \n",
      "['2', '4', '1', '3', '8', '7', '9', '5', '6', '19-22', '10-20', '4-5', '10-1', '12-20', '1-2', '10-14']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  143 contient  11  mots\n",
      " \n",
      " \n",
      "['phd', 'harvard', 'grad', 'uni', 'cambridge', 'econ', 'undergrad', 'yale', 'dissertation', 'univ', 'princeton']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  144 contient  20  mots\n",
      " \n",
      " \n",
      "['epa', 'gop', 'teaparty', 'reid', 'obama', 'barack', 'kerry', 'palin', 'biden', 'obozo', 'whitehouse', 'pelosi', 'mccain', 'dnc', 'clinton', 'obamas', 'atty', 'scotus', 'barry', 'hillary']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le Cluster numéro :  145 contient  15  mots\n",
      " \n",
      " \n",
      "['two', 'three', 'thousand', 'eight', 'nine', 'fifty', 'six', 'twenty', 'ten', 'hundred', 'twelve', 'four', 'thirty', 'twenty-five', 'forty-nine']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  146 contient  45  mots\n",
      " \n",
      " \n",
      "['news', 'book', 'magazine', 'journal', 'memo', 'press', 'release', 'newspaper', 'item', 'agenda', 'protocol', 'backgrounder', 'paper', 'editorial', 'coda', 'newswire', 'announcement', 'word', 'plank', 'headline', 'letter', 'phrase', 'term', 'version', 'charter', 'edition', 'chapter', 'draft', 'manifesto', 'roadmap', 'publication', 'roundup', 'piece', 'tidbit', 'rumor', 'theme', 'passage', 'metaphor', 'treaty', 'excerpt', 'communique', 'convention', 'primer', 'gazette', 'recommendation']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  147 contient  45  mots\n",
      " \n",
      " \n",
      "['stay', 'start', 'wait', 'stop', 'settle', 'come', 'delay', 'arrive', 'go', 'curb', 'await', 'suffer', 'continue', 'dawdle', 'spur', 'keep', 'let', 'migrate', 'lie', 'left', 'decide', 'halt', 'begin', 'refrain', 'emerge', 'kept', 'sack', 'finish', 'leave', 'hurry', 'withstand', 'sit', 'lay', 'alone', 'rush', 'bear', 'endure', 'rest', 'stand', 'survive', 'delayed', 'thrive', 'resign', 'quit', 'lag']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  148 contient  35  mots\n",
      " \n",
      " \n",
      "['thought', 'hold', 'gotten', 'met', 'mean', 'risen', 'saw', 'held', 'developed', 'experienced', 'won', 'brimming', 'run', 'found', 'knew', 'drive', 'feed', 'spread', 'pumped', 'fed', 'unearthed', 'grow', 'fell', 'ran', 'finding', 'clocked', 'grown', 'laden', 'drip', 'meant', 'rode', 'rose', 'driven', 'bought', 'spews']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  149 contient  27  mots\n",
      " \n",
      " \n",
      "['we', 'you', 'they', 'people', 'person', 'me', 'everyone', 'yourselves', 'man', 'them', 'woman', 'someone', 'he', 'him', 'she', 'themselves', 'anyone', 'others', 'guy', 'somebody', 'himself', 'myself', 'everybody', 'men', 'dude', 'us', 'ourselves']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  150 contient  10  mots\n",
      " \n",
      " \n",
      "['sneeze', 'excrement', 'poo', 'fart', 'flatulence', 'sweat', 'breath', 'gassy', 'smell', 'poop']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  151 contient  45  mots\n",
      " \n",
      " \n",
      "['lindsay', 'lindsey', 'rebecca', 'mary', 'ellen', 'cynthia', 'sarah', 'lori', 'tracy', 'claire', 'gail', 'brooke', 'geoff', 'jessica', 'meredith', 'marley', 'cory', 'laura', 'christie', 'jackie', 'jesse', 'freddie', 'tina', 'whitney', 'amy', 'juliet', 'kate', 'jennifer', 'naomi', 'geldof', 'jane', 'rachel', 'kim', 'lisa', 'laurie', 'billie', 'irene', 'michelle', 'cathy', 'kendall', 'julia', 'carrie', 'amanda', 'wendy', 'suzanne']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  152 contient  21  mots\n",
      " \n",
      " \n",
      "['farce', 'scandal', 'indiscretion', 'blunder', 'embarassment', 'shame', 'error', 'mess', 'stupidity', 'disgrace', 'bungle', 'ignorance', 'mistake', 'contradiction', 'incoherence', 'idiocy', 'gaffe', 'goof', 'fiasco', 'stupidness', 'confusion']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  153 contient  10  mots\n",
      " \n",
      " \n",
      "['climate-change', 'global-warming', 'biochar', 'geoengineering', 'pollutant', 'pollution', 'cap-and-trade', 'polluter', 'air-quality', 'sequestration']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  154 contient  11  mots\n",
      " \n",
      " \n",
      "['topography', 'volcano', 'map', 'geologist', 'volcanic', 'eruption', 'magmatic', 'geological', 'mapping', 'geography', 'tectonics']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  155 contient  14  mots\n",
      " \n",
      " \n",
      "['discover', 'hide', 'unveiled', 'unveil', 'reveal', 'disclosure', 'expose', 'secret', 'disclose', 'announces', 'hiding', 'announce', 'hidden', 'uncover']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  156 contient  16  mots\n",
      " \n",
      " \n",
      "['rationalist', 'religious', 'evangelical', 'moral', 'epistemic', 'evangelicals', 'faith-based', 'religion', 'secular', 'ethical', 'faith', 'belief', 'non-believers', 'atheist', 'ethic', 'worldviews']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  157 contient  22  mots\n",
      " \n",
      " \n",
      "['probs', 'definately', 'isnt', 'hav', 'youve', 'im', 'thats', 'prob', 'hv', 'youre', 'prolly', 'certaintly', 'musta', 'whats', 'wheres', 'wouldve', 'happend', 'havent', 'hows', 'wasnt', 'ive', 'probly']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  158 contient  42  mots\n",
      " \n",
      " \n",
      "['africa', 'uruguay', 'india', 'bolivia', 'mediterranean', 'indian', 'african', 'ethiopia', 'nigerian', 'kenya', 'arabia', 'ethiopian', 'bolivian', 'zealand', 'namibia', 'malaysia', 'indonesia', 'peru', 'arab', 'atlantic', 'thailand', 'wwii', 'greenland', 'kerala', 'uganda', 'nile', 'maldives', 'nigeria', 'pakistan', 'iran', 'mongolia', 'iraqi', 'lagos', 'siberia', 'papua', 'muslim', 'jakarta', 'worl', 'briton', 'delta', 'indus', 'ecuador']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  159 contient  7  mots\n",
      " \n",
      " \n",
      "['gravest', 'coldest', 'coolest', 'snowiest', 'most-watched', 'hottest', 'deadliest']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  160 contient  23  mots\n",
      " \n",
      " \n",
      "['fortunate', 'conscious', 'aware', 'sorry', 'able', 'ready', 'keen', 'sure', 'astute', 'happy', 'lucky', 'capable', 'welcome', 'luck', 'sad', 'unwilling', 'willing', 'interested', 'prepared', 'busy', 'glad', 'responsible', 'curious']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  161 contient  41  mots\n",
      " \n",
      " \n",
      "['warms', 'identifies', 'brings', 'sends', 'expands', 'lessens', 'delivers', 'avoids', 'brought', 'replaces', 'dismisses', 'downplays', 'promotes', 'defends', 'creates', 'solves', 'investigates', 'receives', 'likens', 'adopts', 'considers', 'nears', 'extends', 'destroys', 'explores', 'decries', 'rearranges', 'reinforces', 'violates', 'reorganizes', 'enhances', 'encourages', 'conflates', 'coincides', 'ignores', 'eliminates', 'enters', 'reaffirms', 'undermined', 'recognizes', 'undermines']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  162 contient  19  mots\n",
      " \n",
      " \n",
      "['increase', 'offset', 'reduce', 'extend', 'prevent', 'improve', 'accelerate', 'expand', 'shorten', 'double', 'avoid', 'mitigate', 'compensate', 'minimise', 'redouble', 'quadruple', 'eliminate', 'decrease', 'discourage']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  163 contient  9  mots\n",
      " \n",
      " \n",
      "['boil', 'cure', 'nettle', 'tincture', 'lance', 'physic', 'heal', 'salve', 'remedy']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  164 contient  7  mots\n",
      " \n",
      " \n",
      "['baseball', 'cricket', 'soccer', 'golf', 'sport', 'tennis', 'golfer']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  165 contient  15  mots\n",
      " \n",
      " \n",
      "['dinner', 'meal', 'kitchen', 'bake', 'lunch', 'burger', 'buffet', 'soup', 'microwave', 'takeaway', 'cooked', 'pot', 'cook', 'pub', 'oven']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  166 contient  6  mots\n",
      " \n",
      " \n",
      "['saltiness', 'acidification', 'salinity', 'acid', 'acidity', 'acidic']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  167 contient  20  mots\n",
      " \n",
      " \n",
      "['safety', 'security', 'defense', 'hedge', 'sentinel', 'guardian', 'caretaker', 'deposit', 'protection', 'observatory', 'keeper', 'lighthouse', 'buffer', 'survival', 'protective', 'reserve', 'defence', 'defensive', 'survivability', 'guard']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  168 contient  10  mots\n",
      " \n",
      " \n",
      "['looney', 'nut', 'maniac', 'lunatic', 'loon', 'wacko', 'fruitcake', 'nutcase', 'crank', 'loony']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  169 contient  8  mots\n",
      " \n",
      " \n",
      "['rain', 'snow', 'blizzard', 'sleet', 'snowstorm', 'rainstorm', 'snowfall', 'precipitation']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  170 contient  54  mots\n",
      " \n",
      " \n",
      "['just', 'previously', 'not', 'today', 'ever', 'also', 'who', 'still', 'never', 'now', 'typically', 'clearly', 'only', 'even', 'actually', 'already', 'yet', 'lately', 'purportedly', 'always', 'really', 'rarely', 'truly', 'regularly', 'often', 'half', 'sometimes', 'probably', 'nor', 'apparently', 'currently', 'unsurprisingly', 'barely', 'recently', 'usually', 'definitely', 'specifically', 'oftentimes', 'sadly', 'fundamentally', 'indeed', 'necessarily', 'predictably', 'essentially', 'surprisingly', 'neither', 'basically', 'supposedly', 'certainly', 'scarcely', 'originally', 'one-third', 'literally', 'thankfully']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  171 contient  29  mots\n",
      " \n",
      " \n",
      "['ama', 'iri', 'mau', 'chu', 'lau', 'chan', 'fu', 'aro', 'liu', 'huang', 'kun', 'sev', 'matai', 'kari', 'gue', 'kita', 'deh', 'sama', 'chang', 'pon', 'saran', 'buz', 'koko', 'hou', 'hea', 'oba', 'gua', 'nao', 'anu']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  172 contient  14  mots\n",
      " \n",
      " \n",
      "['reuters', 'newsweek', 'bbc', 'bloomberg', 'cnn', 'foxnews', 'nbc', 'abc', 'wsj', 'nyt', 'foxnews.com', 'msnbc', 'nytimes', 'cbs']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  173 contient  16  mots\n",
      " \n",
      " \n",
      "['ikut', 'dgn', 'bumi', 'udah', 'buat', 'cari', 'aja', 'hujan', 'panas', 'baca', 'tentang', 'bisa', 'mungkin', 'rumah', 'masih', 'industri']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  174 contient  14  mots\n",
      " \n",
      " \n",
      "['funniest', 'funny', 'joke', 'hilarious', 'comedy', 'parody', 'laugh', 'irony', 'comedian', 'ironic', 'humor', 'wit', 'spoof', 'satirical']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  175 contient  10  mots\n",
      " \n",
      " \n",
      "['london', 'bristol', 'fc', 'sheffield', 'cfc', 'wakefield', 'kent', 'chelsea', 'bradford', 'preston']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  176 contient  33  mots\n",
      " \n",
      " \n",
      "['idea', 'source', 'assumption', 'claim', 'implication', 'comment', 'quote', 'declaration', 'question', 'answer', 'remark', 'statement', 'reflection', 'cite', 'complaint', 'hypothesis', 'proposal', 'notion', 'premise', 'response', 'conclusion', 'theory', 'reply', 'rebuttal', 'assertations', 'reference', 'stmt', 'allegation', 'observation', 'commentary', 'presumption', 'misquote', 'assertion']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  177 contient  19  mots\n",
      " \n",
      " \n",
      "['alarmist', 'birthers', 'statists', 'anti-americanism', 'nutjobs', 'sheeple', 'fearmongering', 'alarmism', 'enviros', 'antiscience', 'doomsayers', 'knuckle-draggers', 'anti-intellectualism', 'asshats', 'pervs', 'greenies', 'pseudoskeptics', 'interwebs', 'cultism']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  178 contient  10  mots\n",
      " \n",
      " \n",
      "['ad', 'advertisement', 'advert', 'advertising', 'hoc', 'marketing', 'branding', 'label', 'brand', 'tourism']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le Cluster numéro :  179 contient  31  mots\n",
      " \n",
      " \n",
      "['75', '86', '90', '65', '350', '100', '85', '140', '66', '70', '60', '77', '110', '82', '120', '76', '210', '406', '73', '225', '201', '124', '78', '62', '298', '80', '102', '101', '287', '141', '83']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  180 contient  8  mots\n",
      " \n",
      " \n",
      "['warming', 'man-made', 'human-caused', 'human-induced', 'human-driven', 'anthropogenic', 'man-caused', 'manmade']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  181 contient  23  mots\n",
      " \n",
      " \n",
      "['complicate', 'daunt', 'excite', 'simplify', 'whet', 'illuminate', 'amaze', 'confuse', 'inspire', 'empower', 'entertain', 'amuse', 'mislead', 'motivate', 'overwhelm', 'tempt', 'animate', 'scare', 'enrich', 'frighten', 'dominate', 'enlighten', 'terrify']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  182 contient  8  mots\n",
      " \n",
      " \n",
      "['1.1', '2.5', '1.6', '9.1', '2.4', '3.5', '4.3', '8.8']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  183 contient  32  mots\n",
      " \n",
      " \n",
      "['leader', 'negotiator', 'director', 'founder', 'secretary', 'president', 'associate', 'vice', 'management', 'secretary-general', 'assistant', 'envoy', 'chairman', 'leadership', 'agent', 'producer', 'agency', 'delegate', 'organiser', 'secretariat', 'executive', 'spokesman', 'spokesperson', 'delegation', 'ambassador', 'manager', 'vice-chairman', 'worker', 'organizer', 'charismatic', 'boss', 'owner']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  184 contient  29  mots\n",
      " \n",
      " \n",
      "['face', 'solve', 'fracture', 'tackle', 'hit', 'unite', 'address', 'united', 'confront', 'struck', 'challenge', 'gulf', 'divide', 'cross', 'break', 'pose', 'broke', 'bridge', 'dealt', 'blow', 'head-on', 'strike', 'collide', 'encounter', 'crush', 'crack', 'resolve', 'broken', 'clash']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  185 contient  18  mots\n",
      " \n",
      " \n",
      "['brussels', 'dems', 'hague', 'alp', 'blair', 'cameron', 'lib', 'clegg', 'eu', 'mp', 'ukip', 'tory', 'rudd', 'abbott', 'libs', 'msm', 'rupert', 'murdoch']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  186 contient  39  mots\n",
      " \n",
      " \n",
      "['exit', 'video', 'clip', 'takedown', 'ramp', 'file', 'document', 'vid', 'internet', 'download', 'anonymous', 'site', 'block', 'online', 'password', 'mail', 'e-mail', 'extension', 'yahoo', 'web', 'copy', 'google', 'vein', 'email', 'avatar', 'pointer', 'confidential', 'portal', 'cyberspace', 'bookmark', 'access', 'sign-up', 'tracker', 'homepage', 'website', 'log', 'pdf', 'peer', 'search']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  187 contient  16  mots\n",
      " \n",
      " \n",
      "['belgium', 'swedish', 'iceland', 'oslo', 'icelandic', 'finnish', 'copenhagen', 'dk', 'denmark', 'danish', 'dutch', 'netherlands', 'norwegian', 'estonian', 'holland', 'amsterdam']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  188 contient  3  mots\n",
      " \n",
      " \n",
      "['2030', '2050', '2035']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  189 contient  17  mots\n",
      " \n",
      " \n",
      "['scum', 'idiot', 'douche', 'jackass', 'twerp', 'scumbag', 'moron', 'whiner', 'bitch', 'slut', 'dumbass', 'dick', 'dipshit', 'asshole', 'liar', 'cocksucker', 'dickhead']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  190 contient  14  mots\n",
      " \n",
      " \n",
      "['cooperation', 'co-operation', 'coalition', 'partnership', 'partner', 'alliance', 'joint', 'collaborative', 'cooperative', 'communication', 'teamwork', 'venture', 'collaboration', 'consortium']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  191 contient  15  mots\n",
      " \n",
      " \n",
      "['baloney', 'bullshit', 'propaganda', 'shit', 'troll', 'hooey', 'indoctrination', 'rubbish', 'crock', 'brainwashing', 'nonsense', 'agitprop', 'crap', 'shill', 'crapola']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  192 contient  12  mots\n",
      " \n",
      " \n",
      "['scientifique', 'climat', 'austral', 'bel', 'bon', 'aire', 'mer', 'cru', 'ont', 'pu', 'mon', 'environ']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  193 contient  10  mots\n",
      " \n",
      " \n",
      "['liberal', 'conservative', 'right-wing', 'leftist', 'progressive', 'rightwing', 'left-wing', 'radical', 'extremist', 'lefty']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  194 contient  13  mots\n",
      " \n",
      " \n",
      "['apr', 'april', 'november', 'january', 'aug', 'feb', 'february', 'july', 'dec', 'jan', 'august', 'september', 'december']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  195 contient  4  mots\n",
      " \n",
      " \n",
      "['spent', 'spend', 'spends', 'devotes']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  196 contient  18  mots\n",
      " \n",
      " \n",
      "['cancer', 'illness', 'allergy', 'curable', 'disease', 'smallpox', 'asthma', 'lyme', 'headache', 'migraine', 'fever', 'flu', 'autism', 'vaccine', 'polio', 'infectious', 'malaria', 'allergic']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  197 contient  16  mots\n",
      " \n",
      " \n",
      "['child', 'baby', 'boomer', 'mom', 'youth', 'kiddo', 'kid', 'daddy', 'girl', 'boy', 'young', 'adult', 'mama', 'dad', 'teen', 'impressionable']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  198 contient  17  mots\n",
      " \n",
      " \n",
      "['salt', 'aerosol', 'cement', 'grit', 'slate', 'tobacco', 'stone', 'dust', 'concrete', 'asbestos', 'talcum', 'spray', 'powder', 'sand', 'desert', 'smoke', 'chalk']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n",
      "Le Cluster numéro :  199 contient  20  mots\n",
      " \n",
      " \n",
      "['ban', 'law', 'legislation', 'bill', 'policy', 'regulation', 'mandate', 'rule', 'copyright', 'prohibition', 'provision', 'amendment', 'liability', 'enforcement', 'outlaw', 'violation', 'edict', 'regulatory', 'doctrine', 'legistlation']\n",
      " \n",
      " \n",
      "################\n",
      " \n",
      " \n"
     ]
    }
   ],
   "source": [
    "for j in range(200):\n",
    "    names = []\n",
    "    for k, cluster in enumerate(clustering.labels_):\n",
    "        if cluster == j:\n",
    "            names.append(dataset_ft.index[k])\n",
    "    print(\"Le Cluster numéro : \", j, \"contient \", len(names), \" mots\")\n",
    "    print(\" \")\n",
    "    print(\" \")\n",
    "    print(names)\n",
    "    print(\" \")\n",
    "    print(\" \")\n",
    "    print(\"################\")\n",
    "    print(\" \")\n",
    "    print(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors_ft = {}\n",
    "id_tweets = {}\n",
    "words_list = dataset_ft.index.tolist()\n",
    "\n",
    "\n",
    "\n",
    "for i, tweet in enumerate(clean_text):\n",
    "    vector = [0] * 200\n",
    "    for word in tweet:\n",
    "        if word in dic_words.keys():\n",
    "            vector[clustering.labels_[words_list.index(word)]] += 1\n",
    "    vectors_ft[\"T\" + str(i)] = vector\n",
    "    id_tweets[\"T\" + str(i)] = tweet    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "df2 = df.copy()\n",
    "df_rep = pd.DataFrame(vectors_ft)\n",
    "df_rep = df_rep.T\n",
    "\n",
    "existence = []\n",
    "for i, elt in enumerate(df2[\"Existence\"]):\n",
    "    existence.append(elt)\n",
    "df_rep.columns=[str(x) for x in range(df_rep.shape[1])]\n",
    "df_rep['Labels'] = existence\n",
    "\n",
    "df_fast2vec_cluster=df_rep.reset_index(drop=True)\n",
    "df_fast2vec_cluster.to_csv('representations/df_fast2vec_cluster.csv')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>191</th>\n",
       "      <th>192</th>\n",
       "      <th>193</th>\n",
       "      <th>194</th>\n",
       "      <th>195</th>\n",
       "      <th>196</th>\n",
       "      <th>197</th>\n",
       "      <th>198</th>\n",
       "      <th>199</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5534</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5535</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5536</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5537</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5538</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5539 rows × 201 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0  1  2  3  4  5  6  7  8  9  ...  191  192  193  194  195  196  197  \\\n",
       "0     0  0  0  1  0  0  0  0  0  0  ...    0    0    0    0    0    0    0   \n",
       "1     0  0  0  0  0  0  0  0  0  0  ...    0    0    0    0    0    0    0   \n",
       "2     0  0  0  0  0  0  0  0  0  0  ...    0    0    0    0    0    0    0   \n",
       "3     0  0  0  0  0  0  0  0  0  0  ...    0    0    0    0    0    0    0   \n",
       "4     0  0  0  0  0  0  0  0  0  0  ...    0    0    0    0    0    0    0   \n",
       "...  .. .. .. .. .. .. .. .. .. ..  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "5534  0  0  0  0  0  0  0  0  0  0  ...    0    0    0    0    0    0    0   \n",
       "5535  0  0  0  0  0  0  0  0  0  0  ...    0    0    0    0    0    0    0   \n",
       "5536  0  0  0  0  0  0  0  0  0  0  ...    0    0    0    0    0    0    0   \n",
       "5537  0  0  0  0  1  0  0  0  0  0  ...    0    0    0    0    0    0    0   \n",
       "5538  0  0  0  0  0  0  0  0  0  0  ...    0    0    0    0    0    0    0   \n",
       "\n",
       "      198  199  Labels  \n",
       "0       0    0     Yes  \n",
       "1       0    0     Yes  \n",
       "2       0    0     Yes  \n",
       "3       0    0     Yes  \n",
       "4       0    0     Yes  \n",
       "...   ...  ...     ...  \n",
       "5534    0    0     NaN  \n",
       "5535    0    0      No  \n",
       "5536    0    0      No  \n",
       "5537    0    0      No  \n",
       "5538    0    0     NaN  \n",
       "\n",
       "[5539 rows x 201 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fast2vec_cluster=pd.read_csv('representations/df_fast2vec_cluster.csv',index_col=0)\n",
    "df_fast2vec_cluster                 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### En moyennant la sortie de Fast2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nvectors_ft_moy = {}\\nid_tweets = {}\\n\\n\\nfor i, tweet in enumerate(clean_text):\\n    vector = [0] * 300\\n    qtt = 0\\n    for word in tweet:\\n        if word in dic_words.keys():\\n            s = []\\n            for elt in list(dataset_ft.loc[word]):\\n                s.append(float(elt))\\n            qtt += 1\\n            vector = list( map(add, vector, s) )\\n    if qtt != 0:\\n        vectors_ft_moy[\"T\" + str(i)] = [x/qtt for x in vector]\\n    else:\\n        vectors_ft_moy[\"T\" + str(i)] = vector\\n    id_tweets[\"T\" + str(i)] = tweet \\n    \\ndf_moy = pd.DataFrame(vectors_ft_moy)\\ndf_moy = df_moy.T\\ndf_moy.columns=[str(x) for x in range(df_moy.shape[1])]\\ndf_moy[\\'Labels\\'] = existence\\n\\ndf_fast2vec_mean=df_moy.reset_index(drop=True)\\ndf_fast2vec_mean.to_csv(\"representations/df_fast2vec_mean.csv\")\\n'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "vectors_ft_moy = {}\n",
    "id_tweets = {}\n",
    "\n",
    "\n",
    "for i, tweet in enumerate(clean_text):\n",
    "    vector = [0] * 300\n",
    "    qtt = 0\n",
    "    for word in tweet:\n",
    "        if word in dic_words.keys():\n",
    "            s = []\n",
    "            for elt in list(dataset_ft.loc[word]):\n",
    "                s.append(float(elt))\n",
    "            qtt += 1\n",
    "            vector = list( map(add, vector, s) )\n",
    "    if qtt != 0:\n",
    "        vectors_ft_moy[\"T\" + str(i)] = [x/qtt for x in vector]\n",
    "    else:\n",
    "        vectors_ft_moy[\"T\" + str(i)] = vector\n",
    "    id_tweets[\"T\" + str(i)] = tweet \n",
    "    \n",
    "df_moy = pd.DataFrame(vectors_ft_moy)\n",
    "df_moy = df_moy.T\n",
    "df_moy.columns=[str(x) for x in range(df_moy.shape[1])]\n",
    "df_moy['Labels'] = existence\n",
    "\n",
    "df_fast2vec_mean=df_moy.reset_index(drop=True)\n",
    "df_fast2vec_mean.to_csv(\"representations/df_fast2vec_mean.csv\")\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.023414</td>\n",
       "      <td>0.005850</td>\n",
       "      <td>-0.041093</td>\n",
       "      <td>-0.032021</td>\n",
       "      <td>0.004571</td>\n",
       "      <td>0.005043</td>\n",
       "      <td>0.039657</td>\n",
       "      <td>0.020650</td>\n",
       "      <td>0.031514</td>\n",
       "      <td>-0.048857</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.033821</td>\n",
       "      <td>-0.002979</td>\n",
       "      <td>-0.011879</td>\n",
       "      <td>-0.015871</td>\n",
       "      <td>-0.042950</td>\n",
       "      <td>0.002714</td>\n",
       "      <td>0.093157</td>\n",
       "      <td>0.018993</td>\n",
       "      <td>-0.028171</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.021233</td>\n",
       "      <td>0.064300</td>\n",
       "      <td>-0.068433</td>\n",
       "      <td>0.039700</td>\n",
       "      <td>0.008767</td>\n",
       "      <td>0.032167</td>\n",
       "      <td>0.017867</td>\n",
       "      <td>0.007667</td>\n",
       "      <td>0.114133</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.038667</td>\n",
       "      <td>0.038833</td>\n",
       "      <td>-0.007900</td>\n",
       "      <td>0.012667</td>\n",
       "      <td>0.049933</td>\n",
       "      <td>-0.054100</td>\n",
       "      <td>0.070800</td>\n",
       "      <td>0.014133</td>\n",
       "      <td>-0.050967</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>-0.047160</td>\n",
       "      <td>0.005480</td>\n",
       "      <td>0.012520</td>\n",
       "      <td>-0.022360</td>\n",
       "      <td>-0.002520</td>\n",
       "      <td>-0.084140</td>\n",
       "      <td>-0.029600</td>\n",
       "      <td>-0.017000</td>\n",
       "      <td>0.055100</td>\n",
       "      <td>-0.033980</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003260</td>\n",
       "      <td>-0.014620</td>\n",
       "      <td>0.018440</td>\n",
       "      <td>-0.022480</td>\n",
       "      <td>0.009400</td>\n",
       "      <td>-0.023080</td>\n",
       "      <td>0.209880</td>\n",
       "      <td>0.079020</td>\n",
       "      <td>0.044420</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>-0.004100</td>\n",
       "      <td>0.014900</td>\n",
       "      <td>-0.017750</td>\n",
       "      <td>0.000950</td>\n",
       "      <td>-0.040650</td>\n",
       "      <td>-0.120650</td>\n",
       "      <td>-0.033950</td>\n",
       "      <td>0.036200</td>\n",
       "      <td>-0.010050</td>\n",
       "      <td>-0.011100</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.007550</td>\n",
       "      <td>-0.043650</td>\n",
       "      <td>0.019400</td>\n",
       "      <td>-0.031350</td>\n",
       "      <td>-0.021100</td>\n",
       "      <td>-0.049050</td>\n",
       "      <td>0.225300</td>\n",
       "      <td>0.009250</td>\n",
       "      <td>-0.010300</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.052200</td>\n",
       "      <td>0.022450</td>\n",
       "      <td>-0.183250</td>\n",
       "      <td>0.029650</td>\n",
       "      <td>-0.077250</td>\n",
       "      <td>-0.056450</td>\n",
       "      <td>-0.046750</td>\n",
       "      <td>-0.042300</td>\n",
       "      <td>0.083000</td>\n",
       "      <td>-0.031850</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>-0.058650</td>\n",
       "      <td>0.013300</td>\n",
       "      <td>-0.014750</td>\n",
       "      <td>-0.095300</td>\n",
       "      <td>-0.062300</td>\n",
       "      <td>0.187300</td>\n",
       "      <td>-0.010800</td>\n",
       "      <td>0.036300</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5534</td>\n",
       "      <td>0.012700</td>\n",
       "      <td>0.068600</td>\n",
       "      <td>0.007980</td>\n",
       "      <td>0.049280</td>\n",
       "      <td>-0.011000</td>\n",
       "      <td>0.042040</td>\n",
       "      <td>0.105280</td>\n",
       "      <td>-0.005640</td>\n",
       "      <td>0.039080</td>\n",
       "      <td>-0.023800</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.099220</td>\n",
       "      <td>0.037980</td>\n",
       "      <td>0.084960</td>\n",
       "      <td>-0.065920</td>\n",
       "      <td>0.066540</td>\n",
       "      <td>-0.000320</td>\n",
       "      <td>0.015800</td>\n",
       "      <td>0.041500</td>\n",
       "      <td>-0.024940</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5535</td>\n",
       "      <td>-0.096400</td>\n",
       "      <td>-0.005040</td>\n",
       "      <td>-0.030640</td>\n",
       "      <td>-0.004840</td>\n",
       "      <td>0.003840</td>\n",
       "      <td>-0.017080</td>\n",
       "      <td>0.009400</td>\n",
       "      <td>-0.070480</td>\n",
       "      <td>0.013000</td>\n",
       "      <td>0.011100</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.085400</td>\n",
       "      <td>0.056460</td>\n",
       "      <td>0.015820</td>\n",
       "      <td>-0.029300</td>\n",
       "      <td>-0.073400</td>\n",
       "      <td>-0.051820</td>\n",
       "      <td>0.199580</td>\n",
       "      <td>-0.021740</td>\n",
       "      <td>-0.001900</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5536</td>\n",
       "      <td>0.013713</td>\n",
       "      <td>-0.016407</td>\n",
       "      <td>-0.069427</td>\n",
       "      <td>-0.011700</td>\n",
       "      <td>0.005907</td>\n",
       "      <td>0.010667</td>\n",
       "      <td>0.012180</td>\n",
       "      <td>0.028887</td>\n",
       "      <td>-0.005393</td>\n",
       "      <td>0.038313</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043380</td>\n",
       "      <td>-0.026667</td>\n",
       "      <td>0.035780</td>\n",
       "      <td>-0.004920</td>\n",
       "      <td>-0.018840</td>\n",
       "      <td>-0.004713</td>\n",
       "      <td>0.126353</td>\n",
       "      <td>0.048653</td>\n",
       "      <td>-0.038813</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5537</td>\n",
       "      <td>-0.007162</td>\n",
       "      <td>0.026894</td>\n",
       "      <td>-0.014887</td>\n",
       "      <td>0.013413</td>\n",
       "      <td>0.022212</td>\n",
       "      <td>-0.037306</td>\n",
       "      <td>0.027094</td>\n",
       "      <td>-0.007219</td>\n",
       "      <td>0.005625</td>\n",
       "      <td>0.003894</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.029994</td>\n",
       "      <td>-0.009288</td>\n",
       "      <td>0.019863</td>\n",
       "      <td>0.012325</td>\n",
       "      <td>0.002912</td>\n",
       "      <td>0.004813</td>\n",
       "      <td>0.145725</td>\n",
       "      <td>0.043256</td>\n",
       "      <td>-0.017325</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5538</td>\n",
       "      <td>-0.003313</td>\n",
       "      <td>0.019009</td>\n",
       "      <td>-0.007722</td>\n",
       "      <td>-0.007883</td>\n",
       "      <td>-0.022217</td>\n",
       "      <td>-0.039978</td>\n",
       "      <td>0.031226</td>\n",
       "      <td>0.013878</td>\n",
       "      <td>-0.010235</td>\n",
       "      <td>-0.038139</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005626</td>\n",
       "      <td>-0.020522</td>\n",
       "      <td>0.007996</td>\n",
       "      <td>0.011543</td>\n",
       "      <td>-0.023609</td>\n",
       "      <td>0.002535</td>\n",
       "      <td>0.129130</td>\n",
       "      <td>0.011243</td>\n",
       "      <td>0.011800</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5539 rows × 301 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5         6  \\\n",
       "0     0.023414  0.005850 -0.041093 -0.032021  0.004571  0.005043  0.039657   \n",
       "1     0.021233  0.064300 -0.068433  0.039700  0.008767  0.032167  0.017867   \n",
       "2    -0.047160  0.005480  0.012520 -0.022360 -0.002520 -0.084140 -0.029600   \n",
       "3    -0.004100  0.014900 -0.017750  0.000950 -0.040650 -0.120650 -0.033950   \n",
       "4     0.052200  0.022450 -0.183250  0.029650 -0.077250 -0.056450 -0.046750   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "5534  0.012700  0.068600  0.007980  0.049280 -0.011000  0.042040  0.105280   \n",
       "5535 -0.096400 -0.005040 -0.030640 -0.004840  0.003840 -0.017080  0.009400   \n",
       "5536  0.013713 -0.016407 -0.069427 -0.011700  0.005907  0.010667  0.012180   \n",
       "5537 -0.007162  0.026894 -0.014887  0.013413  0.022212 -0.037306  0.027094   \n",
       "5538 -0.003313  0.019009 -0.007722 -0.007883 -0.022217 -0.039978  0.031226   \n",
       "\n",
       "             7         8         9  ...       291       292       293  \\\n",
       "0     0.020650  0.031514 -0.048857  ... -0.033821 -0.002979 -0.011879   \n",
       "1     0.007667  0.114133  0.016667  ... -0.038667  0.038833 -0.007900   \n",
       "2    -0.017000  0.055100 -0.033980  ... -0.003260 -0.014620  0.018440   \n",
       "3     0.036200 -0.010050 -0.011100  ... -0.007550 -0.043650  0.019400   \n",
       "4    -0.042300  0.083000 -0.031850  ...  0.003200 -0.058650  0.013300   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "5534 -0.005640  0.039080 -0.023800  ... -0.099220  0.037980  0.084960   \n",
       "5535 -0.070480  0.013000  0.011100  ... -0.085400  0.056460  0.015820   \n",
       "5536  0.028887 -0.005393  0.038313  ...  0.043380 -0.026667  0.035780   \n",
       "5537 -0.007219  0.005625  0.003894  ... -0.029994 -0.009288  0.019863   \n",
       "5538  0.013878 -0.010235 -0.038139  ... -0.005626 -0.020522  0.007996   \n",
       "\n",
       "           294       295       296       297       298       299  Labels  \n",
       "0    -0.015871 -0.042950  0.002714  0.093157  0.018993 -0.028171     Yes  \n",
       "1     0.012667  0.049933 -0.054100  0.070800  0.014133 -0.050967     Yes  \n",
       "2    -0.022480  0.009400 -0.023080  0.209880  0.079020  0.044420     Yes  \n",
       "3    -0.031350 -0.021100 -0.049050  0.225300  0.009250 -0.010300     Yes  \n",
       "4    -0.014750 -0.095300 -0.062300  0.187300 -0.010800  0.036300     Yes  \n",
       "...        ...       ...       ...       ...       ...       ...     ...  \n",
       "5534 -0.065920  0.066540 -0.000320  0.015800  0.041500 -0.024940     NaN  \n",
       "5535 -0.029300 -0.073400 -0.051820  0.199580 -0.021740 -0.001900      No  \n",
       "5536 -0.004920 -0.018840 -0.004713  0.126353  0.048653 -0.038813      No  \n",
       "5537  0.012325  0.002912  0.004813  0.145725  0.043256 -0.017325      No  \n",
       "5538  0.011543 -0.023609  0.002535  0.129130  0.011243  0.011800     NaN  \n",
       "\n",
       "[5539 rows x 301 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fast2vec_mean=pd.read_csv(\"representations/df_fast2vec_mean.csv\",index_col=0)\n",
    "df_fast2vec_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Représentation Bert pre-trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_text=import_clean_text()\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "\n",
    "# Input formating for BERT\n",
    "\n",
    "#tokenization spécifique BERT\n",
    "def tokenization_BERT(tweet,tokenizer):\n",
    "    text=''\n",
    "    for word in tweet:\n",
    "        text=text+' '+word\n",
    "    tokenized_text='[CLS]'+text+' [SEP]'\n",
    "    tokenized_text = tokenizer.tokenize(tokenized_text)\n",
    "    indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "    segments_ids = [0] * len(tokenized_text)\n",
    "    \n",
    "    return(indexed_tokens,segments_ids)\n",
    "\n",
    "##########################################\n",
    "##########################################\n",
    "\n",
    "# Embedding du tweet\n",
    "def BERT_embedding(tweet,tokenizer):\n",
    "    \n",
    "    #tokenization et convertion des inputs en tensors\n",
    "    index, segments= tokenization_BERT(tweet,tokenizer)\n",
    "    \n",
    "    tokens_tensor = torch.tensor([index])\n",
    "    segments_tensors = torch.tensor([segments])\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        encoded_layers, _ = model(tokens_tensor, segments_tensors)\n",
    "\n",
    "    token_embeddings = torch.stack(encoded_layers, dim=0)\n",
    "    token_embeddings = torch.squeeze(token_embeddings, dim=1)\n",
    "    token_embeddings = token_embeddings.permute(1,0,2)\n",
    "    \n",
    "    token_vecs = encoded_layers[11][0]\n",
    "    sentence_embedding = torch.mean(token_vecs, dim=0)\n",
    "    \n",
    "    return(list(sentence_embedding.numpy())) #return le vecteur du tweet\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Load pre-trained model (weights)\\nmodel = BertModel.from_pretrained(\\'bert-base-uncased\\')\\n\\n# Put the model in \"evaluation\" mode, meaning feed-forward operation.\\nmodel.eval()\\n'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import du modèle\n",
    "\"\"\"\n",
    "# Load pre-trained model (weights)\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Put the model in \"evaluation\" mode, meaning feed-forward operation.\n",
    "model.eval()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfor tweet_index in range(5):\\n    print('Tweet initial : '+df.iloc[tweet_index]['Tweet'])\\n    print(' ')\\n    text=''\\n    for word in clean_text[tweet_index]:\\n        text=text+' '+word\\n    print('Tweet nettoyé : '+text)\\n    print(' ')\\n    print('10 premières valeurs de la représentation vectorielle : '+str(BERT_embedding(clean_text[tweet_index],tokenizer)[0:10]))\\n    print(' ')\\n    print('#'*20)\\n    print(' ')\\n\\n\""
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Représentation des 5 premiers tweets de la base\n",
    "\"\"\"\n",
    "for tweet_index in range(5):\n",
    "    print('Tweet initial : '+df.iloc[tweet_index]['Tweet'])\n",
    "    print(' ')\n",
    "    text=''\n",
    "    for word in clean_text[tweet_index]:\n",
    "        text=text+' '+word\n",
    "    print('Tweet nettoyé : '+text)\n",
    "    print(' ')\n",
    "    print('10 premières valeurs de la représentation vectorielle : '+str(BERT_embedding(clean_text[tweet_index],tokenizer)[0:10]))\n",
    "    print(' ')\n",
    "    print('#'*20)\n",
    "    print(' ')\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndataframe={}\\nfor tweet_index in tqdm(range(len(clean_text))):\\n    dataframe[tweet_index]=BERT_embedding(clean_text[tweet_index],tokenizer)\\ndf_bert=pd.DataFrame(dataframe)\\ndf_bert=df_bert.T\\ndf_bert[\\'Labels\\']=list(df.Existence)\\n\\ndf_bert.to_csv(\"representations/df_bert.csv\")\\n'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Représentation de la base entière par BERT\n",
    "\"\"\"\n",
    "dataframe={}\n",
    "for tweet_index in tqdm(range(len(clean_text))):\n",
    "    dataframe[tweet_index]=BERT_embedding(clean_text[tweet_index],tokenizer)\n",
    "df_bert=pd.DataFrame(dataframe)\n",
    "df_bert=df_bert.T\n",
    "df_bert['Labels']=list(df.Existence)\n",
    "\n",
    "df_bert.to_csv(\"representations/df_bert.csv\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>759</th>\n",
       "      <th>760</th>\n",
       "      <th>761</th>\n",
       "      <th>762</th>\n",
       "      <th>763</th>\n",
       "      <th>764</th>\n",
       "      <th>765</th>\n",
       "      <th>766</th>\n",
       "      <th>767</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>-0.194920</td>\n",
       "      <td>-0.112881</td>\n",
       "      <td>0.388437</td>\n",
       "      <td>-0.109874</td>\n",
       "      <td>0.041914</td>\n",
       "      <td>-0.137204</td>\n",
       "      <td>0.109907</td>\n",
       "      <td>0.556634</td>\n",
       "      <td>-0.304503</td>\n",
       "      <td>-0.419192</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.042977</td>\n",
       "      <td>-0.004823</td>\n",
       "      <td>-0.049975</td>\n",
       "      <td>0.218379</td>\n",
       "      <td>-0.276184</td>\n",
       "      <td>0.220082</td>\n",
       "      <td>-0.796053</td>\n",
       "      <td>0.144477</td>\n",
       "      <td>-0.509098</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>-0.174782</td>\n",
       "      <td>-0.099447</td>\n",
       "      <td>-0.468011</td>\n",
       "      <td>0.108068</td>\n",
       "      <td>-0.028635</td>\n",
       "      <td>-0.427431</td>\n",
       "      <td>0.169761</td>\n",
       "      <td>0.651794</td>\n",
       "      <td>-0.305934</td>\n",
       "      <td>-0.692678</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.023003</td>\n",
       "      <td>-0.002153</td>\n",
       "      <td>-0.354740</td>\n",
       "      <td>0.397673</td>\n",
       "      <td>-0.244706</td>\n",
       "      <td>0.033439</td>\n",
       "      <td>-0.483247</td>\n",
       "      <td>-0.173934</td>\n",
       "      <td>-0.337515</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.039530</td>\n",
       "      <td>-0.073837</td>\n",
       "      <td>-0.087995</td>\n",
       "      <td>0.360194</td>\n",
       "      <td>0.181992</td>\n",
       "      <td>-0.366591</td>\n",
       "      <td>0.008656</td>\n",
       "      <td>0.453784</td>\n",
       "      <td>-0.260378</td>\n",
       "      <td>-0.490275</td>\n",
       "      <td>...</td>\n",
       "      <td>0.075246</td>\n",
       "      <td>0.057701</td>\n",
       "      <td>-0.087006</td>\n",
       "      <td>0.320335</td>\n",
       "      <td>-0.269148</td>\n",
       "      <td>0.119730</td>\n",
       "      <td>-0.637774</td>\n",
       "      <td>0.000480</td>\n",
       "      <td>-0.097225</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>-0.264160</td>\n",
       "      <td>-0.126185</td>\n",
       "      <td>-0.099923</td>\n",
       "      <td>0.301749</td>\n",
       "      <td>0.262108</td>\n",
       "      <td>-0.213265</td>\n",
       "      <td>0.108956</td>\n",
       "      <td>0.407808</td>\n",
       "      <td>-0.187299</td>\n",
       "      <td>-0.148701</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.155414</td>\n",
       "      <td>-0.248788</td>\n",
       "      <td>-0.342570</td>\n",
       "      <td>0.218711</td>\n",
       "      <td>-0.174955</td>\n",
       "      <td>-0.092277</td>\n",
       "      <td>-0.557828</td>\n",
       "      <td>-0.256308</td>\n",
       "      <td>-0.358489</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.078526</td>\n",
       "      <td>0.177795</td>\n",
       "      <td>0.488374</td>\n",
       "      <td>0.213472</td>\n",
       "      <td>0.312748</td>\n",
       "      <td>-0.280140</td>\n",
       "      <td>0.397646</td>\n",
       "      <td>0.429720</td>\n",
       "      <td>-0.310175</td>\n",
       "      <td>-0.554000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.093388</td>\n",
       "      <td>-0.008426</td>\n",
       "      <td>0.207753</td>\n",
       "      <td>0.094225</td>\n",
       "      <td>-0.148403</td>\n",
       "      <td>0.101668</td>\n",
       "      <td>-0.530785</td>\n",
       "      <td>0.069791</td>\n",
       "      <td>-0.241589</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5534</td>\n",
       "      <td>-0.400154</td>\n",
       "      <td>-0.256461</td>\n",
       "      <td>-0.183564</td>\n",
       "      <td>0.033262</td>\n",
       "      <td>0.159400</td>\n",
       "      <td>-0.255320</td>\n",
       "      <td>0.377321</td>\n",
       "      <td>0.061936</td>\n",
       "      <td>-0.094525</td>\n",
       "      <td>-0.187200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.181568</td>\n",
       "      <td>0.113463</td>\n",
       "      <td>-0.217428</td>\n",
       "      <td>-0.007062</td>\n",
       "      <td>-0.436011</td>\n",
       "      <td>-0.095360</td>\n",
       "      <td>-0.296756</td>\n",
       "      <td>0.257059</td>\n",
       "      <td>-0.234672</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5535</td>\n",
       "      <td>0.051658</td>\n",
       "      <td>-0.054771</td>\n",
       "      <td>0.298856</td>\n",
       "      <td>0.032705</td>\n",
       "      <td>0.214817</td>\n",
       "      <td>-0.419218</td>\n",
       "      <td>-0.005545</td>\n",
       "      <td>0.701181</td>\n",
       "      <td>-0.368737</td>\n",
       "      <td>-0.288521</td>\n",
       "      <td>...</td>\n",
       "      <td>0.209300</td>\n",
       "      <td>-0.141448</td>\n",
       "      <td>-0.260576</td>\n",
       "      <td>0.385859</td>\n",
       "      <td>-0.042413</td>\n",
       "      <td>-0.044953</td>\n",
       "      <td>-0.381793</td>\n",
       "      <td>0.155324</td>\n",
       "      <td>-0.293402</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5536</td>\n",
       "      <td>-0.120506</td>\n",
       "      <td>0.175940</td>\n",
       "      <td>0.014781</td>\n",
       "      <td>-0.156842</td>\n",
       "      <td>0.175269</td>\n",
       "      <td>0.039736</td>\n",
       "      <td>0.083392</td>\n",
       "      <td>0.751514</td>\n",
       "      <td>0.105191</td>\n",
       "      <td>-0.167486</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.151757</td>\n",
       "      <td>-0.134946</td>\n",
       "      <td>-0.152878</td>\n",
       "      <td>-0.033997</td>\n",
       "      <td>-0.350957</td>\n",
       "      <td>-0.388650</td>\n",
       "      <td>-0.116329</td>\n",
       "      <td>0.089427</td>\n",
       "      <td>-0.230295</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5537</td>\n",
       "      <td>0.073636</td>\n",
       "      <td>0.110835</td>\n",
       "      <td>0.429038</td>\n",
       "      <td>0.118876</td>\n",
       "      <td>0.007961</td>\n",
       "      <td>-0.031842</td>\n",
       "      <td>-0.030791</td>\n",
       "      <td>0.188152</td>\n",
       "      <td>-0.325286</td>\n",
       "      <td>-0.172276</td>\n",
       "      <td>...</td>\n",
       "      <td>0.337875</td>\n",
       "      <td>-0.096466</td>\n",
       "      <td>-0.481865</td>\n",
       "      <td>0.066156</td>\n",
       "      <td>-0.208680</td>\n",
       "      <td>0.082813</td>\n",
       "      <td>-0.188787</td>\n",
       "      <td>0.365409</td>\n",
       "      <td>0.169572</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5538</td>\n",
       "      <td>-0.029584</td>\n",
       "      <td>0.114278</td>\n",
       "      <td>0.226568</td>\n",
       "      <td>0.230094</td>\n",
       "      <td>-0.027433</td>\n",
       "      <td>-0.308322</td>\n",
       "      <td>0.019580</td>\n",
       "      <td>0.600823</td>\n",
       "      <td>-0.277417</td>\n",
       "      <td>-0.068723</td>\n",
       "      <td>...</td>\n",
       "      <td>0.241541</td>\n",
       "      <td>0.066769</td>\n",
       "      <td>-0.011381</td>\n",
       "      <td>0.492085</td>\n",
       "      <td>-0.038748</td>\n",
       "      <td>0.007048</td>\n",
       "      <td>-0.074291</td>\n",
       "      <td>0.399871</td>\n",
       "      <td>-0.195889</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5539 rows × 769 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5         6  \\\n",
       "0    -0.194920 -0.112881  0.388437 -0.109874  0.041914 -0.137204  0.109907   \n",
       "1    -0.174782 -0.099447 -0.468011  0.108068 -0.028635 -0.427431  0.169761   \n",
       "2     0.039530 -0.073837 -0.087995  0.360194  0.181992 -0.366591  0.008656   \n",
       "3    -0.264160 -0.126185 -0.099923  0.301749  0.262108 -0.213265  0.108956   \n",
       "4     0.078526  0.177795  0.488374  0.213472  0.312748 -0.280140  0.397646   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "5534 -0.400154 -0.256461 -0.183564  0.033262  0.159400 -0.255320  0.377321   \n",
       "5535  0.051658 -0.054771  0.298856  0.032705  0.214817 -0.419218 -0.005545   \n",
       "5536 -0.120506  0.175940  0.014781 -0.156842  0.175269  0.039736  0.083392   \n",
       "5537  0.073636  0.110835  0.429038  0.118876  0.007961 -0.031842 -0.030791   \n",
       "5538 -0.029584  0.114278  0.226568  0.230094 -0.027433 -0.308322  0.019580   \n",
       "\n",
       "             7         8         9  ...       759       760       761  \\\n",
       "0     0.556634 -0.304503 -0.419192  ... -0.042977 -0.004823 -0.049975   \n",
       "1     0.651794 -0.305934 -0.692678  ... -0.023003 -0.002153 -0.354740   \n",
       "2     0.453784 -0.260378 -0.490275  ...  0.075246  0.057701 -0.087006   \n",
       "3     0.407808 -0.187299 -0.148701  ... -0.155414 -0.248788 -0.342570   \n",
       "4     0.429720 -0.310175 -0.554000  ... -0.093388 -0.008426  0.207753   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "5534  0.061936 -0.094525 -0.187200  ...  0.181568  0.113463 -0.217428   \n",
       "5535  0.701181 -0.368737 -0.288521  ...  0.209300 -0.141448 -0.260576   \n",
       "5536  0.751514  0.105191 -0.167486  ... -0.151757 -0.134946 -0.152878   \n",
       "5537  0.188152 -0.325286 -0.172276  ...  0.337875 -0.096466 -0.481865   \n",
       "5538  0.600823 -0.277417 -0.068723  ...  0.241541  0.066769 -0.011381   \n",
       "\n",
       "           762       763       764       765       766       767  Labels  \n",
       "0     0.218379 -0.276184  0.220082 -0.796053  0.144477 -0.509098     Yes  \n",
       "1     0.397673 -0.244706  0.033439 -0.483247 -0.173934 -0.337515     Yes  \n",
       "2     0.320335 -0.269148  0.119730 -0.637774  0.000480 -0.097225     Yes  \n",
       "3     0.218711 -0.174955 -0.092277 -0.557828 -0.256308 -0.358489     Yes  \n",
       "4     0.094225 -0.148403  0.101668 -0.530785  0.069791 -0.241589     Yes  \n",
       "...        ...       ...       ...       ...       ...       ...     ...  \n",
       "5534 -0.007062 -0.436011 -0.095360 -0.296756  0.257059 -0.234672     NaN  \n",
       "5535  0.385859 -0.042413 -0.044953 -0.381793  0.155324 -0.293402      No  \n",
       "5536 -0.033997 -0.350957 -0.388650 -0.116329  0.089427 -0.230295      No  \n",
       "5537  0.066156 -0.208680  0.082813 -0.188787  0.365409  0.169572      No  \n",
       "5538  0.492085 -0.038748  0.007048 -0.074291  0.399871 -0.195889     NaN  \n",
       "\n",
       "[5539 rows x 769 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bert=pd.read_csv(\"representations/df_bert.csv\",index_col=0)\n",
    "\n",
    "df_bert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. Classification des tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le premier objectif de cette partie est d'estimer les performances de nos différentes représentations. L'idée est d'entrainer des modèles de classification pour voir si ils arrivent à bien discerner les personnes pour/contre le réchauffement climatique à partir des différentes représentations\n",
    "\n",
    "\n",
    "Nous avons utilisé des modèles de classifications classiques comme le RandomForest, le XGBoost et un SVM.\n",
    "\n",
    "Pour avoir une idée de la significativité des résultats, nous avons utilisé un modèle 'représentation-free' dans le sens où il ne dépend pas de la représentation. Il s'agit du réseau de neuronnes LSTM (Long short-term memory) qui prend en input directement le texte."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Bases considérées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bases d'apprentissage\n",
    "\n",
    "## Liste des bases d'apprentissage\n",
    "dic_representations_init={'tf_idf':df_tfidf,'word2vec':df_word2vec,'fast2vec_cluster':df_fast2vec_cluster,\n",
    "                        'fast2vec_mean':df_fast2vec_mean, 'bert':df_bert} \n",
    "dic_representations={}\n",
    "dic_representations_labels={}\n",
    "\n",
    "### fonction\n",
    "def conserv_YN(base_):\n",
    "    base_=base_[(base_.Labels=='Yes')|(base_.Labels=='No')]\n",
    "    labels=list(base_.Labels)\n",
    "    base_=base_[[str(x) for x in range((base_.shape[1]-1))]]\n",
    "    return([base_,labels])\n",
    "\n",
    "### applications aux bases \n",
    "for base_name in dic_representations_init.keys():\n",
    "    dic_representations[base_name],labels=conserv_YN(dic_representations_init[base_name])[0],conserv_YN(dic_representations_init[base_name])[1]\n",
    "    #labels=conserv_YN(dic_representations[base_name])[1]\n",
    "    dic_representations_labels[base_name]=[(labels[tweet]=='Yes')*1 for tweet in range(len(labels))]\n",
    "\n",
    "### labels=0 si 'No' \n",
    "###labels=1 si 'Yes'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Algorithmes de classifications classiques : XGboost, RandomForest, SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création des bases de train/test\n",
    "\n",
    "def X_split(base_name):\n",
    "    return(train_test_split(dic_representations[base_name],dic_representations_labels[base_name], test_size=0.5))\n",
    "\n",
    "dic_Xtrain={}\n",
    "dic_Ytrain={}\n",
    "dic_Xtest={}\n",
    "dic_Ytest={}\n",
    "for base_name in dic_representations.keys():\n",
    "    Xtrain,Xtest,Ytrain,Ytest=X_split(base_name)\n",
    "    dic_Xtrain[base_name]=Xtrain.reset_index()\n",
    "    dic_Ytrain[base_name]=Ytrain\n",
    "    dic_Xtest[base_name]=Xtest.reset_index()\n",
    "    dic_Ytest[base_name]=Ytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"    \\n## Apprentissage et sauvegarde\\n### vous devez créer un répertoire nommer 'models' pour sauvegarder les modèles \\nresults = pd.DataFrame({},index=['precision_yes','precision_no','precision_global','f1_yes','f1_no','f1_global']).T\\nprint(' ')\\nfor name_representation in dic_representations.keys():\\n    print('APPRENTISSAGE {} : '.format(name_representation))\\n    print(' ')\\n    resutls_representation=models_XGB_RF_SVM(name_representation,'models')\\n    results = pd.concat([results, resutls_representation])\\n    print(' ')\\n    print('#'*60)\\n    print('#'*60)\\n\\n### Export des résultats \\nresults.to_csv('results_classification_classique.csv')\\n\""
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apprentissage des modèles pour chaque représentation et sauvegarde des résultats sur le test\n",
    "\n",
    "## fonction\n",
    "def models_XGB_RF_SVM(name_representation,name_folder_tosave_models):\n",
    "    \n",
    "    df_representation={}\n",
    "\n",
    "    ##RandomForest apprentissage\n",
    "    print('Apprentissage Random Forest ...')\n",
    "    t=time.time()\n",
    "    rfc = RandomForestClassifier(n_estimators=100)\n",
    "    rfc.fit(dic_Xtrain[name_representation],dic_Ytrain[name_representation])\n",
    "    print('Apprentissage Random Forest done ({}s to learn)'.format(str(round(time.time()-t,0))))\n",
    "    with open(name_folder_tosave_models+'/{}_RF_model.p'.format(name_representation), 'wb') as fp:\n",
    "        pickle.dump(rfc, fp)\n",
    "    print(' ')\n",
    "    \n",
    "    ##RandomForest predictions et scores\n",
    "    predictions=rfc.predict(dic_Xtest[name_representation])\n",
    "    precision_yes=precision_score(dic_Ytest[name_representation], predictions,average=None)[1]\n",
    "    precision_no=precision_score(dic_Ytest[name_representation], predictions,average=None)[0]\n",
    "    precision_gen=precision_score(dic_Ytest[name_representation], predictions, average='macro')\n",
    "    f1_yes=f1_score(dic_Ytest[name_representation], predictions,average=None)[1]\n",
    "    f1_no=f1_score(dic_Ytest[name_representation], predictions,average=None)[0]\n",
    "    f1_gen=f1_score(dic_Ytest[name_representation], predictions, average='macro')\n",
    "    df_representation['RandomForest_{}'.format(name_representation)]=[precision_yes,precision_no,precision_gen,f1_yes,f1_no,f1_gen]\n",
    "    \n",
    "\n",
    "    ##XgBoost Classifier\n",
    "    print('Apprentissage XGBoost ...')\n",
    "    t=time.time()\n",
    "    clf = xgb.XGBClassifier()\n",
    "    clf.fit(dic_Xtrain[name_representation],dic_Ytrain[name_representation])\n",
    "    print('Apprentissage XGBoost done ({}s to learn)'.format(str(round(time.time()-t,0))))\n",
    "    with open(name_folder_tosave_models+'/{}_XGB_model.p'.format(name_representation), 'wb') as fp:\n",
    "        pickle.dump(clf, fp)\n",
    "    print(' ')\n",
    "    \n",
    "    ##XgBoost Classifier predictions et scores\n",
    "    predictions=clf.predict(dic_Xtest[name_representation])\n",
    "    precision_yes=precision_score(dic_Ytest[name_representation], predictions,average=None)[1]\n",
    "    precision_no=precision_score(dic_Ytest[name_representation], predictions,average=None)[0]\n",
    "    precision_gen=precision_score(dic_Ytest[name_representation], predictions, average='macro')\n",
    "    f1_yes=f1_score(dic_Ytest[name_representation], predictions,average=None)[1]\n",
    "    f1_no=f1_score(dic_Ytest[name_representation], predictions,average=None)[0]\n",
    "    f1_gen=f1_score(dic_Ytest[name_representation], predictions, average='macro')\n",
    "    df_representation['XGBoost_{}'.format(name_representation)]=[precision_yes,precision_no,precision_gen,f1_yes,f1_no,f1_gen]\n",
    "\n",
    "\n",
    "    ##SVM\n",
    "    print('Apprentissage SVM ...')\n",
    "    t=time.time()\n",
    "    svm = SVC()\n",
    "    svm.fit(dic_Xtrain[name_representation],dic_Ytrain[name_representation])\n",
    "    print('Apprentissage SVM done ({}s to learn)'.format(str(round(time.time()-t,0))))\n",
    "    with open(name_folder_tosave_models+'/{}_SVM_model.p'.format(name_representation), 'wb') as fp:\n",
    "        pickle.dump(svm, fp)\n",
    "    print(' ')\n",
    "    print('#'*60)\n",
    "    print('#'*60)\n",
    "    print(' ')\n",
    "    print('Sauvegarde des résultats...')\n",
    "    ##SVM Classifier predictions et scores\n",
    "    predictions=svm.predict(dic_Xtest[name_representation])\n",
    "    precision_yes=precision_score(dic_Ytest[name_representation], predictions,average=None)[1]\n",
    "    precision_no=precision_score(dic_Ytest[name_representation], predictions,average=None)[0]\n",
    "    precision_gen=precision_score(dic_Ytest[name_representation], predictions, average='macro')\n",
    "    f1_yes=f1_score(dic_Ytest[name_representation], predictions,average=None)[1]\n",
    "    f1_no=f1_score(dic_Ytest[name_representation], predictions,average=None)[0]\n",
    "    f1_gen=f1_score(dic_Ytest[name_representation], predictions, average='macro')\n",
    "    df_representation['SVM_{}'.format(name_representation)]=[precision_yes,precision_no,precision_gen,f1_yes,f1_no,f1_gen]\n",
    "    \n",
    "    \n",
    "    ##DataFrame avec les résultats pour les trois modèles \n",
    "    df_representation_results=pd.DataFrame(df_representation,index=['precision_yes','precision_no','precision_global','f1_yes','f1_no','f1_global']).T\n",
    "    \n",
    "    return(df_representation_results)\n",
    "\"\"\"    \n",
    "## Apprentissage et sauvegarde\n",
    "### vous devez créer un répertoire nommer 'models' pour sauvegarder les modèles \n",
    "results = pd.DataFrame({},index=['precision_yes','precision_no','precision_global','f1_yes','f1_no','f1_global']).T\n",
    "print(' ')\n",
    "for name_representation in dic_representations.keys():\n",
    "    print('APPRENTISSAGE {} : '.format(name_representation))\n",
    "    print(' ')\n",
    "    resutls_representation=models_XGB_RF_SVM(name_representation,'models')\n",
    "    results = pd.concat([results, resutls_representation])\n",
    "    print(' ')\n",
    "    print('#'*60)\n",
    "    print('#'*60)\n",
    "\n",
    "### Export des résultats \n",
    "results.to_csv('results_classification_classique.csv')\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "Scores obtenus avec les modèles classiques :\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision_yes</th>\n",
       "      <th>precision_no</th>\n",
       "      <th>precision_global</th>\n",
       "      <th>f1_yes</th>\n",
       "      <th>f1_no</th>\n",
       "      <th>f1_global</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>RandomForest_tf_idf</td>\n",
       "      <td>0.782007</td>\n",
       "      <td>0.778351</td>\n",
       "      <td>0.780179</td>\n",
       "      <td>0.865624</td>\n",
       "      <td>0.417704</td>\n",
       "      <td>0.641664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>XGBoost_tf_idf</td>\n",
       "      <td>0.772260</td>\n",
       "      <td>0.738636</td>\n",
       "      <td>0.755448</td>\n",
       "      <td>0.858775</td>\n",
       "      <td>0.368794</td>\n",
       "      <td>0.613785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>SVM_tf_idf</td>\n",
       "      <td>0.738313</td>\n",
       "      <td>0.626866</td>\n",
       "      <td>0.682589</td>\n",
       "      <td>0.842945</td>\n",
       "      <td>0.140940</td>\n",
       "      <td>0.491942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>RandomForest_word2vec</td>\n",
       "      <td>0.795699</td>\n",
       "      <td>0.582133</td>\n",
       "      <td>0.688916</td>\n",
       "      <td>0.843164</td>\n",
       "      <td>0.463303</td>\n",
       "      <td>0.653233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>XGBoost_word2vec</td>\n",
       "      <td>0.804672</td>\n",
       "      <td>0.578811</td>\n",
       "      <td>0.691742</td>\n",
       "      <td>0.842391</td>\n",
       "      <td>0.491228</td>\n",
       "      <td>0.666810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>SVM_word2vec</td>\n",
       "      <td>0.765133</td>\n",
       "      <td>0.496377</td>\n",
       "      <td>0.630755</td>\n",
       "      <td>0.827496</td>\n",
       "      <td>0.342072</td>\n",
       "      <td>0.584784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>RandomForest_fast2vec_cluster</td>\n",
       "      <td>0.815163</td>\n",
       "      <td>0.644578</td>\n",
       "      <td>0.729871</td>\n",
       "      <td>0.863018</td>\n",
       "      <td>0.508918</td>\n",
       "      <td>0.685968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>XGBoost_fast2vec_cluster</td>\n",
       "      <td>0.795455</td>\n",
       "      <td>0.652344</td>\n",
       "      <td>0.723899</td>\n",
       "      <td>0.860563</td>\n",
       "      <td>0.436601</td>\n",
       "      <td>0.648582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>SVM_fast2vec_cluster</td>\n",
       "      <td>0.768908</td>\n",
       "      <td>0.473282</td>\n",
       "      <td>0.621095</td>\n",
       "      <td>0.830470</td>\n",
       "      <td>0.321660</td>\n",
       "      <td>0.576065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>RandomForest_fast2vec_mean</td>\n",
       "      <td>0.753326</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.763760</td>\n",
       "      <td>0.851771</td>\n",
       "      <td>0.288722</td>\n",
       "      <td>0.570246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>XGBoost_fast2vec_mean</td>\n",
       "      <td>0.787132</td>\n",
       "      <td>0.705660</td>\n",
       "      <td>0.746396</td>\n",
       "      <td>0.858361</td>\n",
       "      <td>0.464020</td>\n",
       "      <td>0.661190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>SVM_fast2vec_mean</td>\n",
       "      <td>0.751286</td>\n",
       "      <td>0.592179</td>\n",
       "      <td>0.671733</td>\n",
       "      <td>0.838010</td>\n",
       "      <td>0.294444</td>\n",
       "      <td>0.566227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>RandomForest_bert</td>\n",
       "      <td>0.790476</td>\n",
       "      <td>0.689516</td>\n",
       "      <td>0.739996</td>\n",
       "      <td>0.860940</td>\n",
       "      <td>0.443580</td>\n",
       "      <td>0.652260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>XGBoost_bert</td>\n",
       "      <td>0.814815</td>\n",
       "      <td>0.643646</td>\n",
       "      <td>0.729231</td>\n",
       "      <td>0.858970</td>\n",
       "      <td>0.526554</td>\n",
       "      <td>0.692762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>SVM_bert</td>\n",
       "      <td>0.757135</td>\n",
       "      <td>0.502370</td>\n",
       "      <td>0.629752</td>\n",
       "      <td>0.832799</td>\n",
       "      <td>0.288828</td>\n",
       "      <td>0.560814</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               precision_yes  precision_no  precision_global  \\\n",
       "RandomForest_tf_idf                 0.782007      0.778351          0.780179   \n",
       "XGBoost_tf_idf                      0.772260      0.738636          0.755448   \n",
       "SVM_tf_idf                          0.738313      0.626866          0.682589   \n",
       "RandomForest_word2vec               0.795699      0.582133          0.688916   \n",
       "XGBoost_word2vec                    0.804672      0.578811          0.691742   \n",
       "SVM_word2vec                        0.765133      0.496377          0.630755   \n",
       "RandomForest_fast2vec_cluster       0.815163      0.644578          0.729871   \n",
       "XGBoost_fast2vec_cluster            0.795455      0.652344          0.723899   \n",
       "SVM_fast2vec_cluster                0.768908      0.473282          0.621095   \n",
       "RandomForest_fast2vec_mean          0.753326      0.774194          0.763760   \n",
       "XGBoost_fast2vec_mean               0.787132      0.705660          0.746396   \n",
       "SVM_fast2vec_mean                   0.751286      0.592179          0.671733   \n",
       "RandomForest_bert                   0.790476      0.689516          0.739996   \n",
       "XGBoost_bert                        0.814815      0.643646          0.729231   \n",
       "SVM_bert                            0.757135      0.502370          0.629752   \n",
       "\n",
       "                                 f1_yes     f1_no  f1_global  \n",
       "RandomForest_tf_idf            0.865624  0.417704   0.641664  \n",
       "XGBoost_tf_idf                 0.858775  0.368794   0.613785  \n",
       "SVM_tf_idf                     0.842945  0.140940   0.491942  \n",
       "RandomForest_word2vec          0.843164  0.463303   0.653233  \n",
       "XGBoost_word2vec               0.842391  0.491228   0.666810  \n",
       "SVM_word2vec                   0.827496  0.342072   0.584784  \n",
       "RandomForest_fast2vec_cluster  0.863018  0.508918   0.685968  \n",
       "XGBoost_fast2vec_cluster       0.860563  0.436601   0.648582  \n",
       "SVM_fast2vec_cluster           0.830470  0.321660   0.576065  \n",
       "RandomForest_fast2vec_mean     0.851771  0.288722   0.570246  \n",
       "XGBoost_fast2vec_mean          0.858361  0.464020   0.661190  \n",
       "SVM_fast2vec_mean              0.838010  0.294444   0.566227  \n",
       "RandomForest_bert              0.860940  0.443580   0.652260  \n",
       "XGBoost_bert                   0.858970  0.526554   0.692762  \n",
       "SVM_bert                       0.832799  0.288828   0.560814  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import des modèles et print\n",
    "\n",
    "results = pd.read_csv('results_classification_classique.csv',index_col=0)\n",
    "\n",
    "print(' ')\n",
    "print('Scores obtenus avec les modèles classiques :')\n",
    "display(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Classification avec le LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Le maximum de mots à utiliser \\nMax_nb_words= 50000\\n# Longueur maximum du tweet \\nMax_sequence_length = 30 # on a retenu en moyenne 14 mots par tweet\\nEmbedding_dim= 100\\ntokenizer = keras.preprocessing.text.Tokenizer(num_words=Max_nb_words, filters=\\'!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\', lower=True)\\n\\n################################################################\\n################################################################\\n\\n# Formating des bases en input\\n\\n# Tweets to convert\\ncorpus=import_clean_text()\\nlabels=list(df.Existence)\\ncorpus_new=[]\\nfor tweet in corpus: \\n    tweet_sentence=\\'\\'\\n    for word in tweet:\\n        tweet_sentence=tweet_sentence+\\' \\'+word\\n    corpus_new.append(tweet_sentence)\\n\\ncorpus=[]\\nnew_labels=[]\\nfor label_index in range(len(labels)):\\n    if (labels[label_index]==\\'Yes\\')or(labels[label_index]==\\'No\\'):\\n        corpus.append(corpus_new[label_index])\\n        new_labels.append(labels[label_index])\\nlabels=new_labels\\nlabels=[(labels[tweet]==\\'Yes\\')*1 for tweet in range(len(labels))]\\n\\n    \\ntokenizer.fit_on_texts(np.array(corpus))\\nX = tokenizer.texts_to_sequences(np.array(corpus))\\nX = sequence.pad_sequences(X, maxlen=Max_sequence_length) \\n\\nX_train, X_test, Y_train, Y_test= train_test_split(X,labels, test_size=0.5)\\n'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hyperparamètres du réseau \n",
    "\"\"\"\n",
    "# Le maximum de mots à utiliser \n",
    "Max_nb_words= 50000\n",
    "# Longueur maximum du tweet \n",
    "Max_sequence_length = 30 # on a retenu en moyenne 14 mots par tweet\n",
    "Embedding_dim= 100\n",
    "tokenizer = keras.preprocessing.text.Tokenizer(num_words=Max_nb_words, filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~', lower=True)\n",
    "\n",
    "################################################################\n",
    "################################################################\n",
    "\n",
    "# Formating des bases en input\n",
    "\n",
    "# Tweets to convert\n",
    "corpus=import_clean_text()\n",
    "labels=list(df.Existence)\n",
    "corpus_new=[]\n",
    "for tweet in corpus: \n",
    "    tweet_sentence=''\n",
    "    for word in tweet:\n",
    "        tweet_sentence=tweet_sentence+' '+word\n",
    "    corpus_new.append(tweet_sentence)\n",
    "\n",
    "corpus=[]\n",
    "new_labels=[]\n",
    "for label_index in range(len(labels)):\n",
    "    if (labels[label_index]=='Yes')or(labels[label_index]=='No'):\n",
    "        corpus.append(corpus_new[label_index])\n",
    "        new_labels.append(labels[label_index])\n",
    "labels=new_labels\n",
    "labels=[(labels[tweet]=='Yes')*1 for tweet in range(len(labels))]\n",
    "\n",
    "    \n",
    "tokenizer.fit_on_texts(np.array(corpus))\n",
    "X = tokenizer.texts_to_sequences(np.array(corpus))\n",
    "X = sequence.pad_sequences(X, maxlen=Max_sequence_length) \n",
    "\n",
    "X_train, X_test, Y_train, Y_test= train_test_split(X,labels, test_size=0.5)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n## entrainement du modèle \\nembedding_vecor_length = 32\\nmodel = Sequential()\\nmodel.add(Embedding(Max_nb_words, Embedding_dim, input_length=Max_sequence_length))\\nmodel.add(LSTM(100))\\nmodel.add(Dense(1, activation='sigmoid'))\\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\\nprint(model.summary())\\nmodel.fit(X_train, Y_train, epochs=10, batch_size=64)\\n\\n## prédictions du modèle sur la base de test\\nprint(' ')\\nprint(' ')\\nprint('#'*60)\\nprint(' ')\\nprint('Prédiction LSTM sur le Test...')\\npred_LSTM=model.predict(X_test)\\npred_LSTM=[(float(pred_LSTM[pred])>=0.5)*1 for pred in range(len(pred_LSTM))]\\nprint('DONE')\\nprint(' ')\\n\\n## export des résultats\\ndf_results={}\\nprecision_yes=precision_score(Y_test, pred_LSTM,average=None)[1]\\nprecision_no=precision_score(Y_test, pred_LSTM,average=None)[1]\\nprecision_gen=precision_score(Y_test, pred_LSTM, average='macro')\\nf1_yes=f1_score(Y_test, pred_LSTM,average=None)[1]\\nf1_no=f1_score(Y_test, pred_LSTM,average=None)[0]\\nf1_gen=f1_score(Y_test, pred_LSTM, average='macro')\\ndf_results['LSTM']=[precision_yes,precision_no,precision_gen,f1_yes,f1_no,f1_gen]\\ndf_results=pd.DataFrame(df_results,index=['precision_yes','precision_no','precision_global','f1_yes','f1_no','f1_global']).T\\ndf_results.to_csv('results_classification_LSTM.csv')\\n\\n\""
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creation du modèle et entrainement \n",
    "\"\"\"\n",
    "## entrainement du modèle \n",
    "embedding_vecor_length = 32\n",
    "model = Sequential()\n",
    "model.add(Embedding(Max_nb_words, Embedding_dim, input_length=Max_sequence_length))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "model.fit(X_train, Y_train, epochs=10, batch_size=64)\n",
    "\n",
    "## prédictions du modèle sur la base de test\n",
    "print(' ')\n",
    "print(' ')\n",
    "print('#'*60)\n",
    "print(' ')\n",
    "print('Prédiction LSTM sur le Test...')\n",
    "pred_LSTM=model.predict(X_test)\n",
    "pred_LSTM=[(float(pred_LSTM[pred])>=0.5)*1 for pred in range(len(pred_LSTM))]\n",
    "print('DONE')\n",
    "print(' ')\n",
    "\n",
    "## export des résultats\n",
    "df_results={}\n",
    "precision_yes=precision_score(Y_test, pred_LSTM,average=None)[1]\n",
    "precision_no=precision_score(Y_test, pred_LSTM,average=None)[1]\n",
    "precision_gen=precision_score(Y_test, pred_LSTM, average='macro')\n",
    "f1_yes=f1_score(Y_test, pred_LSTM,average=None)[1]\n",
    "f1_no=f1_score(Y_test, pred_LSTM,average=None)[0]\n",
    "f1_gen=f1_score(Y_test, pred_LSTM, average='macro')\n",
    "df_results['LSTM']=[precision_yes,precision_no,precision_gen,f1_yes,f1_no,f1_gen]\n",
    "df_results=pd.DataFrame(df_results,index=['precision_yes','precision_no','precision_global','f1_yes','f1_no','f1_global']).T\n",
    "df_results.to_csv('results_classification_LSTM.csv')\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "Scores obtenus avec le modèle LSTM \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision_yes</th>\n",
       "      <th>precision_no</th>\n",
       "      <th>precision_global</th>\n",
       "      <th>f1_yes</th>\n",
       "      <th>f1_no</th>\n",
       "      <th>f1_global</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>LSTM</td>\n",
       "      <td>0.835072</td>\n",
       "      <td>0.835072</td>\n",
       "      <td>0.755099</td>\n",
       "      <td>0.87054</td>\n",
       "      <td>0.582694</td>\n",
       "      <td>0.726617</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      precision_yes  precision_no  precision_global   f1_yes     f1_no  \\\n",
       "LSTM       0.835072      0.835072          0.755099  0.87054  0.582694   \n",
       "\n",
       "      f1_global  \n",
       "LSTM   0.726617  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n"
     ]
    }
   ],
   "source": [
    "# Import des résultats et prints\n",
    "\n",
    "df_results = pd.read_csv('results_classification_LSTM.csv',index_col=0)\n",
    "\n",
    "print(' ')\n",
    "print('Scores obtenus avec le modèle LSTM ')\n",
    "display(df_results)\n",
    "print(' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III. Analyse des tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III.a Première analyse descriptive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bases des tweets Yes et des tweets No\n",
    "\n",
    "df_yes=df[df.Existence=='Yes'].reset_index()\n",
    "Tweet_clean_yes=import_clean_text(option='yes') \n",
    "Tweet_clean_yes=reduce(add, Tweet_clean_yes)\n",
    "\n",
    "df_no=df[df.Existence=='No'].reset_index()\n",
    "Tweet_clean_no=import_clean_text(option='no') \n",
    "Tweet_clean_no=reduce(add, Tweet_clean_no)\n",
    "\n",
    "Tweet_clean=import_clean_text() \n",
    "Tweet_clean=reduce(add, Tweet_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les 10 mots qui apparaissent le plus dans la base sont (par ordre décroissant) :\n",
      " \n",
      "climate_change (2936) \n",
      "global_warming (2709) \n",
      "the (2275) \n",
      "be (1801) \n",
      "to (1443) \n",
      "of (1328) \n",
      "a (1193) \n",
      "on (962) \n",
      "and (869) \n",
      "in (845) \n"
     ]
    }
   ],
   "source": [
    "# Mots les plus occurents dans la base globale\n",
    "counter=collections.Counter(Tweet_clean)\n",
    "\n",
    "number_word=10\n",
    "print('Les {} mots qui apparaissent le plus dans la base sont (par ordre décroissant) :'.format(number_word))\n",
    "print(' ')\n",
    "for word in counter.most_common(number_word):\n",
    "    print(word[0]+' ('+str(word[1])+') ') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les 10 mots qui apparaissent le plus dans la base No sont (par ordre décroissant) :\n",
      " \n",
      "global_warming (812) \n",
      "be (547) \n",
      "the (454) \n",
      "a (311) \n",
      "climate_change (280) \n",
      "of (269) \n",
      "to (260) \n",
      "it (185) \n",
      "in (146) \n",
      "on (143) \n"
     ]
    }
   ],
   "source": [
    "# Mots les plus occurents dans la base No\n",
    "counter=collections.Counter(Tweet_clean_no)\n",
    "\n",
    "number_word=10\n",
    "print('Les {} mots qui apparaissent le plus dans la base No sont (par ordre décroissant) :'.format(number_word))\n",
    "print(' ')\n",
    "for word in counter.most_common(number_word):\n",
    "    print(word[0]+' ('+str(word[1])+') ') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les 10 mots qui apparaissent le plus dans la base Yes sont (par ordre décroissant) :\n",
      " \n",
      "climate_change (1607) \n",
      "global_warming (1309) \n",
      "the (1138) \n",
      "be (902) \n",
      "to (840) \n",
      "of (634) \n",
      "a (577) \n",
      "on (479) \n",
      "and (468) \n",
      "in (455) \n"
     ]
    }
   ],
   "source": [
    "# Mots les plus occurents dans la base Yes\n",
    "counter=collections.Counter(Tweet_clean_yes)\n",
    "\n",
    "number_word=10\n",
    "print('Les {} mots qui apparaissent le plus dans la base Yes sont (par ordre décroissant) :'.format(number_word))\n",
    "print(' ')\n",
    "for word in counter.most_common(number_word):\n",
    "    print(word[0]+' ('+str(word[1])+') ') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sous ce point de vue, il n'y a pas de réelle différence entre la base No et Yes. On regarde donc ceux qui sont propres aux Yes parmis les 200 mots les plus occurrents. Pareil pour les mots propres aux No."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determination des mots propres aux tweets Yes et aux tweets No\n",
    "\n",
    "counter=collections.Counter(Tweet_clean_yes)\n",
    "list_commun_yes=[word[0] for word in counter.most_common(200)]\n",
    "\n",
    "counter=collections.Counter(Tweet_clean_no)\n",
    "list_commun_no=[word[0] for word in counter.most_common(200)]\n",
    "\n",
    "list_spe_yes=[]\n",
    "for word in list_commun_yes:\n",
    "    if word not in list_commun_no:\n",
    "        list_spe_yes.append(word)\n",
    "        \n",
    "list_spe_no=[]\n",
    "for word in list_commun_no:\n",
    "    if word not in list_commun_yes:\n",
    "        list_spe_no.append(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On s'interesse maintenant en détails aux statistiques de présences de ces mots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calcul des statistiques les mots intéressants que l'on a retenu\n",
    "\n",
    "## Mots intéressantes \n",
    "mots_interessants_yes=['green','us','could','world','energy','earth','fight','worse','help','carbon']\n",
    "mots_interessants_no=['gore','hoax','scam','climategate','gop','teaparty','palin','collapse','fraud','believe']\n",
    "\n",
    "#################################################\n",
    "#################################################\n",
    "\n",
    "##Calcul des statistiques \n",
    "\n",
    "counter_yes=collections.Counter(Tweet_clean_yes)\n",
    "counter_no=collections.Counter(Tweet_clean_no)\n",
    "\n",
    "### Fréquence de ces mots dans les bases\n",
    "frequence_yes_in_yes={}\n",
    "frequence_yes_in_no={}\n",
    "for word in mots_interessants_yes:\n",
    "    frequence_yes_in_yes[word]=counter_yes[word]/len(Tweet_clean_yes)*100\n",
    "    frequence_yes_in_no[word]=counter_no[word]/len(Tweet_clean_no)*100\n",
    "    \n",
    "    \n",
    "frequence_no_in_no={}\n",
    "frequence_no_in_yes={}\n",
    "for word in mots_interessants_no:\n",
    "    frequence_no_in_no[word]=(counter_no[word]/len(Tweet_clean_no))*100\n",
    "    frequence_no_in_yes[word]=(counter_yes[word]/len(Tweet_clean_yes))*100\n",
    "    \n",
    "### Nombre de tweets dans lequels ils apparaissent \n",
    "def Number_apparition_tweets(list_tweet,word):\n",
    "    number=0\n",
    "    for tweet in list_tweet:\n",
    "        if word in tweet:\n",
    "            number=number+1\n",
    "    return(number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mots intéressants en faveur du changement climatique :\n",
      " \n",
      "'fréquence'=tout mots compris de la base Yes (ou No)\n",
      " \n",
      "statistiques dans les tweets Yes :\n",
      " \n",
      "green: frequence = 0.28% , nombre de tweets le contenant = 91 (sur 2821)--> 3.23%\n",
      "us: frequence = 0.01% , nombre de tweets le contenant = 3 (sur 2821)--> 0.11%\n",
      "could: frequence = 0.18% , nombre de tweets le contenant = 62 (sur 2821)--> 2.2%\n",
      "world: frequence = 0.2% , nombre de tweets le contenant = 67 (sur 2821)--> 2.38%\n",
      "energy: frequence = 0.18% , nombre de tweets le contenant = 59 (sur 2821)--> 2.09%\n",
      "earth: frequence = 0.11% , nombre de tweets le contenant = 38 (sur 2821)--> 1.35%\n",
      "fight: frequence = 0.21% , nombre de tweets le contenant = 73 (sur 2821)--> 2.59%\n",
      "worse: frequence = 0.0% , nombre de tweets le contenant = 0 (sur 2821)--> 0.0%\n",
      "help: frequence = 0.11% , nombre de tweets le contenant = 38 (sur 2821)--> 1.35%\n",
      "carbon: frequence = 0.13% , nombre de tweets le contenant = 44 (sur 2821)--> 1.56%\n",
      " \n",
      "##########\n",
      " \n",
      "statistiques dans les tweets No :\n",
      " \n",
      "green: frequence  = 0.1% , nombre de tweets le contenant = 14 (sur 1035)--> 1.35%\n",
      "us: frequence  = 0.01% , nombre de tweets le contenant = 1 (sur 1035)--> 0.1%\n",
      "could: frequence  = 0.08% , nombre de tweets le contenant = 11 (sur 1035)--> 1.06%\n",
      "world: frequence  = 0.09% , nombre de tweets le contenant = 12 (sur 1035)--> 1.16%\n",
      "energy: frequence  = 0.06% , nombre de tweets le contenant = 9 (sur 1035)--> 0.87%\n",
      "earth: frequence  = 0.06% , nombre de tweets le contenant = 9 (sur 1035)--> 0.87%\n",
      "fight: frequence  = 0.04% , nombre de tweets le contenant = 6 (sur 1035)--> 0.58%\n",
      "worse: frequence  = 0.0% , nombre de tweets le contenant = 0 (sur 1035)--> 0.0%\n",
      "help: frequence  = 0.07% , nombre de tweets le contenant = 10 (sur 1035)--> 0.97%\n",
      "carbon: frequence  = 0.04% , nombre de tweets le contenant = 6 (sur 1035)--> 0.58%\n"
     ]
    }
   ],
   "source": [
    "# Print des résultats pour les tweets en faveur du changement climatique\n",
    "\n",
    "print('Mots intéressants en faveur du changement climatique :')\n",
    "print(' ')\n",
    "print('\\'fréquence\\'=tout mots compris de la base Yes (ou No)')\n",
    "print(' ')\n",
    "print('statistiques dans les tweets Yes :')\n",
    "print(' ')\n",
    "list_tweet_yes=import_clean_text(option='yes')\n",
    "for key in frequence_yes_in_yes.keys():\n",
    "    print(key+': frequence = '+str(round(frequence_yes_in_yes[key],2))+'%'+' , nombre de tweets le contenant = '+str(Number_apparition_tweets(list_tweet_yes,key))+' (sur {})'.format(len(list_tweet_yes))+'--> {}%'.format(round(100*Number_apparition_tweets(list_tweet_yes,key)/len(list_tweet_yes),2)))                                   \n",
    "print(' ') \n",
    "print('#'*10)\n",
    "print(' ')\n",
    "print('statistiques dans les tweets No :')\n",
    "print(' ')\n",
    "list_tweet_no=import_clean_text(option='no')\n",
    "for key in frequence_yes_in_no.keys():\n",
    "    print(key+': frequence  = '+str(round(frequence_yes_in_no[key],2))+'%'+' , nombre de tweets le contenant = '+str(Number_apparition_tweets(list_tweet_no,key))+' (sur {})'.format(len(list_tweet_no))+'--> {}%'.format(round(100*Number_apparition_tweets(list_tweet_no,key)/len(list_tweet_no),2))) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mots intéressants contre changement climatique :\n",
      " \n",
      "'fréquence'=tout mots compris de la base Yes (ou No)\n",
      " \n",
      "statistiques dans les tweets Yes :\n",
      " \n",
      "gore: frequence  = 0.01% , nombre de tweets le contenant = 2 (sur 2821)--> 0.07%\n",
      "hoax: frequence  = 0.02% , nombre de tweets le contenant = 6 (sur 2821)--> 0.21%\n",
      "scam: frequence  = 0.0% , nombre de tweets le contenant = 0 (sur 2821)--> 0.0%\n",
      "climategate: frequence  = 0.07% , nombre de tweets le contenant = 23 (sur 2821)--> 0.82%\n",
      "gop: frequence  = 0.04% , nombre de tweets le contenant = 13 (sur 2821)--> 0.46%\n",
      "teaparty: frequence  = 0.02% , nombre de tweets le contenant = 8 (sur 2821)--> 0.28%\n",
      "palin: frequence  = 0.04% , nombre de tweets le contenant = 12 (sur 2821)--> 0.43%\n",
      "collapse: frequence  = 0.03% , nombre de tweets le contenant = 9 (sur 2821)--> 0.32%\n",
      "fraud: frequence  = 0.01% , nombre de tweets le contenant = 4 (sur 2821)--> 0.14%\n",
      "believe: frequence  = 0.03% , nombre de tweets le contenant = 11 (sur 2821)--> 0.39%\n",
      " \n",
      "##########\n",
      " \n",
      "statistiques dans les tweets No :\n",
      " \n",
      "gore: frequence = 0.07% , nombre de tweets le contenant = 10 (sur 1035)--> 0.97%\n",
      "hoax: frequence = 0.21% , nombre de tweets le contenant = 28 (sur 1035)--> 2.71%\n",
      "scam: frequence = 0.16% , nombre de tweets le contenant = 22 (sur 1035)--> 2.13%\n",
      "climategate: frequence = 0.19% , nombre de tweets le contenant = 27 (sur 1035)--> 2.61%\n",
      "gop: frequence = 0.18% , nombre de tweets le contenant = 26 (sur 1035)--> 2.51%\n",
      "teaparty: frequence = 0.1% , nombre de tweets le contenant = 15 (sur 1035)--> 1.45%\n",
      "palin: frequence = 0.1% , nombre de tweets le contenant = 13 (sur 1035)--> 1.26%\n",
      "collapse: frequence = 0.15% , nombre de tweets le contenant = 22 (sur 1035)--> 2.13%\n",
      "fraud: frequence = 0.15% , nombre de tweets le contenant = 21 (sur 1035)--> 2.03%\n",
      "believe: frequence = 0.08% , nombre de tweets le contenant = 10 (sur 1035)--> 0.97%\n"
     ]
    }
   ],
   "source": [
    "# Print des résultats pour les tweets sceptiques au changement climatique\n",
    "\n",
    "print('Mots intéressants contre changement climatique :')\n",
    "print(' ')\n",
    "print('\\'fréquence\\'=tout mots compris de la base Yes (ou No)')\n",
    "print(' ')\n",
    "print('statistiques dans les tweets Yes :')                                  \n",
    "print(' ')\n",
    "list_tweet_yes=import_clean_text(option='yes')\n",
    "for key in frequence_no_in_yes.keys():\n",
    "    print(key+': frequence  = '+str(round(frequence_no_in_yes[key],2))+'%'+' , nombre de tweets le contenant = '+str(Number_apparition_tweets(list_tweet_yes,key))+' (sur {})'.format(len(list_tweet_yes))+'--> {}%'.format(round(100*Number_apparition_tweets(list_tweet_yes,key)/len(list_tweet_yes),2))) \n",
    "print(' ') \n",
    "print('#'*10)\n",
    "print(' ')\n",
    "print('statistiques dans les tweets No :')\n",
    "print(' ')\n",
    "list_tweet_no=import_clean_text(option='no')\n",
    "for key in frequence_no_in_no.keys():\n",
    "    print(key+': frequence = '+str(round(frequence_no_in_no[key],2))+'%'+' , nombre de tweets le contenant = '+str(Number_apparition_tweets(list_tweet_no,key))+' (sur {})'.format(len(list_tweet_no))+'--> {}%'.format(round(100*Number_apparition_tweets(list_tweet_no,key)/len(list_tweet_no),2))) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\underline{Commentaires}$\n",
    "\n",
    "Au vu des ces premières statistiques simplement descriptives, on observe que:\n",
    "\n",
    "Le vocabulaire des tweets sceptiques au changement climatique semble principalement constitué de deux thèmes :\n",
    "- le vocabulaire du scandale médiatique et politique. Par exemple, certaines controverses semblent particulièrement présentes avec les noms d'Al Gore et de 'climategate' qui ressortent particulièrement dans ces tweets. Les personnalités politiques sont égalements citées avec les noms de Sarah Palin et de GOP qui apparaissent.\n",
    "- le vocabulaire du mensonge et de la farce. On peut citer les mots canular (hoax), escroquerie(scam) ou encore 'teaparty'\n",
    "\n",
    "Concernant les tweets qui croient au changement climatique , on observe globalement le thème lié à l'effort (could, energy,fight) de la solidarité (us,help,world) et de l'environnement(green, earth, carbon)\n",
    "\n",
    "\n",
    "A première vue, les septiques semblent davantage 'négatifs'. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III.b Clustering à partir des représentations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'idée de ce clustering est de regrouper les tweets en des groupes de 'sujets' significatifs. l'objectif est ensuite d'observer quels sont les mots dominants dans ces sujets.\n",
    "\n",
    "Les représentations selectionnées sont choisies en fonction de leurs performances sur l'étape de classification.\n",
    "L'objectif globale étant l'étude des arguments des personnes climato-sceptiques, nous avons privilégié les représentations ayant un bon F1-score sur le classe 'No'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "Scores obtenus avec les modèles classiques :\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision_yes</th>\n",
       "      <th>precision_no</th>\n",
       "      <th>precision_global</th>\n",
       "      <th>f1_yes</th>\n",
       "      <th>f1_no</th>\n",
       "      <th>f1_global</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>XGBoost_bert</td>\n",
       "      <td>0.814815</td>\n",
       "      <td>0.643646</td>\n",
       "      <td>0.729231</td>\n",
       "      <td>0.858970</td>\n",
       "      <td>0.526554</td>\n",
       "      <td>0.692762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>RandomForest_fast2vec_cluster</td>\n",
       "      <td>0.815163</td>\n",
       "      <td>0.644578</td>\n",
       "      <td>0.729871</td>\n",
       "      <td>0.863018</td>\n",
       "      <td>0.508918</td>\n",
       "      <td>0.685968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>XGBoost_word2vec</td>\n",
       "      <td>0.804672</td>\n",
       "      <td>0.578811</td>\n",
       "      <td>0.691742</td>\n",
       "      <td>0.842391</td>\n",
       "      <td>0.491228</td>\n",
       "      <td>0.666810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>XGBoost_fast2vec_mean</td>\n",
       "      <td>0.787132</td>\n",
       "      <td>0.705660</td>\n",
       "      <td>0.746396</td>\n",
       "      <td>0.858361</td>\n",
       "      <td>0.464020</td>\n",
       "      <td>0.661190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>RandomForest_word2vec</td>\n",
       "      <td>0.795699</td>\n",
       "      <td>0.582133</td>\n",
       "      <td>0.688916</td>\n",
       "      <td>0.843164</td>\n",
       "      <td>0.463303</td>\n",
       "      <td>0.653233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>RandomForest_bert</td>\n",
       "      <td>0.790476</td>\n",
       "      <td>0.689516</td>\n",
       "      <td>0.739996</td>\n",
       "      <td>0.860940</td>\n",
       "      <td>0.443580</td>\n",
       "      <td>0.652260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>XGBoost_fast2vec_cluster</td>\n",
       "      <td>0.795455</td>\n",
       "      <td>0.652344</td>\n",
       "      <td>0.723899</td>\n",
       "      <td>0.860563</td>\n",
       "      <td>0.436601</td>\n",
       "      <td>0.648582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>RandomForest_tf_idf</td>\n",
       "      <td>0.782007</td>\n",
       "      <td>0.778351</td>\n",
       "      <td>0.780179</td>\n",
       "      <td>0.865624</td>\n",
       "      <td>0.417704</td>\n",
       "      <td>0.641664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>XGBoost_tf_idf</td>\n",
       "      <td>0.772260</td>\n",
       "      <td>0.738636</td>\n",
       "      <td>0.755448</td>\n",
       "      <td>0.858775</td>\n",
       "      <td>0.368794</td>\n",
       "      <td>0.613785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>SVM_word2vec</td>\n",
       "      <td>0.765133</td>\n",
       "      <td>0.496377</td>\n",
       "      <td>0.630755</td>\n",
       "      <td>0.827496</td>\n",
       "      <td>0.342072</td>\n",
       "      <td>0.584784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>SVM_fast2vec_cluster</td>\n",
       "      <td>0.768908</td>\n",
       "      <td>0.473282</td>\n",
       "      <td>0.621095</td>\n",
       "      <td>0.830470</td>\n",
       "      <td>0.321660</td>\n",
       "      <td>0.576065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>SVM_fast2vec_mean</td>\n",
       "      <td>0.751286</td>\n",
       "      <td>0.592179</td>\n",
       "      <td>0.671733</td>\n",
       "      <td>0.838010</td>\n",
       "      <td>0.294444</td>\n",
       "      <td>0.566227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>SVM_bert</td>\n",
       "      <td>0.757135</td>\n",
       "      <td>0.502370</td>\n",
       "      <td>0.629752</td>\n",
       "      <td>0.832799</td>\n",
       "      <td>0.288828</td>\n",
       "      <td>0.560814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>RandomForest_fast2vec_mean</td>\n",
       "      <td>0.753326</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.763760</td>\n",
       "      <td>0.851771</td>\n",
       "      <td>0.288722</td>\n",
       "      <td>0.570246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>SVM_tf_idf</td>\n",
       "      <td>0.738313</td>\n",
       "      <td>0.626866</td>\n",
       "      <td>0.682589</td>\n",
       "      <td>0.842945</td>\n",
       "      <td>0.140940</td>\n",
       "      <td>0.491942</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               precision_yes  precision_no  precision_global  \\\n",
       "XGBoost_bert                        0.814815      0.643646          0.729231   \n",
       "RandomForest_fast2vec_cluster       0.815163      0.644578          0.729871   \n",
       "XGBoost_word2vec                    0.804672      0.578811          0.691742   \n",
       "XGBoost_fast2vec_mean               0.787132      0.705660          0.746396   \n",
       "RandomForest_word2vec               0.795699      0.582133          0.688916   \n",
       "RandomForest_bert                   0.790476      0.689516          0.739996   \n",
       "XGBoost_fast2vec_cluster            0.795455      0.652344          0.723899   \n",
       "RandomForest_tf_idf                 0.782007      0.778351          0.780179   \n",
       "XGBoost_tf_idf                      0.772260      0.738636          0.755448   \n",
       "SVM_word2vec                        0.765133      0.496377          0.630755   \n",
       "SVM_fast2vec_cluster                0.768908      0.473282          0.621095   \n",
       "SVM_fast2vec_mean                   0.751286      0.592179          0.671733   \n",
       "SVM_bert                            0.757135      0.502370          0.629752   \n",
       "RandomForest_fast2vec_mean          0.753326      0.774194          0.763760   \n",
       "SVM_tf_idf                          0.738313      0.626866          0.682589   \n",
       "\n",
       "                                 f1_yes     f1_no  f1_global  \n",
       "XGBoost_bert                   0.858970  0.526554   0.692762  \n",
       "RandomForest_fast2vec_cluster  0.863018  0.508918   0.685968  \n",
       "XGBoost_word2vec               0.842391  0.491228   0.666810  \n",
       "XGBoost_fast2vec_mean          0.858361  0.464020   0.661190  \n",
       "RandomForest_word2vec          0.843164  0.463303   0.653233  \n",
       "RandomForest_bert              0.860940  0.443580   0.652260  \n",
       "XGBoost_fast2vec_cluster       0.860563  0.436601   0.648582  \n",
       "RandomForest_tf_idf            0.865624  0.417704   0.641664  \n",
       "XGBoost_tf_idf                 0.858775  0.368794   0.613785  \n",
       "SVM_word2vec                   0.827496  0.342072   0.584784  \n",
       "SVM_fast2vec_cluster           0.830470  0.321660   0.576065  \n",
       "SVM_fast2vec_mean              0.838010  0.294444   0.566227  \n",
       "SVM_bert                       0.832799  0.288828   0.560814  \n",
       "RandomForest_fast2vec_mean     0.851771  0.288722   0.570246  \n",
       "SVM_tf_idf                     0.842945  0.140940   0.491942  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Classement des scores sur le F1-No\n",
    "results = pd.read_csv('results_classification_classique.csv',index_col=0)\n",
    "print(' ')\n",
    "print('Scores obtenus avec les modèles classiques :')\n",
    "display(results.sort_values(by=['f1_no'],ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Clustering à partir de la representation BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Cut_words(option='all'):\n",
    "    \n",
    "    Tweet_clean=import_clean_text(option)\n",
    "\n",
    "    # On enlève les mots de trois lettres ou moins et les stowords\n",
    "    Tweet_clean_lemmatize=[]\n",
    "    for tweet in Tweet_clean:\n",
    "        new_tweet=[]\n",
    "        for token in tweet:\n",
    "            if (len(token)>3)&(token not in stopWords):\n",
    "                new_tweet.append(token)\n",
    "        Tweet_clean_lemmatize.append(new_tweet)\n",
    "    Tweet_clean=Tweet_clean_lemmatize  \n",
    "    \n",
    "    return(Tweet_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/salimyoussfi/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les 10 mots les plus fréquents dans les cluster 0 sont :\n",
      " \n",
      "[('global_warming', 335), ('snow', 83), ('climate_change', 79), ('do_not', 33), ('tcot', 30), ('cold', 28), ('al_gore', 27), ('in_dc', 27), ('cause', 22), ('make', 22)]\n",
      " \n",
      "Dans ce cluster, la part de No relative au nombre total de No est 37.39 %\n",
      " \n",
      "############################################################\n",
      "############################################################\n",
      " \n",
      "Les 10 mots les plus fréquents dans les cluster 1 sont :\n",
      " \n",
      "[('global_warming', 288), ('climate_change', 97), ('tcot', 47), ('al_gore', 29), ('snow', 21), ('science', 19), ('a_silly', 18), ('obama', 18), ('call', 16), ('scam', 15)]\n",
      " \n",
      "Dans ce cluster, la part de No relative au nombre total de No est 36.91 %\n",
      " \n",
      "############################################################\n",
      "############################################################\n",
      " \n",
      "Les 10 mots les plus fréquents dans les cluster 2 sont :\n",
      " \n",
      "[('global_warming', 189), ('climate_change', 104), ('science', 26), ('climate', 23), ('the_great', 23), ('collapse', 19), ('climategate', 13), ('fraud', 11), ('hoax', 11), ('theory', 10)]\n",
      " \n",
      "Dans ce cluster, la part de No relative au nombre total de No est 25.7 %\n",
      " \n",
      "############################################################\n",
      "############################################################\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/salimyoussfi/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "#Clustering que sur la base de No et print des résultats \n",
    "\n",
    "##Appel de la base d'apprentissage et des tweets correspondants\n",
    "\n",
    "df_bert_clustering=df_bert[df_bert.Labels=='No']\n",
    "data=Cut_words(option='no')\n",
    "df_bert_clustering['Words_tweet']=data\n",
    "\n",
    "##Clustering\n",
    "n_clusters=3\n",
    "kmeans = KMeans(n_clusters=n_clusters,random_state=2)\n",
    "\n",
    "##Apprentissage\n",
    "kmeans.fit(df_bert_clustering[[str(x) for x in range(df_bert_clustering.shape[1]-2)]])\n",
    "\n",
    "##prédiction\n",
    "df_bert_clustering['cluster']=kmeans.predict(df_bert_clustering[[str(x) for x in range(df_bert_clustering.shape[1]-2)]]).tolist()\n",
    "\n",
    "df_bert_clustering=df_bert_clustering[['Words_tweet','cluster','Labels']]\n",
    "\n",
    "\n",
    "\n",
    "########################################################################\n",
    "########################################################################\n",
    "\n",
    "\n",
    "# Print des mots dans chaque cluster\n",
    "\n",
    "nombre_total_no=len(df_bert_clustering)\n",
    "\n",
    "for number_cluster in range(n_clusters):\n",
    "    cluster=df_bert_clustering[df_bert_clustering.cluster==number_cluster]\n",
    "    list_cluster=reduce(add, list(cluster.Words_tweet))\n",
    "    counts = Counter(list_cluster)\n",
    "    counts = counts.most_common(10)\n",
    "    print('Les 10 mots les plus fréquents dans les cluster {} sont :'.format(str(number_cluster)))\n",
    "    print(' ')\n",
    "    print(counts)\n",
    "    print(' ')\n",
    "    number_no=round(100*len(cluster[cluster.Labels=='No'])/nombre_total_no,2) \n",
    "    print('Dans ce cluster, la part de No relative au nombre total de No est {} %'.format(str(number_no))) \n",
    "    print(' ')\n",
    "    print('#'*60)\n",
    "    print('#'*60)\n",
    "    print(' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\underline{Commentaires}$\n",
    "\n",
    "On a choisi de faire 3 clusters pour eviter de nous éparpiller sur les sujets et types d'arguments possibles. Le clustering sur les personnes climat-sceptique fait ressortir du principaux thèmes. \n",
    "\n",
    "La repartition des tweets dans ces clusters semble équitable. La repartition de cette population dans les clusters 0,1 et 2 sont respectivement $37$ %, $37$ % et $26$%.\n",
    "\n",
    "Deux clusters nous semble particulièrement interprétables.\n",
    "\n",
    "Le cluster 2 fait clairement ressortir le thème du mensonge, de la fraude et du complot. C'est notamment le seul cluster où on retrouve les termes climategate','fraud' et 'hoax'. Dans ce contexte, le mote 'theory' nous fait penser à l'argumentaire de la théorie du complot.\n",
    "\n",
    "Le cluster 1 semble faire reférence au monde politique. On y retrouve les mots 'Obama' et 'al gore', deux personnalités politiques particulièrement engagées dans la lutte contre le changement climatique. Les mots 'scam' (escroquerie) et 'silly' s'y retrouve également. On peut donc interpréter ce cluster comme une critique de la classe politique. \n",
    "\n",
    "Le cluster 0 est plus difficile à interpréter. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/salimyoussfi/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les 10 mots les plus fréquents dans les cluster 0 sont :\n",
      " \n",
      "[('climate_change', 659), ('global_warming', 545), ('climate', 94), ('news', 63), ('green', 51), ('science', 46), ('fight', 39), ('snow', 38), ('make', 37), ('tcot', 37)]\n",
      " \n",
      "Dans ce cluster, la part de Yes relative au nombre total de Yes est 42.4 %\n",
      " \n",
      "############################################################\n",
      "############################################################\n",
      " \n",
      "Les 10 mots les plus fréquents dans les cluster 1 sont :\n",
      " \n",
      "[('climate_change', 581), ('global_warming', 285), ('climate', 57), ('global', 37), ('energy', 31), ('green', 29), ('study', 28), ('fight', 25), ('stop', 25), ('effect_of', 24)]\n",
      " \n",
      "Dans ce cluster, la part de Yes relative au nombre total de Yes est 29.21 %\n",
      " \n",
      "############################################################\n",
      "############################################################\n",
      " \n",
      "Les 10 mots les plus fréquents dans les cluster 2 sont :\n",
      " \n",
      "[('global_warming', 479), ('climate_change', 367), ('climate', 60), ('do_not', 48), ('scientist', 45), ('cause', 40), ('snow', 38), ('change', 36), ('could', 36), ('report', 35)]\n",
      " \n",
      "Dans ce cluster, la part de Yes relative au nombre total de Yes est 28.39 %\n",
      " \n",
      "############################################################\n",
      "############################################################\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/salimyoussfi/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "#Clustering que sur la base de Yes et print des résultats \n",
    "\n",
    "##Appel de la base d'apprentissage et des tweets correspondants\n",
    "\n",
    "df_bert_clustering=df_bert[df_bert.Labels=='Yes']\n",
    "data=Cut_words(option='yes')\n",
    "df_bert_clustering['Words_tweet']=data\n",
    "\n",
    "##Clustering\n",
    "n_clusters=3\n",
    "kmeans = KMeans(n_clusters=n_clusters,random_state=1)\n",
    "\n",
    "##Apprentissage\n",
    "kmeans.fit(df_bert_clustering[[str(x) for x in range(df_bert_clustering.shape[1]-2)]])\n",
    "\n",
    "##prédiction\n",
    "df_bert_clustering['cluster']=kmeans.predict(df_bert_clustering[[str(x) for x in range(df_bert_clustering.shape[1]-2)]]).tolist()\n",
    "\n",
    "df_bert_clustering=df_bert_clustering[['Words_tweet','cluster','Labels']]\n",
    "\n",
    "\n",
    "\n",
    "########################################################################\n",
    "########################################################################\n",
    "\n",
    "\n",
    "# Print des mots dans chaque cluster\n",
    "\n",
    "nombre_total_yes=len(df_bert_clustering)\n",
    "\n",
    "for number_cluster in range(n_clusters):\n",
    "    cluster=df_bert_clustering[df_bert_clustering.cluster==number_cluster]\n",
    "    list_cluster=reduce(add, list(cluster.Words_tweet))\n",
    "    counts = Counter(list_cluster)\n",
    "    counts = counts.most_common(10)\n",
    "    print('Les 10 mots les plus fréquents dans les cluster {} sont :'.format(str(number_cluster)))\n",
    "    print(' ')\n",
    "    print(counts)\n",
    "    print(' ')\n",
    "    number_yes=round(100*len(cluster[cluster.Labels=='Yes'])/nombre_total_yes,2) \n",
    "    print('Dans ce cluster, la part de Yes relative au nombre total de Yes est {} %'.format(str(number_yes))) \n",
    "    print(' ')\n",
    "    print('#'*60)\n",
    "    print('#'*60)\n",
    "    print(' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\underline{Commentaires}$ \n",
    "\n",
    "La repartition de la population est également équitable, avec une faible sur-représentation du cluster 0.\n",
    "\n",
    "L'interpétation de ces clusters est plus difficile. On retrouve plus ou moins les même thèmes au sein de chaque cluster. Il s'agit principalement de la science et des effets du changement climatique ('science', 'scientist','report') ; de la lutte contre ce changement (particulièrement présent dans le cluster 1 avec les mots 'fight', 'stop' et 'effect_of' ; et du changement 'climate_change', 'change', 'cause','effect-of'.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III.c Modèle LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour utiliser le modèle LDA, nous avons choisi de représenter les mots sous une représentation Bag-Of-Word."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Representation BAW des tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Représentation Bag-Of-Word \n",
    "lemmatizer = WordNetLemmatizer() \n",
    "\n",
    "def Representation_BOW(Tweet_clean):\n",
    "    \n",
    "    bow=pd.DataFrame([Tweet_clean]).T\n",
    "    bow.columns=['headline_text']\n",
    "    bow=bow.headline_text\n",
    "    \n",
    "    dictionary = gensim.corpora.Dictionary(bow)\n",
    "    dictionary.filter_extremes(no_below=15, no_above=0.5, keep_n=100000)\n",
    "    bow_corpus = [dictionary.doc2bow(doc) for doc in bow]\n",
    "    \n",
    "    return(bow_corpus,dictionary)\n",
    "    \n",
    "# Représentations BAW\n",
    "tweets_no=Cut_words(option='no')\n",
    "tweets_yes=Cut_words(option='yes')\n",
    "BOW_global , dictionary_global = Representation_BOW(tweets_no+tweets_yes)\n",
    "BOW_yes, dictionary_yes = Representation_BOW(tweets_yes)\n",
    "BOW_no, dictionary_no = Representation_BOW(tweets_no)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "Construction du modèle sur le base entière..\n",
      "DONE (12.26s)\n",
      " \n",
      "Construction du modèle sur le base Yes..\n",
      "DONE (9.28s)\n",
      " \n",
      "Construction du modèle sur le base No..\n",
      "DONE (5.11s)\n"
     ]
    }
   ],
   "source": [
    "#Construction des modèles LDA\n",
    "dic_models_lda={}\n",
    "\n",
    "number_topics=3\n",
    "print(' ')\n",
    "# Construction du modèle LDA sur la base des Yes et No\n",
    "print('Construction du modèle sur le base entière..')\n",
    "t=time.time()\n",
    "lda_model_global = gensim.models.LdaMulticore(BOW_global, num_topics=number_topics, id2word=dictionary_global, passes=2, workers=2)\n",
    "print('DONE ({}s)'.format(str(round(time.time()-t,2))))\n",
    "print(' ')\n",
    "\n",
    "# Construction du modèle LDA sur la base des Yes\n",
    "print('Construction du modèle sur le base Yes..')\n",
    "t=time.time()\n",
    "lda_model_yes = gensim.models.LdaMulticore(BOW_yes, num_topics=number_topics, id2word=dictionary_yes, passes=2, workers=2)\n",
    "print('DONE ({}s)'.format(str(round(time.time()-t,2))))\n",
    "print(' ')\n",
    "\n",
    "# Construction du modèle LDA sur la base des No\n",
    "print('Construction du modèle sur le base No..')\n",
    "t=time.time()\n",
    "lda_model_no = gensim.models.LdaMulticore(BOW_no, num_topics=number_topics, id2word=dictionary_no, passes=2, workers=2)\n",
    "print('DONE ({}s)'.format(str(round(time.time()-t,2))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "Sujets qui apparaissent dans la base global : \n",
      " \n",
      "Sujet numéro : 0 \n",
      "Words: 0.092*\"climate_change\" + 0.032*\"tcot\" + 0.024*\"cause\" + 0.022*\"do_not\" + 0.017*\"report\" + 0.015*\"make\" + 0.014*\"al_gore\" + 0.014*\"volcano\" + 0.014*\"snow\" + 0.012*\"scientist\"\n",
      " \n",
      "Sujet numéro : 1 \n",
      "Words: 0.094*\"climate_change\" + 0.038*\"snow\" + 0.034*\"science\" + 0.017*\"climate\" + 0.012*\"stop\" + 0.012*\"global\" + 0.012*\"time\" + 0.011*\"due_to\" + 0.011*\"impact\" + 0.011*\"could\"\n",
      " \n",
      "Sujet numéro : 2 \n",
      "Words: 0.214*\"climate_change\" + 0.033*\"climate\" + 0.016*\"news\" + 0.015*\"green\" + 0.012*\"change\" + 0.011*\"like\" + 0.010*\"bill\" + 0.009*\"make\" + 0.009*\"study\" + 0.008*\"weather\"\n",
      " \n",
      "##############################\n",
      " \n",
      "Sujets qui apparaissent dans la base Yes : \n",
      " \n",
      "Sujet numéro : 0 \n",
      "Words: 0.256*\"global_warming\" + 0.024*\"climate\" + 0.019*\"scientist\" + 0.016*\"science\" + 0.016*\"cause\" + 0.015*\"report\" + 0.014*\"volcano\" + 0.013*\"stop\" + 0.012*\"global\" + 0.011*\"could\"\n",
      " \n",
      "Sujet numéro : 1 \n",
      "Words: 0.070*\"global_warming\" + 0.039*\"green\" + 0.028*\"make\" + 0.022*\"climate\" + 0.021*\"carbon\" + 0.020*\"global\" + 0.017*\"effect_of\" + 0.017*\"environment\" + 0.016*\"energy\" + 0.015*\"obama\"\n",
      " \n",
      "Sujet numéro : 2 \n",
      "Words: 0.087*\"global_warming\" + 0.038*\"climate\" + 0.027*\"world\" + 0.025*\"do_not\" + 0.023*\"snow\" + 0.020*\"tackle\" + 0.019*\"fight\" + 0.018*\"think\" + 0.018*\"change\" + 0.018*\"weather\"\n",
      " \n",
      "##############################\n",
      " \n",
      "Sujets qui apparaissent dans la base No : \n",
      " \n",
      "Sujet numéro : 0 \n",
      "Words: 0.125*\"snow\" + 0.098*\"climate_change\" + 0.063*\"tcot\" + 0.051*\"do_not\" + 0.034*\"time\" + 0.032*\"blizzard\" + 0.030*\"climate\" + 0.028*\"cause\" + 0.027*\"make\" + 0.026*\"news\"\n",
      " \n",
      "Sujet numéro : 1 \n",
      "Words: 0.270*\"climate_change\" + 0.069*\"al_gore\" + 0.053*\"science\" + 0.037*\"the_great\" + 0.033*\"weather\" + 0.031*\"hoax\" + 0.031*\"call\" + 0.030*\"snow\" + 0.029*\"collapse\" + 0.029*\"tcot\"\n",
      " \n",
      "Sujet numéro : 2 \n",
      "Words: 0.058*\"scientist\" + 0.056*\"like\" + 0.055*\"climate\" + 0.047*\"in_dc\" + 0.042*\"tcot\" + 0.040*\"winter\" + 0.039*\"alarmist\" + 0.039*\"would\" + 0.037*\"cold\" + 0.035*\"think\"\n",
      " \n",
      "##############################\n",
      " \n"
     ]
    }
   ],
   "source": [
    "list_model={'global':lda_model_global, 'Yes':lda_model_yes, 'No':lda_model_no}\n",
    "\n",
    "# Pour chaque sujet remonté par le modèle, on regarde quels sont les mots qui apparaissent et avec quels poids\n",
    "print(' ')\n",
    "for model in list_model.keys():\n",
    "    print('Sujets qui apparaissent dans la base {} : '.format(model))\n",
    "    print(' ')\n",
    "    for idx, topic in list_model[model].print_topics(-1):\n",
    "        print('Sujet numéro : {} \\nWords: {}'.format(idx, topic))\n",
    "        print(' ')\n",
    "    print('#'*30)\n",
    "    print(' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\underline{Commentaires}$\n",
    "\n",
    "Nous avons choisis de fixer le nombre de sujet à 3 pour ne pas trop nous éparpiller et capter les principaux élements. \n",
    "\n",
    "Concernant le sujets présents dans la base entière, on observe sans grande surprise que les termes 'climate_change', 'climate', 'green' ou encore 'science' sont des mots leaders des sujets. Le sujet numéro 1 est particulièrement intéressant avec les termes 'time', 'report', 'news' et 'change' qui peut nous faire penser à l'urgence lié au changement climatique.\n",
    "\n",
    "Nous nous sommes davantage intéressés aux sujets ressortant dans les bases Yes et No.\n",
    "\n",
    "Fait marquant, le terme principal dans les les sujets de la base entière est 'climate_change'. Ceux qui croient aux changement climatique ont pour mot principal 'global_warming'. Ainsi, en utilisant le terme 'réchauffement climatique', ces personnes utilisent un terme beaucoup plus précis. \n",
    "\n",
    "Le premier sujet tiré de la base des personnes labélisées 'Yes' semble porté (en partie) sur les news liées au changement climatique. En effet, l'association de mots comme 'news', 'reuters' ou encore 'carbon' implique l'idée d'informations relayées par exemple par les médias.\n",
    "Le deuxième sujet semble porté davantage sur des faits scientifique et prouvés. On retrouve notamment les mots 'science', 'report', 'due_to' ou encore 'real'. \n",
    "Le troisième sujet peut être lié aux causes du rechauffement climtique et en particulier aux personnes inactifs. On y retrouve les mots 'do_not', 'tcot' ou encore 'tackle'. Notons que le terme TCOT ('Top Conservatives On Twitter') fait référence aux personnes conservatrices.\n",
    "\n",
    "Le sujet nous semblant les plus interessant chez les personnes climato-sceptiques est le dernier sujet (sujet numéro 2). En effet, le mot leader du groupe est 'hoax' (canular). On y retrouve également le mot 'skeptic'. Ce sujet fait très clairement référence au thème du mensonge et de la farce. Le terme 'a_silly' ne fait que renforcé l'idée de mensonge.\n",
    "Notons également que le terme 'tcot' apparait dans tout les sujets (majeur dans le sujet numéro 0). La plupart de ces personnes sont donc classées comme conservatrices.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III.d Etude de la tonalité des tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour chaque tweet de la base, on utilise le modèle SentiWordNet pour déterminer les sentiments qui lui sont associés. On fait ensuite la moyenne des scores associés aux mots d'un tweet. \n",
    "\n",
    "A la fin de ce processus, on a un score associé à la positivité, négativité et neutralité pour chaque tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonctions permettant de scorer et de faire la moyennes des scores des mots pour un tweet\n",
    "lemmatizer = WordNetLemmatizer() \n",
    "\n",
    "def penn_to_wn(tag):\n",
    "    \"\"\"\n",
    "    Convert between the PennTreebank tags to simple Wordnet tags\n",
    "    \"\"\"\n",
    "    if tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    return None\n",
    "\n",
    "def get_sentiment(word,tag):\n",
    "    \"\"\" returns list of pos neg and objective score. But returns empty list if not present in senti wordnet. \"\"\"\n",
    "\n",
    "    wn_tag = penn_to_wn(tag)\n",
    "    if wn_tag not in (wordnet.NOUN, wordnet.ADJ, wordnet.ADV):\n",
    "        return []\n",
    "\n",
    "    lemma = lemmatizer.lemmatize(word, pos=wn_tag)\n",
    "    if not lemma:\n",
    "        return []\n",
    "\n",
    "    synsets = wordnet.synsets(word, pos=wn_tag)\n",
    "    if not synsets:\n",
    "        return []\n",
    "\n",
    "    # Take the first sense, the most common\n",
    "    synset = synsets[0]\n",
    "    swn_synset = swn.senti_synset(synset.name())\n",
    "\n",
    "    return [swn_synset.pos_score(),swn_synset.neg_score(),swn_synset.obj_score()]\n",
    "\n",
    "\n",
    "# Pour chaque tweet calcul des trois scores\n",
    "def sentiments_score(Tweets,Initial_Tweet,labels):\n",
    "    \n",
    "    Tweet_sentiments=[]\n",
    "    for tweet_index in range(len(Tweets)):\n",
    "\n",
    "        list_tweet=[]\n",
    "\n",
    "        # Append le tweet initial\n",
    "        list_tweet.append(Initial_Tweet[tweet_index])\n",
    "\n",
    "        # Append les scores\n",
    "\n",
    "        ##Calcul des scores pour chaque mot du tweet\n",
    "        pos_val = nltk.pos_tag(Tweets[tweet_index])\n",
    "        senti_val = [get_sentiment(x,y) for (x,y) in pos_val]\n",
    "\n",
    "        ## Moyenne de ces scores\n",
    "        pos_score=0\n",
    "        neg_score=0\n",
    "        neutre_score=0\n",
    "        size_senti=0\n",
    "        for score in senti_val:\n",
    "            if len(score)==3:\n",
    "                pos_score=pos_score+score[0]\n",
    "                neg_score=neg_score+score[1]\n",
    "                neutre_score=neutre_score+score[2]\n",
    "                size_senti=size_senti+1\n",
    "        if size_senti==0:\n",
    "            list_tweet.append('pas de mots connus par SWN')\n",
    "        else:\n",
    "            pos_score=pos_score/size_senti\n",
    "            neg_score=neg_score/size_senti\n",
    "            neutre_score=neutre_score/size_senti\n",
    "        \n",
    "            list_tweet.append([pos_score,neg_score,neutre_score])\n",
    "        \n",
    "        # Append le label \n",
    "        list_tweet.append(labels[tweet_index])\n",
    "    \n",
    "        Tweet_sentiments.append(list_tweet)\n",
    "    \n",
    "    return(Tweet_sentiments)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "Calcul des scores de chaque mot et des scores moyens pour chaque tweet..\n",
      "DONE (15.35s)\n"
     ]
    }
   ],
   "source": [
    "# Calcul des scores de sentiments\n",
    "\n",
    "Tweet_clean=import_clean_text()\n",
    "Labels=df.Existence\n",
    "\n",
    "print(' ')\n",
    "print('Calcul des scores de chaque mot et des scores moyens pour chaque tweet..')\n",
    "t=time.time()\n",
    "Base_SWN=sentiments_score(Tweet_clean,df.Tweet,Labels)\n",
    "print('DONE ({}s)'.format(str(round(time.time()-t,2))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['global_warming',\n",
       "  'report',\n",
       "  'urge',\n",
       "  'government',\n",
       "  'to',\n",
       "  'act',\n",
       "  'brussels',\n",
       "  'belgium',\n",
       "  'ap',\n",
       "  'the',\n",
       "  'world',\n",
       "  'face',\n",
       "  'increase',\n",
       "  'hunger',\n",
       "  'and'],\n",
       " ['fight', 'poverty_and', 'global_warming', 'in', 'africa'],\n",
       " ['carbon_offset',\n",
       "  'how',\n",
       "  'a',\n",
       "  'vatican_forest',\n",
       "  'fail',\n",
       "  'to',\n",
       "  'reduce',\n",
       "  'global_warming'],\n",
       " ['uruguay_tool',\n",
       "  'need',\n",
       "  'for_those',\n",
       "  'most_vulnerable',\n",
       "  'to',\n",
       "  'climate_change'],\n",
       " ['ocean_saltiness',\n",
       "  'show',\n",
       "  'global_warming',\n",
       "  'be',\n",
       "  'intensify_our',\n",
       "  'water_cycle'],\n",
       " ['global_warming',\n",
       "  'evidence',\n",
       "  'all',\n",
       "  'around',\n",
       "  'u',\n",
       "  'a',\n",
       "  'message',\n",
       "  'to',\n",
       "  'global_warming',\n",
       "  'denier',\n",
       "  'and',\n",
       "  'doubter',\n",
       "  'just',\n",
       "  'look',\n",
       "  'around',\n",
       "  'our'],\n",
       " ['migratory', 'bird', 'new', 'climate_change', 'strategy', 'stay', 'home'],\n",
       " ['southern',\n",
       "  'africa',\n",
       "  'compete',\n",
       "  'for',\n",
       "  'limpopo',\n",
       "  'water',\n",
       "  'climate_change',\n",
       "  'will',\n",
       "  'bring',\n",
       "  'high_temperature',\n",
       "  'to',\n",
       "  'southe'],\n",
       " ['global_warming',\n",
       "  'to',\n",
       "  'impact',\n",
       "  'wheat',\n",
       "  'rice',\n",
       "  'production',\n",
       "  'in',\n",
       "  'india',\n",
       "  'ludhiana',\n",
       "  'apr',\n",
       "  '18',\n",
       "  'scarcity',\n",
       "  'of',\n",
       "  'water',\n",
       "  'will',\n",
       "  'have',\n",
       "  'a',\n",
       "  'serious'],\n",
       " ['how', 'do', 'we_solve', 'this', 'global_warming', 'thing'],\n",
       " ['blog',\n",
       "  'a',\n",
       "  'preliminary',\n",
       "  'analysis',\n",
       "  'suggests_that',\n",
       "  'natural',\n",
       "  'gas',\n",
       "  'could',\n",
       "  'contribute',\n",
       "  'far',\n",
       "  'more',\n",
       "  'to',\n",
       "  'global_warming',\n",
       "  'than',\n",
       "  'previously'],\n",
       " ['ecotone', 'climate_change', 'from', 'a', 'population', 'perspective'],\n",
       " ['climate_change',\n",
       "  'blame',\n",
       "  'a',\n",
       "  'coastal',\n",
       "  'whale',\n",
       "  'migration',\n",
       "  'dwindles',\n",
       "  'à_',\n",
       "  'ventura',\n",
       "  'county'],\n",
       " ['spring',\n",
       "  'storm',\n",
       "  'season',\n",
       "  'start',\n",
       "  'a',\n",
       "  'little',\n",
       "  'late',\n",
       "  'this_year',\n",
       "  'must',\n",
       "  'be',\n",
       "  'global_warming'],\n",
       " ['government_report',\n",
       "  'say',\n",
       "  'global_warming',\n",
       "  'may_cause',\n",
       "  'cancer_mental',\n",
       "  'illness',\n",
       "  'cnsnews.com'],\n",
       " ['for',\n",
       "  'earthday',\n",
       "  'global_warming',\n",
       "  'could',\n",
       "  'affect',\n",
       "  'patient',\n",
       "  'symptom'],\n",
       " ['wait',\n",
       "  \"here's\",\n",
       "  'an',\n",
       "  'idea',\n",
       "  'it',\n",
       "  'be',\n",
       "  'natural',\n",
       "  'climate_change',\n",
       "  'not',\n",
       "  'human',\n",
       "  'induced',\n",
       "  'global_warming'],\n",
       " ['epa',\n",
       "  'issue',\n",
       "  'report',\n",
       "  'on',\n",
       "  'u',\n",
       "  'climate_change',\n",
       "  'indicator',\n",
       "  'warming',\n",
       "  'be',\n",
       "  'have',\n",
       "  'measurable',\n",
       "  'effect',\n",
       "  'across',\n",
       "  'ecosystem'],\n",
       " ['qut', 'researcher', 'track', 'climate_change'],\n",
       " ['global_warming',\n",
       "  'ocean_chemistry',\n",
       "  'be',\n",
       "  'change',\n",
       "  'faster_than',\n",
       "  'it',\n",
       "  'have',\n",
       "  'in',\n",
       "  '800,000',\n",
       "  'year',\n",
       "  'and',\n",
       "  'that',\n",
       "  'be',\n",
       "  'because',\n",
       "  'of',\n",
       "  'the',\n",
       "  'carbon'],\n",
       " ['topography',\n",
       "  'of',\n",
       "  'mountain',\n",
       "  'could',\n",
       "  'complicate',\n",
       "  'rate',\n",
       "  'of',\n",
       "  'global_warming',\n",
       "  'sciencedaily',\n",
       "  'apr',\n",
       "  '25',\n",
       "  '2010',\n",
       "  'à_',\n",
       "  'a',\n",
       "  'new',\n",
       "  'study',\n",
       "  'concl'],\n",
       " ['soar',\n",
       "  'mercury',\n",
       "  'blame',\n",
       "  'it',\n",
       "  'on',\n",
       "  'global_warming',\n",
       "  'agartala',\n",
       "  'apr',\n",
       "  '14',\n",
       "  'environmentalist',\n",
       "  'have',\n",
       "  'attribute',\n",
       "  'the'],\n",
       " ['leader',\n",
       "  'of',\n",
       "  'national',\n",
       "  'indigenous',\n",
       "  \"women's\",\n",
       "  'org',\n",
       "  'climate_change',\n",
       "  'be',\n",
       "  'not',\n",
       "  'just',\n",
       "  'abt',\n",
       "  'the',\n",
       "  'climate',\n",
       "  'it',\n",
       "  'abt',\n",
       "  'life',\n",
       "  'bit.ly/9gdzrw'],\n",
       " ['have',\n",
       "  'there_be',\n",
       "  'any',\n",
       "  'reporting',\n",
       "  'on',\n",
       "  'if',\n",
       "  'the',\n",
       "  'increase',\n",
       "  'in',\n",
       "  'sediment',\n",
       "  'in',\n",
       "  'upper',\n",
       "  'atmospher',\n",
       "  'could',\n",
       "  'reduce',\n",
       "  'global_warming',\n",
       "  'effect',\n",
       "  'by',\n",
       "  'reduce',\n",
       "  'sun'],\n",
       " ['effect_of',\n",
       "  'global_warming',\n",
       "  'à_',\n",
       "  'youtube',\n",
       "  'à_',\n",
       "  'effect_of',\n",
       "  'global_warming',\n",
       "  'stats',\n",
       "  'back',\n",
       "  'with',\n",
       "  'more',\n",
       "  'news',\n",
       "  'for',\n",
       "  'you',\n",
       "  'today',\n",
       "  'it',\n",
       "  'be',\n",
       "  'ama'],\n",
       " ['it', 'be', 'global', 'climate', 'change-not', 'warming', 'ac', 'read'],\n",
       " ['a',\n",
       "  'preliminary',\n",
       "  'analysis',\n",
       "  'suggests_that',\n",
       "  'natural',\n",
       "  'gas',\n",
       "  'could',\n",
       "  'contribute',\n",
       "  'far',\n",
       "  'more',\n",
       "  'to',\n",
       "  'global_warming',\n",
       "  'than',\n",
       "  'previously',\n",
       "  'thought'],\n",
       " ['science',\n",
       "  'scientist',\n",
       "  'explore',\n",
       "  'the',\n",
       "  'evolution',\n",
       "  'of',\n",
       "  'climate_change'],\n",
       " ['eaarth',\n",
       "  'global_warming',\n",
       "  'be',\n",
       "  'here',\n",
       "  'to',\n",
       "  'stay',\n",
       "  'how',\n",
       "  'will',\n",
       "  'we',\n",
       "  'deal_with',\n",
       "  'it'],\n",
       " ['allergy_bad', 'than_ever', 'blame', 'global_warming'],\n",
       " ['i',\n",
       "  'have',\n",
       "  'it',\n",
       "  'on',\n",
       "  'good',\n",
       "  'auth',\n",
       "  'tht',\n",
       "  'global_warming',\n",
       "  'also',\n",
       "  'cause',\n",
       "  'toe',\n",
       "  'fungus',\n",
       "  'we',\n",
       "  'all',\n",
       "  'fortunate',\n",
       "  'tht',\n",
       "  'thr',\n",
       "  'be',\n",
       "  'no',\n",
       "  'global_warming',\n",
       "  'tcot'],\n",
       " ['illegal',\n",
       "  'war',\n",
       "  'and',\n",
       "  'the',\n",
       "  'myth',\n",
       "  'of',\n",
       "  'global_warming',\n",
       "  'my',\n",
       "  'main',\n",
       "  'campaign',\n",
       "  'platform',\n",
       "  'for',\n",
       "  'this',\n",
       "  'election',\n",
       "  'will',\n",
       "  'be',\n",
       "  'the',\n",
       "  'illegal'],\n",
       " ['the',\n",
       "  'scientific',\n",
       "  'community',\n",
       "  'be',\n",
       "  'scam',\n",
       "  'by',\n",
       "  'global',\n",
       "  'green',\n",
       "  'gov',\n",
       "  'warming',\n",
       "  'scam'],\n",
       " ['40',\n",
       "  'degree',\n",
       "  'in',\n",
       "  'nyc',\n",
       "  'please',\n",
       "  'urinate',\n",
       "  'on',\n",
       "  'next',\n",
       "  'liberal',\n",
       "  'global_warming',\n",
       "  'climate_change',\n",
       "  'scum',\n",
       "  'you',\n",
       "  'see'],\n",
       " ['hey',\n",
       "  'al_gore',\n",
       "  'see',\n",
       "  'these',\n",
       "  'tornado',\n",
       "  'race',\n",
       "  'across',\n",
       "  'mississippi',\n",
       "  'so_much',\n",
       "  'for',\n",
       "  'global_warming',\n",
       "  'tornadocot',\n",
       "  'ocra',\n",
       "  'sgp',\n",
       "  'gop',\n",
       "  'ucot',\n",
       "  'tlot',\n",
       "  'p2',\n",
       "  'tycot'],\n",
       " ['justinbiebersucks', 'and', 'global_warming', 'be', 'a', 'farce'],\n",
       " ['one',\n",
       "  'stop',\n",
       "  'book',\n",
       "  'stop',\n",
       "  'confirm',\n",
       "  'global_warming',\n",
       "  'be',\n",
       "  'settle',\n",
       "  'à_',\n",
       "  'a',\n",
       "  'a',\n",
       "  'scam',\n",
       "  'wnd.com',\n",
       "  \"sussman's\",\n",
       "  'book',\n",
       "  'the'],\n",
       " ['rationalist',\n",
       "  'who',\n",
       "  'believe',\n",
       "  'alien',\n",
       "  'exist',\n",
       "  'global_warming',\n",
       "  'cause_by',\n",
       "  'human',\n",
       "  'might',\n",
       "  'a',\n",
       "  'well',\n",
       "  'believe_in',\n",
       "  'jesus',\n",
       "  'miracle',\n",
       "  'angel',\n",
       "  'fairy',\n",
       "  'tcot_p2'],\n",
       " ['air',\n",
       "  'ban',\n",
       "  'lead',\n",
       "  'by',\n",
       "  'flaw',\n",
       "  'computer',\n",
       "  'model',\n",
       "  'global_warming',\n",
       "  'come',\n",
       "  'to',\n",
       "  'mind'],\n",
       " ['proof',\n",
       "  \"there's_no\",\n",
       "  'climate_change',\n",
       "  '75',\n",
       "  'ft',\n",
       "  'killer',\n",
       "  'tsunami',\n",
       "  'create',\n",
       "  'in',\n",
       "  'a',\n",
       "  'peruvian',\n",
       "  'lake',\n",
       "  'when',\n",
       "  'a',\n",
       "  'glacier',\n",
       "  'fracture',\n",
       "  'fall',\n",
       "  'into',\n",
       "  'the',\n",
       "  'lake'],\n",
       " ['real',\n",
       "  'science',\n",
       "  'not',\n",
       "  \"algore's\",\n",
       "  'climate_change',\n",
       "  'science',\n",
       "  'hack',\n",
       "  'with',\n",
       "  'their',\n",
       "  'man-made',\n",
       "  'global_warming',\n",
       "  'hoax',\n",
       "  'gore',\n",
       "  '=p',\n",
       "  'alin'],\n",
       " ['30000',\n",
       "  'anti-global',\n",
       "  'warming',\n",
       "  'scientist',\n",
       "  'ca_not',\n",
       "  'be',\n",
       "  'wrong',\n",
       "  'stranger',\n",
       "  'nature',\n",
       "  'magazine',\n",
       "  'the',\n",
       "  'academic',\n",
       "  'journal',\n",
       "  'that',\n",
       "  'int'],\n",
       " ['global_warming',\n",
       "  'baloney',\n",
       "  'accord_to',\n",
       "  'the',\n",
       "  'expert',\n",
       "  'at',\n",
       "  'nasa',\n",
       "  'the',\n",
       "  'difference',\n",
       "  'between',\n",
       "  'weather',\n",
       "  'and',\n",
       "  'climate',\n",
       "  'be',\n",
       "  'a',\n",
       "  'measure'],\n",
       " ['computer',\n",
       "  'forensics',\n",
       "  'expert',\n",
       "  'be',\n",
       "  'there',\n",
       "  'still',\n",
       "  'any',\n",
       "  'idiot',\n",
       "  'out_there',\n",
       "  'that',\n",
       "  'belive',\n",
       "  'global_warming',\n",
       "  'be',\n",
       "  'true'],\n",
       " ['liberal',\n",
       "  'looney',\n",
       "  'toon',\n",
       "  'global_warming',\n",
       "  'alarmist',\n",
       "  'come',\n",
       "  'home',\n",
       "  'with',\n",
       "  'artic',\n",
       "  'frost',\n",
       "  'bite',\n",
       "  'gather.com',\n",
       "  'they',\n",
       "  'wont',\n",
       "  'learn',\n",
       "  'huh',\n",
       "  'lo'],\n",
       " ['global_warming',\n",
       "  'you_tube',\n",
       "  'explanation',\n",
       "  'you',\n",
       "  'will',\n",
       "  'enjoy',\n",
       "  'ipcc',\n",
       "  'teaparty'],\n",
       " ['immigration_reform',\n",
       "  'and',\n",
       "  'climate_change',\n",
       "  'a_tale',\n",
       "  'of',\n",
       "  'two_issue',\n",
       "  'in',\n",
       "  'the',\n",
       "  'senate'],\n",
       " ['memo',\n",
       "  'on',\n",
       "  'the',\n",
       "  'white_house',\n",
       "  'correspondent',\n",
       "  'dinner',\n",
       "  'if_you',\n",
       "  'want',\n",
       "  'to',\n",
       "  'be',\n",
       "  'green',\n",
       "  'report',\n",
       "  'on',\n",
       "  'climate_change',\n",
       "  \"i'd\",\n",
       "  'never',\n",
       "  'be',\n",
       "  'on'],\n",
       " ['view',\n",
       "  'on',\n",
       "  'global_warming',\n",
       "  'vary',\n",
       "  'in_three',\n",
       "  'country',\n",
       "  'angus',\n",
       "  'reid',\n",
       "  'global',\n",
       "  'monitor',\n",
       "  'people',\n",
       "  'in_three',\n",
       "  'country',\n",
       "  'hold'],\n",
       " ['scenarios-challenges',\n",
       "  'to',\n",
       "  'california',\n",
       "  'climate_change',\n",
       "  'law',\n",
       "  'source',\n",
       "  'reuters',\n",
       "  'by',\n",
       "  'peter',\n",
       "  'henderson',\n",
       "  'san',\n",
       "  'francisco',\n",
       "  'april_26'],\n",
       " ['the',\n",
       "  'climate',\n",
       "  'of',\n",
       "  'lindsay',\n",
       "  \"graham's\",\n",
       "  'support',\n",
       "  'for',\n",
       "  'climate_change',\n",
       "  'legislation',\n",
       "  'have',\n",
       "  'change',\n",
       "  'today',\n",
       "  'lindsey_graham'],\n",
       " [\"arizona's\",\n",
       "  'immigration',\n",
       "  'law',\n",
       "  'climate_change',\n",
       "  'legislation',\n",
       "  'stalling--which',\n",
       "  'issue',\n",
       "  'should',\n",
       "  'congress',\n",
       "  'focus_on',\n",
       "  'now',\n",
       "  'poll'],\n",
       " [\"graham's_exit\",\n",
       "  'from_talk',\n",
       "  'put',\n",
       "  'climate_change',\n",
       "  'bill',\n",
       "  'in_limbo',\n",
       "  'a',\n",
       "  'climate-change_bill',\n",
       "  'that',\n",
       "  'be',\n",
       "  'schedule_to',\n",
       "  'be',\n",
       "  'unveile'],\n",
       " ['u', 'climate_change', 'bill', 'stall', 'in', 'senate'],\n",
       " ['people',\n",
       "  'world',\n",
       "  'grand',\n",
       "  'rapid',\n",
       "  'mich',\n",
       "  'opponent',\n",
       "  'of',\n",
       "  'climate_change',\n",
       "  'legislation',\n",
       "  'typically',\n",
       "  'argue',\n",
       "  'that',\n",
       "  'regulate',\n",
       "  'globa'],\n",
       " ['cnnbrk',\n",
       "  'sen',\n",
       "  \"graham's\",\n",
       "  'move_imperils',\n",
       "  'dems',\n",
       "  'push',\n",
       "  'for',\n",
       "  'immigration',\n",
       "  'climate_change',\n",
       "  'bill'],\n",
       " ['cafe_scientifique',\n",
       "  'present',\n",
       "  'global_warming',\n",
       "  'talk',\n",
       "  'film',\n",
       "  'the',\n",
       "  'april',\n",
       "  'cafe_scientifique',\n",
       "  'presentation',\n",
       "  'will',\n",
       "  'be',\n",
       "  'on',\n",
       "  'the'],\n",
       " ['check_this',\n",
       "  'video',\n",
       "  'out',\n",
       "  'the',\n",
       "  'business',\n",
       "  'of',\n",
       "  'climate_change',\n",
       "  'conference',\n",
       "  '2009'],\n",
       " ['brilliant',\n",
       "  'tip',\n",
       "  'for',\n",
       "  \"valentine's_day\",\n",
       "  'a_scream',\n",
       "  'à_o_à_',\n",
       "  'climate_change',\n",
       "  'clinical_trial',\n",
       "  'collagen_clinique',\n",
       "  'clip'],\n",
       " ['usa', 'climate_change', 'policy', 'update', 'april', '12', '2010'],\n",
       " ['press',\n",
       "  'release',\n",
       "  'april',\n",
       "  '2010',\n",
       "  'climate_change',\n",
       "  'negotiator',\n",
       "  'agree',\n",
       "  'on',\n",
       "  'intensified'],\n",
       " ['global_warming', 'clearly'],\n",
       " ['postpartisan',\n",
       "  'harry',\n",
       "  \"reid's\",\n",
       "  'hapless',\n",
       "  'play',\n",
       "  'on',\n",
       "  'immigration',\n",
       "  'and',\n",
       "  'climate_change'],\n",
       " ['foe',\n",
       "  'of',\n",
       "  \"california's\",\n",
       "  'global_warming',\n",
       "  'law_pour',\n",
       "  'money_into',\n",
       "  'a',\n",
       "  'campaign',\n",
       "  'to_delay',\n",
       "  'it'],\n",
       " ['earth_day',\n",
       "  'live',\n",
       "  'chat',\n",
       "  'with',\n",
       "  'carol_browner',\n",
       "  'director',\n",
       "  'of',\n",
       "  'the',\n",
       "  'office',\n",
       "  'of',\n",
       "  'energy',\n",
       "  'and',\n",
       "  'climate_change',\n",
       "  'policy',\n",
       "  'for',\n",
       "  'the',\n",
       "  'obama',\n",
       "  'admin'],\n",
       " ['klein',\n",
       "  'a',\n",
       "  '50-50',\n",
       "  'chance',\n",
       "  'that',\n",
       "  'the',\n",
       "  'senate',\n",
       "  'pass',\n",
       "  'a',\n",
       "  'climate_change',\n",
       "  'bill',\n",
       "  'this_year'],\n",
       " ['yes',\n",
       "  'i',\n",
       "  'have',\n",
       "  'heard',\n",
       "  'at_least',\n",
       "  'one',\n",
       "  'person',\n",
       "  'make',\n",
       "  'the',\n",
       "  'connection',\n",
       "  'between',\n",
       "  'the',\n",
       "  'volcano',\n",
       "  'and',\n",
       "  'global_warming'],\n",
       " ['nasa',\n",
       "  'change',\n",
       "  'fact',\n",
       "  'guess',\n",
       "  'they',\n",
       "  'thought',\n",
       "  'you',\n",
       "  'wouldnt',\n",
       "  'notice',\n",
       "  'global_warming',\n",
       "  'climate_change',\n",
       "  'eco'],\n",
       " ['a_religious', 'spin', 'on', 'climate_change'],\n",
       " ['environmental',\n",
       "  'group',\n",
       "  'praise',\n",
       "  'basic',\n",
       "  'meeting',\n",
       "  'on',\n",
       "  'climate_change',\n",
       "  'environmental',\n",
       "  'group',\n",
       "  'be',\n",
       "  'give',\n",
       "  'qualify',\n",
       "  'praise',\n",
       "  'to',\n",
       "  'a'],\n",
       " ['only',\n",
       "  'a',\n",
       "  'third',\n",
       "  'of',\n",
       "  'american',\n",
       "  'believe',\n",
       "  'global_warming',\n",
       "  'be',\n",
       "  'human-caused',\n",
       "  'by',\n",
       "  'bob',\n",
       "  'elli',\n",
       "  'on',\n",
       "  'april',\n",
       "  '26th',\n",
       "  '2010',\n",
       "  'good_news',\n",
       "  'what'],\n",
       " ['global_warming',\n",
       "  'of',\n",
       "  'the',\n",
       "  'heart_earth',\n",
       "  'day',\n",
       "  'be',\n",
       "  'over',\n",
       "  'or',\n",
       "  'be',\n",
       "  'it_thousand',\n",
       "  'perhaps',\n",
       "  'million',\n",
       "  'of',\n",
       "  'conscious',\n",
       "  'action'],\n",
       " ['in',\n",
       "  'climate',\n",
       "  'data',\n",
       "  'that',\n",
       "  'suggests',\n",
       "  'global_warming',\n",
       "  'and',\n",
       "  'then',\n",
       "  'the',\n",
       "  'assumption',\n",
       "  'that',\n",
       "  'it',\n",
       "  'be',\n",
       "  'our',\n",
       "  'do'],\n",
       " ['global_warming',\n",
       "  'fiction',\n",
       "  'or',\n",
       "  'fact',\n",
       "  'denier',\n",
       "  'claim',\n",
       "  'either',\n",
       "  'that',\n",
       "  'there_be',\n",
       "  'no',\n",
       "  'global_warming',\n",
       "  'or',\n",
       "  'that',\n",
       "  'it',\n",
       "  'be',\n",
       "  'not',\n",
       "  'due_to'],\n",
       " ['the',\n",
       "  'b-cast',\n",
       "  'interview',\n",
       "  'minnesotan',\n",
       "  'for',\n",
       "  'global_warming',\n",
       "  'fight',\n",
       "  'youtube',\n",
       "  'takedown'],\n",
       " ['opponent',\n",
       "  'ramp',\n",
       "  'up',\n",
       "  'effort',\n",
       "  'to_delay',\n",
       "  'calif',\n",
       "  'global_warming',\n",
       "  'law'],\n",
       " ['how',\n",
       "  'many',\n",
       "  'be',\n",
       "  'aware',\n",
       "  'of',\n",
       "  'the',\n",
       "  \"world_people's\",\n",
       "  'conference_on',\n",
       "  'climate_change',\n",
       "  'and',\n",
       "  'earth',\n",
       "  'right',\n",
       "  'in',\n",
       "  'bolivia',\n",
       "  'earthweek',\n",
       "  'indigenous',\n",
       "  '1stnations'],\n",
       " ['sorry',\n",
       "  'i',\n",
       "  'will',\n",
       "  'not',\n",
       "  'be',\n",
       "  'able',\n",
       "  'to',\n",
       "  'accept',\n",
       "  'the',\n",
       "  'invitation',\n",
       "  'to',\n",
       "  'be',\n",
       "  'a',\n",
       "  'panelist',\n",
       "  'at',\n",
       "  'bolivia',\n",
       "  'climate_change',\n",
       "  'talk'],\n",
       " ['climate',\n",
       "  'scientist_sue',\n",
       "  'newspaper_for',\n",
       "  'poison',\n",
       "  'global_warming',\n",
       "  'debate'],\n",
       " ['sharifkouddous',\n",
       "  'indigenous',\n",
       "  'group',\n",
       "  'from',\n",
       "  'across',\n",
       "  'bolivia',\n",
       "  'arrive',\n",
       "  'at',\n",
       "  \"world_people's\",\n",
       "  'conference_on',\n",
       "  'climate_change'],\n",
       " ['recycle_water', 'meat', 'and', 'global_warming', 'peanut_rare', 'grape'],\n",
       " ['great', 'article'],\n",
       " ['cuccinelli',\n",
       "  'file',\n",
       "  'motion',\n",
       "  'to',\n",
       "  'force',\n",
       "  'epa',\n",
       "  'to',\n",
       "  'reopen',\n",
       "  'global_warming',\n",
       "  'find',\n",
       "  'virginia',\n",
       "  'attorney',\n",
       "  'general',\n",
       "  'ken',\n",
       "  'cuccinelli',\n",
       "  'ha'],\n",
       " ['don_blankenship',\n",
       "  'mine_safety',\n",
       "  'regulator',\n",
       "  'a_silly',\n",
       "  'a',\n",
       "  'global_warming'],\n",
       " ['bring',\n",
       "  'back',\n",
       "  'the',\n",
       "  'hair',\n",
       "  'that',\n",
       "  'you',\n",
       "  'once',\n",
       "  'have',\n",
       "  'with',\n",
       "  \"nanogen's\",\n",
       "  'nanofibers',\n",
       "  'climate_change',\n",
       "  'clinical_trial',\n",
       "  'collagen'],\n",
       " ['street-corner',\n",
       "  'global-warming',\n",
       "  'counsel',\n",
       "  'urgh',\n",
       "  'certain',\n",
       "  'element',\n",
       "  'of',\n",
       "  'this',\n",
       "  'item',\n",
       "  'in',\n",
       "  \"sunday's\",\n",
       "  'washington',\n",
       "  'post',\n",
       "  'à_five',\n",
       "  'myth'],\n",
       " ['a_religious', 'take', 'on', 'climate_change'],\n",
       " ['be',\n",
       "  'you',\n",
       "  'ready',\n",
       "  'for',\n",
       "  'the',\n",
       "  'climate_change',\n",
       "  'pli',\n",
       "  'be',\n",
       "  'with',\n",
       "  'environmental',\n",
       "  'regulation',\n",
       "  'commercial',\n",
       "  'implication',\n",
       "  '2010',\n",
       "  'how',\n",
       "  'the'],\n",
       " ['live',\n",
       "  'tonight',\n",
       "  'fellow',\n",
       "  'heather_rogers',\n",
       "  'join',\n",
       "  'climate_change',\n",
       "  'expert',\n",
       "  'james_hansen',\n",
       "  'to',\n",
       "  'discus',\n",
       "  'real_solution',\n",
       "  'to',\n",
       "  'climate'],\n",
       " ['plan_california', 'brace_for', 'climate_change'],\n",
       " ['plant_effective',\n",
       "  'way',\n",
       "  'of',\n",
       "  'tackle',\n",
       "  'global_warming',\n",
       "  'washington',\n",
       "  'apr',\n",
       "  '30',\n",
       "  'plant',\n",
       "  'leaf',\n",
       "  'account_for',\n",
       "  'less_than',\n",
       "  'one',\n",
       "  'per'],\n",
       " ['it',\n",
       "  'be',\n",
       "  'about',\n",
       "  '2',\n",
       "  'be',\n",
       "  '86',\n",
       "  'degree',\n",
       "  'out',\n",
       "  'here',\n",
       "  'in',\n",
       "  'nyc',\n",
       "  'shiiiiiitttt',\n",
       "  'fuck',\n",
       "  'glodman',\n",
       "  'sachs',\n",
       "  'obama',\n",
       "  'well',\n",
       "  'get',\n",
       "  'a',\n",
       "  'plan',\n",
       "  '4',\n",
       "  'this',\n",
       "  'global_warming'],\n",
       " ['climate_change',\n",
       "  'sustainability',\n",
       "  'will',\n",
       "  'be',\n",
       "  'a',\n",
       "  'key',\n",
       "  'driver',\n",
       "  'of',\n",
       "  'future',\n",
       "  'economic',\n",
       "  'development',\n",
       "  'listen',\n",
       "  'at'],\n",
       " ['frederic',\n",
       "  'hague',\n",
       "  'at',\n",
       "  'pen',\n",
       "  'climate_change',\n",
       "  'be',\n",
       "  'not',\n",
       "  'just',\n",
       "  'a',\n",
       "  'alarm',\n",
       "  'bell',\n",
       "  'it',\n",
       "  'be',\n",
       "  'a',\n",
       "  'whole',\n",
       "  'blinking',\n",
       "  'discotech'],\n",
       " ['u',\n",
       "  'general',\n",
       "  'say',\n",
       "  'climate_change',\n",
       "  'threatens',\n",
       "  \"america's\",\n",
       "  'security',\n",
       "  'the',\n",
       "  'pentagon',\n",
       "  'have',\n",
       "  'make',\n",
       "  'it',\n",
       "  'well',\n",
       "  'know',\n",
       "  'that',\n",
       "  'it',\n",
       "  'consider'],\n",
       " ['even',\n",
       "  'the',\n",
       "  'general',\n",
       "  'know',\n",
       "  'climate_change',\n",
       "  'be',\n",
       "  'go',\n",
       "  'to',\n",
       "  'screw',\n",
       "  'u'],\n",
       " ['government_report',\n",
       "  'say',\n",
       "  'global_warming',\n",
       "  'may_cause',\n",
       "  'cancer_mental',\n",
       "  'illness'],\n",
       " ['climate_change', 'increase_heat', 'wave', 'flood', 'epa'],\n",
       " ['plant', 'remain', 'an', 'effective_way', 'of', 'tackle', 'global_warming'],\n",
       " ['so',\n",
       "  'far',\n",
       "  'in',\n",
       "  'that',\n",
       "  'class',\n",
       "  'i',\n",
       "  'have',\n",
       "  'gotten',\n",
       "  'into',\n",
       "  'heat',\n",
       "  'discussion',\n",
       "  'with',\n",
       "  'global',\n",
       "  'climate_change',\n",
       "  'denier',\n",
       "  'and',\n",
       "  'student',\n",
       "  'that',\n",
       "  'nothing',\n",
       "  'be',\n",
       "  'their',\n",
       "  'fault'],\n",
       " ['global_warming', 'kill', 'forest', 'in', 'colorado'],\n",
       " ['epa',\n",
       "  'confirms',\n",
       "  'climate',\n",
       "  'be',\n",
       "  'change',\n",
       "  'in',\n",
       "  'another',\n",
       "  'display',\n",
       "  'of',\n",
       "  'the',\n",
       "  'sea',\n",
       "  'change',\n",
       "  'that',\n",
       "  'have',\n",
       "  'occur',\n",
       "  'at',\n",
       "  'the',\n",
       "  'u',\n",
       "  'environmental'],\n",
       " ['must',\n",
       "  'see',\n",
       "  'place',\n",
       "  'before_they',\n",
       "  'disappear',\n",
       "  'europe',\n",
       "  'pic',\n",
       "  ']:',\n",
       "  'if',\n",
       "  'global_warming',\n",
       "  'prediction',\n",
       "  'prove',\n",
       "  'to',\n",
       "  'be',\n",
       "  'true',\n",
       "  'the',\n",
       "  'foll'],\n",
       " ['combat',\n",
       "  'climate_change',\n",
       "  'lesson_from',\n",
       "  'the',\n",
       "  'world',\n",
       "  'à_s',\n",
       "  'indigenous_people'],\n",
       " ['i',\n",
       "  'live',\n",
       "  'in',\n",
       "  'ct',\n",
       "  'please',\n",
       "  'support',\n",
       "  'the',\n",
       "  'climate',\n",
       "  'bill',\n",
       "  'and',\n",
       "  'strong',\n",
       "  'action',\n",
       "  'on',\n",
       "  'climate_change'],\n",
       " ['indigenous', 'tradition', 'use', 'to', 'fight', 'climate_change'],\n",
       " ['james_hansen',\n",
       "  'heather_rogers',\n",
       "  'green',\n",
       "  'go_wrong',\n",
       "  'false_hope',\n",
       "  'real_solution',\n",
       "  'to',\n",
       "  'climate_change',\n",
       "  '7pm',\n",
       "  '4/30'],\n",
       " ['climate_change',\n",
       "  'forest',\n",
       "  'not',\n",
       "  'for_absorb',\n",
       "  'carbon',\n",
       "  'say',\n",
       "  'activist'],\n",
       " ['climate_change',\n",
       "  'melt',\n",
       "  'two',\n",
       "  'glacier',\n",
       "  'billing',\n",
       "  'mont',\n",
       "  'glacier_national',\n",
       "  'park',\n",
       "  'have',\n",
       "  'lose',\n",
       "  'two_more',\n",
       "  'of',\n",
       "  'it',\n",
       "  'namesake'],\n",
       " ['climate_change', 'forest', 'not', 'for_absorb', 'carbon'],\n",
       " ['what',\n",
       "  'beautiful',\n",
       "  'fall',\n",
       "  'weather',\n",
       "  'this',\n",
       "  'morning',\n",
       "  'new_york',\n",
       "  'thanks',\n",
       "  'climate_change',\n",
       "  'bleh'],\n",
       " ['what',\n",
       "  'beautiful',\n",
       "  'fall',\n",
       "  'weather',\n",
       "  'this',\n",
       "  'morning',\n",
       "  'new_york',\n",
       "  'thanks',\n",
       "  'climate_change',\n",
       "  'bleh'],\n",
       " ['climate_change',\n",
       "  'threatens',\n",
       "  \"japan's\",\n",
       "  'cherry',\n",
       "  'blossom',\n",
       "  'environment',\n",
       "  'if_you',\n",
       "  'be',\n",
       "  'not',\n",
       "  'familiar',\n",
       "  'with',\n",
       "  'the',\n",
       "  'culture',\n",
       "  'japan'],\n",
       " ['wed',\n",
       "  'podcast',\n",
       "  'mountain',\n",
       "  'valley',\n",
       "  'temp',\n",
       "  'stretch',\n",
       "  'apart',\n",
       "  'with',\n",
       "  'climate_change'],\n",
       " ['mountain', 'valley', 'temp', 'stretch', 'apart', 'with', 'climate_change'],\n",
       " ['arctic',\n",
       "  'rain_in',\n",
       "  'april',\n",
       "  'be',\n",
       "  'sign',\n",
       "  'of',\n",
       "  'global_warming',\n",
       "  'the',\n",
       "  'canadian',\n",
       "  'arctic',\n",
       "  'have',\n",
       "  'be',\n",
       "  'hit',\n",
       "  'by',\n",
       "  'rain_in',\n",
       "  'a',\n",
       "  'sign',\n",
       "  'that',\n",
       "  'the'],\n",
       " ['microbe',\n",
       "  'contribute',\n",
       "  'less',\n",
       "  'to',\n",
       "  'global_warming',\n",
       "  'new',\n",
       "  'haven',\n",
       "  'conn',\n",
       "  '. ..'],\n",
       " ['south',\n",
       "  'asian',\n",
       "  'nation',\n",
       "  'to',\n",
       "  'fight',\n",
       "  'climate_change',\n",
       "  'foreign',\n",
       "  'minister',\n",
       "  'of',\n",
       "  'eight',\n",
       "  'south',\n",
       "  'asian',\n",
       "  'nation',\n",
       "  'met',\n",
       "  'in',\n",
       "  'this',\n",
       "  'seclude'],\n",
       " ['climate_change',\n",
       "  'increase_heat',\n",
       "  'wave',\n",
       "  'flood',\n",
       "  'washington_reuters',\n",
       "  'death',\n",
       "  'from',\n",
       "  'heat_wave',\n",
       "  'property',\n",
       "  'damage',\n",
       "  'from'],\n",
       " ['james_hansen',\n",
       "  'heather_rogers',\n",
       "  'green',\n",
       "  'go_wrong',\n",
       "  'false_hope',\n",
       "  'real_solution',\n",
       "  'to',\n",
       "  'climate_change',\n",
       "  '7pm',\n",
       "  '4/30'],\n",
       " ['i_love',\n",
       "  \"frog's\",\n",
       "  'leap',\n",
       "  'seriously',\n",
       "  'what',\n",
       "  'climate_change',\n",
       "  'mean',\n",
       "  'for',\n",
       "  'the',\n",
       "  'wine',\n",
       "  'industry',\n",
       "  'via'],\n",
       " ['report',\n",
       "  'save',\n",
       "  'the',\n",
       "  'whale',\n",
       "  'and',\n",
       "  'they_will',\n",
       "  'save',\n",
       "  'u',\n",
       "  'from',\n",
       "  'global_warming'],\n",
       " ['the',\n",
       "  'contribution',\n",
       "  'of',\n",
       "  'organic',\n",
       "  'agriculture',\n",
       "  'to',\n",
       "  'climate_change',\n",
       "  'mitigation'],\n",
       " ['arctic',\n",
       "  'beauty',\n",
       "  'in',\n",
       "  'black',\n",
       "  'and',\n",
       "  'white',\n",
       "  'alaska_before',\n",
       "  'the',\n",
       "  'effect_of',\n",
       "  'global_warming',\n",
       "  'slide',\n",
       "  'show',\n",
       "  ']:',\n",
       "  'toward',\n",
       "  'the',\n",
       "  'end',\n",
       "  'of',\n",
       "  'wor'],\n",
       " ['epa',\n",
       "  'report',\n",
       "  'document',\n",
       "  'very',\n",
       "  'real',\n",
       "  'impact',\n",
       "  'from',\n",
       "  'climate_change',\n",
       "  'in',\n",
       "  '22',\n",
       "  'of',\n",
       "  '24',\n",
       "  'indicator',\n",
       "  'study'],\n",
       " ['canadian',\n",
       "  'ceo',\n",
       "  'more',\n",
       "  'keen',\n",
       "  'on',\n",
       "  'green',\n",
       "  'than',\n",
       "  'global',\n",
       "  'counterpart',\n",
       "  'prepare',\n",
       "  'for',\n",
       "  'impact',\n",
       "  'of',\n",
       "  'climate_change'],\n",
       " ['ask',\n",
       "  'the',\n",
       "  'g8',\n",
       "  'g20',\n",
       "  'to',\n",
       "  'support',\n",
       "  'biochar',\n",
       "  'fight',\n",
       "  'climate_change',\n",
       "  'food',\n",
       "  'shortage',\n",
       "  'check_this',\n",
       "  'huffpo',\n",
       "  'post'],\n",
       " ['whale',\n",
       "  'doodoo',\n",
       "  'could_help',\n",
       "  'fight',\n",
       "  'climate_change',\n",
       "  'sure',\n",
       "  'why',\n",
       "  'not'],\n",
       " ['global_warming',\n",
       "  'science',\n",
       "  'good_news',\n",
       "  'soil',\n",
       "  'release',\n",
       "  'less',\n",
       "  'carbon',\n",
       "  'than',\n",
       "  'though',\n",
       "  'a',\n",
       "  'world',\n",
       "  'warms'],\n",
       " ['so',\n",
       "  'it',\n",
       "  'april',\n",
       "  '27th',\n",
       "  'phoenix',\n",
       "  'have',\n",
       "  '90',\n",
       "  '_á',\n",
       "  'weather',\n",
       "  'it',\n",
       "  'might',\n",
       "  'snow',\n",
       "  'in',\n",
       "  'new_york',\n",
       "  'today',\n",
       "  'hmmmm',\n",
       "  'global_warming',\n",
       "  'much'],\n",
       " ['high_temperature',\n",
       "  'sea_level',\n",
       "  'due_to',\n",
       "  'global_warming',\n",
       "  'kuala',\n",
       "  'lumpur',\n",
       "  \"malaysia's\",\n",
       "  'average',\n",
       "  'temperature',\n",
       "  'have',\n",
       "  'risen',\n",
       "  'by',\n",
       "  '1.1'],\n",
       " ['west', 'mediterranean', 'country', 'unite', 'on', 'climate_change', 'afp'],\n",
       " ['cleaner_air',\n",
       "  'could_speed',\n",
       "  'global_warming',\n",
       "  'hugh',\n",
       "  'pickens',\n",
       "  'writes',\n",
       "  'scientist',\n",
       "  'estimate',\n",
       "  'that',\n",
       "  'the',\n",
       "  'u',\n",
       "  'clean',\n",
       "  'air',\n",
       "  'act',\n",
       "  'have',\n",
       "  'cut'],\n",
       " ['3,000_business', 'create_new', 'ad_for', 'climate_change', 'action'],\n",
       " ['person',\n",
       "  '1',\n",
       "  'snow',\n",
       "  'then',\n",
       "  '65',\n",
       "  'degree',\n",
       "  'on',\n",
       "  'the',\n",
       "  'same',\n",
       "  'day',\n",
       "  'weather',\n",
       "  'do_not',\n",
       "  'even',\n",
       "  'surprise',\n",
       "  'me',\n",
       "  'anymore',\n",
       "  'person',\n",
       "  '2',\n",
       "  'that',\n",
       "  'be',\n",
       "  'why',\n",
       "  'global_warming',\n",
       "  'will',\n",
       "  'win'],\n",
       " ['just',\n",
       "  'heard',\n",
       "  'an',\n",
       "  'interest',\n",
       "  'report',\n",
       "  'on',\n",
       "  'report',\n",
       "  'on',\n",
       "  'understand',\n",
       "  'climate_change',\n",
       "  'climate',\n",
       "  'variability',\n",
       "  'influence',\n",
       "  'on',\n",
       "  'human',\n",
       "  'evolution',\n",
       "  'and',\n",
       "  'dispersal'],\n",
       " ['alaska_before', 'the', 'effect_of', 'global_warming', 'pic', ']:'],\n",
       " ['new',\n",
       "  'blog_post',\n",
       "  'mandate',\n",
       "  'energy',\n",
       "  'benchmarking',\n",
       "  'the',\n",
       "  'next',\n",
       "  'step',\n",
       "  'for',\n",
       "  'city',\n",
       "  'in',\n",
       "  'address',\n",
       "  'climate_change'],\n",
       " ['realdocwatson',\n",
       "  'on',\n",
       "  'global_warming',\n",
       "  'go',\n",
       "  'to',\n",
       "  'antarctica',\n",
       "  'and',\n",
       "  'stake',\n",
       "  'a',\n",
       "  'claim',\n",
       "  'now',\n",
       "  'it',\n",
       "  'will',\n",
       "  'be',\n",
       "  'like',\n",
       "  'florida',\n",
       "  'in',\n",
       "  'a',\n",
       "  'few',\n",
       "  'year'],\n",
       " ['how_much',\n",
       "  'trouble',\n",
       "  'do',\n",
       "  'global_warming',\n",
       "  'mean',\n",
       "  'for',\n",
       "  'agriculture',\n",
       "  'just_ask',\n",
       "  'the',\n",
       "  'wine',\n",
       "  'industry'],\n",
       " ['arctic',\n",
       "  'beauty',\n",
       "  'in',\n",
       "  'black',\n",
       "  'and',\n",
       "  'white',\n",
       "  'alaska_before',\n",
       "  'the',\n",
       "  'effect_of',\n",
       "  'global_warming',\n",
       "  'slide',\n",
       "  'show'],\n",
       " ['climate_change',\n",
       "  'from',\n",
       "  'paris',\n",
       "  'to',\n",
       "  'the',\n",
       "  'alp',\n",
       "  'european',\n",
       "  'place',\n",
       "  'in',\n",
       "  'peril',\n",
       "  'photo'],\n",
       " ['how',\n",
       "  'climate_change',\n",
       "  'will',\n",
       "  'change',\n",
       "  'the',\n",
       "  'electoral',\n",
       "  'map',\n",
       "  'the',\n",
       "  'national',\n",
       "  'oceanic',\n",
       "  'and',\n",
       "  'atmospheric',\n",
       "  'administration',\n",
       "  'be',\n",
       "  'not',\n",
       "  'know'],\n",
       " ['report',\n",
       "  'cleaner_air',\n",
       "  'could',\n",
       "  'actually_intensify',\n",
       "  'global_warming',\n",
       "  'a',\n",
       "  'much',\n",
       "  'of',\n",
       "  'the',\n",
       "  'world',\n",
       "  'marked',\n",
       "  'earth_day',\n",
       "  'this',\n",
       "  'past',\n",
       "  'week',\n",
       "  'the',\n",
       "  'environmental'],\n",
       " ['global_warming',\n",
       "  'be',\n",
       "  'a',\n",
       "  'threat',\n",
       "  'after',\n",
       "  'all',\n",
       "  'tim',\n",
       "  'blair',\n",
       "  'round',\n",
       "  'up',\n",
       "  'the',\n",
       "  'late',\n",
       "  'news',\n",
       "  'from',\n",
       "  'the',\n",
       "  'wild',\n",
       "  'frontier',\n",
       "  'of',\n",
       "  'global'],\n",
       " ['kuna',\n",
       "  'indian',\n",
       "  'prepare',\n",
       "  'for',\n",
       "  'relocation',\n",
       "  'a',\n",
       "  'traditional',\n",
       "  'home',\n",
       "  'sink',\n",
       "  'due_to',\n",
       "  'climate_change'],\n",
       " ['how',\n",
       "  'global_warming',\n",
       "  'be',\n",
       "  'kill',\n",
       "  \"california's\",\n",
       "  'wine',\n",
       "  'buzz',\n",
       "  'dr',\n",
       "  'kimberley',\n",
       "  'cahill',\n",
       "  'present',\n",
       "  'on',\n",
       "  'climate_change',\n",
       "  'in',\n",
       "  'califor'],\n",
       " ['uncajoe',\n",
       "  'plz_digg',\n",
       "  'climate',\n",
       "  'of',\n",
       "  'hate',\n",
       "  'the',\n",
       "  'politics',\n",
       "  'of',\n",
       "  'climate_change',\n",
       "  'denial',\n",
       "  'a'],\n",
       " ['global_warming',\n",
       "  'ocean_chemistry',\n",
       "  'be',\n",
       "  'change',\n",
       "  'faster_than',\n",
       "  'it',\n",
       "  'have',\n",
       "  'in',\n",
       "  '800,000',\n",
       "  'year',\n",
       "  'and',\n",
       "  'that',\n",
       "  'be',\n",
       "  'because',\n",
       "  'of',\n",
       "  'the',\n",
       "  'carbon'],\n",
       " ['good',\n",
       "  'go',\n",
       "  'douche',\n",
       "  \"i'm\",\n",
       "  'sure',\n",
       "  'there_be',\n",
       "  'no',\n",
       "  'climate_change',\n",
       "  'in',\n",
       "  'your',\n",
       "  'backass',\n",
       "  'world',\n",
       "  'graham',\n",
       "  'move_imperils',\n",
       "  'obama',\n",
       "  'agenda'],\n",
       " ['ski_resort',\n",
       "  'fight',\n",
       "  'global_warming',\n",
       "  'salt_lake',\n",
       "  'city',\n",
       "  'ap',\n",
       "  'ski_resort',\n",
       "  'across',\n",
       "  'the',\n",
       "  'u',\n",
       "  'be',\n",
       "  'use',\n",
       "  'this',\n",
       "  'thanksgiving'],\n",
       " ['bat_bird',\n",
       "  'and_lizard',\n",
       "  'can_fight',\n",
       "  'climate_change',\n",
       "  'by',\n",
       "  'eat',\n",
       "  'insect',\n",
       "  'bird_bat',\n",
       "  'and_lizard',\n",
       "  'may_play',\n",
       "  'an_important'],\n",
       " ['make',\n",
       "  'it',\n",
       "  'green',\n",
       "  'cloud',\n",
       "  'compute',\n",
       "  'and',\n",
       "  'it',\n",
       "  'contribution',\n",
       "  'to',\n",
       "  'climate_change'],\n",
       " ['climate_change',\n",
       "  'favor',\n",
       "  'invasive_specie',\n",
       "  'over',\n",
       "  'indigenous',\n",
       "  'one',\n",
       "  '30',\n",
       "  'of',\n",
       "  'plant',\n",
       "  'thoreau',\n",
       "  'saw',\n",
       "  'be',\n",
       "  'now',\n",
       "  'extinct'],\n",
       " ['scary',\n",
       "  'climate_change',\n",
       "  'alter',\n",
       "  'u',\n",
       "  'season',\n",
       "  'spring',\n",
       "  '10',\n",
       "  'day',\n",
       "  'early'],\n",
       " ['pres',\n",
       "  'evo_morale',\n",
       "  'in',\n",
       "  'climate_change',\n",
       "  'lesson_from',\n",
       "  'indigenous_people'],\n",
       " ['mediaglobal',\n",
       "  'report',\n",
       "  'on',\n",
       "  'special',\n",
       "  'tip',\n",
       "  'point',\n",
       "  'earth_day',\n",
       "  'event',\n",
       "  'science',\n",
       "  'and',\n",
       "  'art',\n",
       "  'mobilize',\n",
       "  'to',\n",
       "  'fight',\n",
       "  'climate_change'],\n",
       " ['a', 'review', 'of', \"yesterday's\", 'discussion'],\n",
       " ['global_warming', 'kill', 'forest', 'in', 'colorado'],\n",
       " ['combat',\n",
       "  'climate_change',\n",
       "  'lesson_from',\n",
       "  'the',\n",
       "  \"world's\",\n",
       "  'indigenous_people',\n",
       "  'when',\n",
       "  'i',\n",
       "  'arrive',\n",
       "  'at',\n",
       "  'the',\n",
       "  'united_nation',\n",
       "  'climat'],\n",
       " ['africa',\n",
       "  'meteorology',\n",
       "  'service',\n",
       "  'gear',\n",
       "  'up',\n",
       "  'for',\n",
       "  'climate_change',\n",
       "  'on',\n",
       "  'the',\n",
       "  'continent',\n",
       "  'most_vulnerable',\n",
       "  'to',\n",
       "  'climate'],\n",
       " ['gecko',\n",
       "  '10_first',\n",
       "  'step',\n",
       "  'to',\n",
       "  'greener_living',\n",
       "  'it',\n",
       "  'all_seem',\n",
       "  'so_daunt',\n",
       "  'climate_change',\n",
       "  'carbon_credit',\n",
       "  'not',\n",
       "  'to',\n",
       "  'mention'],\n",
       " ['china',\n",
       "  'the',\n",
       "  'key',\n",
       "  'to',\n",
       "  'fix',\n",
       "  'global_warming',\n",
       "  'with',\n",
       "  'rapid',\n",
       "  'expansion',\n",
       "  'come',\n",
       "  'sizable',\n",
       "  'environmental',\n",
       "  'impact',\n",
       "  'so',\n",
       "  'the',\n",
       "  \"world's\"],\n",
       " ['now',\n",
       "  'on',\n",
       "  'pb',\n",
       "  'go_green',\n",
       "  'new_york',\n",
       "  'examine',\n",
       "  'how',\n",
       "  'new',\n",
       "  'yorkers',\n",
       "  'be',\n",
       "  'confront',\n",
       "  'climate_change',\n",
       "  'check',\n",
       "  'local',\n",
       "  'listing'],\n",
       " ['official', 'nasa', 'report', 'sun', 'cause', 'climate_change'],\n",
       " ['well',\n",
       "  'this',\n",
       "  'be',\n",
       "  'just',\n",
       "  'crazy',\n",
       "  'coal_ceo',\n",
       "  'call_mine',\n",
       "  'safety_rule',\n",
       "  'a_silly',\n",
       "  'a',\n",
       "  'global_warming'],\n",
       " ['impact', 'of', 'climate_change', 'extend', 'to', 'human_health'],\n",
       " ['impact', 'of', 'climate_change', 'extend', 'to', 'human_health'],\n",
       " ['the',\n",
       "  'good_news',\n",
       "  'about',\n",
       "  'the',\n",
       "  'very_bad',\n",
       "  'news',\n",
       "  'about',\n",
       "  'climate_change',\n",
       "  'by',\n",
       "  'rebecca',\n",
       "  'solnit'],\n",
       " ['alpha',\n",
       "  'phi',\n",
       "  'alpha',\n",
       "  'take',\n",
       "  'on',\n",
       "  'climate_change',\n",
       "  'and',\n",
       "  'energy',\n",
       "  'efficiency'],\n",
       " ['natural',\n",
       "  'variability',\n",
       "  'do_not',\n",
       "  'explain',\n",
       "  'global_warming',\n",
       "  'climate',\n",
       "  'scientist',\n",
       "  'tell',\n",
       "  'popular',\n",
       "  'tv',\n",
       "  'meteorologist'],\n",
       " ['rebecca',\n",
       "  'solnit',\n",
       "  '350',\n",
       "  'degree',\n",
       "  'of',\n",
       "  'inseparability',\n",
       "  'the',\n",
       "  'good_news',\n",
       "  'about',\n",
       "  'the',\n",
       "  'very_bad',\n",
       "  'news',\n",
       "  'about',\n",
       "  'climate_change'],\n",
       " ['watch',\n",
       "  'video',\n",
       "  'climate_change',\n",
       "  'threatens',\n",
       "  'sacred',\n",
       "  'tibetan',\n",
       "  'mountain',\n",
       "  'include',\n",
       "  'land',\n",
       "  'know',\n",
       "  'a',\n",
       "  'shangri-la'],\n",
       " ['african',\n",
       "  'meteorology',\n",
       "  'service',\n",
       "  'gear',\n",
       "  'up',\n",
       "  'for',\n",
       "  'climate_change',\n",
       "  'america.gov',\n",
       "  'iri'],\n",
       " ['economist', 'say', 'climate_change', 'be', 'bad', 'for', 'economy'],\n",
       " ['report',\n",
       "  'allergy_season',\n",
       "  'to',\n",
       "  'get_bad',\n",
       "  'with',\n",
       "  'climate_change',\n",
       "  'time.com'],\n",
       " ['don',\n",
       "  'à_t',\n",
       "  'kill',\n",
       "  'bill',\n",
       "  'à_',\n",
       "  'save',\n",
       "  'the',\n",
       "  'climate_change',\n",
       "  'accountability',\n",
       "  'act'],\n",
       " ['climate_change',\n",
       "  'make',\n",
       "  'farmer',\n",
       "  'pastoralists',\n",
       "  'in',\n",
       "  'ethiopia',\n",
       "  'increasingly',\n",
       "  'vulnerable'],\n",
       " ['denis',\n",
       "  'hayes',\n",
       "  'founder',\n",
       "  'of',\n",
       "  'earth_day',\n",
       "  'compare',\n",
       "  'global',\n",
       "  'climate_change',\n",
       "  'to',\n",
       "  'irish',\n",
       "  'famine',\n",
       "  'irishcentral',\n",
       "  'news',\n",
       "  'weather',\n",
       "  'politics'],\n",
       " ['climate_change',\n",
       "  'make',\n",
       "  'farmer',\n",
       "  'pastoralists',\n",
       "  'in',\n",
       "  'ethiopia',\n",
       "  'increasingly',\n",
       "  'vulnerable'],\n",
       " ['it',\n",
       "  'earthday',\n",
       "  'be',\n",
       "  'aware',\n",
       "  'of',\n",
       "  'what',\n",
       "  'you',\n",
       "  'consume',\n",
       "  'waste',\n",
       "  'how',\n",
       "  'you',\n",
       "  'treat',\n",
       "  'this',\n",
       "  'place',\n",
       "  'we',\n",
       "  'only',\n",
       "  'have',\n",
       "  '1',\n",
       "  'a',\n",
       "  'we_can',\n",
       "  'see',\n",
       "  'global_warming',\n",
       "  'be',\n",
       "  'in',\n",
       "  'effect'],\n",
       " ['earth_day',\n",
       "  'ben',\n",
       "  'verwaayen',\n",
       "  'on',\n",
       "  'what',\n",
       "  'we',\n",
       "  'be',\n",
       "  'do',\n",
       "  'to_curb',\n",
       "  'climate_change'],\n",
       " ['health',\n",
       "  'u',\n",
       "  'and',\n",
       "  'other',\n",
       "  'industrial',\n",
       "  'nation',\n",
       "  'already',\n",
       "  'feel',\n",
       "  'impact',\n",
       "  'of',\n",
       "  'climate_change',\n",
       "  'report'],\n",
       " ['10_first',\n",
       "  'step',\n",
       "  'to',\n",
       "  'greener_living',\n",
       "  'it',\n",
       "  'all_seem',\n",
       "  'so_daunt',\n",
       "  'climate_change',\n",
       "  'carbon_credit',\n",
       "  'not',\n",
       "  'to',\n",
       "  'mention',\n",
       "  'biofuel'],\n",
       " ['climate_change', 'could_raise', 'cost_of', 'u', 'allergy', 'reuters'],\n",
       " ['treat',\n",
       "  'climate_change',\n",
       "  'a',\n",
       "  'a',\n",
       "  'curable_disease',\n",
       "  'bioethicists',\n",
       "  'and',\n",
       "  'international',\n",
       "  'law',\n",
       "  'expert',\n",
       "  'met',\n",
       "  'in',\n",
       "  'asilomar',\n",
       "  'later',\n",
       "  'la'],\n",
       " ['well',\n",
       "  'this',\n",
       "  'be',\n",
       "  'just',\n",
       "  'crazy',\n",
       "  'coal_ceo',\n",
       "  'call_mine',\n",
       "  'safety_rule',\n",
       "  'a_silly',\n",
       "  'a',\n",
       "  'global_warming'],\n",
       " ['military_lead', 'fight_against', 'climate_change'],\n",
       " ['military_lead',\n",
       "  'fight_against',\n",
       "  'climate_change',\n",
       "  'the',\n",
       "  'u',\n",
       "  'military',\n",
       "  'the',\n",
       "  \"government's\",\n",
       "  'large',\n",
       "  'fuel',\n",
       "  'buyer',\n",
       "  'be',\n",
       "  'lead',\n",
       "  'th'],\n",
       " ['swedish',\n",
       "  'expert',\n",
       "  'say',\n",
       "  'co2',\n",
       "  'be',\n",
       "  'not',\n",
       "  'the',\n",
       "  'main',\n",
       "  'cause',\n",
       "  'of',\n",
       "  'global_warming',\n",
       "  'swedish',\n",
       "  'climate',\n",
       "  'expert',\n",
       "  'dr',\n",
       "  'fred',\n",
       "  'goldberg',\n",
       "  'have',\n",
       "  'say'],\n",
       " ['treat',\n",
       "  'climate_change',\n",
       "  'a',\n",
       "  'a',\n",
       "  'curable_disease',\n",
       "  'wire',\n",
       "  'science',\n",
       "  'wired.com',\n",
       "  'green'],\n",
       " [],\n",
       " ['thursday',\n",
       "  'on',\n",
       "  'pb',\n",
       "  'go_green',\n",
       "  'new_york',\n",
       "  'examine',\n",
       "  'how',\n",
       "  'new',\n",
       "  'yorkers',\n",
       "  'be',\n",
       "  'confront',\n",
       "  'climate_change',\n",
       "  'check',\n",
       "  'local',\n",
       "  'listing'],\n",
       " ['un',\n",
       "  'à_',\n",
       "  'only',\n",
       "  'global',\n",
       "  'cooperation',\n",
       "  'can',\n",
       "  'prevent',\n",
       "  'runaway',\n",
       "  'climate_change',\n",
       "  'secretary',\n",
       "  'à_',\n",
       "  'the',\n",
       "  'united_nation',\n",
       "  'seek',\n",
       "  'dialogue',\n",
       "  'i'],\n",
       " ['most_important',\n",
       "  'event',\n",
       "  'in',\n",
       "  'struggle_against',\n",
       "  'climate_change',\n",
       "  'nigerian_environmentalist',\n",
       "  'nnimmo_bassey'],\n",
       " ['military_lead', 'fight_against', 'climate_change', 'pew'],\n",
       " ['report',\n",
       "  'identifies',\n",
       "  '11',\n",
       "  'disease',\n",
       "  'health',\n",
       "  'issue',\n",
       "  'affctd',\n",
       "  'by',\n",
       "  'climate_change',\n",
       "  'once',\n",
       "  'u',\n",
       "  'inclde',\n",
       "  'mental',\n",
       "  'health',\n",
       "  \"evrything's\",\n",
       "  'stake'],\n",
       " ['for', 'earth_day', 'resource', 'on', 'cop', 'with', 'climate_change'],\n",
       " ['ocean_saltiness',\n",
       "  'show',\n",
       "  'global_warming',\n",
       "  'be',\n",
       "  'intensify_our',\n",
       "  'water_cycle'],\n",
       " ['fedele',\n",
       "  'bauccio',\n",
       "  'combat',\n",
       "  'climate_change',\n",
       "  'one',\n",
       "  'meal',\n",
       "  'at',\n",
       "  'a',\n",
       "  'time',\n",
       "  'this_week',\n",
       "  'american',\n",
       "  'will',\n",
       "  'celebrate',\n",
       "  'the',\n",
       "  '40th',\n",
       "  'anniver'],\n",
       " ['i',\n",
       "  'support',\n",
       "  \"world_people's\",\n",
       "  'conf',\n",
       "  'on',\n",
       "  'climate_change',\n",
       "  'in',\n",
       "  'cochabamba',\n",
       "  'bolivia.watch',\n",
       "  'live'],\n",
       " ['barrett',\n",
       "  'well',\n",
       "  'to',\n",
       "  'have',\n",
       "  'lot',\n",
       "  'of',\n",
       "  'small',\n",
       "  'protocol',\n",
       "  'on',\n",
       "  'climate_change',\n",
       "  'than',\n",
       "  'push',\n",
       "  'for',\n",
       "  'one',\n",
       "  'comprehensive',\n",
       "  'one'],\n",
       " ['topography',\n",
       "  'of',\n",
       "  'mountain',\n",
       "  'could',\n",
       "  'complicate',\n",
       "  'rate',\n",
       "  'of',\n",
       "  'global_warming'],\n",
       " ['i',\n",
       "  'support',\n",
       "  'the',\n",
       "  \"world_people's\",\n",
       "  'conference_on',\n",
       "  'climate_change',\n",
       "  'in',\n",
       "  'cochabamba',\n",
       "  'bolivia',\n",
       "  'watch',\n",
       "  'live',\n",
       "  'now',\n",
       "  'at'],\n",
       " ['many',\n",
       "  'global',\n",
       "  'issue',\n",
       "  'require',\n",
       "  'universal',\n",
       "  'co-operation',\n",
       "  'to',\n",
       "  'address',\n",
       "  'smallpox',\n",
       "  'ozone',\n",
       "  'layer',\n",
       "  'climate_change'],\n",
       " ['bolivia', 'president', 'on', 'global_warming'],\n",
       " ['boil',\n",
       "  'point',\n",
       "  'contain',\n",
       "  'the',\n",
       "  'spill',\n",
       "  'over',\n",
       "  'of',\n",
       "  'climate_change',\n",
       "  'in',\n",
       "  'the',\n",
       "  'indian',\n",
       "  'subcontinent',\n",
       "  'a',\n",
       "  'à_'],\n",
       " ['no',\n",
       "  'link',\n",
       "  'now',\n",
       "  'between',\n",
       "  'eyjafjallaj',\n",
       "  '__kull',\n",
       "  'and',\n",
       "  'climate_change',\n",
       "  'but',\n",
       "  'a',\n",
       "  'warming',\n",
       "  'world',\n",
       "  'could_trigger',\n",
       "  'earthquake',\n",
       "  'landslide'],\n",
       " ['ethiopia', 'climate_change', 'increase', 'poverty_and', 'vulnerability'],\n",
       " ['ethiopia',\n",
       "  'climate_change',\n",
       "  'increase',\n",
       "  'poverty_and',\n",
       "  'vulnerability',\n",
       "  'small-scale',\n",
       "  'farmer',\n",
       "  'and',\n",
       "  'pastoralists',\n",
       "  'i'],\n",
       " ['the',\n",
       "  'most_important',\n",
       "  'event',\n",
       "  'in',\n",
       "  'the',\n",
       "  'struggle_against',\n",
       "  'climate_change',\n",
       "  'nigerian_environmentalist',\n",
       "  'nnimmo_bassey',\n",
       "  'on',\n",
       "  'à_'],\n",
       " ['the',\n",
       "  'most_important',\n",
       "  'event',\n",
       "  'in',\n",
       "  'the',\n",
       "  'struggle_against',\n",
       "  'climate_change',\n",
       "  'nigerian_environmentalist',\n",
       "  'nnimmo_bassey',\n",
       "  'on',\n",
       "  'à_'],\n",
       " ['backgrounder',\n",
       "  \"china's\",\n",
       "  'major',\n",
       "  'policy',\n",
       "  'to',\n",
       "  'tackle',\n",
       "  'climate_change',\n",
       "  'since',\n",
       "  'year',\n",
       "  '2000'],\n",
       " ['uw_biologist',\n",
       "  'link_early',\n",
       "  'bloom',\n",
       "  'to',\n",
       "  'global_warming',\n",
       "  'associate',\n",
       "  'press',\n",
       "  'april',\n",
       "  '21',\n",
       "  '2010',\n",
       "  '6:15',\n",
       "  'be',\n",
       "  'et',\n",
       "  'stevens',\n",
       "  'point'],\n",
       " ['will',\n",
       "  'global_warming',\n",
       "  \"make_iceland's\",\n",
       "  'volcano_angry',\n",
       "  'melt_glacier',\n",
       "  'around',\n",
       "  'the',\n",
       "  'world',\n",
       "  'could_trigger',\n",
       "  'a',\n",
       "  'global'],\n",
       " ['climate_change',\n",
       "  'could',\n",
       "  'nyc',\n",
       "  'get',\n",
       "  'katrina-like',\n",
       "  'flood',\n",
       "  'in',\n",
       "  'a',\n",
       "  'warmer',\n",
       "  'wetter',\n",
       "  'future',\n",
       "  'sea_level',\n",
       "  'rise',\n",
       "  'of',\n",
       "  '2_foot',\n",
       "  'in',\n",
       "  '70yrs'],\n",
       " ['climate_change',\n",
       "  'geologist',\n",
       "  'drill',\n",
       "  'into',\n",
       "  'antarctica',\n",
       "  'find',\n",
       "  'trouble',\n",
       "  'sign',\n",
       "  '4',\n",
       "  'ice',\n",
       "  'sheet',\n",
       "  'future',\n",
       "  'à_',\n",
       "  'melt',\n",
       "  'could',\n",
       "  'come',\n",
       "  'fast'],\n",
       " ['either',\n",
       "  'capitalism',\n",
       "  'dy',\n",
       "  'or',\n",
       "  'mother_earth',\n",
       "  'do',\n",
       "  'evo_morale',\n",
       "  'claim',\n",
       "  'in',\n",
       "  'the',\n",
       "  \"people's_world\",\n",
       "  'conference_on',\n",
       "  'climate_change'],\n",
       " ['yet',\n",
       "  'another',\n",
       "  'gift',\n",
       "  'from',\n",
       "  'global_warming',\n",
       "  'increase',\n",
       "  'allergy',\n",
       "  'attack'],\n",
       " ['africa',\n",
       "  'time',\n",
       "  'bomb',\n",
       "  'await',\n",
       "  'africa',\n",
       "  'there_be',\n",
       "  'no',\n",
       "  'doubt',\n",
       "  'that',\n",
       "  'climate_change',\n",
       "  'a',\n",
       "  'an',\n",
       "  'environmental',\n",
       "  'issue',\n",
       "  'ha'],\n",
       " ['buying',\n",
       "  'carbon_offset',\n",
       "  'may',\n",
       "  'ease',\n",
       "  'eco-guilt',\n",
       "  'but',\n",
       "  'not',\n",
       "  'global_warming'],\n",
       " ['all',\n",
       "  'eye',\n",
       "  'on',\n",
       "  'cochabamba',\n",
       "  'those',\n",
       "  'alrdy',\n",
       "  'suffer_from',\n",
       "  'global_warming',\n",
       "  'will',\n",
       "  'havechancetospeakout'],\n",
       " ['this',\n",
       "  'ecomonday',\n",
       "  'discussion',\n",
       "  'of',\n",
       "  'climate_change',\n",
       "  'and',\n",
       "  'invasive_specie',\n",
       "  'recommend'],\n",
       " ['on',\n",
       "  'ocean',\n",
       "  'floor',\n",
       "  'population',\n",
       "  'of',\n",
       "  'organism',\n",
       "  'despite',\n",
       "  'little',\n",
       "  'oxygen',\n",
       "  'global_warming',\n",
       "  'cause',\n",
       "  'oxygen',\n",
       "  'depletion',\n",
       "  'reduce',\n",
       "  'biodiversity'],\n",
       " ['join',\n",
       "  'u',\n",
       "  'for',\n",
       "  'a',\n",
       "  'discussion',\n",
       "  'on',\n",
       "  'earth_day',\n",
       "  '4/22',\n",
       "  'climate_change',\n",
       "  'food',\n",
       "  'security',\n",
       "  'irreversible',\n",
       "  'destiny'],\n",
       " ['new_york',\n",
       "  \"city's\",\n",
       "  'new',\n",
       "  'waterfront',\n",
       "  'plan',\n",
       "  'will',\n",
       "  'take',\n",
       "  'climate_change',\n",
       "  'into',\n",
       "  'consideration'],\n",
       " ['pat',\n",
       "  'mooney',\n",
       "  'on',\n",
       "  'the',\n",
       "  'danger',\n",
       "  'of',\n",
       "  'geoengineering',\n",
       "  'and',\n",
       "  'manipulate',\n",
       "  'the',\n",
       "  'planet',\n",
       "  'to_combat',\n",
       "  'climate_change'],\n",
       " ['seasonal_allergy', 'get_bad', 'from', 'climate_change'],\n",
       " ['just',\n",
       "  'because',\n",
       "  'i',\n",
       "  'believe_in',\n",
       "  'global_warming',\n",
       "  'peep',\n",
       "  'think',\n",
       "  'i',\n",
       "  'should',\n",
       "  'believe_in',\n",
       "  'god',\n",
       "  'instead',\n",
       "  'why'],\n",
       " ['i',\n",
       "  'advise',\n",
       "  'everyone',\n",
       "  'who_think',\n",
       "  'global_warming',\n",
       "  'be',\n",
       "  'dead',\n",
       "  'to',\n",
       "  'buy',\n",
       "  'oceanfront',\n",
       "  'property',\n",
       "  'and',\n",
       "  'live',\n",
       "  'there',\n",
       "  'see',\n",
       "  'ya'],\n",
       " ['global_warming',\n",
       "  'melt_ice',\n",
       "  'cap',\n",
       "  'could_help',\n",
       "  'trigger_more',\n",
       "  'volcanic_eruption'],\n",
       " ['mary',\n",
       "  'ellen',\n",
       "  'harte',\n",
       "  'and',\n",
       "  'john',\n",
       "  'harte',\n",
       "  'address',\n",
       "  'climate_change',\n",
       "  'win',\n",
       "  'the',\n",
       "  'war',\n",
       "  'on',\n",
       "  'sustainability',\n",
       "  'at',\n",
       "  'it',\n",
       "  'heart',\n",
       "  'clim'],\n",
       " ['state_dept',\n",
       "  'declares',\n",
       "  'global_warming',\n",
       "  'unequivocal',\n",
       "  'and_primarily',\n",
       "  'human-induced'],\n",
       " ['increasingly',\n",
       "  'corporation',\n",
       "  'be',\n",
       "  'conclude',\n",
       "  'climate_change',\n",
       "  'be',\n",
       "  'real',\n",
       "  'bet_on',\n",
       "  'climate_change',\n",
       "  'wired.com'],\n",
       " ['right',\n",
       "  'on',\n",
       "  'richard',\n",
       "  \"branson's\",\n",
       "  'earthday',\n",
       "  'message',\n",
       "  '2',\n",
       "  'biz',\n",
       "  'get',\n",
       "  'ur',\n",
       "  'house',\n",
       "  'in',\n",
       "  'order.fight',\n",
       "  'global_warming',\n",
       "  'green_eco'],\n",
       " ['meat-wise',\n",
       "  'cynthia',\n",
       "  'bateman',\n",
       "  'on',\n",
       "  'meat-wise',\n",
       "  'monday',\n",
       "  'how',\n",
       "  'animal',\n",
       "  'agriculture',\n",
       "  'make',\n",
       "  'global_warming',\n",
       "  'bad'],\n",
       " ['state_dept',\n",
       "  'declares',\n",
       "  'global_warming',\n",
       "  'unequivocal',\n",
       "  'and_primarily',\n",
       "  'human-induced'],\n",
       " ['global_warming',\n",
       "  'melt_ice',\n",
       "  'cap',\n",
       "  'could_trigger',\n",
       "  'more',\n",
       "  'volcanic_eruption'],\n",
       " ['hey',\n",
       "  'we',\n",
       "  'come',\n",
       "  'up',\n",
       "  'with',\n",
       "  'all',\n",
       "  'kind',\n",
       "  'of',\n",
       "  'idea',\n",
       "  'for',\n",
       "  'fix',\n",
       "  'global_warming',\n",
       "  'love',\n",
       "  'my',\n",
       "  'environmentalism',\n",
       "  'class',\n",
       "  'sigh'],\n",
       " ['an',\n",
       "  'overview',\n",
       "  'of',\n",
       "  'the',\n",
       "  'green',\n",
       "  'car',\n",
       "  'revolution',\n",
       "  'go_green',\n",
       "  'the',\n",
       "  'increase',\n",
       "  'awareness',\n",
       "  'about',\n",
       "  'the',\n",
       "  'threat',\n",
       "  'of',\n",
       "  'global_warming'],\n",
       " ['2nd',\n",
       "  'eruption',\n",
       "  'of',\n",
       "  'hekla',\n",
       "  'in',\n",
       "  'iceland',\n",
       "  \"let's\",\n",
       "  'call',\n",
       "  '2010',\n",
       "  'the',\n",
       "  'year',\n",
       "  'the',\n",
       "  'earth',\n",
       "  'struck',\n",
       "  'back',\n",
       "  'this',\n",
       "  'be',\n",
       "  'for',\n",
       "  'global_warming',\n",
       "  'and',\n",
       "  'this',\n",
       "  'be',\n",
       "  'for',\n",
       "  'oil',\n",
       "  'spill'],\n",
       " ['climate_change',\n",
       "  'place',\n",
       "  'to',\n",
       "  'see',\n",
       "  'before_they',\n",
       "  'disappear',\n",
       "  'à_the',\n",
       "  'america',\n",
       "  'photo'],\n",
       " ['bishop',\n",
       "  'lane',\n",
       "  'episcopal',\n",
       "  'dio',\n",
       "  'of',\n",
       "  'maine',\n",
       "  'climate_change',\n",
       "  'most_important',\n",
       "  'issue',\n",
       "  'of',\n",
       "  'our',\n",
       "  'time',\n",
       "  'bangor',\n",
       "  'daily',\n",
       "  'nw'],\n",
       " ['in',\n",
       "  'case',\n",
       "  'you',\n",
       "  'be',\n",
       "  'wonder_what',\n",
       "  'impact',\n",
       "  'will',\n",
       "  'the',\n",
       "  'volcano',\n",
       "  'in',\n",
       "  'iceland',\n",
       "  'have',\n",
       "  'on',\n",
       "  'climate_change'],\n",
       " ['cool',\n",
       "  'it',\n",
       "  'global_warming',\n",
       "  'be',\n",
       "  'bad',\n",
       "  'enough',\n",
       "  'without',\n",
       "  'you',\n",
       "  'heating',\n",
       "  'thing',\n",
       "  'up',\n",
       "  'in',\n",
       "  'the',\n",
       "  'interest',\n",
       "  'of',\n",
       "  'honest',\n",
       "  'discussion',\n",
       "  'can',\n",
       "  'we'],\n",
       " ['climate_change',\n",
       "  'migration',\n",
       "  'pattern',\n",
       "  'have',\n",
       "  'change',\n",
       "  'for',\n",
       "  '20',\n",
       "  'billion',\n",
       "  'bird'],\n",
       " ['volcanic_ash',\n",
       "  'cloud',\n",
       "  'global_warming',\n",
       "  'may_trigger',\n",
       "  'more',\n",
       "  'volcano',\n",
       "  'climate_change',\n",
       "  'could',\n",
       "  'spark',\n",
       "  'more',\n",
       "  'hazardous'],\n",
       " ['just',\n",
       "  'briefed',\n",
       "  'on',\n",
       "  'global',\n",
       "  'cool',\n",
       "  'volcano',\n",
       "  'via',\n",
       "  'but',\n",
       "  'i',\n",
       "  'wonder',\n",
       "  'if',\n",
       "  'it',\n",
       "  'get',\n",
       "  'to',\n",
       "  'the',\n",
       "  'stratosphere',\n",
       "  'can',\n",
       "  'it',\n",
       "  'slow',\n",
       "  'improve',\n",
       "  'global_warming'],\n",
       " ['climate', 'change-ing', 'your_allergy'],\n",
       " ['obama',\n",
       "  'say',\n",
       "  'china',\n",
       "  'ca_not',\n",
       "  'wait',\n",
       "  'on',\n",
       "  'climate_change',\n",
       "  'sydney',\n",
       "  'afp',\n",
       "  'april',\n",
       "  '15',\n",
       "  '2010',\n",
       "  'u',\n",
       "  'president_barack',\n",
       "  'obama',\n",
       "  'on',\n",
       "  'thursd'],\n",
       " ['climate_change',\n",
       "  'denier',\n",
       "  'bobby',\n",
       "  'jindal',\n",
       "  'mocked',\n",
       "  'volcano',\n",
       "  'warning',\n",
       "  'read',\n",
       "  'the',\n",
       "  'paper',\n",
       "  'lately',\n",
       "  'start',\n",
       "  'think',\n",
       "  'for',\n",
       "  'yourselves'],\n",
       " ['cara',\n",
       "  'mertes',\n",
       "  'at',\n",
       "  'tedxvolcano',\n",
       "  'we',\n",
       "  'be',\n",
       "  'all',\n",
       "  'strand',\n",
       "  'this',\n",
       "  'weekend',\n",
       "  'and',\n",
       "  'we',\n",
       "  'be',\n",
       "  'get',\n",
       "  'a',\n",
       "  'sneak',\n",
       "  'preview',\n",
       "  'of',\n",
       "  'climate_change',\n",
       "  'we',\n",
       "  'have',\n",
       "  'to',\n",
       "  'adapt'],\n",
       " ['larry_brilliant',\n",
       "  'at',\n",
       "  'tedxvolcano',\n",
       "  'we',\n",
       "  'have',\n",
       "  'to',\n",
       "  'fight',\n",
       "  'for',\n",
       "  'science',\n",
       "  'the',\n",
       "  'single',\n",
       "  'most_important',\n",
       "  'thing',\n",
       "  'we',\n",
       "  'face',\n",
       "  'be',\n",
       "  'climate_change',\n",
       "  'socmedia'],\n",
       " ['larry_brilliant',\n",
       "  'at',\n",
       "  'tedxvolcano',\n",
       "  'we',\n",
       "  'have',\n",
       "  'to',\n",
       "  'fight',\n",
       "  'for',\n",
       "  'science',\n",
       "  'the',\n",
       "  'single',\n",
       "  'most_important',\n",
       "  'thing',\n",
       "  'we',\n",
       "  'face',\n",
       "  'be',\n",
       "  'climate_change',\n",
       "  'socent',\n",
       "  'green'],\n",
       " ['damn',\n",
       "  'man',\n",
       "  'that',\n",
       "  'ash_cloud',\n",
       "  'in',\n",
       "  'europe',\n",
       "  'be',\n",
       "  'crazy',\n",
       "  'they',\n",
       "  'say',\n",
       "  'due_to',\n",
       "  'global_warming',\n",
       "  'with',\n",
       "  'the',\n",
       "  'volcano',\n",
       "  'activate',\n",
       "  'get',\n",
       "  'crazy'],\n",
       " ['larry_brilliant',\n",
       "  'at',\n",
       "  'tedxvolcano',\n",
       "  'climate_change',\n",
       "  'be',\n",
       "  'exacerbate',\n",
       "  'all',\n",
       "  'other',\n",
       "  'crisis',\n",
       "  'of',\n",
       "  'our',\n",
       "  'age',\n",
       "  'but',\n",
       "  'climate',\n",
       "  'science',\n",
       "  'be',\n",
       "  'now',\n",
       "  'under_attack'],\n",
       " ['global_warming',\n",
       "  'cause',\n",
       "  'volcano',\n",
       "  'eruption',\n",
       "  'by',\n",
       "  'jonah',\n",
       "  'goldberg',\n",
       "  'from',\n",
       "  'reuters',\n",
       "  'oslo',\n",
       "  'reuters',\n",
       "  'a',\n",
       "  'thaw',\n",
       "  'of',\n",
       "  \"iceland's\"],\n",
       " ['bring',\n",
       "  'indigenous',\n",
       "  'voice',\n",
       "  'into',\n",
       "  'the',\n",
       "  'conversation',\n",
       "  'about',\n",
       "  'climate_change'],\n",
       " ['climate_change',\n",
       "  'volcanic',\n",
       "  'activity',\n",
       "  'ice_cap',\n",
       "  'thaw',\n",
       "  'may',\n",
       "  'awaken',\n",
       "  'icelandic',\n",
       "  'volcano'],\n",
       " ['à_no',\n",
       "  'rain_in',\n",
       "  'the',\n",
       "  'amazon',\n",
       "  'how',\n",
       "  'south',\n",
       "  'america',\n",
       "  'à_s',\n",
       "  'climate_change',\n",
       "  'affect',\n",
       "  'entire',\n",
       "  'planet',\n",
       "  'à_',\n",
       "  'interview',\n",
       "  'of',\n",
       "  'nikolas',\n",
       "  'kozloff',\n",
       "  'vid'],\n",
       " ['climate_change',\n",
       "  'place',\n",
       "  'to',\n",
       "  'see',\n",
       "  'before_they',\n",
       "  'disappear',\n",
       "  'à_the',\n",
       "  'america',\n",
       "  'photo'],\n",
       " ['hmmm',\n",
       "  'they',\n",
       "  'rather',\n",
       "  'bury',\n",
       "  'the',\n",
       "  'lede',\n",
       "  'here',\n",
       "  'iceland',\n",
       "  'glacier',\n",
       "  'melt',\n",
       "  'from',\n",
       "  'global_warming',\n",
       "  'then',\n",
       "  'volcano',\n",
       "  'go',\n",
       "  'off'],\n",
       " ['not',\n",
       "  'sure',\n",
       "  'if',\n",
       "  'this',\n",
       "  'be',\n",
       "  'consensus',\n",
       "  'but',\n",
       "  'scientist',\n",
       "  'warns',\n",
       "  'climate_change',\n",
       "  'will',\n",
       "  'lead',\n",
       "  'to',\n",
       "  'more',\n",
       "  'volcano',\n",
       "  'crisis',\n",
       "  'due_to',\n",
       "  'melt_ice'],\n",
       " ['wish',\n",
       "  'i',\n",
       "  'be',\n",
       "  'in',\n",
       "  'cochabamba',\n",
       "  'at',\n",
       "  'the',\n",
       "  \"people's_world\",\n",
       "  'conference_on',\n",
       "  'climate_change',\n",
       "  'and',\n",
       "  'the',\n",
       "  'right',\n",
       "  'of',\n",
       "  'mother_earth'],\n",
       " ['i',\n",
       "  'feel',\n",
       "  'that',\n",
       "  'already',\n",
       "  'climate_change',\n",
       "  'make',\n",
       "  'seasonal_allergy',\n",
       "  'bad',\n",
       "  'near-record',\n",
       "  'high',\n",
       "  'this',\n",
       "  'spring'],\n",
       " ['climate_change',\n",
       "  'make',\n",
       "  'seasonal_allergy',\n",
       "  'bad',\n",
       "  'near-record',\n",
       "  'high',\n",
       "  'this',\n",
       "  'spring'],\n",
       " ['like',\n",
       "  'icelandic',\n",
       "  'volcanic_eruption',\n",
       "  'disrupt',\n",
       "  'your',\n",
       "  'air_travel',\n",
       "  'climate_change',\n",
       "  'glacier',\n",
       "  'thaw',\n",
       "  'more',\n",
       "  'of',\n",
       "  'it'],\n",
       " ['cochabamba',\n",
       "  'summit',\n",
       "  'offer',\n",
       "  'new',\n",
       "  'approach_to',\n",
       "  'combat',\n",
       "  'climate_change'],\n",
       " ['climate_change', 'be', 'make', 'you', 'sneeze'],\n",
       " ['environment',\n",
       "  'climate',\n",
       "  'of',\n",
       "  'change',\n",
       "  'from',\n",
       "  'something',\n",
       "  'a',\n",
       "  'simple',\n",
       "  'a',\n",
       "  'remind',\n",
       "  'computer',\n",
       "  'user',\n",
       "  'to',\n",
       "  'power',\n",
       "  'down',\n",
       "  'when',\n",
       "  'not',\n",
       "  'workin'],\n",
       " ['professor',\n",
       "  'perspective',\n",
       "  'reason',\n",
       "  'to',\n",
       "  'be',\n",
       "  'concerned',\n",
       "  'about',\n",
       "  'climate_change',\n",
       "  'spring',\n",
       "  'in',\n",
       "  'connecticut',\n",
       "  'brings',\n",
       "  'renewal'],\n",
       " ['the',\n",
       "  'need',\n",
       "  'to',\n",
       "  'switch',\n",
       "  'to',\n",
       "  'renewable_energy',\n",
       "  'climate',\n",
       "  'scientist',\n",
       "  'have',\n",
       "  'long',\n",
       "  'warn',\n",
       "  'u',\n",
       "  'that',\n",
       "  'global_warming',\n",
       "  'be',\n",
       "  'accelerate'],\n",
       " ['climate_change', 'culprit', 'for', 'off-the-charts', 'pollen', 'count'],\n",
       " ['coalition',\n",
       "  'of',\n",
       "  'the',\n",
       "  'tire',\n",
       "  'of',\n",
       "  'wait_fight',\n",
       "  'climate_change',\n",
       "  'at_ground',\n",
       "  'level'],\n",
       " ['allergy_season',\n",
       "  'to',\n",
       "  'worsen',\n",
       "  'with',\n",
       "  'climate_change',\n",
       "  'report',\n",
       "  'a',\n",
       "  'new',\n",
       "  'report_release',\n",
       "  'on',\n",
       "  'wednesday',\n",
       "  'by',\n",
       "  'the',\n",
       "  'national',\n",
       "  'wildlife'],\n",
       " ['author',\n",
       "  'nikolas',\n",
       "  'kozloff',\n",
       "  'on',\n",
       "  'no',\n",
       "  'rain_in',\n",
       "  'the',\n",
       "  'amazon',\n",
       "  'how',\n",
       "  'south',\n",
       "  \"america's\",\n",
       "  'climate_change',\n",
       "  'affect',\n",
       "  'the',\n",
       "  'entire',\n",
       "  'planet'],\n",
       " ['cute',\n",
       "  'i',\n",
       "  'mention',\n",
       "  'global_warming',\n",
       "  'and',\n",
       "  'a',\n",
       "  'denialist',\n",
       "  'sends',\n",
       "  'me',\n",
       "  'a',\n",
       "  'link',\n",
       "  'to',\n",
       "  'a',\n",
       "  'finnish',\n",
       "  'newspaper',\n",
       "  'article',\n",
       "  'purportedly',\n",
       "  'refute',\n",
       "  'it'],\n",
       " ['be',\n",
       "  'nationalize',\n",
       "  'the',\n",
       "  'energy',\n",
       "  'industry',\n",
       "  'necessary',\n",
       "  'to',\n",
       "  'fight',\n",
       "  'global_warming'],\n",
       " ['iceland_volcano',\n",
       "  'not',\n",
       "  'likely',\n",
       "  'to_slow',\n",
       "  'global_warming',\n",
       "  'a',\n",
       "  'vast',\n",
       "  'cloud',\n",
       "  'from',\n",
       "  'an',\n",
       "  'intensify',\n",
       "  'volcanic_eruption',\n",
       "  'in',\n",
       "  'iceland'],\n",
       " ['reading', 'from', 'allergy_bad', 'than_ever', 'blame', 'global_warming'],\n",
       " ['the',\n",
       "  '6bn',\n",
       "  'redd',\n",
       "  'forest',\n",
       "  'conservation',\n",
       "  'partnership',\n",
       "  'to_curb',\n",
       "  'climate_change',\n",
       "  'leaf',\n",
       "  'on',\n",
       "  \"env'l\",\n",
       "  'group',\n",
       "  'indigenous',\n",
       "  'population'],\n",
       " ['2/3',\n",
       "  'rds',\n",
       "  'of',\n",
       "  'tbaggers',\n",
       "  'do_not',\n",
       "  'think',\n",
       "  'climate_change',\n",
       "  'be',\n",
       "  'a',\n",
       "  'serious',\n",
       "  'problem',\n",
       "  'a',\n",
       "  'i',\n",
       "  'say',\n",
       "  'they',\n",
       "  'be',\n",
       "  'ignorant'],\n",
       " ['miss_heat', 'may_affect', 'future', 'climate_change'],\n",
       " ['climate_change', 'building', 'a', 'green', 'economy'],\n",
       " ['climate_change',\n",
       "  'threaten',\n",
       "  'glacier_national',\n",
       "  'park',\n",
       "  'and',\n",
       "  \"montana's\",\n",
       "  'economy',\n",
       "  'examiner.com'],\n",
       " ['new_york', 'climate_change', 'could_raise', 'cost_of', 'allergy'],\n",
       " ['think',\n",
       "  'your_allergy',\n",
       "  'be',\n",
       "  'bad',\n",
       "  'now',\n",
       "  'wait',\n",
       "  'until',\n",
       "  'climate_change',\n",
       "  'kick',\n",
       "  'in',\n",
       "  'michig'],\n",
       " ['exclusive',\n",
       "  'climate_change',\n",
       "  'could_raise',\n",
       "  'cost_of',\n",
       "  'u',\n",
       "  'allergy',\n",
       "  'reuters'],\n",
       " ['kenya',\n",
       "  'extreme_weather',\n",
       "  'test',\n",
       "  'pastoralist',\n",
       "  'perception',\n",
       "  'the',\n",
       "  'effect_of',\n",
       "  'climate_change',\n",
       "  'such_a',\n",
       "  'drought'],\n",
       " ['climate_change',\n",
       "  'be',\n",
       "  'not',\n",
       "  'just',\n",
       "  'about',\n",
       "  'the',\n",
       "  'climate',\n",
       "  'it',\n",
       "  'be',\n",
       "  'about',\n",
       "  'our',\n",
       "  'life',\n",
       "  'treehugger'],\n",
       " ['all',\n",
       "  '30_major',\n",
       "  'league_baseball',\n",
       "  'team_throw',\n",
       "  'curve',\n",
       "  'to',\n",
       "  'climate_change',\n",
       "  'denier'],\n",
       " ['climate_change',\n",
       "  '100',\n",
       "  'endanger',\n",
       "  'place',\n",
       "  'and',\n",
       "  'how',\n",
       "  'to',\n",
       "  'save_them',\n",
       "  'newsweek'],\n",
       " ['tip',\n",
       "  'of',\n",
       "  'the',\n",
       "  'day',\n",
       "  'plant',\n",
       "  'one',\n",
       "  'tree',\n",
       "  'on',\n",
       "  'your',\n",
       "  'birthday',\n",
       "  'plant',\n",
       "  'absorb',\n",
       "  'co2',\n",
       "  'which',\n",
       "  'help',\n",
       "  'reduce',\n",
       "  'global_warming'],\n",
       " ['united_state',\n",
       "  'must',\n",
       "  'lead',\n",
       "  'on',\n",
       "  'climate_change',\n",
       "  'à_',\n",
       "  'kerry',\n",
       "  'climate',\n",
       "  'and',\n",
       "  'energy',\n",
       "  'bill',\n",
       "  'have',\n",
       "  'multiple',\n",
       "  'benefit',\n",
       "  'green'],\n",
       " ['green',\n",
       "  'net',\n",
       "  'how',\n",
       "  'the',\n",
       "  'internet',\n",
       "  'compute',\n",
       "  'can_fight',\n",
       "  'climate_change'],\n",
       " ['3,000_business',\n",
       "  'create_new',\n",
       "  'ad_for',\n",
       "  'climate_change',\n",
       "  'action',\n",
       "  'cleantechnica'],\n",
       " ['green',\n",
       "  'net',\n",
       "  'how',\n",
       "  'the',\n",
       "  'internet',\n",
       "  'compute',\n",
       "  'can_fight',\n",
       "  'climate_change',\n",
       "  'the',\n",
       "  'internet',\n",
       "  'software',\n",
       "  'compute'],\n",
       " ['leak',\n",
       "  'u_document',\n",
       "  'call',\n",
       "  'for',\n",
       "  'à_global',\n",
       "  'regime',\n",
       "  'à_',\n",
       "  'to',\n",
       "  'tackle',\n",
       "  'climate_change'],\n",
       " ['reinvent', 'city', 'to', 'stop', 'climate_change'],\n",
       " ['climate_change',\n",
       "  'continue',\n",
       "  'to',\n",
       "  'melt_glacier',\n",
       "  'national',\n",
       "  \"park's\",\n",
       "  'icon',\n",
       "  'national'],\n",
       " ['abu',\n",
       "  'dhabi',\n",
       "  'face',\n",
       "  'climate_change',\n",
       "  'flood',\n",
       "  'threat',\n",
       "  'expert',\n",
       "  'culture',\n",
       "  'society',\n",
       "  'arabia'],\n",
       " ['china',\n",
       "  'active',\n",
       "  'serious',\n",
       "  'in',\n",
       "  'tackle',\n",
       "  'climate_change',\n",
       "  'say',\n",
       "  'vice_president',\n",
       "  'humani'],\n",
       " ['you',\n",
       "  'and',\n",
       "  'u',\n",
       "  'and',\n",
       "  'me',\n",
       "  'china',\n",
       "  'active',\n",
       "  'serious',\n",
       "  'in',\n",
       "  'tackle',\n",
       "  'climate_change',\n",
       "  'say',\n",
       "  'vic'],\n",
       " ['study', 'se', 'asia', 'will', 'be', 'hit', 'hard', 'by', 'climate_change'],\n",
       " ['take_action', 'help_protect', 'wildlife_habitat', 'from', 'climate_change'],\n",
       " ['obama', 'china', 'must', 'act', 'soon', 'on', 'climate_change'],\n",
       " ['if',\n",
       "  'capitalism',\n",
       "  'doesn',\n",
       "  'à_t',\n",
       "  'end',\n",
       "  'climate_change',\n",
       "  'climate_change',\n",
       "  'will',\n",
       "  'end',\n",
       "  'capitalism',\n",
       "  'degrowth'],\n",
       " ['demand',\n",
       "  'congress',\n",
       "  'take_action',\n",
       "  'on',\n",
       "  'climate_change',\n",
       "  'pls',\n",
       "  'sign',\n",
       "  'the',\n",
       "  'petition'],\n",
       " ['carbon', 'age', 'be', 'kill', 'u', 'climate_change', 'legislation', 'now'],\n",
       " ['obama',\n",
       "  'say',\n",
       "  'in',\n",
       "  'tv',\n",
       "  'interview',\n",
       "  'that',\n",
       "  'we',\n",
       "  'ca_not',\n",
       "  'allow',\n",
       "  'china',\n",
       "  'to',\n",
       "  'wait',\n",
       "  'on',\n",
       "  'tackle',\n",
       "  'climate_change'],\n",
       " ['government', 'claim', 'global_warming', 'may_cause', 'cancer'],\n",
       " ['protect_wildlife', 'habitat_from', 'climate_change'],\n",
       " ['plan_california', 'brace_for', 'climate_change'],\n",
       " ['nine',\n",
       "  'scenario',\n",
       "  'for',\n",
       "  'imminent',\n",
       "  'apocalypse',\n",
       "  'à_only',\n",
       "  'one',\n",
       "  'be',\n",
       "  'global_warming'],\n",
       " ['dc',\n",
       "  'ft_work',\n",
       "  'for',\n",
       "  'greenpeace',\n",
       "  'to',\n",
       "  'stop',\n",
       "  'global_warming',\n",
       "  '12_13',\n",
       "  'hr',\n",
       "  'get_involve',\n",
       "  'call',\n",
       "  'now',\n",
       "  '202-595-3368',\n",
       "  'greenpeac'],\n",
       " ['sec',\n",
       "  'warns',\n",
       "  'publically',\n",
       "  'held',\n",
       "  'company',\n",
       "  'to',\n",
       "  'advise',\n",
       "  'investor',\n",
       "  'of',\n",
       "  'risk',\n",
       "  'of',\n",
       "  'climate_change'],\n",
       " ['save',\n",
       "  'the',\n",
       "  'whale',\n",
       "  'and',\n",
       "  'they_will',\n",
       "  'save',\n",
       "  'u',\n",
       "  'from',\n",
       "  'global_warming'],\n",
       " ['al_gore',\n",
       "  'ira',\n",
       "  'if',\n",
       "  'a',\n",
       "  'snake',\n",
       "  'be',\n",
       "  'come',\n",
       "  'up',\n",
       "  'the',\n",
       "  'aisle',\n",
       "  'there',\n",
       "  'would',\n",
       "  'not',\n",
       "  'be',\n",
       "  'a',\n",
       "  'long',\n",
       "  'debate',\n",
       "  'about',\n",
       "  'what',\n",
       "  'to',\n",
       "  'do',\n",
       "  'and',\n",
       "  'we',\n",
       "  'dawdle',\n",
       "  'about',\n",
       "  'climate_change'],\n",
       " ['we',\n",
       "  'should',\n",
       "  'be',\n",
       "  'leader',\n",
       "  'on',\n",
       "  'climate_change',\n",
       "  'but',\n",
       "  'it',\n",
       "  'be',\n",
       "  'always',\n",
       "  'put',\n",
       "  'on',\n",
       "  'the',\n",
       "  'back',\n",
       "  'burner'],\n",
       " ['grape',\n",
       "  'of',\n",
       "  'wrath',\n",
       "  'how_much',\n",
       "  'trouble',\n",
       "  'do',\n",
       "  'climate_change',\n",
       "  'mean',\n",
       "  'for',\n",
       "  'agriculture'],\n",
       " ['get',\n",
       "  'allergy',\n",
       "  'by',\n",
       "  'jonah',\n",
       "  'goldberg',\n",
       "  'blame',\n",
       "  'global_warming',\n",
       "  'from',\n",
       "  'time_magazine',\n",
       "  'allergy_bad',\n",
       "  'than_ever',\n",
       "  'blame'],\n",
       " ['climate_change', 'and', 'why', 'your_allergy', 'be', 'get_bad'],\n",
       " ['watch',\n",
       "  'pb',\n",
       "  'dim',\n",
       "  'the',\n",
       "  'sun',\n",
       "  'for',\n",
       "  'more',\n",
       "  'on',\n",
       "  'this',\n",
       "  'npr',\n",
       "  'could',\n",
       "  'cleaner_air',\n",
       "  'actually_intensify',\n",
       "  'global_warming',\n",
       "  'more',\n",
       "  'at'],\n",
       " ['people',\n",
       "  'in',\n",
       "  'poor',\n",
       "  'country',\n",
       "  'be',\n",
       "  '20',\n",
       "  'time',\n",
       "  'more',\n",
       "  'likely',\n",
       "  'to',\n",
       "  'be',\n",
       "  'affected',\n",
       "  'by',\n",
       "  'disaster',\n",
       "  'cause_by',\n",
       "  'climate_change',\n",
       "  'than',\n",
       "  'those',\n",
       "  'in',\n",
       "  'the',\n",
       "  'developed',\n",
       "  'world'],\n",
       " ['italy',\n",
       "  'phd',\n",
       "  'programme',\n",
       "  'in',\n",
       "  'science',\n",
       "  'and',\n",
       "  'management',\n",
       "  'of',\n",
       "  'climate_change',\n",
       "  'phd',\n",
       "  'programme',\n",
       "  'in',\n",
       "  'science',\n",
       "  'and',\n",
       "  'management',\n",
       "  'of'],\n",
       " ['oxfam', 'climate_change', 'devastate', 'rural', 'ethiopian', 'community'],\n",
       " ['alexi',\n",
       "  'believe_in',\n",
       "  'put',\n",
       "  'a',\n",
       "  'price',\n",
       "  'on',\n",
       "  'global_warming',\n",
       "  'pollutant',\n",
       "  'to',\n",
       "  'spur',\n",
       "  'development',\n",
       "  'of',\n",
       "  'alternative',\n",
       "  'technology',\n",
       "  'p2',\n",
       "  'ilsen'],\n",
       " ['go',\n",
       "  'for',\n",
       "  'the',\n",
       "  'green',\n",
       "  'olympic',\n",
       "  'athlete',\n",
       "  'push',\n",
       "  'for',\n",
       "  'climate_change',\n",
       "  'action'],\n",
       " ['dc',\n",
       "  'ft_work',\n",
       "  'for',\n",
       "  'greenpeace',\n",
       "  'to',\n",
       "  'stop',\n",
       "  'global_warming',\n",
       "  '12_13',\n",
       "  'hr',\n",
       "  'get_involve',\n",
       "  'call',\n",
       "  'now',\n",
       "  '202-595-3368',\n",
       "  'greenpeace'],\n",
       " ['health',\n",
       "  'effect',\n",
       "  'be',\n",
       "  'a',\n",
       "  'big',\n",
       "  'deal',\n",
       "  'impact',\n",
       "  'of',\n",
       "  'climate_change',\n",
       "  'extend',\n",
       "  'to',\n",
       "  'human_health'],\n",
       " ['climate_change',\n",
       "  'cause',\n",
       "  'change',\n",
       "  'in',\n",
       "  'ocean_chemistry',\n",
       "  'at',\n",
       "  'unprecedented',\n",
       "  'rate'],\n",
       " ['global_warming', 'can', 'be', 'good', 'for'],\n",
       " ['allergy_bad', 'than_ever', 'blame', 'global_warming', 'time.com'],\n",
       " ['bat_bird', 'lizard_can', 'fight', 'climate_change', 'wire'],\n",
       " ['just',\n",
       "  'sign',\n",
       "  'an',\n",
       "  'earthday',\n",
       "  'petition',\n",
       "  'to',\n",
       "  'take_action',\n",
       "  'on',\n",
       "  'climate_change',\n",
       "  'via'],\n",
       " ['treat', 'climate_change', 'a', 'a', 'curable_disease'],\n",
       " ['global_warming',\n",
       "  'believe',\n",
       "  'it',\n",
       "  'vallejo',\n",
       "  'times-herald',\n",
       "  'your',\n",
       "  'editorial',\n",
       "  'on',\n",
       "  'global_warming',\n",
       "  'keep',\n",
       "  'the',\n",
       "  'debate',\n",
       "  'honest'],\n",
       " ['see',\n",
       "  'how',\n",
       "  'ccx',\n",
       "  'member',\n",
       "  'motorola',\n",
       "  'be',\n",
       "  'work',\n",
       "  'to',\n",
       "  'be',\n",
       "  'part',\n",
       "  'of',\n",
       "  'the',\n",
       "  'solution',\n",
       "  'in',\n",
       "  'address',\n",
       "  'the',\n",
       "  'climate_change',\n",
       "  'challenge'],\n",
       " ['bolivian_president', 'blame_capitalism', 'for', 'global_warming'],\n",
       " ['interest',\n",
       "  'point',\n",
       "  're',\n",
       "  'why',\n",
       "  'macro-probs',\n",
       "  'like',\n",
       "  'global_warming',\n",
       "  'be',\n",
       "  'never',\n",
       "  'solve',\n",
       "  'politician',\n",
       "  'need',\n",
       "  'only',\n",
       "  'solve',\n",
       "  'immediate',\n",
       "  'probs',\n",
       "  'for',\n",
       "  're-election'],\n",
       " ['yet',\n",
       "  'another',\n",
       "  'gift',\n",
       "  'from',\n",
       "  'global_warming',\n",
       "  'increase',\n",
       "  'allergy',\n",
       "  'attack'],\n",
       " ['global',\n",
       "  'climate_change',\n",
       "  'effect',\n",
       "  'on',\n",
       "  'the',\n",
       "  'mid-continent',\n",
       "  'download',\n",
       "  'to',\n",
       "  'view',\n",
       "  'animation'],\n",
       " ['be',\n",
       "  'you',\n",
       "  'ready',\n",
       "  'for',\n",
       "  'climate_change',\n",
       "  'if',\n",
       "  'so',\n",
       "  'let',\n",
       "  'your',\n",
       "  'lawmaker',\n",
       "  'know',\n",
       "  'how',\n",
       "  'tell',\n",
       "  'them',\n",
       "  'sign',\n",
       "  'petition',\n",
       "  'drop',\n",
       "  'a',\n",
       "  'hint',\n",
       "  ':)'],\n",
       " ['umc',\n",
       "  'expands',\n",
       "  'climate_change',\n",
       "  'policy',\n",
       "  'and',\n",
       "  'carbon',\n",
       "  'emission',\n",
       "  'reduction',\n",
       "  'goal'],\n",
       " ['allergy_bad',\n",
       "  'than_ever',\n",
       "  'blame',\n",
       "  'global_warming',\n",
       "  'thanks',\n",
       "  'to',\n",
       "  'an',\n",
       "  'unusually',\n",
       "  'cold',\n",
       "  'and',\n",
       "  'snowy',\n",
       "  'winter',\n",
       "  'follow',\n",
       "  'by',\n",
       "  'an',\n",
       "  'earl'],\n",
       " ['ridiculous',\n",
       "  'give',\n",
       "  'a',\n",
       "  'climate_change',\n",
       "  'denier',\n",
       "  'a',\n",
       "  'nature',\n",
       "  'show',\n",
       "  'keep',\n",
       "  'sarah_palin',\n",
       "  'off',\n",
       "  'discovery'],\n",
       " ['report',\n",
       "  'allergy_season',\n",
       "  'to',\n",
       "  'get_bad',\n",
       "  'with',\n",
       "  'climate_change',\n",
       "  'read',\n",
       "  'from',\n",
       "  'this',\n",
       "  'really',\n",
       "  'suck',\n",
       "  'for',\n",
       "  'me'],\n",
       " ['coda',\n",
       "  'automotive',\n",
       "  'laud',\n",
       "  'for',\n",
       "  'innovation',\n",
       "  'and',\n",
       "  'technology',\n",
       "  'effort',\n",
       "  'to_combat',\n",
       "  'climate_change',\n",
       "  'and',\n",
       "  'air_pollution'],\n",
       " ['report',\n",
       "  'claim',\n",
       "  'climate_change',\n",
       "  'be',\n",
       "  'to',\n",
       "  'blame',\n",
       "  'for',\n",
       "  'increase',\n",
       "  'of',\n",
       "  'allergy'],\n",
       " ['tulip',\n",
       "  'in',\n",
       "  'mid-april',\n",
       "  'in',\n",
       "  'chicago',\n",
       "  'love',\n",
       "  'the',\n",
       "  'global_warming'],\n",
       " ['global_warming',\n",
       "  'will',\n",
       "  'make',\n",
       "  'allergy_bad',\n",
       "  'for',\n",
       "  '25',\n",
       "  'million',\n",
       "  'american',\n",
       "  'hit',\n",
       "  'those',\n",
       "  'with',\n",
       "  'asthma',\n",
       "  'hardest',\n",
       "  'wwf',\n",
       "  'climatewire',\n",
       "  'globalwarming'],\n",
       " ['85',\n",
       "  'degree',\n",
       "  'in',\n",
       "  'april',\n",
       "  'eh',\n",
       "  'hellooo',\n",
       "  'global_warming',\n",
       "  'nice',\n",
       "  'to',\n",
       "  'meet',\n",
       "  'u'],\n",
       " ['rejoice',\n",
       "  'ny',\n",
       "  'time',\n",
       "  'mention',\n",
       "  'crop',\n",
       "  'wild',\n",
       "  'relative',\n",
       "  'in',\n",
       "  'article',\n",
       "  'about',\n",
       "  'adapt',\n",
       "  'agriculture',\n",
       "  'to',\n",
       "  'climate_change'],\n",
       " ['u_document',\n",
       "  'call',\n",
       "  'for',\n",
       "  'à_global',\n",
       "  'regime',\n",
       "  'à_',\n",
       "  'to',\n",
       "  'tackle',\n",
       "  'climate_change'],\n",
       " ['two_more',\n",
       "  'glacier',\n",
       "  'be',\n",
       "  'go',\n",
       "  'from',\n",
       "  'namesake',\n",
       "  'nat',\n",
       "  'park',\n",
       "  'due_to',\n",
       "  'global_warming',\n",
       "  'usgs',\n",
       "  'report'],\n",
       " ['feel',\n",
       "  'the',\n",
       "  'heat',\n",
       "  'down',\n",
       "  'under',\n",
       "  'when',\n",
       "  'it',\n",
       "  'come',\n",
       "  'to',\n",
       "  'climate_change',\n",
       "  'erwin',\n",
       "  'jackson',\n",
       "  'the',\n",
       "  'climate',\n",
       "  'institute'],\n",
       " ['uk',\n",
       "  'lead',\n",
       "  'the',\n",
       "  'way',\n",
       "  'schumacher',\n",
       "  'college',\n",
       "  'mobilise',\n",
       "  'democracy',\n",
       "  'to',\n",
       "  'tackle',\n",
       "  'climate_change'],\n",
       " ['exclusive', 'climate_change', 'could_raise', 'cost_of', 'u', 'allergy'],\n",
       " ['harvard',\n",
       "  'and',\n",
       "  'mit',\n",
       "  'receive',\n",
       "  '2',\n",
       "  'million',\n",
       "  'to',\n",
       "  'study',\n",
       "  'health',\n",
       "  'and',\n",
       "  'environmental',\n",
       "  'impact',\n",
       "  'of',\n",
       "  'climate_change'],\n",
       " ['sen',\n",
       "  'kerry',\n",
       "  'write',\n",
       "  'in',\n",
       "  'the',\n",
       "  'hill',\n",
       "  'today',\n",
       "  'u',\n",
       "  'must',\n",
       "  'lead',\n",
       "  'on',\n",
       "  'climate_change'],\n",
       " ['fight', 'climate_change', 'from', 'all_front'],\n",
       " ['the',\n",
       "  'clothing',\n",
       "  'industry',\n",
       "  'start',\n",
       "  'global_warming',\n",
       "  'in',\n",
       "  'the',\n",
       "  'first',\n",
       "  'place',\n",
       "  'yvon',\n",
       "  'chouinard',\n",
       "  'patagonia',\n",
       "  'fortunegreen'],\n",
       " ['filmmaker_travel',\n",
       "  'the',\n",
       "  'globe',\n",
       "  'to',\n",
       "  'find',\n",
       "  'people',\n",
       "  'fight',\n",
       "  'climate_change'],\n",
       " ['filmmaker_travel',\n",
       "  'the',\n",
       "  'globe',\n",
       "  'to',\n",
       "  'find',\n",
       "  'people',\n",
       "  'fight',\n",
       "  'climate_change',\n",
       "  'filmmaker_travel',\n",
       "  'the',\n",
       "  'globe',\n",
       "  'to',\n",
       "  'find',\n",
       "  'people'],\n",
       " ['effort',\n",
       "  'to',\n",
       "  'remake',\n",
       "  \"america's\",\n",
       "  'energy',\n",
       "  'future',\n",
       "  'and',\n",
       "  'fight',\n",
       "  'global_warming',\n",
       "  'could',\n",
       "  'be',\n",
       "  'harm',\n",
       "  'or',\n",
       "  'spur',\n",
       "  'by',\n",
       "  'gulf',\n",
       "  'oilspill'],\n",
       " ['how',\n",
       "  'would',\n",
       "  'catastrophic',\n",
       "  'climate_change',\n",
       "  'change',\n",
       "  'the',\n",
       "  'average',\n",
       "  'person',\n",
       "  'life',\n",
       "  'think',\n",
       "  '100',\n",
       "  'unemployment',\n",
       "  'every',\n",
       "  'where',\n",
       "  'on',\n",
       "  'the',\n",
       "  'planet',\n",
       "  'for',\n",
       "  'several',\n",
       "  'decade'],\n",
       " ['arctic_ice',\n",
       "  'loss',\n",
       "  'accelerate',\n",
       "  'global_warming',\n",
       "  'research',\n",
       "  'topnews',\n",
       "  'new',\n",
       "  'zealand',\n",
       "  'global_warming',\n",
       "  'may',\n",
       "  'be',\n",
       "  'get_bad',\n",
       "  'tha'],\n",
       " ['california', 'take', 'the', 'lead', 'on', 'climate_change'],\n",
       " ['plant_effective',\n",
       "  'way',\n",
       "  'of',\n",
       "  'tackle',\n",
       "  'global_warming',\n",
       "  'washington',\n",
       "  'apr',\n",
       "  '30',\n",
       "  'ani_):',\n",
       "  'plant',\n",
       "  'leaf',\n",
       "  'account_for',\n",
       "  'less_than',\n",
       "  'one'],\n",
       " ['namibia', 'govt', 'to', 'get', 'active', 'on', 'climate_change'],\n",
       " ['plant_effective', 'way', 'of', 'tackle', 'global_warming'],\n",
       " ['just',\n",
       "  'read',\n",
       "  'u',\n",
       "  'general',\n",
       "  'say',\n",
       "  'climate_change',\n",
       "  'threatens',\n",
       "  \"america's\",\n",
       "  'security'],\n",
       " ['glacial',\n",
       "  'melt',\n",
       "  'from',\n",
       "  'global_warming',\n",
       "  'could',\n",
       "  'unplug',\n",
       "  'volcano',\n",
       "  'earthweek',\n",
       "  'a',\n",
       "  'diary',\n",
       "  'of',\n",
       "  'the',\n",
       "  'planet',\n",
       "  'eruption',\n",
       "  'of',\n",
       "  'glacial',\n",
       "  'vol'],\n",
       " ['33',\n",
       "  'u',\n",
       "  'military',\n",
       "  'general',\n",
       "  'admiral',\n",
       "  'climate_change',\n",
       "  'be',\n",
       "  'threaten'],\n",
       " ['off',\n",
       "  'shore',\n",
       "  'drilling',\n",
       "  'threatens',\n",
       "  'wildlife',\n",
       "  'and',\n",
       "  'contributes',\n",
       "  'to',\n",
       "  'climate_change',\n",
       "  'urge',\n",
       "  'obama',\n",
       "  'not',\n",
       "  'to',\n",
       "  'expand',\n",
       "  'drilling'],\n",
       " ['allgov',\n",
       "  'news',\n",
       "  'global_warming',\n",
       "  'be',\n",
       "  'not',\n",
       "  'all',\n",
       "  'bad',\n",
       "  'à_if',\n",
       "  'you',\n",
       "  'be',\n",
       "  'an',\n",
       "  'in',\n",
       "  'the',\n",
       "  'frozen',\n",
       "  'reach',\n",
       "  'of',\n",
       "  'canada',\n",
       "  'warmer',\n",
       "  'temperature'],\n",
       " ['government_report',\n",
       "  'say',\n",
       "  'global_warming',\n",
       "  'may_cause',\n",
       "  'cancer_mental',\n",
       "  'illness',\n",
       "  'a',\n",
       "  'new',\n",
       "  'government_report',\n",
       "  'say',\n",
       "  'global',\n",
       "  'warmin'],\n",
       " ['global_warming',\n",
       "  'pick',\n",
       "  'up',\n",
       "  'steam',\n",
       "  'obama',\n",
       "  'top',\n",
       "  'science',\n",
       "  'adviser',\n",
       "  'say',\n",
       "  'john',\n",
       "  'holdren',\n",
       "  \"obama's\",\n",
       "  'top',\n",
       "  'science',\n",
       "  'adviser',\n",
       "  'dis'],\n",
       " ['lyme',\n",
       "  'disease',\n",
       "  'already',\n",
       "  'cost',\n",
       "  '2.5',\n",
       "  'billion',\n",
       "  'a',\n",
       "  'year',\n",
       "  'and',\n",
       "  'climate_change',\n",
       "  'could',\n",
       "  'make',\n",
       "  'it',\n",
       "  'even',\n",
       "  'pricier'],\n",
       " ['whale',\n",
       "  'excrement',\n",
       "  'to',\n",
       "  'check',\n",
       "  'global_warming',\n",
       "  'topnews',\n",
       "  'united_state',\n",
       "  'new',\n",
       "  'researcher',\n",
       "  'carry',\n",
       "  'out',\n",
       "  'by',\n",
       "  'the',\n",
       "  'australian',\n",
       "  'antarc'],\n",
       " ['government_report',\n",
       "  'say',\n",
       "  'global_warming',\n",
       "  'to',\n",
       "  'cause_cancer',\n",
       "  'mental_illness',\n",
       "  'cnsnews.com',\n",
       "  'by',\n",
       "  'matt',\n",
       "  'cover',\n",
       "  'staff',\n",
       "  'writer',\n",
       "  'cn'],\n",
       " ['report',\n",
       "  'save',\n",
       "  'the',\n",
       "  'whale',\n",
       "  'and',\n",
       "  'they_will',\n",
       "  'save',\n",
       "  'u',\n",
       "  'from',\n",
       "  'global_warming',\n",
       "  'need',\n",
       "  'more_proof',\n",
       "  'that',\n",
       "  'global_warming',\n",
       "  'be',\n",
       "  'the',\n",
       "  'proble'],\n",
       " ['wine_grape',\n",
       "  'have_become',\n",
       "  'our_best',\n",
       "  'early-warning_system',\n",
       "  'for',\n",
       "  'the',\n",
       "  'effect_of',\n",
       "  'global_warming'],\n",
       " ['wine_grape',\n",
       "  'have_become',\n",
       "  'our_best',\n",
       "  'early-warning_system',\n",
       "  'for',\n",
       "  'the',\n",
       "  'effect_of',\n",
       "  'global_warming'],\n",
       " ['epa',\n",
       "  'climate_change',\n",
       "  'indicator_report',\n",
       "  'show',\n",
       "  'the',\n",
       "  'evidence',\n",
       "  'of',\n",
       "  'global_warming',\n",
       "  'all',\n",
       "  'around',\n",
       "  'u'],\n",
       " ['epa',\n",
       "  'climate_change',\n",
       "  'indicator_report',\n",
       "  'show',\n",
       "  'the',\n",
       "  'evidence',\n",
       "  'of',\n",
       "  'global_warming',\n",
       "  'all',\n",
       "  'natural',\n",
       "  'resource',\n",
       "  'defense',\n",
       "  'counc'],\n",
       " ['syed',\n",
       "  'husin',\n",
       "  'want',\n",
       "  'to',\n",
       "  'know',\n",
       "  'the',\n",
       "  'effect_of',\n",
       "  'global_warming',\n",
       "  'to',\n",
       "  'malaysia'],\n",
       " ['cleaner_air', 'could_speed', 'global_warming'],\n",
       " ['whale_poo',\n",
       "  'fight',\n",
       "  'global_warming',\n",
       "  'by',\n",
       "  'rob',\n",
       "  'mayeda',\n",
       "  'and',\n",
       "  'lori',\n",
       "  'preuitt',\n",
       "  'star',\n",
       "  'trek',\n",
       "  'iv',\n",
       "  'the',\n",
       "  'voyage',\n",
       "  'home',\n",
       "  'have',\n",
       "  'many',\n",
       "  'convince'],\n",
       " ['new',\n",
       "  'fact',\n",
       "  'support',\n",
       "  'global_warming',\n",
       "  'case',\n",
       "  'recent',\n",
       "  'letter-writer',\n",
       "  'charles',\n",
       "  'kesner',\n",
       "  'be',\n",
       "  'either',\n",
       "  'out-of-touch',\n",
       "  'with',\n",
       "  'reliable',\n",
       "  'ne'],\n",
       " ['study', 'climate_change', 'threatens', 'your', 'health', 'too'],\n",
       " ['slideshow', 'of', 'alaska_before', 'the', 'effect_of', 'global_warming'],\n",
       " ['in',\n",
       "  'vino',\n",
       "  'veritas',\n",
       "  'the',\n",
       "  'delicate',\n",
       "  'wine_grape',\n",
       "  'have_become',\n",
       "  'our_best',\n",
       "  'early-warning_system',\n",
       "  'for',\n",
       "  'the',\n",
       "  'effect_of',\n",
       "  'global_warming'],\n",
       " ['conservation',\n",
       "  'international',\n",
       "  '::',\n",
       "  'give',\n",
       "  'a',\n",
       "  'gift',\n",
       "  'that',\n",
       "  'help',\n",
       "  'prevent',\n",
       "  'climate_change',\n",
       "  'provide',\n",
       "  'habitat',\n",
       "  'for',\n",
       "  'endanger_specie'],\n",
       " ['climate_change',\n",
       "  'be',\n",
       "  'real',\n",
       "  'and',\n",
       "  'climate_change',\n",
       "  'have',\n",
       "  'consequence',\n",
       "  'for',\n",
       "  'all',\n",
       "  'of',\n",
       "  'u'],\n",
       " ['global_warming',\n",
       "  'contributes',\n",
       "  'to',\n",
       "  'rapidly',\n",
       "  'increase',\n",
       "  'ocean',\n",
       "  'acidification',\n",
       "  'the',\n",
       "  'u',\n",
       "  'national',\n",
       "  'research',\n",
       "  'council',\n",
       "  'warn',\n",
       "  'last'],\n",
       " ['global_warming',\n",
       "  'threatens',\n",
       "  'ca_mau',\n",
       "  'province',\n",
       "  'ca_mau',\n",
       "  'à_',\n",
       "  'the',\n",
       "  'southernmost',\n",
       "  'province',\n",
       "  'of',\n",
       "  'ca_mau',\n",
       "  'be',\n",
       "  'among',\n",
       "  'locality',\n",
       "  'most'],\n",
       " ['global_warming', 'mean', 'local', 'storm'],\n",
       " ['could',\n",
       "  'cleaner_air',\n",
       "  'actually_intensify',\n",
       "  'global_warming',\n",
       "  'by',\n",
       "  'npr',\n",
       "  'staff',\n",
       "  'a',\n",
       "  'much',\n",
       "  'of',\n",
       "  'the',\n",
       "  'world',\n",
       "  'marked',\n",
       "  'earth_day',\n",
       "  'this',\n",
       "  'past'],\n",
       " ['renewable_energy',\n",
       "  'advance',\n",
       "  'à_',\n",
       "  'ocean_saltiness',\n",
       "  'show',\n",
       "  'global_warming',\n",
       "  'after',\n",
       "  'pull',\n",
       "  'data',\n",
       "  'from',\n",
       "  '1.6',\n",
       "  'million',\n",
       "  'salinity'],\n",
       " ['the',\n",
       "  'key',\n",
       "  'to',\n",
       "  'fix',\n",
       "  'global_warming',\n",
       "  'china',\n",
       "  'magazine',\n",
       "  'it',\n",
       "  'be',\n",
       "  'late',\n",
       "  'november',\n",
       "  '2009',\n",
       "  'and',\n",
       "  'u',\n",
       "  'energy',\n",
       "  'secretary',\n",
       "  'steven',\n",
       "  'chu',\n",
       "  'be'],\n",
       " ['africa',\n",
       "  'monitoring',\n",
       "  'a',\n",
       "  'change',\n",
       "  'climate',\n",
       "  'the',\n",
       "  'gathering',\n",
       "  'environmental',\n",
       "  'crisis',\n",
       "  'present',\n",
       "  'by',\n",
       "  'global_warming'],\n",
       " ['the',\n",
       "  'volcanic_ash',\n",
       "  'be',\n",
       "  'bad',\n",
       "  'for',\n",
       "  'plane',\n",
       "  'but',\n",
       "  'should',\n",
       "  'help',\n",
       "  'reduce',\n",
       "  'global_warming'],\n",
       " ['ocean_current',\n",
       "  'still',\n",
       "  'strong',\n",
       "  'despite',\n",
       "  'global_warming',\n",
       "  'researcher',\n",
       "  'at',\n",
       "  'nasa',\n",
       "  'have',\n",
       "  'discover',\n",
       "  'that',\n",
       "  'the',\n",
       "  'ocean_current'],\n",
       " ['long-distance',\n",
       "  'journey',\n",
       "  'out',\n",
       "  'of',\n",
       "  'fashion',\n",
       "  'global_warming',\n",
       "  'may',\n",
       "  'be',\n",
       "  'cause',\n",
       "  'evolutionary',\n",
       "  'change',\n",
       "  'in',\n",
       "  'bird',\n",
       "  'migration',\n",
       "  'sourc'],\n",
       " ['funniest',\n",
       "  'conservative',\n",
       "  'comment',\n",
       "  'of',\n",
       "  'the',\n",
       "  'day',\n",
       "  'climate_change',\n",
       "  'be',\n",
       "  'due_to',\n",
       "  'increase_heat',\n",
       "  'from',\n",
       "  'the',\n",
       "  \"earth's\",\n",
       "  'core'],\n",
       " ['scientist',\n",
       "  'say',\n",
       "  'global_warming',\n",
       "  'affect',\n",
       "  'marine',\n",
       "  'life',\n",
       "  'in',\n",
       "  'narragansett',\n",
       "  'bay',\n",
       "  'rhode',\n",
       "  'island',\n",
       "  'winter',\n",
       "  'flounder',\n",
       "  'no_longer',\n",
       "  're'],\n",
       " ['redding',\n",
       "  'architect',\n",
       "  'theimer',\n",
       "  'global_warming',\n",
       "  'doubter',\n",
       "  'stupid',\n",
       "  'james',\n",
       "  'theimer',\n",
       "  'know',\n",
       "  'locally',\n",
       "  'for',\n",
       "  'his',\n",
       "  'environmentally'],\n",
       " ['indonesia',\n",
       "  'tree',\n",
       "  'program',\n",
       "  'look',\n",
       "  'to',\n",
       "  'reduce',\n",
       "  'global_warming',\n",
       "  'plant',\n",
       "  'tree',\n",
       "  'be',\n",
       "  'one',\n",
       "  'way',\n",
       "  'to',\n",
       "  'help',\n",
       "  'maintain',\n",
       "  'the',\n",
       "  'natural',\n",
       "  'pres'],\n",
       " ['earth_day', 'report', 'climate_change', 'be', 'endanger', 'our', 'health'],\n",
       " ['global', 'climate_change', 'not', 'global_warming'],\n",
       " ['cubeyond',\n",
       "  'wlliam',\n",
       "  'lau',\n",
       "  'say',\n",
       "  'climate_change',\n",
       "  'be',\n",
       "  'happen',\n",
       "  'and',\n",
       "  'we',\n",
       "  'must',\n",
       "  'deal_with',\n",
       "  'it',\n",
       "  'no',\n",
       "  'matter',\n",
       "  'what',\n",
       "  'be',\n",
       "  'cause',\n",
       "  'it',\n",
       "  'chapmanu'],\n",
       " [\"chew's\",\n",
       "  'focus',\n",
       "  'be',\n",
       "  'on',\n",
       "  'the',\n",
       "  'way',\n",
       "  'global_warming',\n",
       "  'be',\n",
       "  'cause',\n",
       "  'the',\n",
       "  'redistribution',\n",
       "  'of',\n",
       "  'plant',\n",
       "  'and',\n",
       "  'animal',\n",
       "  'specie'],\n",
       " ['military_lead', 'fight_against', 'climate_change', 'pew'],\n",
       " ['royal',\n",
       "  'society',\n",
       "  'stunner',\n",
       "  'hazardous',\n",
       "  'geosphere',\n",
       "  'activity',\n",
       "  'and',\n",
       "  'global_warming',\n",
       "  'link',\n",
       "  'period',\n",
       "  'of',\n",
       "  'exceptional',\n",
       "  'climate',\n",
       "  'chan'],\n",
       " ['fight',\n",
       "  'poverty_and',\n",
       "  'global_warming',\n",
       "  'in',\n",
       "  'africa',\n",
       "  'by',\n",
       "  'marc',\n",
       "  'gunther',\n",
       "  'on',\n",
       "  '04/21',\n",
       "  '2010',\n",
       "  '22:10',\n",
       "  '0',\n",
       "  'comment',\n",
       "  '0',\n",
       "  'view',\n",
       "  'rarely',\n",
       "  'do'],\n",
       " ['military_lead', 'fight_against', 'climate_change', 'pew', 'reuters'],\n",
       " ['spring',\n",
       "  'come',\n",
       "  '10',\n",
       "  'day',\n",
       "  'earlier',\n",
       "  'in',\n",
       "  'u',\n",
       "  'due_to',\n",
       "  'climate_change'],\n",
       " ['nasa', 'launch', 'climate_change', 'supercomputer'],\n",
       " ['excellent',\n",
       "  'take',\n",
       "  'on',\n",
       "  'why',\n",
       "  'even',\n",
       "  'environmental_economics',\n",
       "  'limit',\n",
       "  'our',\n",
       "  'climate_change',\n",
       "  'policy',\n",
       "  'option'],\n",
       " ['the', 'key', 'to', 'fix', 'global_warming', 'china'],\n",
       " ['be',\n",
       "  'here',\n",
       "  'tonight',\n",
       "  'at',\n",
       "  '7:30',\n",
       "  'to',\n",
       "  'discus',\n",
       "  'what',\n",
       "  'climate_change',\n",
       "  'be',\n",
       "  'do',\n",
       "  'to',\n",
       "  'woman',\n",
       "  'child',\n",
       "  'family',\n",
       "  'community'],\n",
       " ['baby',\n",
       "  'boomer',\n",
       "  'must',\n",
       "  'tackle',\n",
       "  'global_warming',\n",
       "  'while',\n",
       "  'they',\n",
       "  'can',\n",
       "  'by',\n",
       "  'anonymous',\n",
       "  'baby',\n",
       "  'boomer',\n",
       "  'have',\n",
       "  'enjoy',\n",
       "  'peace',\n",
       "  'and',\n",
       "  'the',\n",
       "  'large'],\n",
       " ['ocean_saltiness',\n",
       "  'show',\n",
       "  'global_warming',\n",
       "  'be',\n",
       "  'intensify_our',\n",
       "  'water_cycle',\n",
       "  'treehugger'],\n",
       " ['daniel',\n",
       "  'esty',\n",
       "  'climate_change',\n",
       "  'plan',\n",
       "  'bring',\n",
       "  'down',\n",
       "  'greenhouse_gas',\n",
       "  'emission',\n",
       "  'with',\n",
       "  'a',\n",
       "  'cap',\n",
       "  'and',\n",
       "  'trade',\n",
       "  'system',\n",
       "  'of',\n",
       "  'tr'],\n",
       " ['military_lead',\n",
       "  'fight_against',\n",
       "  'climate_change',\n",
       "  'pew',\n",
       "  'washington_reuters',\n",
       "  'the',\n",
       "  'u',\n",
       "  'military',\n",
       "  'the',\n",
       "  \"government's\",\n",
       "  'large'],\n",
       " ['global_warming',\n",
       "  'implicate',\n",
       "  'in',\n",
       "  'shorten',\n",
       "  'bird',\n",
       "  'migration',\n",
       "  'science',\n",
       "  'codex',\n",
       "  'global_warming',\n",
       "  'implicate',\n",
       "  'in',\n",
       "  'shorten',\n",
       "  'bird'],\n",
       " ['nasa',\n",
       "  'à_s',\n",
       "  'gift',\n",
       "  'to',\n",
       "  'earth',\n",
       "  'a',\n",
       "  'climate_change',\n",
       "  'supercomputer'],\n",
       " ['uw_biologist', 'link_early', 'bloom', 'to', 'global_warming'],\n",
       " ['uw_biologist',\n",
       "  'link_early',\n",
       "  'bloom',\n",
       "  'to',\n",
       "  'global_warming',\n",
       "  'a',\n",
       "  'researcher',\n",
       "  'say',\n",
       "  'plant',\n",
       "  'in',\n",
       "  'central',\n",
       "  'wisconsin',\n",
       "  'be',\n",
       "  'flower',\n",
       "  'ear'],\n",
       " ['bolivian_president',\n",
       "  'blame_capitalism',\n",
       "  'for',\n",
       "  'global_warming',\n",
       "  'environment',\n",
       "  'news',\n",
       "  'service',\n",
       "  'cochabamba',\n",
       "  'bolivia',\n",
       "  'april',\n",
       "  '20',\n",
       "  '2'],\n",
       " ['uruguay_tool',\n",
       "  'need',\n",
       "  'for_those',\n",
       "  'most_vulnerable',\n",
       "  'to',\n",
       "  'climate_change',\n",
       "  'global',\n",
       "  'geopolitics',\n",
       "  'net',\n",
       "  'site',\n",
       "  'ip',\n",
       "  'in',\n",
       "  '__s',\n",
       "  'acosta'],\n",
       " ['an',\n",
       "  'explosive',\n",
       "  'idea',\n",
       "  'be',\n",
       "  'volcano',\n",
       "  'the',\n",
       "  'cure',\n",
       "  'for',\n",
       "  'global_warming'],\n",
       " ['see',\n",
       "  'where',\n",
       "  'change',\n",
       "  'be',\n",
       "  'happen',\n",
       "  '8-p',\n",
       "  'art',\n",
       "  'series',\n",
       "  'on',\n",
       "  'city',\n",
       "  'and',\n",
       "  'climate_change',\n",
       "  'for',\n",
       "  'bbc',\n",
       "  'worldnews'],\n",
       " ['carbon_offset',\n",
       "  'how',\n",
       "  'a',\n",
       "  'vatican_forest',\n",
       "  'fail',\n",
       "  'to',\n",
       "  'reduce',\n",
       "  'global_warming',\n",
       "  'christian',\n",
       "  'science',\n",
       "  'monitor',\n",
       "  'from',\n",
       "  'a',\n",
       "  'scheme',\n",
       "  'to'],\n",
       " ['buying',\n",
       "  'carbon_offset',\n",
       "  'may',\n",
       "  'ease',\n",
       "  'eco-guilt',\n",
       "  'but',\n",
       "  'not',\n",
       "  'global_warming'],\n",
       " ['pat',\n",
       "  'mooney',\n",
       "  'on',\n",
       "  'the',\n",
       "  'danger',\n",
       "  'of',\n",
       "  'geoengineering',\n",
       "  'and',\n",
       "  'manipulate',\n",
       "  'the',\n",
       "  'planet',\n",
       "  'to_combat',\n",
       "  'climate_change'],\n",
       " ['icelandic',\n",
       "  \"volcano's\",\n",
       "  'impact',\n",
       "  'on',\n",
       "  'global_warming',\n",
       "  'green',\n",
       "  'transportation',\n",
       "  'bird',\n",
       "  'by',\n",
       "  'alisa',\n",
       "  'opar',\n",
       "  'nasa',\n",
       "  'satellite',\n",
       "  'captur'],\n",
       " ['bird', 'in', 'southern', 'england', 'suffer_from', 'global_warming'],\n",
       " ['video', 'get', 'focus', 'back', 'on', 'climate_change'],\n",
       " ['volcanic_ash', 'cloud', 'global_warming', 'may_trigger', 'more', 'volcano'],\n",
       " ['global_warming',\n",
       "  'blame',\n",
       "  'for',\n",
       "  'european',\n",
       "  'air',\n",
       "  'traffic',\n",
       "  'collapse',\n",
       "  'the',\n",
       "  'financial',\n",
       "  'global_warming',\n",
       "  'which',\n",
       "  'alter',\n",
       "  'european'],\n",
       " ['republican',\n",
       "  'why',\n",
       "  'do',\n",
       "  'you',\n",
       "  'oppose',\n",
       "  'global_warming',\n",
       "  'environmental',\n",
       "  'really',\n",
       "  'it',\n",
       "  'make',\n",
       "  'no',\n",
       "  'sense',\n",
       "  'to',\n",
       "  'oppose_effort',\n",
       "  'to',\n",
       "  'red'],\n",
       " ['safe',\n",
       "  'secure',\n",
       "  'nuclear',\n",
       "  'energy',\n",
       "  'must',\n",
       "  'be',\n",
       "  'part',\n",
       "  'of',\n",
       "  'climate_change',\n",
       "  'solution'],\n",
       " ['global_warming',\n",
       "  'à_s',\n",
       "  'eyjafjoell',\n",
       "  'volcano',\n",
       "  'trigger_more',\n",
       "  'global_warming'],\n",
       " ['state_dept',\n",
       "  'declares',\n",
       "  'global_warming',\n",
       "  'unequivocal',\n",
       "  'and_primarily',\n",
       "  'human-induced'],\n",
       " ['5th',\n",
       "  'u',\n",
       "  'climate',\n",
       "  'action',\n",
       "  'report_release',\n",
       "  'global_warming',\n",
       "  'be',\n",
       "  'unequivocal'],\n",
       " ['global_warming',\n",
       "  'melt_ice',\n",
       "  'cap',\n",
       "  'could_help',\n",
       "  'trigger_more',\n",
       "  'volcanic_eruption'],\n",
       " ['photo',\n",
       "  'we',\n",
       "  'dare',\n",
       "  'someone',\n",
       "  'tell_u',\n",
       "  'that',\n",
       "  'climate_change',\n",
       "  'be',\n",
       "  'not',\n",
       "  'real'],\n",
       " ['5th',\n",
       "  'u',\n",
       "  'climate',\n",
       "  'action',\n",
       "  'report_release',\n",
       "  'global_warming',\n",
       "  'be',\n",
       "  'unequivocal',\n",
       "  'treehugger',\n",
       "  'by',\n",
       "  'brian',\n",
       "  'merchant',\n",
       "  'brooklyn',\n",
       "  'ne'],\n",
       " ['since',\n",
       "  'man',\n",
       "  'ca_not',\n",
       "  'mother',\n",
       "  'nature',\n",
       "  'to',\n",
       "  'end',\n",
       "  'global_warming',\n",
       "  'with',\n",
       "  'volcano',\n",
       "  'earthquake',\n",
       "  'hekla',\n",
       "  'icelandic'],\n",
       " ['blame', 'the', 'volcano', 'trouble', 'on', 'sun', 'and', 'global_warming'],\n",
       " ['some',\n",
       "  'hot',\n",
       "  'health',\n",
       "  'reminder',\n",
       "  'on',\n",
       "  'global_warming',\n",
       "  'the',\n",
       "  'debate',\n",
       "  'be',\n",
       "  'over',\n",
       "  'nearly',\n",
       "  'all',\n",
       "  'scientist',\n",
       "  'and',\n",
       "  'politician',\n",
       "  'agree',\n",
       "  'tha'],\n",
       " ['since',\n",
       "  'man',\n",
       "  'ca_not',\n",
       "  'mother_earth',\n",
       "  'to',\n",
       "  'end',\n",
       "  'global_warming',\n",
       "  'with',\n",
       "  'volcano',\n",
       "  'earthquake',\n",
       "  'ashtag',\n",
       "  'hekla',\n",
       "  'icelandic'],\n",
       " ['joe',\n",
       "  'romm',\n",
       "  '):',\n",
       "  'climate_change',\n",
       "  'be',\n",
       "  'a',\n",
       "  'bfd',\n",
       "  'if',\n",
       "  'i',\n",
       "  'can',\n",
       "  'quote',\n",
       "  'joe',\n",
       "  'biden'],\n",
       " ['reinvent',\n",
       "  'city',\n",
       "  'to',\n",
       "  'stop',\n",
       "  'climate_change',\n",
       "  'green',\n",
       "  'living',\n",
       "  'idea'],\n",
       " ['all',\n",
       "  '30_major',\n",
       "  'league_baseball',\n",
       "  'team_throw',\n",
       "  'curve',\n",
       "  'to',\n",
       "  'climate_change',\n",
       "  'denier',\n",
       "  'cleantechnica'],\n",
       " ['cst',\n",
       "  'a',\n",
       "  'lack_of',\n",
       "  'air_pollution',\n",
       "  'be',\n",
       "  'bad',\n",
       "  'for',\n",
       "  'global_warming',\n",
       "  'à_',\n",
       "  \"pirate's\"],\n",
       " ['an',\n",
       "  'estimate',\n",
       "  '20',\n",
       "  'billion',\n",
       "  'bird',\n",
       "  'change',\n",
       "  'their',\n",
       "  'migrate',\n",
       "  'habit',\n",
       "  'in',\n",
       "  'last',\n",
       "  'few',\n",
       "  'decade',\n",
       "  'due_to',\n",
       "  'global_warming'],\n",
       " ['global_warming',\n",
       "  'melt_ice',\n",
       "  'and',\n",
       "  'this',\n",
       "  'can',\n",
       "  'influence',\n",
       "  'magmatic',\n",
       "  'system',\n",
       "  'he',\n",
       "  'told',\n",
       "  'reuters'],\n",
       " ['volcanic_ash',\n",
       "  'be',\n",
       "  'a',\n",
       "  'good_thing',\n",
       "  'block',\n",
       "  'the',\n",
       "  \"sun's\",\n",
       "  'heat',\n",
       "  'lessens',\n",
       "  'air_travel',\n",
       "  'bye',\n",
       "  'bye',\n",
       "  'global_warming',\n",
       "  'fb'],\n",
       " ['why_cleaner',\n",
       "  'air_could',\n",
       "  'speed',\n",
       "  'global_warming',\n",
       "  'air_pollution',\n",
       "  'news'],\n",
       " ['leak',\n",
       "  'u_document',\n",
       "  'call',\n",
       "  'for',\n",
       "  'global',\n",
       "  'regime',\n",
       "  'to',\n",
       "  'tackle',\n",
       "  'climate_change'],\n",
       " ['why_cleaner',\n",
       "  'air_could',\n",
       "  'speed',\n",
       "  'global_warming',\n",
       "  'aerosol',\n",
       "  'pollution',\n",
       "  'which',\n",
       "  'be',\n",
       "  'now',\n",
       "  'on',\n",
       "  'the',\n",
       "  'downswing',\n",
       "  'have',\n",
       "  'help',\n",
       "  'keep',\n",
       "  'the'],\n",
       " ['why_cleaner', 'air_could', 'speed', 'global_warming'],\n",
       " ['global_warming',\n",
       "  'today',\n",
       "  'à_',\n",
       "  'blog_archive',\n",
       "  'à_',\n",
       "  'how',\n",
       "  'can',\n",
       "  'we',\n",
       "  'tackle',\n",
       "  'global',\n",
       "  'the',\n",
       "  'only',\n",
       "  'way',\n",
       "  'at',\n",
       "  'present',\n",
       "  'be',\n",
       "  'to',\n",
       "  'reduce',\n",
       "  'greenhous'],\n",
       " ['coda',\n",
       "  'automotive',\n",
       "  'laud',\n",
       "  'for',\n",
       "  'effort',\n",
       "  'to_combat',\n",
       "  'climate_change',\n",
       "  'air_pollution'],\n",
       " ['ocean_saltiness',\n",
       "  'get',\n",
       "  'weird',\n",
       "  'à_',\n",
       "  'blame',\n",
       "  'global_warming',\n",
       "  'indyposted',\n",
       "  'blog',\n",
       "  'a',\n",
       "  'study',\n",
       "  'conduct',\n",
       "  'by',\n",
       "  'scientist',\n",
       "  'at',\n",
       "  'austral'],\n",
       " ['usc',\n",
       "  'prof',\n",
       "  'dan',\n",
       "  'mazmanian',\n",
       "  'money',\n",
       "  'need',\n",
       "  'for',\n",
       "  'adaption',\n",
       "  'to',\n",
       "  'climate_change',\n",
       "  'in',\n",
       "  'the',\n",
       "  'state',\n",
       "  'be',\n",
       "  'a',\n",
       "  'press',\n",
       "  'social',\n",
       "  'justice',\n",
       "  'issue',\n",
       "  'usc',\n",
       "  'sppd',\n",
       "  'keston'],\n",
       " ['iceland_volcano', 'unlikely', 'to_slow', 'global_warming', 'scientist'],\n",
       " ['iceland_volcano',\n",
       "  'unlikely',\n",
       "  'to_slow',\n",
       "  'global_warming',\n",
       "  'scientist',\n",
       "  'afp',\n",
       "  'paris',\n",
       "  'à_',\n",
       "  'big',\n",
       "  'volcanic_eruption',\n",
       "  'have',\n",
       "  'have',\n",
       "  'a',\n",
       "  'cool'],\n",
       " ['global_warming',\n",
       "  'may',\n",
       "  'make',\n",
       "  'cricket',\n",
       "  'bat',\n",
       "  'history',\n",
       "  'london',\n",
       "  'cricket',\n",
       "  'be',\n",
       "  'face',\n",
       "  'a',\n",
       "  'bizarre',\n",
       "  'threat',\n",
       "  'follow',\n",
       "  'a',\n",
       "  'european',\n",
       "  'unio'],\n",
       " ['volcano_unlikely',\n",
       "  'to_slow',\n",
       "  'global_warming',\n",
       "  'by',\n",
       "  'richard',\n",
       "  'ingham',\n",
       "  'afpapril',\n",
       "  '16',\n",
       "  '2010',\n",
       "  '4:44',\n",
       "  'be',\n",
       "  'an',\n",
       "  'eumesat',\n",
       "  'satellite',\n",
       "  'image'],\n",
       " ['fifty',\n",
       "  'year_ago',\n",
       "  'i',\n",
       "  'be',\n",
       "  'teach',\n",
       "  'and',\n",
       "  'preach',\n",
       "  'about',\n",
       "  'global_warming',\n",
       "  'and',\n",
       "  'it',\n",
       "  'catastrophic',\n",
       "  'effect',\n",
       "  'on',\n",
       "  'our',\n",
       "  'climate'],\n",
       " ['president_barack',\n",
       "  'obama',\n",
       "  'say',\n",
       "  'the',\n",
       "  'world',\n",
       "  'cannot',\n",
       "  'wait',\n",
       "  'for',\n",
       "  'china',\n",
       "  'to',\n",
       "  'commit',\n",
       "  'to',\n",
       "  'tackle',\n",
       "  'global_warming'],\n",
       " ['obama', 'china', 'must', 'act', 'on', 'climate_change'],\n",
       " ['renewable_energy',\n",
       "  'possible',\n",
       "  'solution',\n",
       "  'to',\n",
       "  'global_warming',\n",
       "  'by',\n",
       "  'milton',\n",
       "  'takei',\n",
       "  'university',\n",
       "  'alumnus',\n",
       "  '1992',\n",
       "  'in',\n",
       "  'deal_with'],\n",
       " ['effect_of',\n",
       "  'global_warming',\n",
       "  'à_',\n",
       "  'youtube',\n",
       "  'à_',\n",
       "  'impact',\n",
       "  'of',\n",
       "  'climate_change',\n",
       "  'on',\n",
       "  'there_be',\n",
       "  'many',\n",
       "  'predict',\n",
       "  'effect',\n",
       "  'for',\n",
       "  'the',\n",
       "  'en'],\n",
       " ['plz',\n",
       "  'hlp',\n",
       "  'fight',\n",
       "  'global_warming',\n",
       "  'read',\n",
       "  'my',\n",
       "  'post',\n",
       "  'abt',\n",
       "  'effect_of',\n",
       "  'global_warming'],\n",
       " ['un',\n",
       "  'to',\n",
       "  'battle',\n",
       "  'poverty',\n",
       "  'global_warming',\n",
       "  'newkerala.com',\n",
       "  'online',\n",
       "  'news',\n",
       "  'un',\n",
       "  'to',\n",
       "  'battle',\n",
       "  'poverty',\n",
       "  'global_warming',\n",
       "  'new'],\n",
       " ['germany',\n",
       "  'be',\n",
       "  'an_important',\n",
       "  'partner',\n",
       "  'for',\n",
       "  'u',\n",
       "  'in',\n",
       "  'trade',\n",
       "  'a',\n",
       "  'well',\n",
       "  'a',\n",
       "  'in',\n",
       "  'the',\n",
       "  'fight_against',\n",
       "  'climate_change'],\n",
       " ['global_warming',\n",
       "  'likely',\n",
       "  'to',\n",
       "  'worsen',\n",
       "  'allergy',\n",
       "  'in',\n",
       "  'maine',\n",
       "  'that',\n",
       "  'be',\n",
       "  'accord_to',\n",
       "  'a',\n",
       "  'new',\n",
       "  'report_release',\n",
       "  'today',\n",
       "  'by',\n",
       "  'the',\n",
       "  'nationa'],\n",
       " ['subtropolis',\n",
       "  'u',\n",
       "  'a',\n",
       "  'a',\n",
       "  'creative',\n",
       "  'solution',\n",
       "  'to',\n",
       "  'global_warming',\n",
       "  '100',\n",
       "  'foot',\n",
       "  'below',\n",
       "  'ground'],\n",
       " ['global_warming',\n",
       "  'or',\n",
       "  'unemployment',\n",
       "  'choose',\n",
       "  'your',\n",
       "  'own',\n",
       "  'disaster',\n",
       "  'by',\n",
       "  'max',\n",
       "  'jacob',\n",
       "  'company',\n",
       "  'produce',\n",
       "  'greenhouse_gas',\n",
       "  'in'],\n",
       " ['this',\n",
       "  'one',\n",
       "  'explain',\n",
       "  'the',\n",
       "  'extreme',\n",
       "  'cold',\n",
       "  'weather',\n",
       "  'we',\n",
       "  'have',\n",
       "  'experienced',\n",
       "  'this',\n",
       "  'winter',\n",
       "  'a',\n",
       "  'just',\n",
       "  'one',\n",
       "  'more',\n",
       "  'example',\n",
       "  'of',\n",
       "  'global_warming'],\n",
       " ['change',\n",
       "  'giant',\n",
       "  'glacier',\n",
       "  'fall',\n",
       "  'in',\n",
       "  'peru',\n",
       "  'cause',\n",
       "  'deadly',\n",
       "  'tsunami'],\n",
       " ['green_cement',\n",
       "  'make',\n",
       "  'from_rice',\n",
       "  'may_help',\n",
       "  'tackle',\n",
       "  'global_warming',\n",
       "  'london_april',\n",
       "  '13',\n",
       "  'with',\n",
       "  'the',\n",
       "  'increase',\n",
       "  'rise',\n",
       "  'in',\n",
       "  'the'],\n",
       " ['can',\n",
       "  'you',\n",
       "  'feel',\n",
       "  'the',\n",
       "  'shift',\n",
       "  'in',\n",
       "  'consciousness',\n",
       "  '3k',\n",
       "  'business_create',\n",
       "  'new_ad',\n",
       "  'for',\n",
       "  'climate_change',\n",
       "  'action'],\n",
       " ['3,000_business',\n",
       "  'create_new',\n",
       "  'ad_for',\n",
       "  'climate_change',\n",
       "  'action',\n",
       "  'cleantechnica'],\n",
       " ['global_warming', 'threatens', 'armenia', 'by', '2c', 'high_temperature'],\n",
       " ['climate_change',\n",
       "  'deadly',\n",
       "  'scientist',\n",
       "  'suspect',\n",
       "  'global_warming',\n",
       "  'may',\n",
       "  'be',\n",
       "  'contribute',\n",
       "  'to',\n",
       "  'strange',\n",
       "  'death',\n",
       "  'of',\n",
       "  'arctic',\n",
       "  'bird'],\n",
       " ['green_cement',\n",
       "  'make',\n",
       "  'from_rice',\n",
       "  'may_help',\n",
       "  'tackle',\n",
       "  'global_warming',\n",
       "  'london_april',\n",
       "  '13',\n",
       "  'ani_):',\n",
       "  'with',\n",
       "  'the',\n",
       "  'increase',\n",
       "  'rise',\n",
       "  'in'],\n",
       " ['à_green',\n",
       "  'à_',\n",
       "  'cement_make',\n",
       "  'from_rice',\n",
       "  'may_help',\n",
       "  'tackle',\n",
       "  'global_warming'],\n",
       " ['global_warming',\n",
       "  'at',\n",
       "  'point',\n",
       "  'of',\n",
       "  'no',\n",
       "  'return',\n",
       "  'global_warming',\n",
       "  'have',\n",
       "  'reach',\n",
       "  'the',\n",
       "  'point',\n",
       "  'of',\n",
       "  'no',\n",
       "  'return',\n",
       "  'a',\n",
       "  'study',\n",
       "  'publish',\n",
       "  'in',\n",
       "  'th'],\n",
       " ['world-famous',\n",
       "  'place',\n",
       "  'endanger',\n",
       "  'by',\n",
       "  'global_warming',\n",
       "  'if',\n",
       "  'climatologist',\n",
       "  'prediction',\n",
       "  'of',\n",
       "  'global_warming',\n",
       "  'be',\n",
       "  'right',\n",
       "  'some'],\n",
       " ['late',\n",
       "  'weapon',\n",
       "  'in',\n",
       "  'global_warming',\n",
       "  'fight',\n",
       "  'à_',\n",
       "  'green_cement',\n",
       "  'make',\n",
       "  'from_rice',\n",
       "  'by',\n",
       "  'fiona',\n",
       "  'macleod',\n",
       "  'and',\n",
       "  'ruairi',\n",
       "  'creaney',\n",
       "  'scienti'],\n",
       " ['late',\n",
       "  'weapon',\n",
       "  'in',\n",
       "  'global_warming',\n",
       "  'fight',\n",
       "  'à_',\n",
       "  'green_cement',\n",
       "  'make',\n",
       "  'from_rice'],\n",
       " ['cop',\n",
       "  'with',\n",
       "  'global_warming',\n",
       "  'how',\n",
       "  'to',\n",
       "  'save',\n",
       "  'on',\n",
       "  'utility',\n",
       "  'bill',\n",
       "  'by',\n",
       "  'dealman',\n",
       "  'view',\n",
       "  'all',\n",
       "  'post',\n",
       "  'by',\n",
       "  'dealman',\n",
       "  'actually',\n",
       "  'this',\n",
       "  'isn'],\n",
       " ['climate_change',\n",
       "  'building',\n",
       "  'a',\n",
       "  'green',\n",
       "  'economy',\n",
       "  'paul',\n",
       "  'krugman',\n",
       "  'nytimes.com'],\n",
       " ['clean',\n",
       "  'technology',\n",
       "  'industry',\n",
       "  'forecast',\n",
       "  'be',\n",
       "  'strong',\n",
       "  'due_to',\n",
       "  'global_warming',\n",
       "  'concern',\n",
       "  'april',\n",
       "  '12',\n",
       "  '2010',\n",
       "  'mmd',\n",
       "  'newswire'],\n",
       " ['porous', 'material', 'to', 'reduce', 'the', 'climate_change'],\n",
       " ['celebrate',\n",
       "  'earth_day',\n",
       "  'by',\n",
       "  'signing',\n",
       "  'declaration',\n",
       "  'of',\n",
       "  'energy',\n",
       "  'independence',\n",
       "  'to',\n",
       "  'show',\n",
       "  'the',\n",
       "  'senate',\n",
       "  'we',\n",
       "  'demand',\n",
       "  'action',\n",
       "  'on',\n",
       "  'climate_change'],\n",
       " ['top',\n",
       "  'u',\n",
       "  'vacation',\n",
       "  'spot',\n",
       "  'become',\n",
       "  'endanger',\n",
       "  'landscape',\n",
       "  'threaten',\n",
       "  'by',\n",
       "  'global_warming',\n",
       "  'mining',\n",
       "  'weather',\n",
       "  'environmental',\n",
       "  'hazard',\n",
       "  'population'],\n",
       " ['leader',\n",
       "  'be',\n",
       "  'fail',\n",
       "  'to',\n",
       "  'address',\n",
       "  'the',\n",
       "  'gravest',\n",
       "  'threat',\n",
       "  'our',\n",
       "  'world',\n",
       "  'have',\n",
       "  'ever',\n",
       "  'face',\n",
       "  'pressure',\n",
       "  'politician',\n",
       "  'on',\n",
       "  'climate_change',\n",
       "  'be',\n",
       "  'not',\n",
       "  'work'],\n",
       " ['glacier_national',\n",
       "  'park',\n",
       "  'loses',\n",
       "  'two_more',\n",
       "  'glacier',\n",
       "  'due_to',\n",
       "  'global_warming',\n",
       "  'thaindian.com',\n",
       "  'by',\n",
       "  'meena',\n",
       "  'kar',\n",
       "  'montana',\n",
       "  'apr',\n",
       "  '11'],\n",
       " ['plant',\n",
       "  'can',\n",
       "  'effectively',\n",
       "  'tackle',\n",
       "  'global_warming',\n",
       "  'do_not',\n",
       "  'have',\n",
       "  'siliconindia',\n",
       "  'account',\n",
       "  'sign',\n",
       "  'up',\n",
       "  'forgot',\n",
       "  'your',\n",
       "  'password',\n",
       "  'reset'],\n",
       " ['climate_change',\n",
       "  'affect',\n",
       "  'subterranean',\n",
       "  'ecosystem',\n",
       "  'change',\n",
       "  'above',\n",
       "  'the',\n",
       "  'ground',\n",
       "  'such_a',\n",
       "  'a',\n",
       "  'high',\n",
       "  'concentration',\n",
       "  'of',\n",
       "  'carbon'],\n",
       " ['gulf',\n",
       "  'coast',\n",
       "  'spill',\n",
       "  'well',\n",
       "  'give',\n",
       "  'climate_change',\n",
       "  'legislation',\n",
       "  'some',\n",
       "  'momentum',\n",
       "  'it',\n",
       "  'be',\n",
       "  'a',\n",
       "  'big',\n",
       "  'tragedy',\n",
       "  'than',\n",
       "  'we',\n",
       "  'be',\n",
       "  'even',\n",
       "  'aware',\n",
       "  'of',\n",
       "  'yet'],\n",
       " ['spill',\n",
       "  'coal',\n",
       "  'mine',\n",
       "  'tragedy',\n",
       "  'need',\n",
       "  'for',\n",
       "  'alt',\n",
       "  'energy',\n",
       "  'gulf',\n",
       "  'coast',\n",
       "  'spill',\n",
       "  'well',\n",
       "  'give',\n",
       "  'climate_change',\n",
       "  'legislation',\n",
       "  'some',\n",
       "  'momentum'],\n",
       " ['gulf',\n",
       "  'coast',\n",
       "  'spill',\n",
       "  'well',\n",
       "  'give',\n",
       "  'climate_change',\n",
       "  'legislation',\n",
       "  'some',\n",
       "  'momentum',\n",
       "  'it',\n",
       "  'be',\n",
       "  'a',\n",
       "  'big',\n",
       "  'tragedy',\n",
       "  'than',\n",
       "  'we',\n",
       "  'be',\n",
       "  'even',\n",
       "  'aware',\n",
       "  'of',\n",
       "  'yet',\n",
       "  'p2'],\n",
       " ['live',\n",
       "  'now',\n",
       "  'green',\n",
       "  'go_wrong',\n",
       "  'false_hope',\n",
       "  'and',\n",
       "  'real_solution',\n",
       "  'to',\n",
       "  'climate_change'],\n",
       " ['it',\n",
       "  'be',\n",
       "  'in',\n",
       "  'the',\n",
       "  '30',\n",
       "  'what_happen',\n",
       "  'to',\n",
       "  'spring',\n",
       "  'global_warming',\n",
       "  'be',\n",
       "  'for_those',\n",
       "  'that',\n",
       "  'care',\n",
       "  'to',\n",
       "  'read',\n",
       "  'about',\n",
       "  'and',\n",
       "  'not',\n",
       "  'live',\n",
       "  'it',\n",
       "  'the',\n",
       "  'coldest',\n",
       "  'winter',\n",
       "  'ever',\n",
       "  'fu'],\n",
       " ['i',\n",
       "  'truly',\n",
       "  'fat',\n",
       "  'as',\n",
       "  'gore',\n",
       "  'should',\n",
       "  'get',\n",
       "  'the',\n",
       "  'scam',\n",
       "  'artist',\n",
       "  'award',\n",
       "  'of',\n",
       "  'the',\n",
       "  'decade',\n",
       "  'with',\n",
       "  'his',\n",
       "  'global_warming',\n",
       "  'and',\n",
       "  'energy',\n",
       "  'credit',\n",
       "  'worth',\n",
       "  'close',\n",
       "  'to',\n",
       "  'billion'],\n",
       " ['hide',\n",
       "  'the',\n",
       "  'decline',\n",
       "  'be',\n",
       "  'the',\n",
       "  'global_warming',\n",
       "  'nut',\n",
       "  'job',\n",
       "  'current',\n",
       "  'policy',\n",
       "  'it',\n",
       "  'all',\n",
       "  'a',\n",
       "  'epic',\n",
       "  'scam',\n",
       "  'they',\n",
       "  'be',\n",
       "  'lie',\n",
       "  'to',\n",
       "  'the',\n",
       "  'world',\n",
       "  'climategate',\n",
       "  'tcot_p2'],\n",
       " ['boycott',\n",
       "  'siemens',\n",
       "  'for',\n",
       "  'buying',\n",
       "  'global_warming',\n",
       "  'climate_change',\n",
       "  'in',\n",
       "  'their',\n",
       "  'advertisement',\n",
       "  'tcot',\n",
       "  'sgp',\n",
       "  'teaparty'],\n",
       " ['climate_change', 'scam', '3wordslibshate'],\n",
       " ['global_warming',\n",
       "  'vostok',\n",
       "  'antarctica',\n",
       "  'sits',\n",
       "  'at',\n",
       "  '100f',\n",
       "  'with',\n",
       "  'windchills',\n",
       "  'to',\n",
       "  '142f'],\n",
       " ['global_warming',\n",
       "  'vostok',\n",
       "  'antarctica',\n",
       "  'sits',\n",
       "  'at',\n",
       "  '100f',\n",
       "  'with',\n",
       "  'low',\n",
       "  'forecast',\n",
       "  'to',\n",
       "  '110f'],\n",
       " ['scam',\n",
       "  'another',\n",
       "  'warmist',\n",
       "  'have',\n",
       "  'to',\n",
       "  'be',\n",
       "  'rescue',\n",
       "  'from',\n",
       "  'arctic',\n",
       "  'cold',\n",
       "  'global_warming',\n",
       "  'activist',\n",
       "  'transport'],\n",
       " ['why',\n",
       "  'be',\n",
       "  'not',\n",
       "  'upset_with',\n",
       "  'the',\n",
       "  'volcano',\n",
       "  'for',\n",
       "  'cause',\n",
       "  'global_warming',\n",
       "  'climategate'],\n",
       " ['hmmm', 'so', 'global_warming', 'be', 'a', 'fraud'],\n",
       " ['monster', 'chiller', 'horror', 'global_warming'],\n",
       " ['cow', 'fart', 'exonerate', 'from', 'global_warming'],\n",
       " ['get',\n",
       "  'a',\n",
       "  'headache',\n",
       "  'when',\n",
       "  'grandson',\n",
       "  'tell',\n",
       "  'how',\n",
       "  'argue',\n",
       "  'teacher',\n",
       "  'about',\n",
       "  'global_warming',\n",
       "  'be',\n",
       "  'big',\n",
       "  'hoax',\n",
       "  'one',\n",
       "  'threaten',\n",
       "  'to',\n",
       "  'flunk',\n",
       "  'him'],\n",
       " ['global_warming',\n",
       "  'be',\n",
       "  'like',\n",
       "  'the',\n",
       "  'goldman',\n",
       "  'exec',\n",
       "  'full',\n",
       "  'of',\n",
       "  'sh'],\n",
       " ['your',\n",
       "  'voice',\n",
       "  'the',\n",
       "  'fraud',\n",
       "  'of',\n",
       "  'global_warming',\n",
       "  'by',\n",
       "  'tim',\n",
       "  'michael',\n",
       "  'case',\n",
       "  'tracy',\n",
       "  'since',\n",
       "  'the',\n",
       "  'early',\n",
       "  '1970s',\n",
       "  'our',\n",
       "  'public',\n",
       "  'school',\n",
       "  'syste'],\n",
       " ['dear',\n",
       "  'global_warming',\n",
       "  'people',\n",
       "  'it',\n",
       "  'be',\n",
       "  '52',\n",
       "  'degree',\n",
       "  'in',\n",
       "  'ca',\n",
       "  'on',\n",
       "  '4/23',\n",
       "  'heat',\n",
       "  'on',\n",
       "  'content',\n",
       "  'of',\n",
       "  'this',\n",
       "  'message',\n",
       "  'be',\n",
       "  'copyright',\n",
       "  'and',\n",
       "  'property',\n",
       "  'of',\n",
       "  'author'],\n",
       " ['i',\n",
       "  'be',\n",
       "  'freeze',\n",
       "  'still',\n",
       "  'in',\n",
       "  'southern',\n",
       "  'california',\n",
       "  'global_warming',\n",
       "  'fanatic',\n",
       "  'come',\n",
       "  'visit',\n",
       "  'me',\n",
       "  'wear',\n",
       "  'a',\n",
       "  'hat',\n",
       "  'glove',\n",
       "  'and',\n",
       "  'down',\n",
       "  'jacket'],\n",
       " ['you',\n",
       "  'be',\n",
       "  'so',\n",
       "  'on',\n",
       "  'target',\n",
       "  'bullshit',\n",
       "  'be',\n",
       "  'even',\n",
       "  'well',\n",
       "  'than',\n",
       "  'the',\n",
       "  'climate_change',\n",
       "  'hoax',\n",
       "  'gore',\n",
       "  'climate_change',\n",
       "  'be',\n",
       "  'bullshit',\n",
       "  'leadersdebate',\n",
       "  'fact'],\n",
       " ['climate_change',\n",
       "  'fraud',\n",
       "  'the',\n",
       "  'scandal',\n",
       "  'of',\n",
       "  'solar',\n",
       "  'power',\n",
       "  'in',\n",
       "  'spain'],\n",
       " ['climate_change', 'fraud', 'global_warming', 'ethanol', 'ddt', 'and'],\n",
       " ['despite',\n",
       "  'climategate',\n",
       "  'left',\n",
       "  'invest',\n",
       "  'heavily',\n",
       "  'in',\n",
       "  'global_warming',\n",
       "  'hysteria',\n",
       "  'a',\n",
       "  'new',\n",
       "  'way',\n",
       "  '2',\n",
       "  'impose',\n",
       "  \"nat'l\",\n",
       "  'international',\n",
       "  'control',\n",
       "  'on',\n",
       "  'human',\n",
       "  'freedom'],\n",
       " ['obama',\n",
       "  'do',\n",
       "  'a',\n",
       "  '3',\n",
       "  'minute',\n",
       "  'earth_day',\n",
       "  'video',\n",
       "  'fails',\n",
       "  'to',\n",
       "  'mention',\n",
       "  'the',\n",
       "  'global_warming',\n",
       "  'hoax'],\n",
       " ['alms',\n",
       "  'let',\n",
       "  'me',\n",
       "  'politely',\n",
       "  'suggest',\n",
       "  'that',\n",
       "  'i',\n",
       "  'do_not',\n",
       "  'watch',\n",
       "  'motorsports',\n",
       "  'to',\n",
       "  'be',\n",
       "  'lecture',\n",
       "  'on',\n",
       "  'imaginary',\n",
       "  'global_warming',\n",
       "  'nascar'],\n",
       " ['someone',\n",
       "  'go',\n",
       "  'tell',\n",
       "  'the',\n",
       "  'climate_change',\n",
       "  'crowd',\n",
       "  'to',\n",
       "  'go',\n",
       "  'hang',\n",
       "  'after',\n",
       "  'they',\n",
       "  'read',\n",
       "  'this'],\n",
       " ['gagnon',\n",
       "  'like',\n",
       "  'most',\n",
       "  'liberal',\n",
       "  'you',\n",
       "  'have',\n",
       "  'be',\n",
       "  'duped',\n",
       "  'by',\n",
       "  'the',\n",
       "  'global_warming',\n",
       "  'socialist',\n",
       "  'propaganda'],\n",
       " ['i',\n",
       "  'believe',\n",
       "  'that',\n",
       "  'global_warming',\n",
       "  'be',\n",
       "  'an',\n",
       "  'international',\n",
       "  'conspiracy',\n",
       "  'perpetrate',\n",
       "  'by',\n",
       "  'ge',\n",
       "  'in',\n",
       "  'order',\n",
       "  'to',\n",
       "  'sell',\n",
       "  'more',\n",
       "  'air',\n",
       "  'conditioner'],\n",
       " ['un',\n",
       "  'process',\n",
       "  'in',\n",
       "  'danger',\n",
       "  'unless',\n",
       "  'world',\n",
       "  'agrees',\n",
       "  'on',\n",
       "  'climate_change',\n",
       "  'telegraph'],\n",
       " ['do', \"virginia's\", 'governor', 'believe_in', 'global_warming'],\n",
       " ['call', 'bluff', 'on', 'climate_change', 'it', 'be', 'up', 'to', 'you'],\n",
       " ['reid',\n",
       "  'to',\n",
       "  'graham',\n",
       "  'on',\n",
       "  'climate_change',\n",
       "  'it',\n",
       "  'be',\n",
       "  'up',\n",
       "  'to',\n",
       "  'you'],\n",
       " ['what',\n",
       "  'do',\n",
       "  'you_know',\n",
       "  'about',\n",
       "  'climate_change',\n",
       "  'test',\n",
       "  'your',\n",
       "  'knowledge',\n",
       "  'with',\n",
       "  'the',\n",
       "  'follow',\n",
       "  '10',\n",
       "  'question'],\n",
       " [\"shell's\",\n",
       "  'climate_change',\n",
       "  'sponsorship',\n",
       "  'cause',\n",
       "  'blogosphere',\n",
       "  'meltdown'],\n",
       " ['funny',\n",
       "  'how',\n",
       "  'timely',\n",
       "  'oil',\n",
       "  'spill',\n",
       "  'in',\n",
       "  'gulf',\n",
       "  'and',\n",
       "  'new',\n",
       "  'az',\n",
       "  'law',\n",
       "  'have',\n",
       "  'push',\n",
       "  'climate_change',\n",
       "  'bill',\n",
       "  'away',\n",
       "  'and',\n",
       "  'drawn',\n",
       "  'forth',\n",
       "  'immigration_reform'],\n",
       " ['announcement',\n",
       "  'spr',\n",
       "  'principal',\n",
       "  'jeff',\n",
       "  'gracer',\n",
       "  'to',\n",
       "  'moderate',\n",
       "  'panel',\n",
       "  'on',\n",
       "  'climate_change',\n",
       "  'at',\n",
       "  'new_york',\n",
       "  'city',\n",
       "  'à_'],\n",
       " ['tom', 'switzer', \"australia's\", 'change', 'climate-change', 'climate'],\n",
       " ['kindle',\n",
       "  'controversy',\n",
       "  'hansen',\n",
       "  'mckibben',\n",
       "  'revkin',\n",
       "  'lomborg',\n",
       "  'of',\n",
       "  'climate_change',\n",
       "  'guru',\n",
       "  'at',\n",
       "  'the',\n",
       "  'met',\n",
       "  'in',\n",
       "  'nyc',\n",
       "  '8p',\n",
       "  'thurs',\n",
       "  '4/29',\n",
       "  '10'],\n",
       " ['i',\n",
       "  'uploaded',\n",
       "  'a',\n",
       "  'youtube_video',\n",
       "  'maximsnewsnetwork',\n",
       "  'energy',\n",
       "  'climate_change',\n",
       "  'u',\n",
       "  'ban',\n",
       "  'ki-moon',\n",
       "  'untv'],\n",
       " ['climate_change',\n",
       "  'you_tube',\n",
       "  'animation',\n",
       "  'you',\n",
       "  'will',\n",
       "  'like',\n",
       "  'ipcc',\n",
       "  'gop'],\n",
       " ['reid',\n",
       "  'set',\n",
       "  'to',\n",
       "  'move',\n",
       "  'on',\n",
       "  'climate_change',\n",
       "  'bill',\n",
       "  'before',\n",
       "  'immigration'],\n",
       " ['ask',\n",
       "  'your',\n",
       "  'own',\n",
       "  'man',\n",
       "  '100',\n",
       "  'question',\n",
       "  'to',\n",
       "  'discover',\n",
       "  'the',\n",
       "  'answer',\n",
       "  'you',\n",
       "  'want',\n",
       "  'climate_change',\n",
       "  'clinical_trial',\n",
       "  'collag'],\n",
       " ['attend',\n",
       "  'the',\n",
       "  'secretary-general',\n",
       "  'à_s',\n",
       "  'press',\n",
       "  'conference',\n",
       "  'to',\n",
       "  'present',\n",
       "  'the',\n",
       "  'report',\n",
       "  'of',\n",
       "  'his',\n",
       "  'advisory',\n",
       "  'group',\n",
       "  'on',\n",
       "  'energy',\n",
       "  'and',\n",
       "  'climate_change'],\n",
       " ['meeting',\n",
       "  'dr',\n",
       "  'sultan',\n",
       "  'al-jaber',\n",
       "  'assistant',\n",
       "  'foreign',\n",
       "  'minister',\n",
       "  'united',\n",
       "  'arab',\n",
       "  'emirate',\n",
       "  'and',\n",
       "  'special',\n",
       "  'envoy',\n",
       "  'for',\n",
       "  'energy',\n",
       "  'and',\n",
       "  'climate_change'],\n",
       " ['should',\n",
       "  'you',\n",
       "  'removal',\n",
       "  'that',\n",
       "  'mole',\n",
       "  'a_scream',\n",
       "  'à_o_à_',\n",
       "  'climate_change',\n",
       "  'clinical_trial',\n",
       "  'collagen_clinique',\n",
       "  'clip_art'],\n",
       " ['make',\n",
       "  'remark',\n",
       "  'at',\n",
       "  'launch',\n",
       "  'of',\n",
       "  'report',\n",
       "  'by',\n",
       "  'his',\n",
       "  'advisory',\n",
       "  'group',\n",
       "  'on',\n",
       "  'energy',\n",
       "  'and',\n",
       "  'climate_change',\n",
       "  'agecc',\n",
       "  'à_',\n",
       "  'energy',\n",
       "  'for',\n",
       "  'development'],\n",
       " ['discussion',\n",
       "  'on',\n",
       "  'indigenous',\n",
       "  'woman',\n",
       "  'and',\n",
       "  'climate_change',\n",
       "  'at',\n",
       "  'the',\n",
       "  'un'],\n",
       " ['politico',\n",
       "  'story',\n",
       "  'on',\n",
       "  'the',\n",
       "  'state',\n",
       "  'of',\n",
       "  'play',\n",
       "  'in_dc',\n",
       "  're',\n",
       "  'climate_change',\n",
       "  'and',\n",
       "  'immigration'],\n",
       " ['the',\n",
       "  'choice',\n",
       "  'that',\n",
       "  'won',\n",
       "  'à_t',\n",
       "  'change',\n",
       "  'the',\n",
       "  'world',\n",
       "  'and',\n",
       "  'the',\n",
       "  'one',\n",
       "  'that',\n",
       "  'might'],\n",
       " ['at',\n",
       "  'new',\n",
       "  'school',\n",
       "  'climate_change',\n",
       "  'panel',\n",
       "  \"heritage's\",\n",
       "  'david',\n",
       "  'kreutzer',\n",
       "  'just_ask',\n",
       "  'audience',\n",
       "  'to',\n",
       "  'wait',\n",
       "  '3',\n",
       "  'min',\n",
       "  'before',\n",
       "  'throw',\n",
       "  'water',\n",
       "  'bottle',\n",
       "  'at',\n",
       "  'him'],\n",
       " ['geological',\n",
       "  'society',\n",
       "  'of',\n",
       "  'america',\n",
       "  'position',\n",
       "  'statement',\n",
       "  'on',\n",
       "  'climate_change'],\n",
       " ['global_warming',\n",
       "  'dirt-carbon',\n",
       "  'peril',\n",
       "  'model',\n",
       "  'be',\n",
       "  'wrong',\n",
       "  'say',\n",
       "  'boffin',\n",
       "  'greenhouse',\n",
       "  'experiment',\n",
       "  'show',\n",
       "  'reduce',\n",
       "  'greenhouse'],\n",
       " ['climate_change',\n",
       "  'no',\n",
       "  'deal',\n",
       "  'in',\n",
       "  'sight',\n",
       "  'say',\n",
       "  'lead',\n",
       "  'economy',\n",
       "  'of',\n",
       "  'the',\n",
       "  'south',\n",
       "  'cape',\n",
       "  'town',\n",
       "  'apr',\n",
       "  '26',\n",
       "  'ip',\n",
       "  'environment',\n",
       "  'minist'],\n",
       " ['senior',\n",
       "  'technical',\n",
       "  'advisor',\n",
       "  'community',\n",
       "  'and',\n",
       "  'climate_change',\n",
       "  'environment',\n",
       "  'and',\n",
       "  'development',\n",
       "  'new_york',\n",
       "  'job'],\n",
       " ['survey',\n",
       "  'gauge',\n",
       "  'opinion',\n",
       "  'about',\n",
       "  'global_warming',\n",
       "  'dan',\n",
       "  'reiland',\n",
       "  'uw-eau',\n",
       "  'claire',\n",
       "  'student',\n",
       "  'displayed',\n",
       "  'poster',\n",
       "  'monday',\n",
       "  'afternoon'],\n",
       " ['connecticut',\n",
       "  'buy',\n",
       "  'into',\n",
       "  'global_warming',\n",
       "  'but_some',\n",
       "  'senate',\n",
       "  'candidate',\n",
       "  'do_not',\n",
       "  'one',\n",
       "  'might',\n",
       "  'assume',\n",
       "  'that',\n",
       "  'regardless',\n",
       "  'of'],\n",
       " ['legislative_steamroll',\n",
       "  'by_kathryn',\n",
       "  'jean_lopez',\n",
       "  'april_26',\n",
       "  'bloomberg_immigration',\n",
       "  'and',\n",
       "  'climate-change_legisl'],\n",
       " ['afx',\n",
       "  'uk',\n",
       "  'focus',\n",
       "  '2010-04-',\n",
       "  '26',\n",
       "  '20:41',\n",
       "  'scenarios-challenges',\n",
       "  'to',\n",
       "  'california',\n",
       "  'climate_change',\n",
       "  'law',\n",
       "  'by',\n",
       "  'peter',\n",
       "  'henderson'],\n",
       " ['true',\n",
       "  'larry',\n",
       "  'shapiro',\n",
       "  'be',\n",
       "  'astute',\n",
       "  'why',\n",
       "  'immigration_reform',\n",
       "  'be',\n",
       "  'get',\n",
       "  'more',\n",
       "  'traction',\n",
       "  'than',\n",
       "  'climate_change',\n",
       "  'in',\n",
       "  'senate'],\n",
       " ['which',\n",
       "  'be',\n",
       "  'next',\n",
       "  'on',\n",
       "  'capitol_hill',\n",
       "  'immigration',\n",
       "  'or',\n",
       "  'climate_change'],\n",
       " ['pr',\n",
       "  'by',\n",
       "  'noon',\n",
       "  'foxnews.com/gene',\n",
       "  'koprowski',\n",
       "  'seek',\n",
       "  'expert',\n",
       "  're',\n",
       "  'audit',\n",
       "  'of',\n",
       "  'ipcc',\n",
       "  'climate-change',\n",
       "  'report'],\n",
       " ['climate_change', 'bill', 'stall', 'amid', 'epic', 'immigration', 'sortie'],\n",
       " ['cnn',\n",
       "  \"graham's_exit\",\n",
       "  'put',\n",
       "  'climate_change',\n",
       "  'bill',\n",
       "  'in_limbo',\n",
       "  'a',\n",
       "  'climate-change_bill',\n",
       "  'that',\n",
       "  'be',\n",
       "  'schedule_to',\n",
       "  'be',\n",
       "  'unveiled',\n",
       "  'at',\n",
       "  'a'],\n",
       " [\"graham's_exit\", 'put', 'climate_change', 'bill', 'in_limbo'],\n",
       " ['legislative_steamroll',\n",
       "  'by_kathryn',\n",
       "  'jean_lopez',\n",
       "  'april_26',\n",
       "  'bloomberg_immigration',\n",
       "  'and',\n",
       "  'climate-change_legisl'],\n",
       " ['watch',\n",
       "  'gt',\n",
       "  'gt',\n",
       "  'sting',\n",
       "  'and',\n",
       "  'his',\n",
       "  'wife',\n",
       "  'talk',\n",
       "  'to',\n",
       "  'cnn',\n",
       "  'about',\n",
       "  'climate_change'],\n",
       " ['reflection',\n",
       "  'of',\n",
       "  'a',\n",
       "  'rebel',\n",
       "  'climate_change',\n",
       "  'and',\n",
       "  'social',\n",
       "  'justice',\n",
       "  'towards',\n",
       "  'the',\n",
       "  'more',\n",
       "  'familiar',\n",
       "  'image',\n",
       "  'of',\n",
       "  'green',\n",
       "  'capitalism'],\n",
       " ['legislative_steamroll',\n",
       "  'by_kathryn',\n",
       "  'jean_lopez',\n",
       "  'april_26',\n",
       "  'bloomberg_immigration',\n",
       "  'and',\n",
       "  'climate-change_legisl'],\n",
       " ['cnnbrk',\n",
       "  \"graham's_exit\",\n",
       "  'from_talk',\n",
       "  'put',\n",
       "  'climate_change',\n",
       "  'bill',\n",
       "  'in_limbo'],\n",
       " ['climate',\n",
       "  'scientist',\n",
       "  'get',\n",
       "  'hate',\n",
       "  'mail',\n",
       "  'abuse',\n",
       "  'e-mail',\n",
       "  'brimming',\n",
       "  'accuse',\n",
       "  'them',\n",
       "  'of',\n",
       "  'fabricate',\n",
       "  'global_warming',\n",
       "  'data',\n",
       "  'flood'],\n",
       " ['why',\n",
       "  'the',\n",
       "  \"gop's\",\n",
       "  'graham',\n",
       "  'put',\n",
       "  'the',\n",
       "  'kibosh',\n",
       "  'on',\n",
       "  'a',\n",
       "  'climate',\n",
       "  'bill',\n",
       "  'even',\n",
       "  'the',\n",
       "  'industry-friendly',\n",
       "  'senate',\n",
       "  'global-warming',\n",
       "  'legislatio'],\n",
       " [\"graham's_exit\",\n",
       "  'put',\n",
       "  'climate_change',\n",
       "  'bill',\n",
       "  'in_limbo',\n",
       "  'a',\n",
       "  'climate-change_bill',\n",
       "  'that',\n",
       "  'be',\n",
       "  'schedule_to',\n",
       "  'be',\n",
       "  'unveiled',\n",
       "  'at',\n",
       "  'a',\n",
       "  'news'],\n",
       " [\"graham's_exit\", 'from_talk', 'put', 'climate_change', 'bill', 'in_limbo'],\n",
       " ['obama',\n",
       "  'politics',\n",
       "  'push',\n",
       "  'immigration_reform',\n",
       "  'sideline',\n",
       "  'climate_change',\n",
       "  'about',\n",
       "  'news',\n",
       "  'issue',\n",
       "  'blog',\n",
       "  'who',\n",
       "  'regularly'],\n",
       " ['tea_party',\n",
       "  'with',\n",
       "  'a',\n",
       "  'difference',\n",
       "  'climate_change',\n",
       "  'really',\n",
       "  'hit',\n",
       "  'will',\n",
       "  'come',\n",
       "  'with',\n",
       "  'instruction',\n",
       "  'in',\n",
       "  'chinese',\n",
       "  'go_green',\n",
       "  'tea'],\n",
       " ['gawker',\n",
       "  'logic_report',\n",
       "  \"lindsey_graham's\",\n",
       "  'climate_change',\n",
       "  'bill_flip-flop',\n",
       "  'polidicks'],\n",
       " ['logic_report',\n",
       "  \"lindsey_graham's\",\n",
       "  'climate_change',\n",
       "  'bill_flip-flop',\n",
       "  'polidicks'],\n",
       " ['passing',\n",
       "  'any',\n",
       "  'legislation',\n",
       "  'at',\n",
       "  'all',\n",
       "  'will',\n",
       "  'kill',\n",
       "  'the',\n",
       "  'climate_change',\n",
       "  'bill'],\n",
       " ['portfolio',\n",
       "  'light',\n",
       "  'delivers',\n",
       "  'broad',\n",
       "  'assortment',\n",
       "  'light',\n",
       "  'for',\n",
       "  'the',\n",
       "  'home',\n",
       "  'climate_change',\n",
       "  'clinical_trial',\n",
       "  'collag'],\n",
       " ['new', 'delay', 'in', 'senate', 'climate_change', 'bill'],\n",
       " ['the',\n",
       "  'sunday',\n",
       "  'word',\n",
       "  'energy',\n",
       "  'lawmaker',\n",
       "  'decide',\n",
       "  'to_delay',\n",
       "  'the',\n",
       "  'unveil',\n",
       "  'of',\n",
       "  'their',\n",
       "  'bipartisan',\n",
       "  'climate_change',\n",
       "  'and',\n",
       "  'energy'],\n",
       " ['decision', 'time', 'à_', 'uk', 'election', 'climate_change'],\n",
       " ['graham',\n",
       "  'threatens',\n",
       "  'to',\n",
       "  'pull',\n",
       "  'energy',\n",
       "  'bill',\n",
       "  'sponsorship',\n",
       "  'senator',\n",
       "  'lindsey_graham',\n",
       "  'a',\n",
       "  'central',\n",
       "  'architect',\n",
       "  'of',\n",
       "  'a',\n",
       "  'climate_change'],\n",
       " ['survey',\n",
       "  'find',\n",
       "  'u',\n",
       "  'do_not',\n",
       "  'give',\n",
       "  'a',\n",
       "  'about',\n",
       "  'climate_change',\n",
       "  'a',\n",
       "  'new',\n",
       "  'survey',\n",
       "  'conduct',\n",
       "  'by',\n",
       "  'hsbc',\n",
       "  'find',\n",
       "  'that',\n",
       "  'in',\n",
       "  'city',\n",
       "  'aro'],\n",
       " ['best',\n",
       "  'core',\n",
       "  'exercise',\n",
       "  'plank',\n",
       "  'back',\n",
       "  'extension',\n",
       "  'gaiam',\n",
       "  'blog',\n",
       "  'affirmation',\n",
       "  'burn-calories',\n",
       "  'change',\n",
       "  'climate_change',\n",
       "  'diet',\n",
       "  'energy'],\n",
       " ['alexia_park',\n",
       "  'global_warming',\n",
       "  'of',\n",
       "  'the',\n",
       "  'heart_earth',\n",
       "  'day',\n",
       "  'be',\n",
       "  'over',\n",
       "  'or',\n",
       "  'be',\n",
       "  'it_thousand',\n",
       "  'of',\n",
       "  'conscious',\n",
       "  'action',\n",
       "  'take',\n",
       "  'place'],\n",
       " ['alexia_park', 'global_warming', 'of', 'the', 'heart'],\n",
       " ['alexia_park',\n",
       "  'global_warming',\n",
       "  'of',\n",
       "  'the',\n",
       "  'heart_earth',\n",
       "  'day',\n",
       "  'be',\n",
       "  'over',\n",
       "  'or',\n",
       "  'be',\n",
       "  'it_thousand',\n",
       "  'perhaps',\n",
       "  'million',\n",
       "  'of',\n",
       "  'consc'],\n",
       " ['survey',\n",
       "  'find',\n",
       "  'u',\n",
       "  'do_not',\n",
       "  'give',\n",
       "  'a',\n",
       "  'shit',\n",
       "  'about',\n",
       "  'climate_change'],\n",
       " [\"here's\", 'where', 'to', 'start', 'the', 'talk', 'about', 'climate_change'],\n",
       " ['webb',\n",
       "  'tout',\n",
       "  'global_warming',\n",
       "  'department',\n",
       "  'little',\n",
       "  'rock',\n",
       "  'the',\n",
       "  'arkansas',\n",
       "  'lawmaker',\n",
       "  'who',\n",
       "  'author',\n",
       "  'legislation',\n",
       "  'that',\n",
       "  'create'],\n",
       " ['climate',\n",
       "  'bill',\n",
       "  'drop',\n",
       "  'on',\n",
       "  'monday',\n",
       "  'or',\n",
       "  'not',\n",
       "  'the',\n",
       "  'long-awaited',\n",
       "  'senate',\n",
       "  'climate_change',\n",
       "  'bill',\n",
       "  'be',\n",
       "  'broker',\n",
       "  'by',\n",
       "  'senator',\n",
       "  'ker'],\n",
       " ['and',\n",
       "  'sebastian',\n",
       "  'copeland',\n",
       "  'at',\n",
       "  'premiere',\n",
       "  'of',\n",
       "  'climate',\n",
       "  'of',\n",
       "  'change',\n",
       "  'right_now',\n",
       "  'tribeca'],\n",
       " ['climatologist', 'meteorologist', 'divide_on', 'global_warming'],\n",
       " ['climate',\n",
       "  \"science's\",\n",
       "  'chinese',\n",
       "  'whisper',\n",
       "  'the',\n",
       "  'book',\n",
       "  'that',\n",
       "  'separate',\n",
       "  'global_warming',\n",
       "  'fact',\n",
       "  'from',\n",
       "  'fiction',\n",
       "  'the',\n",
       "  'culture',\n",
       "  'shock',\n",
       "  'of'],\n",
       " ['don_blankenship',\n",
       "  'call',\n",
       "  'effort',\n",
       "  'on',\n",
       "  'mine_safety',\n",
       "  'regulation',\n",
       "  'a_silly',\n",
       "  'a',\n",
       "  'global_warming'],\n",
       " ['if_you',\n",
       "  'miss',\n",
       "  'report',\n",
       "  'on',\n",
       "  'u',\n",
       "  'news',\n",
       "  'group',\n",
       "  'work',\n",
       "  'together',\n",
       "  'on',\n",
       "  'climate_change',\n",
       "  'project'],\n",
       " ['sarah_palin', 'on', 'climate_change'],\n",
       " ['don_blankenship',\n",
       "  'call',\n",
       "  'effort',\n",
       "  'on',\n",
       "  'mine_safety',\n",
       "  'regulation',\n",
       "  'a_silly',\n",
       "  'a',\n",
       "  'global_warming',\n",
       "  'at',\n",
       "  'his',\n",
       "  'labor',\n",
       "  'day',\n",
       "  'anti-union'],\n",
       " ['global_warming', 'shangri-la'],\n",
       " ['climate',\n",
       "  'top',\n",
       "  'coal',\n",
       "  'exec',\n",
       "  'to',\n",
       "  'testify',\n",
       "  'before',\n",
       "  'global_warming',\n",
       "  'panel'],\n",
       " ['watersisweb',\n",
       "  'integrate',\n",
       "  'regional',\n",
       "  'water',\n",
       "  'management',\n",
       "  'climate_change',\n",
       "  'document',\n",
       "  'clearinghouse'],\n",
       " ['in', 'with', 'immigration', 'out', 'with', 'climate_change'],\n",
       " ['2009',\n",
       "  'year',\n",
       "  'in',\n",
       "  'which',\n",
       "  'sceptic',\n",
       "  'stole',\n",
       "  'run',\n",
       "  'on',\n",
       "  'climate_change',\n",
       "  'australian',\n",
       "  'business',\n",
       "  'could',\n",
       "  'show',\n",
       "  'our',\n",
       "  'politician',\n",
       "  'the'],\n",
       " ['video',\n",
       "  'larry_brilliant',\n",
       "  'on',\n",
       "  'the',\n",
       "  'volcano',\n",
       "  'and',\n",
       "  'climate_change',\n",
       "  'boing',\n",
       "  'boing'],\n",
       " ['earth_day', 'at', '40', 'the', 'politics', 'finally', 'erupt'],\n",
       " ['paul',\n",
       "  'rogat',\n",
       "  'loeb',\n",
       "  'soul',\n",
       "  'of',\n",
       "  'a',\n",
       "  'citizen',\n",
       "  'jesus',\n",
       "  'and',\n",
       "  'climate_change',\n",
       "  'the',\n",
       "  'journey',\n",
       "  'of',\n",
       "  'evangelical',\n",
       "  'leader',\n",
       "  'rich',\n",
       "  'cizik'],\n",
       " ['climate-change_bill',\n",
       "  'avoids',\n",
       "  'cap-and-trade',\n",
       "  'tag',\n",
       "  'in',\n",
       "  'u',\n",
       "  'senate',\n",
       "  'april_22',\n",
       "  'bloomberg',\n",
       "  'when',\n",
       "  'tea_party',\n",
       "  'activist'],\n",
       " ['u', 'climate_change', 'negotiate', 'plan', 'reveal'],\n",
       " ['overheard',\n",
       "  'from',\n",
       "  'carol_browner',\n",
       "  'assistant',\n",
       "  'to',\n",
       "  'the',\n",
       "  'president',\n",
       "  'for',\n",
       "  'energy',\n",
       "  'and',\n",
       "  'climate_change',\n",
       "  'she',\n",
       "  'mention',\n",
       "  'that'],\n",
       " ['maria',\n",
       "  'rodale',\n",
       "  'do',\n",
       "  'climate_change',\n",
       "  'exist',\n",
       "  'and',\n",
       "  'do',\n",
       "  'it',\n",
       "  'even',\n",
       "  'matter',\n",
       "  'it',\n",
       "  'amazes',\n",
       "  'me',\n",
       "  'really',\n",
       "  'how',\n",
       "  'many',\n",
       "  'different',\n",
       "  'view'],\n",
       " ['stay',\n",
       "  'glue',\n",
       "  'to',\n",
       "  'your',\n",
       "  'fitness',\n",
       "  'plan',\n",
       "  'a_scream',\n",
       "  'à_o_à_',\n",
       "  'climate_change',\n",
       "  'clinical_trial',\n",
       "  'collagen_clinique',\n",
       "  'clip',\n",
       "  'ar'],\n",
       " ['medium',\n",
       "  'ted',\n",
       "  'discourse',\n",
       "  'and',\n",
       "  'climate_change',\n",
       "  'a',\n",
       "  'focus_on',\n",
       "  'political',\n",
       "  'subjectivity',\n",
       "  'and',\n",
       "  'dis',\n",
       "  'engagement'],\n",
       " ['american',\n",
       "  'medium',\n",
       "  'be',\n",
       "  'not',\n",
       "  'put',\n",
       "  'out',\n",
       "  'much',\n",
       "  'on',\n",
       "  'climate_change',\n",
       "  'that',\n",
       "  'be',\n",
       "  'why',\n",
       "  'you_should',\n",
       "  'watch',\n",
       "  'grit',\n",
       "  'be',\n",
       "  'take'],\n",
       " ['american',\n",
       "  'medium',\n",
       "  'be',\n",
       "  'not',\n",
       "  'put',\n",
       "  'out',\n",
       "  'much',\n",
       "  'on',\n",
       "  'climate_change',\n",
       "  'that',\n",
       "  'be',\n",
       "  'why',\n",
       "  'you_should',\n",
       "  'watch',\n",
       "  'grit',\n",
       "  'be',\n",
       "  'take'],\n",
       " ['go',\n",
       "  'big',\n",
       "  'after',\n",
       "  'health_care',\n",
       "  'democrat',\n",
       "  'still',\n",
       "  'plan',\n",
       "  'legislation',\n",
       "  'on',\n",
       "  'bank',\n",
       "  'reform',\n",
       "  'climate_change',\n",
       "  'and',\n",
       "  'immigration'],\n",
       " ['go',\n",
       "  'big',\n",
       "  'after',\n",
       "  'health_care',\n",
       "  'democrat',\n",
       "  'still',\n",
       "  'plan',\n",
       "  'legislation',\n",
       "  'on',\n",
       "  'bank',\n",
       "  'reform',\n",
       "  'climate_change',\n",
       "  'and',\n",
       "  'immigration'],\n",
       " ['superb',\n",
       "  \"valentine's_day\",\n",
       "  'gift',\n",
       "  'for',\n",
       "  'your',\n",
       "  'kitchen',\n",
       "  'a_scream',\n",
       "  'à_o_à_',\n",
       "  'climate_change',\n",
       "  'clinical_trial',\n",
       "  'collagen',\n",
       "  'cli'],\n",
       " ['john',\n",
       "  'fugelsang',\n",
       "  'climate_change',\n",
       "  'and',\n",
       "  'coal',\n",
       "  'go',\n",
       "  'shopping',\n",
       "  'gun',\n",
       "  'advocate',\n",
       "  'rally',\n",
       "  'this_week',\n",
       "  'in',\n",
       "  'support',\n",
       "  'of',\n",
       "  'their',\n",
       "  'rig'],\n",
       " ['so',\n",
       "  'you',\n",
       "  'be',\n",
       "  'a',\n",
       "  'no',\n",
       "  'then',\n",
       "  'on',\n",
       "  'global_warming',\n",
       "  'then',\n",
       "  'and',\n",
       "  'the',\n",
       "  'result_of',\n",
       "  'that'],\n",
       " ['climate_change',\n",
       "  'reporting',\n",
       "  'project',\n",
       "  'involves',\n",
       "  'slate',\n",
       "  'wire',\n",
       "  'pb',\n",
       "  'cir',\n",
       "  'atlantic',\n",
       "  'mother',\n",
       "  'jones'],\n",
       " ['skirmish',\n",
       "  'renew',\n",
       "  'at',\n",
       "  'u',\n",
       "  'global_warming',\n",
       "  'conference',\n",
       "  'climate',\n",
       "  'talk',\n",
       "  'nearly',\n",
       "  'ground',\n",
       "  'to',\n",
       "  'a',\n",
       "  'halt',\n",
       "  'before_they',\n",
       "  'begin',\n",
       "  'in'],\n",
       " ['simple',\n",
       "  'tip',\n",
       "  'for',\n",
       "  'shopping',\n",
       "  'for',\n",
       "  'groove',\n",
       "  'tungsten',\n",
       "  'ring',\n",
       "  'online',\n",
       "  'a',\n",
       "  'climate_change',\n",
       "  'clinical_trial',\n",
       "  'collagen'],\n",
       " ['labour',\n",
       "  'policy',\n",
       "  'environment',\n",
       "  'climate_change',\n",
       "  'and',\n",
       "  'energy',\n",
       "  'policy',\n",
       "  \"labour's\",\n",
       "  'environment',\n",
       "  'energy',\n",
       "  'and',\n",
       "  'climate_change'],\n",
       " ['u',\n",
       "  'climate',\n",
       "  'panel',\n",
       "  'get',\n",
       "  'an',\n",
       "  'an',\n",
       "  'audit',\n",
       "  'of',\n",
       "  'the',\n",
       "  'united_nation',\n",
       "  'landmark',\n",
       "  'climate_change',\n",
       "  'report',\n",
       "  'give',\n",
       "  '21',\n",
       "  'of',\n",
       "  'the',\n",
       "  '44'],\n",
       " ['climate_change', 'and', 'our', 'identity'],\n",
       " ['via',\n",
       "  'kevin',\n",
       "  'drum',\n",
       "  'capitalism',\n",
       "  'and',\n",
       "  'climate_change',\n",
       "  'over',\n",
       "  'at',\n",
       "  'the',\n",
       "  'climate',\n",
       "  'desk',\n",
       "  'clive',\n",
       "  'thompson',\n",
       "  'writes',\n",
       "  'that',\n",
       "  'althoug'],\n",
       " ['what', 'be', 'the', \"people's_world\", 'referendum', 'on', 'climate_change'],\n",
       " ['climate', \"change's\", 'evil', 'twin'],\n",
       " ['itz',\n",
       "  'cold',\n",
       "  'we',\n",
       "  'could',\n",
       "  'put',\n",
       "  'our',\n",
       "  'body',\n",
       "  'together',\n",
       "  'start',\n",
       "  'global_warming'],\n",
       " ['retro',\n",
       "  'video',\n",
       "  'game',\n",
       "  'console',\n",
       "  'for',\n",
       "  \"valentine's_day\",\n",
       "  'gift',\n",
       "  'a_scream',\n",
       "  'à_o_à_',\n",
       "  'climate_change',\n",
       "  'clinical_trial',\n",
       "  'collag'],\n",
       " ['will',\n",
       "  'the',\n",
       "  'iceland_volcano',\n",
       "  'change',\n",
       "  'the',\n",
       "  'climate',\n",
       "  'while',\n",
       "  'volcano',\n",
       "  'can',\n",
       "  'cause',\n",
       "  'change',\n",
       "  'to',\n",
       "  \"earth's\",\n",
       "  'climate',\n",
       "  'recent',\n",
       "  'eruptio'],\n",
       " ['tip',\n",
       "  'for',\n",
       "  'adopt',\n",
       "  'a',\n",
       "  'canine',\n",
       "  'a_scream',\n",
       "  'à_o_à_',\n",
       "  'climate_change',\n",
       "  'clinical_trial',\n",
       "  'collagen_clinique',\n",
       "  'clip_art',\n",
       "  'cl'],\n",
       " ['podcast',\n",
       "  'unrest',\n",
       "  'in',\n",
       "  'thailand',\n",
       "  \"iran's\",\n",
       "  'nuclear',\n",
       "  'summit',\n",
       "  'dc',\n",
       "  'climate_change',\n",
       "  'conference',\n",
       "  'sasc',\n",
       "  'debate',\n",
       "  'ballistic',\n",
       "  'missile',\n",
       "  'defense'],\n",
       " ['internet',\n",
       "  'date',\n",
       "  'a_scream',\n",
       "  'à_o_à_',\n",
       "  'climate_change',\n",
       "  'clinical_trial',\n",
       "  'collagen_clinique',\n",
       "  'clip_art',\n",
       "  'clothes',\n",
       "  'clot'],\n",
       " ['a',\n",
       "  'i',\n",
       "  'say',\n",
       "  'only',\n",
       "  'day',\n",
       "  'ago',\n",
       "  'we',\n",
       "  'will',\n",
       "  'start',\n",
       "  'see',\n",
       "  'much',\n",
       "  'more',\n",
       "  'temper',\n",
       "  'reporting',\n",
       "  'on',\n",
       "  'global_warming',\n",
       "  'start',\n",
       "  'the'],\n",
       " ['food',\n",
       "  'lover',\n",
       "  'fat_loss',\n",
       "  'system',\n",
       "  'review',\n",
       "  'a_scream',\n",
       "  'à_o_à_',\n",
       "  'climate_change',\n",
       "  'clinical_trial',\n",
       "  'collagen_clinique',\n",
       "  'clip'],\n",
       " ['watchdog',\n",
       "  'back',\n",
       "  'dft',\n",
       "  'climate_change',\n",
       "  'advert',\n",
       "  'a',\n",
       "  'clever',\n",
       "  'television',\n",
       "  'advert',\n",
       "  'claim',\n",
       "  'car',\n",
       "  'pollution',\n",
       "  'be',\n",
       "  'the',\n",
       "  'bad'],\n",
       " ['global_warming',\n",
       "  'play',\n",
       "  'decide',\n",
       "  'info',\n",
       "  'discussion',\n",
       "  'game',\n",
       "  'this',\n",
       "  'be',\n",
       "  'a',\n",
       "  'structure',\n",
       "  'discussion',\n",
       "  'in_three',\n",
       "  'stage',\n",
       "  'on',\n",
       "  'global'],\n",
       " ['the',\n",
       "  'tension',\n",
       "  'set',\n",
       "  'wedding',\n",
       "  'ring',\n",
       "  'can',\n",
       "  'be',\n",
       "  'found',\n",
       "  'style',\n",
       "  'to',\n",
       "  'fit',\n",
       "  'every',\n",
       "  'climate_change',\n",
       "  'clinical_trial',\n",
       "  'collagen'],\n",
       " ['state',\n",
       "  'climate_change',\n",
       "  'regulation',\n",
       "  'face',\n",
       "  'opposition',\n",
       "  'à_',\n",
       "  'new',\n",
       "  'mexico',\n",
       "  'turner',\n",
       "  'argue',\n",
       "  'that',\n",
       "  'the',\n",
       "  'issue',\n",
       "  'should',\n",
       "  'be',\n",
       "  'addresse'],\n",
       " ['the',\n",
       "  'advantage',\n",
       "  'of',\n",
       "  'use',\n",
       "  'an',\n",
       "  'elliptical',\n",
       "  'cross',\n",
       "  'trainer',\n",
       "  'before',\n",
       "  'you',\n",
       "  'go',\n",
       "  'climate_change',\n",
       "  'clinical_trial',\n",
       "  'collage'],\n",
       " ['m-edge', 'tour', 'kindle', 'sleeve', 'yellow', 'global_warming', 'advice'],\n",
       " ['the',\n",
       "  'advantage',\n",
       "  'of',\n",
       "  'own',\n",
       "  'a',\n",
       "  'commercial-grade',\n",
       "  'treadmill',\n",
       "  'a',\n",
       "  'climate_change',\n",
       "  'clinical_trial',\n",
       "  'collagen',\n",
       "  'clini'],\n",
       " ['select',\n",
       "  'the',\n",
       "  'proper',\n",
       "  'music',\n",
       "  'for',\n",
       "  'the',\n",
       "  'perfect',\n",
       "  \"valentine's_day\",\n",
       "  'a',\n",
       "  'climate_change',\n",
       "  'clinical_trial',\n",
       "  'collagen'],\n",
       " ['key',\n",
       "  'lesson',\n",
       "  'for',\n",
       "  'married',\n",
       "  'woman',\n",
       "  'look',\n",
       "  'for',\n",
       "  'married',\n",
       "  'a_scream',\n",
       "  'à_o_à_',\n",
       "  'climate_change',\n",
       "  'clinical_trial',\n",
       "  'collagen'],\n",
       " ['can',\n",
       "  'a',\n",
       "  'book',\n",
       "  'on',\n",
       "  'geoengineering',\n",
       "  'change',\n",
       "  'the',\n",
       "  'climate',\n",
       "  'conversation'],\n",
       " ['how',\n",
       "  'people',\n",
       "  'be',\n",
       "  'often',\n",
       "  'find',\n",
       "  'themselves',\n",
       "  'wait',\n",
       "  'in',\n",
       "  'a',\n",
       "  'long',\n",
       "  'line',\n",
       "  'to',\n",
       "  'climate_change',\n",
       "  'clinical_trial',\n",
       "  'collage'],\n",
       " ['basic',\n",
       "  'rule',\n",
       "  'to',\n",
       "  'think',\n",
       "  'about',\n",
       "  'when',\n",
       "  'begin',\n",
       "  'a',\n",
       "  'advertising',\n",
       "  'campaign',\n",
       "  'climate_change',\n",
       "  'clinical_trial',\n",
       "  'collagen'],\n",
       " ['drilling', 'and', 'climate_change'],\n",
       " ['gather',\n",
       "  'info_on',\n",
       "  'how',\n",
       "  'to',\n",
       "  'whiten',\n",
       "  'teeth',\n",
       "  'a_scream',\n",
       "  'à_o_à_',\n",
       "  'climate_change',\n",
       "  'clinical_trial',\n",
       "  'collagen_clinique',\n",
       "  'clip'],\n",
       " ['how',\n",
       "  'to',\n",
       "  'get',\n",
       "  'your',\n",
       "  'ex',\n",
       "  'back',\n",
       "  'a_scream',\n",
       "  'à_o_à_',\n",
       "  'climate_change',\n",
       "  'clinical_trial',\n",
       "  'collagen_clinique',\n",
       "  'clip_art',\n",
       "  'cloth'],\n",
       " ['ask',\n",
       "  'the',\n",
       "  'minister',\n",
       "  'climate_change',\n",
       "  'and',\n",
       "  'energy',\n",
       "  'election',\n",
       "  'debate',\n",
       "  'politics',\n",
       "  'guar'],\n",
       " ['question', 'on', 'climate_change', 'stormfront', 'have', 'an', 'answer'],\n",
       " ['no',\n",
       "  'matter',\n",
       "  'if_you',\n",
       "  'believe_in',\n",
       "  'global_warming',\n",
       "  'or',\n",
       "  'not',\n",
       "  'we_can',\n",
       "  'all',\n",
       "  'do',\n",
       "  'our',\n",
       "  'part',\n",
       "  'to',\n",
       "  'live',\n",
       "  'well',\n",
       "  'and',\n",
       "  'save',\n",
       "  'money',\n",
       "  'resource'],\n",
       " ['best', 'propaganda', 'poster', 'ever'],\n",
       " ['update',\n",
       "  'garp_erp',\n",
       "  'energy',\n",
       "  'news',\n",
       "  'energy_headline',\n",
       "  'police_quiz',\n",
       "  'climate_change',\n",
       "  'sceptic',\n",
       "  'à_',\n",
       "  'ft_bp',\n",
       "  'to',\n",
       "  'press',\n",
       "  'on',\n",
       "  'with'],\n",
       " ['usa', 'sec', 'issue', 'guidance', 'on', 'climate_change', 'disclosure'],\n",
       " ['un',\n",
       "  'agrees',\n",
       "  'to',\n",
       "  'host',\n",
       "  'two_more',\n",
       "  'round',\n",
       "  'of',\n",
       "  'climate_change',\n",
       "  'talk',\n",
       "  'before_summit',\n",
       "  'in_mexico'],\n",
       " ['issue',\n",
       "  '2',\n",
       "  'of',\n",
       "  'wire',\n",
       "  'climate_change',\n",
       "  'now',\n",
       "  'available',\n",
       "  'free',\n",
       "  'online'],\n",
       " ['crunch',\n",
       "  'time',\n",
       "  'for',\n",
       "  'climate_change',\n",
       "  'bill',\n",
       "  'the',\n",
       "  \"hill's\",\n",
       "  'e2',\n",
       "  'wire'],\n",
       " ['senator_prepare', 'compromise', 'climate_change', 'bill', 'yahoo_news'],\n",
       " ['tornado', 'global_warming', 'hurricane'],\n",
       " ['be',\n",
       "  'climate_change',\n",
       "  'a',\n",
       "  'moral',\n",
       "  'issue',\n",
       "  'what',\n",
       "  'would',\n",
       "  'god',\n",
       "  'say',\n",
       "  'green',\n",
       "  'house',\n",
       "  'usatoday.com'],\n",
       " ['aid',\n",
       "  'news',\n",
       "  'copenhagen',\n",
       "  'brought',\n",
       "  'change',\n",
       "  'of',\n",
       "  'climate',\n",
       "  'in',\n",
       "  'sino-india',\n",
       "  'tie',\n",
       "  'ramesh'],\n",
       " [\"npr's\", 'science', 'friday', 'and', 'global_warming'],\n",
       " ['visualization', 'climate_change'],\n",
       " ['to', 'address', 'global_warming', 'skeptic', 'at', '4th', 'iccc'],\n",
       " ['green', 'climate_change', 'wy', 'fellow', 'sierra', 'nevada', 'alliance'],\n",
       " ['green', 'climate_change', 'wy', 'fellow'],\n",
       " ['ezra',\n",
       "  'klein',\n",
       "  'sen',\n",
       "  'lindsey_graham',\n",
       "  'i',\n",
       "  'care',\n",
       "  'equally',\n",
       "  'about',\n",
       "  'immigration',\n",
       "  'and',\n",
       "  'climate_change'],\n",
       " ['climate',\n",
       "  'scientist_sue',\n",
       "  'newspaper_for',\n",
       "  'poison',\n",
       "  'global_warming',\n",
       "  'debate',\n",
       "  'environment',\n",
       "  'guardian.co.uk'],\n",
       " ['garp_erp',\n",
       "  'energy',\n",
       "  'news',\n",
       "  'energy_headline',\n",
       "  'police_quiz',\n",
       "  'climate_change',\n",
       "  'sceptic',\n",
       "  'ft_bp',\n",
       "  'to',\n",
       "  'press',\n",
       "  'on',\n",
       "  'with',\n",
       "  'canada'],\n",
       " ['i',\n",
       "  'never',\n",
       "  'smile',\n",
       "  'because',\n",
       "  'when',\n",
       "  'i',\n",
       "  'do',\n",
       "  'the',\n",
       "  'sun',\n",
       "  'come',\n",
       "  'out',\n",
       "  '2',\n",
       "  'combat',\n",
       "  'global_warming',\n",
       "  'i',\n",
       "  'often',\n",
       "  'refrain',\n",
       "  'from',\n",
       "  'have',\n",
       "  'fun',\n",
       "  'my',\n",
       "  'smile',\n",
       "  'can',\n",
       "  'brighten',\n",
       "  'the',\n",
       "  'day'],\n",
       " ['way',\n",
       "  'the',\n",
       "  'difficult',\n",
       "  'economy',\n",
       "  'have',\n",
       "  'help',\n",
       "  'people',\n",
       "  'focus_on',\n",
       "  'family',\n",
       "  'and',\n",
       "  'climate_change',\n",
       "  'clinical_trial',\n",
       "  'collagen'],\n",
       " ['climate_change',\n",
       "  'bill',\n",
       "  'in_limbo',\n",
       "  'follow',\n",
       "  'white_house',\n",
       "  'push',\n",
       "  'for',\n",
       "  'immigration_reform',\n",
       "  'the',\n",
       "  'bill',\n",
       "  'be',\n",
       "  'not',\n",
       "  'dead',\n",
       "  'but',\n",
       "  'it',\n",
       "  'à_s',\n",
       "  'in'],\n",
       " ['get',\n",
       "  'your',\n",
       "  'dunkin',\n",
       "  'workout',\n",
       "  'plan',\n",
       "  'tenther',\n",
       "  'the',\n",
       "  'simpson',\n",
       "  'macbeth',\n",
       "  'wine',\n",
       "  'country',\n",
       "  'climate_change',\n",
       "  'census',\n",
       "  '2010'],\n",
       " ['it',\n",
       "  'have',\n",
       "  'make',\n",
       "  'frank',\n",
       "  'luntz',\n",
       "  'talk',\n",
       "  'point',\n",
       "  'on',\n",
       "  'climate_change',\n",
       "  'impotent',\n",
       "  'a',\n",
       "  'now',\n",
       "  'the',\n",
       "  'focus',\n",
       "  'be',\n",
       "  'on',\n",
       "  'immigration_reform',\n",
       "  'great',\n",
       "  'job'],\n",
       " ['lindsey',\n",
       "  'be',\n",
       "  'out',\n",
       "  'only',\n",
       "  'gop',\n",
       "  'sponsor',\n",
       "  'jump',\n",
       "  'ship',\n",
       "  'from',\n",
       "  \"obama's\",\n",
       "  'climate_change',\n",
       "  'bill'],\n",
       " ['veteran',\n",
       "  'climate',\n",
       "  'activist',\n",
       "  'asks',\n",
       "  'for',\n",
       "  'name',\n",
       "  'change',\n",
       "  'for',\n",
       "  'earth'],\n",
       " ['trigger',\n",
       "  'number',\n",
       "  'online',\n",
       "  'roulette',\n",
       "  'scam',\n",
       "  'a_scream',\n",
       "  'à_o_à_',\n",
       "  'climate_change',\n",
       "  'clinical_trial',\n",
       "  'collagen_clinique',\n",
       "  'cl'],\n",
       " ['climate',\n",
       "  'scientist_sue',\n",
       "  'newspaper_for',\n",
       "  'à_poisoning',\n",
       "  'à_',\n",
       "  'global_warming',\n",
       "  'debate'],\n",
       " ['politico',\n",
       "  \"graham's\",\n",
       "  'own',\n",
       "  'private',\n",
       "  'climate_change',\n",
       "  'glenn',\n",
       "  'thrush',\n",
       "  \"graham's\",\n",
       "  'own',\n",
       "  'private',\n",
       "  'climatechange'],\n",
       " ['democratic',\n",
       "  'leader',\n",
       "  'move',\n",
       "  'immigration',\n",
       "  'bill',\n",
       "  'ahead',\n",
       "  'of',\n",
       "  'climate_change',\n",
       "  'a',\n",
       "  'a',\n",
       "  'senate',\n",
       "  'priority',\n",
       "  'washington',\n",
       "  'ap',\n",
       "  'à_',\n",
       "  'senate',\n",
       "  'ma'],\n",
       " ['keep',\n",
       "  'a',\n",
       "  'migraine',\n",
       "  'at',\n",
       "  'bay',\n",
       "  'a_scream',\n",
       "  'à_o_à_',\n",
       "  'climate_change',\n",
       "  'clinical_trial',\n",
       "  'collagen_clinique',\n",
       "  'clip_art',\n",
       "  'clo'],\n",
       " ['climate',\n",
       "  'scientist_sue',\n",
       "  'newspaper_for',\n",
       "  'poison',\n",
       "  'global_warming',\n",
       "  'debate'],\n",
       " ['in',\n",
       "  'a',\n",
       "  'half',\n",
       "  'hour',\n",
       "  'carol_browner',\n",
       "  'assistant',\n",
       "  'to',\n",
       "  'the',\n",
       "  'president',\n",
       "  'for',\n",
       "  'energy',\n",
       "  'climate_change',\n",
       "  'will',\n",
       "  'answer',\n",
       "  'question',\n",
       "  'live'],\n",
       " ['can', 'you', 'hedge', 'against', 'climate_change', 'read', 'this'],\n",
       " ['how',\n",
       "  'do',\n",
       "  'i',\n",
       "  'wind',\n",
       "  'up',\n",
       "  'on',\n",
       "  'list',\n",
       "  'call',\n",
       "  'global-warming-frauds',\n",
       "  'douchebags-nuff-said',\n",
       "  'and',\n",
       "  'dilusional',\n",
       "  'sic',\n",
       "  'ho-s-that-hate'],\n",
       " ['global_warming', 'fact', 'or', 'myth', 'daily', 'green'],\n",
       " ['kerry',\n",
       "  'release',\n",
       "  'climate_change',\n",
       "  'law',\n",
       "  'this_week',\n",
       "  'how',\n",
       "  'do',\n",
       "  'it',\n",
       "  'affect',\n",
       "  'the',\n",
       "  'sector',\n",
       "  'find',\n",
       "  'out',\n",
       "  'by',\n",
       "  'reading',\n",
       "  'the',\n",
       "  'week',\n",
       "  'in',\n",
       "  'green',\n",
       "  'energy'],\n",
       " [\"here's\",\n",
       "  'a',\n",
       "  'link',\n",
       "  'to',\n",
       "  'the',\n",
       "  'volcano',\n",
       "  'lt',\n",
       "  'gt',\n",
       "  'global_warming',\n",
       "  'story'],\n",
       " ['i_think',\n",
       "  'it',\n",
       "  'will',\n",
       "  'be',\n",
       "  'the',\n",
       "  'man',\n",
       "  'that',\n",
       "  'control',\n",
       "  'global_warming',\n",
       "  'be',\n",
       "  'racist'],\n",
       " ['what',\n",
       "  'i',\n",
       "  'lean',\n",
       "  'this_week',\n",
       "  'global_warming',\n",
       "  'famine',\n",
       "  'nuclear',\n",
       "  'annihilation',\n",
       "  'no',\n",
       "  'threat',\n",
       "  'to',\n",
       "  'humanity',\n",
       "  'be',\n",
       "  'more',\n",
       "  'dangerous',\n",
       "  'than',\n",
       "  'the',\n",
       "  'double',\n",
       "  'down'],\n",
       " ['calif',\n",
       "  'trucking',\n",
       "  'assn',\n",
       "  'join',\n",
       "  'fight',\n",
       "  'to_suspend',\n",
       "  \"state's\",\n",
       "  'climate-change',\n",
       "  'law',\n",
       "  'enewspm',\n",
       "  'climatechange'],\n",
       " ['birthers',\n",
       "  'global_warming',\n",
       "  'denier',\n",
       "  'young-earth',\n",
       "  'creationists',\n",
       "  'and',\n",
       "  'neil',\n",
       "  'armstrong',\n",
       "  'complains',\n",
       "  'about',\n",
       "  'obama',\n",
       "  'à_s',\n",
       "  'nasa',\n",
       "  'budget'],\n",
       " ['hill', 'crunch', 'time', 'for', 'climate_change', 'bill'],\n",
       " ['will',\n",
       "  'supreme',\n",
       "  'court',\n",
       "  'nomination',\n",
       "  'bump',\n",
       "  'climate_change',\n",
       "  'debate',\n",
       "  'into',\n",
       "  'next',\n",
       "  'year'],\n",
       " ['a_religious', 'take', 'on', 'climate_change'],\n",
       " ['great', 'tom', 'tole', 'climate_change', 'cartoon'],\n",
       " ['one',\n",
       "  'hot',\n",
       "  'topic',\n",
       "  '12',\n",
       "  'web',\n",
       "  'site',\n",
       "  'about',\n",
       "  'global_warming',\n",
       "  'by',\n",
       "  'gail',\n",
       "  'junion-metz',\n",
       "  'school',\n",
       "  'library',\n",
       "  'journal',\n",
       "  '5/1',\n",
       "  '2010',\n",
       "  'this'],\n",
       " ['los_angeles', 'a_religious', 'spin', 'on', 'climate_change'],\n",
       " ['initiative',\n",
       "  'campaign',\n",
       "  'to_suspend',\n",
       "  'global_warming',\n",
       "  'law',\n",
       "  'ab32',\n",
       "  'report',\n",
       "  '973k',\n",
       "  'raise',\n",
       "  '500k',\n",
       "  'from',\n",
       "  'oil',\n",
       "  'comp',\n",
       "  'valero'],\n",
       " ['panel',\n",
       "  'debate',\n",
       "  'business',\n",
       "  'cost_of',\n",
       "  'calif',\n",
       "  'global_warming',\n",
       "  'law',\n",
       "  'san',\n",
       "  'diego',\n",
       "  'panelist',\n",
       "  'debate',\n",
       "  'the',\n",
       "  'economic',\n",
       "  'merit',\n",
       "  'of'],\n",
       " ['really', 'wtf', 'global_warming'],\n",
       " ['do',\n",
       "  'northrop',\n",
       "  'bob',\n",
       "  'grumman',\n",
       "  'mcdonnell',\n",
       "  'believe_in',\n",
       "  'global_warming',\n",
       "  'by',\n",
       "  'david',\n",
       "  'swanson',\n",
       "  'about',\n",
       "  'the',\n",
       "  'author',\n",
       "  'page',\n",
       "  '1',\n",
       "  'of',\n",
       "  '1',\n",
       "  'pa'],\n",
       " ['saarc', 'plan', 'expert', 'group', 'on', 'climate_change'],\n",
       " ['libertarian',\n",
       "  'may',\n",
       "  'debate',\n",
       "  'the',\n",
       "  'merit',\n",
       "  'of',\n",
       "  'global_warming',\n",
       "  'but',\n",
       "  'not',\n",
       "  'the',\n",
       "  'worthiness',\n",
       "  'of',\n",
       "  'an',\n",
       "  'emission',\n",
       "  'market'],\n",
       " ['hide',\n",
       "  'the',\n",
       "  'decline',\n",
       "  'global_warming',\n",
       "  'video',\n",
       "  'creator',\n",
       "  'say',\n",
       "  'mann',\n",
       "  'backlash',\n",
       "  'effort',\n",
       "  'to',\n",
       "  'if_you',\n",
       "  'try_to',\n",
       "  'sweep',\n",
       "  'your',\n",
       "  'problem'],\n",
       " ['some',\n",
       "  'advice',\n",
       "  'on',\n",
       "  'how',\n",
       "  'to',\n",
       "  'avoid',\n",
       "  'your',\n",
       "  'partner',\n",
       "  'get_involve',\n",
       "  'in',\n",
       "  'climate_change',\n",
       "  'clinical_trial',\n",
       "  'collagen'],\n",
       " ['industry',\n",
       "  'insider',\n",
       "  'michaelangelo',\n",
       "  \"l'acqua\",\n",
       "  'global_warming',\n",
       "  'when',\n",
       "  'michaelangelo',\n",
       "  \"l'acqua\",\n",
       "  'first',\n",
       "  'enter',\n",
       "  'the',\n",
       "  'high',\n",
       "  'stake'],\n",
       " ['save',\n",
       "  'the',\n",
       "  'hollywood',\n",
       "  'sign',\n",
       "  'ballot_initiative',\n",
       "  'iceland',\n",
       "  'à_s',\n",
       "  'volcano',\n",
       "  'and',\n",
       "  'global_warming'],\n",
       " ['letter',\n",
       "  'global_warming',\n",
       "  'in',\n",
       "  \"god's\",\n",
       "  'hand',\n",
       "  'à_',\n",
       "  'knoxville',\n",
       "  'news',\n",
       "  'sentinel'],\n",
       " ['long-term', 'fortune', 'favour', 'the', 'brave', 'on', 'climate_change'],\n",
       " ['dedication',\n",
       "  'and',\n",
       "  'persistence',\n",
       "  'necessary',\n",
       "  'for',\n",
       "  'homegrown',\n",
       "  'hydroponics',\n",
       "  'a',\n",
       "  'climate_change',\n",
       "  'clinical_trial',\n",
       "  'collag'],\n",
       " ['news',\n",
       "  'break',\n",
       "  'story',\n",
       "  'reid',\n",
       "  'set',\n",
       "  'to',\n",
       "  'move',\n",
       "  'on',\n",
       "  'climate_change',\n",
       "  'bill',\n",
       "  'ahead',\n",
       "  'of',\n",
       "  'immigration'],\n",
       " ['global_warming',\n",
       "  'retreat',\n",
       "  'à_',\n",
       "  'except',\n",
       "  'for',\n",
       "  \"california's\",\n",
       "  'government',\n",
       "  'the',\n",
       "  'state',\n",
       "  'air',\n",
       "  'board',\n",
       "  'in',\n",
       "  'it',\n",
       "  'wisdom',\n",
       "  'continue',\n",
       "  'to',\n",
       "  'advanc'],\n",
       " ['only',\n",
       "  '12',\n",
       "  'of',\n",
       "  'american',\n",
       "  'be',\n",
       "  'very',\n",
       "  'worried',\n",
       "  'about',\n",
       "  'global_warming',\n",
       "  'a',\n",
       "  'make',\n",
       "  'it_case',\n",
       "  'on',\n",
       "  'climate_change'],\n",
       " ['immigration_reform',\n",
       "  'and',\n",
       "  'climate_change',\n",
       "  'a_tale',\n",
       "  'of',\n",
       "  'two_issue',\n",
       "  'in',\n",
       "  'the',\n",
       "  'senate'],\n",
       " ['uiy',\n",
       "  'kerry',\n",
       "  'action',\n",
       "  'on',\n",
       "  'climate',\n",
       "  'bill',\n",
       "  'remains',\n",
       "  'likely',\n",
       "  'ap_):',\n",
       "  'ap',\n",
       "  'the',\n",
       "  'democratic',\n",
       "  'sponsor',\n",
       "  'of',\n",
       "  'climate_change',\n",
       "  'legisl'],\n",
       " ['global_warming',\n",
       "  'be',\n",
       "  'james_cameron',\n",
       "  'a_genocidal',\n",
       "  'maniac',\n",
       "  'by',\n",
       "  'john',\n",
       "  'nolte',\n",
       "  'either',\n",
       "  'james_cameron',\n",
       "  'be',\n",
       "  'a_genocidal',\n",
       "  'maniac',\n",
       "  'or'],\n",
       " ['brooke_shield',\n",
       "  'annoyed',\n",
       "  'with',\n",
       "  'global_warming',\n",
       "  'do_not',\n",
       "  'exist',\n",
       "  'report'],\n",
       " ['should',\n",
       "  'we',\n",
       "  'focus',\n",
       "  'our',\n",
       "  'energy',\n",
       "  'on',\n",
       "  'climate_change',\n",
       "  'before',\n",
       "  'immigration',\n",
       "  'via',\n",
       "  'goodasks'],\n",
       " ['a_tale',\n",
       "  'of',\n",
       "  '2',\n",
       "  'issue',\n",
       "  'why',\n",
       "  'immigration_reform',\n",
       "  'be',\n",
       "  'get',\n",
       "  'more',\n",
       "  'traction',\n",
       "  'than',\n",
       "  'climate_change',\n",
       "  'in',\n",
       "  'senate'],\n",
       " ['immigration_reform',\n",
       "  'and',\n",
       "  'climate_change',\n",
       "  'a_tale',\n",
       "  'of',\n",
       "  'two_issue',\n",
       "  'in',\n",
       "  'the',\n",
       "  'senate'],\n",
       " ['climb',\n",
       "  'out',\n",
       "  'of',\n",
       "  'the',\n",
       "  'dark',\n",
       "  'social',\n",
       "  'justice',\n",
       "  'replaces',\n",
       "  'global_warming',\n",
       "  'climate_change',\n",
       "  'hang',\n",
       "  'on',\n",
       "  'by',\n",
       "  'it',\n",
       "  'be',\n",
       "  'fingernail',\n",
       "  '. ...'],\n",
       " [\"i'd\",\n",
       "  'like',\n",
       "  'to',\n",
       "  'know',\n",
       "  'who',\n",
       "  'give',\n",
       "  'a',\n",
       "  \"rat's\",\n",
       "  'as',\n",
       "  'if',\n",
       "  'immigration',\n",
       "  'come',\n",
       "  'before',\n",
       "  'climate_change',\n",
       "  'do',\n",
       "  'your',\n",
       "  'job',\n",
       "  'regardless',\n",
       "  'of',\n",
       "  'order',\n",
       "  'childrenactbetter'],\n",
       " ['brooke_shield',\n",
       "  'upset_with',\n",
       "  'report',\n",
       "  'that',\n",
       "  'global_warming',\n",
       "  'do_not',\n",
       "  'exist'],\n",
       " ['that',\n",
       "  'actual',\n",
       "  'provide',\n",
       "  'utilize',\n",
       "  'automatic',\n",
       "  'global',\n",
       "  'trade',\n",
       "  'swap',\n",
       "  'a',\n",
       "  'climate_change',\n",
       "  'clinical_trial',\n",
       "  'collage'],\n",
       " ['brooke_shield',\n",
       "  'upset_with',\n",
       "  'report',\n",
       "  'that',\n",
       "  'global_warming',\n",
       "  'do_not',\n",
       "  'exist',\n",
       "  'foxnews',\n",
       "  'by',\n",
       "  'hollie',\n",
       "  'mckay',\n",
       "  'the',\n",
       "  'subject',\n",
       "  'of',\n",
       "  'global'],\n",
       " ['environmental_economics',\n",
       "  'note',\n",
       "  'to',\n",
       "  'environmentalist',\n",
       "  'part',\n",
       "  'ii',\n",
       "  'the',\n",
       "  'climate_change',\n",
       "  'bill',\n",
       "  'that',\n",
       "  'be',\n",
       "  'suppose',\n",
       "  'to',\n",
       "  'be',\n",
       "  'unveil'],\n",
       " ['podcast', 'climate_change', 'immigration_reform', 'and', 'california'],\n",
       " ['geoff',\n",
       "  'jenkins',\n",
       "  'chairman',\n",
       "  'of',\n",
       "  'the',\n",
       "  'united_nation',\n",
       "  'intergovernmental_panel',\n",
       "  'on',\n",
       "  'climate_change'],\n",
       " ['retuning',\n",
       "  'of',\n",
       "  'love',\n",
       "  'a_scream',\n",
       "  'à_o_à_',\n",
       "  'climate_change',\n",
       "  'clinical_trial',\n",
       "  'collagen_clinique',\n",
       "  'clip_art',\n",
       "  'clothes',\n",
       "  'clo'],\n",
       " ['fox_news',\n",
       "  'watch',\n",
       "  'cite',\n",
       "  'medium',\n",
       "  'research',\n",
       "  'center',\n",
       "  'study',\n",
       "  'on',\n",
       "  'global_warming',\n",
       "  'coverage'],\n",
       " ['fox_news',\n",
       "  'watch',\n",
       "  'cite',\n",
       "  'medium',\n",
       "  'research',\n",
       "  'center',\n",
       "  'study',\n",
       "  'on',\n",
       "  'global_warming',\n",
       "  'coverage',\n",
       "  'by',\n",
       "  'kyle',\n",
       "  'drennen',\n",
       "  'bio',\n",
       "  'archive',\n",
       "  'on',\n",
       "  'sa'],\n",
       " [\"graham's_exit\", 'put', 'climate_change', 'bill', 'in_limbo'],\n",
       " ['soccer',\n",
       "  'fever',\n",
       "  'hit',\n",
       "  'namibia',\n",
       "  'on',\n",
       "  'global_warming',\n",
       "  'by',\n",
       "  'carlos',\n",
       "  'kambaekwa',\n",
       "  'new',\n",
       "  'era',\n",
       "  'omuthiya',\n",
       "  'the',\n",
       "  'chairman',\n",
       "  'of',\n",
       "  'the',\n",
       "  'nfa',\n",
       "  'oshi'],\n",
       " ['via',\n",
       "  'cnnbrk',\n",
       "  \"graham's_exit\",\n",
       "  'from_talk',\n",
       "  'put',\n",
       "  'climate_change',\n",
       "  'bill',\n",
       "  'in_limbo'],\n",
       " [\"graham's_exit\",\n",
       "  'from_talk',\n",
       "  'put',\n",
       "  'climate_change',\n",
       "  'bill',\n",
       "  'in_limbo',\n",
       "  'a',\n",
       "  'climate-change_bill',\n",
       "  'that',\n",
       "  'be',\n",
       "  'schedule_to',\n",
       "  'be',\n",
       "  'unvei'],\n",
       " ['adventure',\n",
       "  'in',\n",
       "  'epistemic',\n",
       "  'opening',\n",
       "  'mark',\n",
       "  'levin',\n",
       "  'jim',\n",
       "  'manzi',\n",
       "  'on',\n",
       "  'global_warming',\n",
       "  'the',\n",
       "  'fancy',\n",
       "  'phrase',\n",
       "  'à_epistemic',\n",
       "  'closure',\n",
       "  'à_'],\n",
       " ['senate_dispute',\n",
       "  'put',\n",
       "  'climate',\n",
       "  'legislation',\n",
       "  'on_hold',\n",
       "  'associate',\n",
       "  'press',\n",
       "  'washington',\n",
       "  'long-awaited',\n",
       "  'climate_change'],\n",
       " ['global_warming',\n",
       "  'the',\n",
       "  'oxburgh',\n",
       "  'inquiry',\n",
       "  'be',\n",
       "  'an',\n",
       "  'offer',\n",
       "  'he',\n",
       "  'could',\n",
       "  'not',\n",
       "  'refuse',\n",
       "  'when',\n",
       "  'lord',\n",
       "  'oxburgh',\n",
       "  'be',\n",
       "  'request',\n",
       "  'to',\n",
       "  'chair',\n",
       "  'the'],\n",
       " ['gawker',\n",
       "  'logic_report',\n",
       "  \"lindsey_graham's\",\n",
       "  'climate_change',\n",
       "  'bill_flip-flop',\n",
       "  'polidicks',\n",
       "  ']:',\n",
       "  'à_'],\n",
       " ['a',\n",
       "  'simple',\n",
       "  'guide',\n",
       "  'to',\n",
       "  'head',\n",
       "  'shave',\n",
       "  'a_scream',\n",
       "  'à_o_à_',\n",
       "  'climate_change',\n",
       "  'clinical_trial',\n",
       "  'collagen_clinique',\n",
       "  'clip_art'],\n",
       " ['uiy',\n",
       "  'climate',\n",
       "  'bill_place',\n",
       "  'on_hold',\n",
       "  'over_senate',\n",
       "  'dispute_ap',\n",
       "  '):_ap',\n",
       "  'long-awaited',\n",
       "  'climate_change',\n",
       "  'legislation',\n",
       "  'be'],\n",
       " ['climate',\n",
       "  'bill_place',\n",
       "  'on_hold',\n",
       "  'over_senate',\n",
       "  'dispute',\n",
       "  'washington',\n",
       "  'long-awaited',\n",
       "  'climate_change',\n",
       "  'legislation',\n",
       "  'be',\n",
       "  'put',\n",
       "  'on'],\n",
       " ['american',\n",
       "  'dont',\n",
       "  'give',\n",
       "  'a',\n",
       "  'about',\n",
       "  'global_warming',\n",
       "  'survey',\n",
       "  'say',\n",
       "  'retail',\n",
       "  'investor',\n",
       "  'from',\n",
       "  'city',\n",
       "  'other',\n",
       "  'than',\n",
       "  'in',\n",
       "  'the',\n",
       "  'u',\n",
       "  'fe'],\n",
       " ['will',\n",
       "  'indigenous_people',\n",
       "  'be',\n",
       "  'include',\n",
       "  'in',\n",
       "  'un',\n",
       "  'climate_change',\n",
       "  'policy'],\n",
       " ['via',\n",
       "  'cnnbrk',\n",
       "  'sen',\n",
       "  \"graham's\",\n",
       "  'move_imperils',\n",
       "  'dems',\n",
       "  'push',\n",
       "  'for',\n",
       "  'immigration',\n",
       "  'climate_change',\n",
       "  'bill'],\n",
       " ['thr',\n",
       "  'climate',\n",
       "  'bill',\n",
       "  'give',\n",
       "  'polluter',\n",
       "  'and',\n",
       "  'nuclear',\n",
       "  'break',\n",
       "  'washington_reuters',\n",
       "  'the',\n",
       "  'u',\n",
       "  'climate_change',\n",
       "  'bill',\n",
       "  'expect'],\n",
       " ['global_warming',\n",
       "  'the',\n",
       "  'new',\n",
       "  'ombudsman',\n",
       "  'eurasia',\n",
       "  'review',\n",
       "  'by',\n",
       "  'sonali',\n",
       "  'huria',\n",
       "  'for',\n",
       "  'ipcs',\n",
       "  'global_warming',\n",
       "  'have',\n",
       "  'purportedly',\n",
       "  'put'],\n",
       " ['just',\n",
       "  'read',\n",
       "  'your',\n",
       "  'blog',\n",
       "  'and',\n",
       "  '1',\n",
       "  'awesome',\n",
       "  '2',\n",
       "  'who',\n",
       "  'hold',\n",
       "  'a',\n",
       "  'climate_change',\n",
       "  'conference',\n",
       "  'in',\n",
       "  'cancun'],\n",
       " ['brochure',\n",
       "  'on',\n",
       "  'global_warming',\n",
       "  '1992',\n",
       "  'brochure',\n",
       "  'on',\n",
       "  'global_warming',\n",
       "  '1992',\n",
       "  'add',\n",
       "  'by',\n",
       "  'neham',\n",
       "  '0',\n",
       "  'comment'],\n",
       " ['fat_loss',\n",
       "  'program',\n",
       "  'a_scream',\n",
       "  'à_o_à_',\n",
       "  'climate_change',\n",
       "  'clinical_trial',\n",
       "  'collagen_clinique',\n",
       "  'clip_art',\n",
       "  'clothes',\n",
       "  'clo'],\n",
       " ['washington',\n",
       "  'the',\n",
       "  'term',\n",
       "  'green',\n",
       "  'movement',\n",
       "  'be',\n",
       "  'not',\n",
       "  'yet',\n",
       "  'in',\n",
       "  'vogue',\n",
       "  'and',\n",
       "  'there_be',\n",
       "  'little',\n",
       "  'talk',\n",
       "  'of',\n",
       "  'combat',\n",
       "  'global_warming'],\n",
       " ['tff',\n",
       "  '2010',\n",
       "  'jessica',\n",
       "  'alba',\n",
       "  'brian',\n",
       "  'hill',\n",
       "  'talk',\n",
       "  'climate',\n",
       "  'of',\n",
       "  'change'],\n",
       " ['native',\n",
       "  'gather',\n",
       "  'in',\n",
       "  'bolivia',\n",
       "  'to',\n",
       "  'criticize',\n",
       "  'copenhagen',\n",
       "  'club'],\n",
       " ['money',\n",
       "  'the',\n",
       "  'graham-kerry-lieberman',\n",
       "  'global_warming',\n",
       "  'bill',\n",
       "  'face',\n",
       "  'a',\n",
       "  'hostile',\n",
       "  'climate',\n",
       "  'world',\n",
       "  'magazine',\n",
       "  'ap',\n",
       "  'photo',\n",
       "  'by',\n",
       "  'har'],\n",
       " ['washington',\n",
       "  'there_be',\n",
       "  'no',\n",
       "  'green',\n",
       "  'movement',\n",
       "  'yet',\n",
       "  'and',\n",
       "  'little',\n",
       "  'talk',\n",
       "  'of',\n",
       "  'global_warming'],\n",
       " ['check_this', 'video', 'out', 'george', 'carlin', 'on', 'global_warming'],\n",
       " ['realclearpolitics',\n",
       "  'global_warming',\n",
       "  'panic',\n",
       "  'attack',\n",
       "  'with',\n",
       "  'the',\n",
       "  'senate',\n",
       "  'about',\n",
       "  'to',\n",
       "  'begin',\n",
       "  'a',\n",
       "  'long-awaited',\n",
       "  'debate',\n",
       "  'over',\n",
       "  'energy'],\n",
       " ['guardian',\n",
       "  'climate',\n",
       "  'scientist_sue',\n",
       "  'newspaper_for',\n",
       "  'poison',\n",
       "  'global_warming',\n",
       "  'debate'],\n",
       " ['live',\n",
       "  'chapmanu',\n",
       "  'climate',\n",
       "  'conference',\n",
       "  'excite',\n",
       "  'climate',\n",
       "  'debate',\n",
       "  'come',\n",
       "  'up',\n",
       "  'at',\n",
       "  '4:30',\n",
       "  'cause',\n",
       "  'pf',\n",
       "  'climate_change'],\n",
       " ['look_like',\n",
       "  'some',\n",
       "  'ppl',\n",
       "  'just',\n",
       "  'give',\n",
       "  'some',\n",
       "  'more',\n",
       "  'fuel',\n",
       "  'to_slow',\n",
       "  'down',\n",
       "  'the',\n",
       "  'california',\n",
       "  'global_warming',\n",
       "  'law',\n",
       "  'ab32'],\n",
       " ['in',\n",
       "  'november',\n",
       "  'of',\n",
       "  '2008',\n",
       "  'i',\n",
       "  'really',\n",
       "  'would',\n",
       "  'not',\n",
       "  'have',\n",
       "  'predict',\n",
       "  'that',\n",
       "  'immigration_reform',\n",
       "  'might',\n",
       "  'move',\n",
       "  'before',\n",
       "  'climate-change_legislation',\n",
       "  'via'],\n",
       " ['global_warming',\n",
       "  'probability',\n",
       "  'poll',\n",
       "  'update',\n",
       "  'ocregister',\n",
       "  'blog',\n",
       "  'and',\n",
       "  'my',\n",
       "  'favorite',\n",
       "  '39',\n",
       "  'time',\n",
       "  'a',\n",
       "  'many',\n",
       "  'people',\n",
       "  'believe',\n",
       "  'our',\n",
       "  'bel'],\n",
       " ['photo',\n",
       "  'protester',\n",
       "  'take',\n",
       "  'on',\n",
       "  'valero',\n",
       "  'over',\n",
       "  'initiative',\n",
       "  'that',\n",
       "  'would',\n",
       "  'change',\n",
       "  \"california's\",\n",
       "  'landmark',\n",
       "  'climate',\n",
       "  'bill'],\n",
       " ['laist',\n",
       "  'protester',\n",
       "  'take',\n",
       "  'on',\n",
       "  'valero',\n",
       "  'over',\n",
       "  'initiative',\n",
       "  'that',\n",
       "  'would',\n",
       "  'change',\n",
       "  \"california's\",\n",
       "  'landmark',\n",
       "  'climate',\n",
       "  'bill',\n",
       "  'à_',\n",
       "  'à_',\n",
       "  'à_',\n",
       "  'à_',\n",
       "  'à_',\n",
       "  'à_',\n",
       "  'à_for'],\n",
       " ['co-host',\n",
       "  'meredith',\n",
       "  'vieira',\n",
       "  'talk',\n",
       "  'about',\n",
       "  'global_warming',\n",
       "  'on',\n",
       "  'nbc',\n",
       "  'à_s',\n",
       "  'today',\n",
       "  'january',\n",
       "  '8',\n",
       "  '2007'],\n",
       " ['campaign',\n",
       "  'asa',\n",
       "  'dismisses',\n",
       "  'complaint_against',\n",
       "  'dft',\n",
       "  'climate_change',\n",
       "  'ad',\n",
       "  'london',\n",
       "  'the',\n",
       "  'advertising',\n",
       "  'standard',\n",
       "  'authority',\n",
       "  'a'],\n",
       " [\"i'm\",\n",
       "  'do',\n",
       "  'my',\n",
       "  'part',\n",
       "  'in',\n",
       "  'contribute',\n",
       "  'to',\n",
       "  'both',\n",
       "  'global_warming',\n",
       "  'and',\n",
       "  'depletion',\n",
       "  'of',\n",
       "  'the',\n",
       "  'ozone',\n",
       "  'layer',\n",
       "  \"i'm\",\n",
       "  'hot',\n",
       "  'and',\n",
       "  'sometimes',\n",
       "  'i',\n",
       "  'fart'],\n",
       " ['from',\n",
       "  'the',\n",
       "  'christian',\n",
       "  'post',\n",
       "  'methodist',\n",
       "  'clergy',\n",
       "  'listens',\n",
       "  'to',\n",
       "  'member',\n",
       "  'on',\n",
       "  'climate_change'],\n",
       " ['pls',\n",
       "  'smile',\n",
       "  'ok',\n",
       "  'climate_change',\n",
       "  'and',\n",
       "  'human_health',\n",
       "  'study',\n",
       "  'bethesda',\n",
       "  'md',\n",
       "  'april_22',\n",
       "  'upi',\n",
       "  'the',\n",
       "  'u',\n",
       "  'national',\n",
       "  'insti'],\n",
       " ['climate',\n",
       "  'of',\n",
       "  'change',\n",
       "  'film',\n",
       "  'festival',\n",
       "  'and',\n",
       "  'on',\n",
       "  'demand',\n",
       "  'earthday',\n",
       "  'p2'],\n",
       " ['brandrep',\n",
       "  'asa',\n",
       "  'dismisses',\n",
       "  'complaint_against',\n",
       "  'dft',\n",
       "  'climate_change',\n",
       "  'ad',\n",
       "  'london',\n",
       "  'the',\n",
       "  'advertising',\n",
       "  'standard',\n",
       "  'authority',\n",
       "  'a'],\n",
       " ['climate',\n",
       "  'scientist_sue',\n",
       "  'newspaper_for',\n",
       "  'poison',\n",
       "  'global_warming',\n",
       "  'debate',\n",
       "  'andrew',\n",
       "  'weaver',\n",
       "  'with',\n",
       "  'the',\n",
       "  \"ipcc's\",\n",
       "  '2007',\n",
       "  'report'],\n",
       " ['state', 'anti-global', 'warming', 'bill', 'probably', 'dead'],\n",
       " ['do_not',\n",
       "  'be',\n",
       "  'swayed',\n",
       "  'by',\n",
       "  'distraction',\n",
       "  'of',\n",
       "  'climate_change',\n",
       "  'treat',\n",
       "  'earth',\n",
       "  'responsibly',\n",
       "  'earthday'],\n",
       " [\"state's\",\n",
       "  'global_warming',\n",
       "  'bill',\n",
       "  'may',\n",
       "  'not',\n",
       "  'have',\n",
       "  'vote',\n",
       "  'to',\n",
       "  'pas',\n",
       "  'madison',\n",
       "  'wi',\n",
       "  'wtaq',\n",
       "  'there',\n",
       "  'might',\n",
       "  'not',\n",
       "  'be',\n",
       "  'enough',\n",
       "  'vote',\n",
       "  'in'],\n",
       " ['solar', 'activity', 'and', 'climate_change'],\n",
       " ['video', 'larry_brilliant', 'on', 'the', 'volcano', 'and', 'climate_change'],\n",
       " ['global_warming',\n",
       "  'bill',\n",
       "  'likely',\n",
       "  'dead',\n",
       "  'by',\n",
       "  'jason',\n",
       "  'stein',\n",
       "  'and',\n",
       "  'patrick',\n",
       "  'marley',\n",
       "  'of',\n",
       "  'the',\n",
       "  'journal',\n",
       "  'sentinel',\n",
       "  'madison',\n",
       "  'à_',\n",
       "  'a',\n",
       "  'bill',\n",
       "  'to',\n",
       "  'cut'],\n",
       " ['fishing',\n",
       "  'from',\n",
       "  'the',\n",
       "  'other',\n",
       "  'side',\n",
       "  'of',\n",
       "  'the',\n",
       "  'boat',\n",
       "  'creation',\n",
       "  'sunday',\n",
       "  'sermon',\n",
       "  'on',\n",
       "  'christianity',\n",
       "  'and',\n",
       "  'global_warming'],\n",
       " ['get',\n",
       "  'into',\n",
       "  'hot',\n",
       "  'water',\n",
       "  'evangelicals',\n",
       "  'and',\n",
       "  'global_warming',\n",
       "  'by',\n",
       "  'benjamin',\n",
       "  'phillips',\n",
       "  'since',\n",
       "  '2000',\n",
       "  'various',\n",
       "  'evangelical',\n",
       "  'gr'],\n",
       " ['global_warming', 'mobile', 'phone'],\n",
       " ['bet_on', 'climate_change'],\n",
       " ['volcanic_eruption',\n",
       "  'global_warming',\n",
       "  '::',\n",
       "  'lacerta',\n",
       "  'knew',\n",
       "  'he',\n",
       "  'imperforate',\n",
       "  'to',\n",
       "  'go',\n",
       "  'to',\n",
       "  'milwaukee',\n",
       "  'to',\n",
       "  'suavely',\n",
       "  'be',\n",
       "  'centrifugal',\n",
       "  'to',\n",
       "  'er'],\n",
       " ['wed',\n",
       "  '4/21',\n",
       "  'chapmanu',\n",
       "  'climate_change',\n",
       "  'confab',\n",
       "  'open',\n",
       "  'film',\n",
       "  'nite',\n",
       "  'at',\n",
       "  'knott',\n",
       "  'studio',\n",
       "  '7pm',\n",
       "  'into',\n",
       "  'the',\n",
       "  'arctic',\n",
       "  'living',\n",
       "  'sea',\n",
       "  'free'],\n",
       " ['ok',\n",
       "  'that',\n",
       "  'last',\n",
       "  'part',\n",
       "  'be',\n",
       "  'a',\n",
       "  'joke',\n",
       "  'but',\n",
       "  'here',\n",
       "  'be',\n",
       "  'the',\n",
       "  'late',\n",
       "  'rank',\n",
       "  'for',\n",
       "  'the',\n",
       "  'un',\n",
       "  'climate_change',\n",
       "  'panel'],\n",
       " ['iceland_volcano',\n",
       "  'alternative_energy',\n",
       "  'and',\n",
       "  'global_warming',\n",
       "  'fslr',\n",
       "  'pbw',\n",
       "  'peix'],\n",
       " ['foe',\n",
       "  'of',\n",
       "  \"california's\",\n",
       "  'global_warming',\n",
       "  'law_pour',\n",
       "  'money_into',\n",
       "  'a',\n",
       "  'campaign',\n",
       "  'to_delay',\n",
       "  'it'],\n",
       " ['effect_of',\n",
       "  'global_warming',\n",
       "  'à_',\n",
       "  'we',\n",
       "  'be',\n",
       "  \"god's\",\n",
       "  'caretaker',\n",
       "  'by',\n",
       "  'cory',\n",
       "  'kemp',\n",
       "  'an',\n",
       "  'inconvenient',\n",
       "  'truth',\n",
       "  'the',\n",
       "  'documentary',\n",
       "  'and',\n",
       "  'bo'],\n",
       " ['dollar', 'sense', 'and', 'climate_change'],\n",
       " ['global_warming',\n",
       "  'bill',\n",
       "  'expect',\n",
       "  'next',\n",
       "  'monday',\n",
       "  'senator',\n",
       "  'john',\n",
       "  'kerry',\n",
       "  'lindsey_graham',\n",
       "  'and',\n",
       "  'joseph',\n",
       "  'lieberman',\n",
       "  'be',\n",
       "  'expect',\n",
       "  'to'],\n",
       " ['kcrw',\n",
       "  'goodfood',\n",
       "  'blog',\n",
       "  'recycle_water',\n",
       "  'meat',\n",
       "  'and',\n",
       "  'global_warming',\n",
       "  'peanut_rare',\n",
       "  'grape'],\n",
       " ['commonsense', 'wonder', 'global_warming', 'need', 'here'],\n",
       " ['global_warming',\n",
       "  'science',\n",
       "  'global_warming',\n",
       "  'summary',\n",
       "  'the',\n",
       "  'summary',\n",
       "  'update',\n",
       "  '2009/08',\n",
       "  '16',\n",
       "  'the',\n",
       "  'simplify',\n",
       "  'nutshell',\n",
       "  'upda'],\n",
       " ['contra',\n",
       "  'costa',\n",
       "  'time',\n",
       "  'editorial',\n",
       "  'ass',\n",
       "  'global_warming',\n",
       "  'with',\n",
       "  'uncensored',\n",
       "  'science',\n",
       "  'the',\n",
       "  'debate',\n",
       "  'over',\n",
       "  'global_warming',\n",
       "  'ha'],\n",
       " ['global_warming',\n",
       "  'balance',\n",
       "  'quote',\n",
       "  'there_be',\n",
       "  'some',\n",
       "  'who',\n",
       "  'be',\n",
       "  'say',\n",
       "  'that',\n",
       "  'because',\n",
       "  'the',\n",
       "  'oxburgh',\n",
       "  'inquiry',\n",
       "  'do_not',\n",
       "  'come',\n",
       "  'back'],\n",
       " ['ben',\n",
       "  'bova',\n",
       "  'in',\n",
       "  'the',\n",
       "  'news',\n",
       "  'global_warming',\n",
       "  'stock',\n",
       "  'market',\n",
       "  'and',\n",
       "  'earth_day',\n",
       "  'by',\n",
       "  'ben',\n",
       "  'bova',\n",
       "  'one',\n",
       "  'swallow',\n",
       "  'do_not',\n",
       "  'a',\n",
       "  'summer',\n",
       "  'ma'],\n",
       " ['podcast',\n",
       "  'recycle_water',\n",
       "  'meat',\n",
       "  'and',\n",
       "  'global_warming',\n",
       "  'peanut_rare',\n",
       "  'grape'],\n",
       " ['climate_change', 'initiative'],\n",
       " ['greenhoof',\n",
       "  'à_',\n",
       "  'blog_archive',\n",
       "  'à_',\n",
       "  'from',\n",
       "  'tobacco',\n",
       "  'to',\n",
       "  'climate_change'],\n",
       " ['pavley',\n",
       "  'predicts',\n",
       "  'ballot',\n",
       "  'measure',\n",
       "  'will',\n",
       "  'aim',\n",
       "  'to',\n",
       "  'overturn',\n",
       "  'global_warming',\n",
       "  'law'],\n",
       " ['county',\n",
       "  'dispute',\n",
       "  'global_warming',\n",
       "  'by',\n",
       "  'laura',\n",
       "  'london',\n",
       "  'staff',\n",
       "  'writer',\n",
       "  'the',\n",
       "  'otero',\n",
       "  'county',\n",
       "  'commission',\n",
       "  'have',\n",
       "  'an',\n",
       "  'involve',\n",
       "  'discussi'],\n",
       " ['what',\n",
       "  'do',\n",
       "  'you_think',\n",
       "  'of',\n",
       "  'global_warming',\n",
       "  'find',\n",
       "  'answer',\n",
       "  'to',\n",
       "  'this',\n",
       "  'question',\n",
       "  'answer',\n",
       "  'to',\n",
       "  'the',\n",
       "  'question',\n",
       "  'what',\n",
       "  'do',\n",
       "  'you_think'],\n",
       " ['it',\n",
       "  'look_like',\n",
       "  'a',\n",
       "  'new',\n",
       "  'climate_change',\n",
       "  'bill',\n",
       "  'be',\n",
       "  'go',\n",
       "  'to',\n",
       "  'be',\n",
       "  'introduce',\n",
       "  'in',\n",
       "  'the',\n",
       "  'senate',\n",
       "  'a',\n",
       "  'week',\n",
       "  'from',\n",
       "  'monday',\n",
       "  'not',\n",
       "  'sure',\n",
       "  'the'],\n",
       " ['new',\n",
       "  'strategy',\n",
       "  'for',\n",
       "  \"senate's\",\n",
       "  'climate',\n",
       "  'bill',\n",
       "  'leaf',\n",
       "  'out',\n",
       "  'global_warming',\n",
       "  'global_warming',\n",
       "  'policy',\n",
       "  'be',\n",
       "  'no_longer',\n",
       "  'drive',\n",
       "  'compr'],\n",
       " ['my',\n",
       "  'mind',\n",
       "  'be',\n",
       "  'not',\n",
       "  'close',\n",
       "  're',\n",
       "  'global_warming',\n",
       "  'the',\n",
       "  'opposite',\n",
       "  'i',\n",
       "  'want',\n",
       "  'evidence',\n",
       "  'on',\n",
       "  'both',\n",
       "  'side',\n",
       "  'present',\n",
       "  'fairly',\n",
       "  'so',\n",
       "  'we_can',\n",
       "  'judge',\n",
       "  'not',\n",
       "  'uncle',\n",
       "  'gorey'],\n",
       " ['what',\n",
       "  'to',\n",
       "  'do',\n",
       "  'when',\n",
       "  'the',\n",
       "  'current',\n",
       "  'climate_change',\n",
       "  'legislation',\n",
       "  'threatens',\n",
       "  'to',\n",
       "  'do',\n",
       "  'more',\n",
       "  'harm',\n",
       "  'than',\n",
       "  'good'],\n",
       " ['gov',\n",
       "  'christie',\n",
       "  'cut',\n",
       "  \"nj's\",\n",
       "  'global-warming',\n",
       "  'fund',\n",
       "  'gov',\n",
       "  'chris',\n",
       "  'christie',\n",
       "  'be',\n",
       "  'take',\n",
       "  '65_million',\n",
       "  'the',\n",
       "  'entire',\n",
       "  'allocation',\n",
       "  'fro'],\n",
       " ['c3',\n",
       "  'new',\n",
       "  \"mexico's\",\n",
       "  'democrat',\n",
       "  'liberal',\n",
       "  'push',\n",
       "  'global_warming',\n",
       "  'read',\n",
       "  'here',\n",
       "  'despite',\n",
       "  'the',\n",
       "  'u',\n",
       "  'government',\n",
       "  'temperature',\n",
       "  'data'],\n",
       " ['global_warming', 'measurement', 'do_not', 'account_for', 'miss_heat'],\n",
       " ['volcanic_ash',\n",
       "  'an',\n",
       "  'air',\n",
       "  'traffic-stopper',\n",
       "  'but',\n",
       "  'not',\n",
       "  'a',\n",
       "  'climate',\n",
       "  'or',\n",
       "  'health',\n",
       "  'hazard',\n",
       "  'unless',\n",
       "  \"there's\",\n",
       "  'a',\n",
       "  'big',\n",
       "  'change',\n",
       "  'in',\n",
       "  'the',\n",
       "  'amount'],\n",
       " ['who',\n",
       "  'care',\n",
       "  'about',\n",
       "  'global_warming',\n",
       "  'by',\n",
       "  'jackie',\n",
       "  'gingrich',\n",
       "  'cushman',\n",
       "  'in',\n",
       "  '1971',\n",
       "  'i',\n",
       "  'join',\n",
       "  'my',\n",
       "  'parent',\n",
       "  'and',\n",
       "  'old',\n",
       "  'sister',\n",
       "  'in',\n",
       "  'the'],\n",
       " ['the',\n",
       "  'climate',\n",
       "  'be',\n",
       "  'worsen',\n",
       "  'for',\n",
       "  'a',\n",
       "  'debate',\n",
       "  'on',\n",
       "  'global_warming',\n",
       "  'that',\n",
       "  'be',\n",
       "  'why',\n",
       "  'the',\n",
       "  'university',\n",
       "  'of',\n",
       "  'east',\n",
       "  \"anglia's\",\n",
       "  'climate',\n",
       "  'resear'],\n",
       " ['hilarious',\n",
       "  'complimenti',\n",
       "  'bake',\n",
       "  'alakasa',\n",
       "  'sarah',\n",
       "  \"palin's\",\n",
       "  'guide',\n",
       "  'to',\n",
       "  'global_warming',\n",
       "  'tcottv'],\n",
       " ['hilarious',\n",
       "  'complimenti',\n",
       "  'bake',\n",
       "  'alakasa',\n",
       "  'sarah',\n",
       "  \"palin's\",\n",
       "  'guide',\n",
       "  'to',\n",
       "  'global_warming',\n",
       "  'tcottv'],\n",
       " ['global_warming', 'melt_glacier', 'and', 'prohibition'],\n",
       " [\"wisconsin's\",\n",
       "  'scaled-back',\n",
       "  'global_warming',\n",
       "  'bill',\n",
       "  'unveiled',\n",
       "  'alternative'],\n",
       " ['ur', 'tweet', 'about', 'drakeseyebrows', 'cause', 'global_warming', 'lol'],\n",
       " ['ditch',\n",
       "  'cardio',\n",
       "  'for',\n",
       "  'rapid',\n",
       "  'fat_loss',\n",
       "  'a_scream',\n",
       "  'à_o_à_',\n",
       "  'climate_change',\n",
       "  'clinical_trial',\n",
       "  'collagen_clinique',\n",
       "  'clip',\n",
       "  'ar'],\n",
       " ['nice',\n",
       "  'governor_christie',\n",
       "  'will_cut',\n",
       "  'all_65',\n",
       "  'million',\n",
       "  \"from_nj's\",\n",
       "  'global_warming',\n",
       "  'fund'],\n",
       " ['the',\n",
       "  'most',\n",
       "  'expensive',\n",
       "  'provision',\n",
       "  'of',\n",
       "  'the',\n",
       "  \"governor's\",\n",
       "  'global_warming',\n",
       "  'task',\n",
       "  'force',\n",
       "  'remain',\n",
       "  'in',\n",
       "  'the',\n",
       "  'new',\n",
       "  'substitute',\n",
       "  'amendment'],\n",
       " ['christie',\n",
       "  'cut',\n",
       "  '65_million',\n",
       "  'for',\n",
       "  'global_warming',\n",
       "  'prevention',\n",
       "  'by',\n",
       "  'tom',\n",
       "  'hester',\n",
       "  'sr',\n",
       "  'gov',\n",
       "  'chris',\n",
       "  'christie',\n",
       "  'be',\n",
       "  'take',\n",
       "  '65',\n",
       "  'mi'],\n",
       " ['don_blankenship',\n",
       "  'call',\n",
       "  'safety_regulator',\n",
       "  'a_silly',\n",
       "  'a',\n",
       "  'global_warming'],\n",
       " ['coal_ceo', 'call_mine', 'safety_rule', 'a_silly', 'a', 'global_warming'],\n",
       " ['u', 'senator_prepare', 'compromise', 'climate_change', 'bill'],\n",
       " ['senator_prepare', 'compromise', 'climate_change', 'bill', 'reuters'],\n",
       " ['find',\n",
       "  'the',\n",
       "  'right',\n",
       "  'gift',\n",
       "  'to',\n",
       "  'give',\n",
       "  'to',\n",
       "  'your',\n",
       "  'wedding',\n",
       "  'guest',\n",
       "  'a',\n",
       "  'climate_change',\n",
       "  'clinical_trial',\n",
       "  'collagen',\n",
       "  'clin'],\n",
       " ['april',\n",
       "  'shower',\n",
       "  'on',\n",
       "  'u',\n",
       "  'right_now',\n",
       "  'feel',\n",
       "  'like',\n",
       "  'winter',\n",
       "  'global_warming'],\n",
       " ['sunday',\n",
       "  'funny',\n",
       "  'stephen',\n",
       "  'colbert',\n",
       "  'moderate',\n",
       "  'global_warming',\n",
       "  'debate',\n",
       "  'by',\n",
       "  'noel',\n",
       "  'sheppard',\n",
       "  'bio',\n",
       "  'archive',\n",
       "  'in',\n",
       "  'fairness',\n",
       "  'it'],\n",
       " ['comedy',\n",
       "  \"central's\",\n",
       "  'stephen',\n",
       "  'colbert',\n",
       "  'on',\n",
       "  'tuesday',\n",
       "  'actually',\n",
       "  'moderate',\n",
       "  'a',\n",
       "  'debate',\n",
       "  'about',\n",
       "  'global_warming'],\n",
       " ['baby',\n",
       "  'furniture',\n",
       "  'keep',\n",
       "  'baby',\n",
       "  'safe',\n",
       "  'a_scream',\n",
       "  'à_o_à_',\n",
       "  'climate_change',\n",
       "  'clinical_trial',\n",
       "  'collagen_clinique',\n",
       "  'clip'],\n",
       " ['thr',\n",
       "  'senator_prepare',\n",
       "  'compromise',\n",
       "  'climate_change',\n",
       "  'bill',\n",
       "  'washington_reuters',\n",
       "  'six_month',\n",
       "  'after_introduce',\n",
       "  'a',\n",
       "  'sweepi'],\n",
       " ['tv_weathercasters',\n",
       "  'divide_on',\n",
       "  'global_warming',\n",
       "  'more_than',\n",
       "  'half',\n",
       "  'believe',\n",
       "  'phenomenon',\n",
       "  'exists',\n",
       "  'but_some',\n",
       "  'say',\n",
       "  'it',\n",
       "  'be',\n",
       "  'a',\n",
       "  'scam'],\n",
       " [\"there's\", 'a', 'link', 'to', 'luntz', 'climate_change', 'memo', 'here'],\n",
       " ['minnesotan',\n",
       "  '4',\n",
       "  'global_warming',\n",
       "  'threaten',\n",
       "  'with',\n",
       "  'law',\n",
       "  'suit',\n",
       "  'over',\n",
       "  'hide',\n",
       "  'the',\n",
       "  'decline',\n",
       "  'video.respond',\n",
       "  'with',\n",
       "  'new',\n",
       "  'vid'],\n",
       " ['global_warming',\n",
       "  'conference_set',\n",
       "  'sunday',\n",
       "  'robert',\n",
       "  'bullard',\n",
       "  'know',\n",
       "  'a',\n",
       "  'the',\n",
       "  'father',\n",
       "  'of',\n",
       "  'environmental',\n",
       "  'justice',\n",
       "  'be',\n",
       "  'a'],\n",
       " ['be',\n",
       "  'you',\n",
       "  'ready',\n",
       "  'for',\n",
       "  'the',\n",
       "  'climate_change',\n",
       "  'pli',\n",
       "  'be',\n",
       "  'with',\n",
       "  'environmental',\n",
       "  'regulation',\n",
       "  'commercial',\n",
       "  'implication',\n",
       "  '2010',\n",
       "  'how',\n",
       "  'the'],\n",
       " ['live',\n",
       "  'tonight',\n",
       "  'fellow',\n",
       "  'heather_rogers',\n",
       "  'join',\n",
       "  'climate_change',\n",
       "  'expert',\n",
       "  'james_hansen',\n",
       "  'to',\n",
       "  'discus',\n",
       "  'real_solution',\n",
       "  'to',\n",
       "  'climate'],\n",
       " ['plan_california', 'brace_for', 'climate_change'],\n",
       " ['plant_effective',\n",
       "  'way',\n",
       "  'of',\n",
       "  'tackle',\n",
       "  'global_warming',\n",
       "  'washington',\n",
       "  'apr',\n",
       "  '30',\n",
       "  'plant',\n",
       "  'leaf',\n",
       "  'account_for',\n",
       "  'less_than',\n",
       "  'one',\n",
       "  'per'],\n",
       " ['plant_effective',\n",
       "  'way',\n",
       "  'of',\n",
       "  'tackle',\n",
       "  'global_warming',\n",
       "  'washington',\n",
       "  'apr',\n",
       "  '30',\n",
       "  'plant',\n",
       "  'leaf',\n",
       "  'account_for',\n",
       "  'less_than',\n",
       "  'one',\n",
       "  'per'],\n",
       " ['climate_change',\n",
       "  'sustainability',\n",
       "  'will',\n",
       "  'be',\n",
       "  'a',\n",
       "  'key',\n",
       "  'driver',\n",
       "  'of',\n",
       "  'future',\n",
       "  'economic',\n",
       "  'development',\n",
       "  'listen',\n",
       "  'at'],\n",
       " ['u',\n",
       "  'general',\n",
       "  'say',\n",
       "  'climate_change',\n",
       "  'threatens',\n",
       "  \"america's\",\n",
       "  'security',\n",
       "  'the',\n",
       "  'pentagon',\n",
       "  'have',\n",
       "  'make',\n",
       "  'it',\n",
       "  'well',\n",
       "  'know',\n",
       "  'that',\n",
       "  'it',\n",
       "  'consider'],\n",
       " ['even',\n",
       "  'the',\n",
       "  'general',\n",
       "  'know',\n",
       "  'climate_change',\n",
       "  'be',\n",
       "  'go',\n",
       "  'to',\n",
       "  'screw',\n",
       "  'u',\n",
       "  'clean_energy',\n",
       "  'bill',\n",
       "  'anyone',\n",
       "  'climate'],\n",
       " ['government_report',\n",
       "  'say',\n",
       "  'global_warming',\n",
       "  'may_cause',\n",
       "  'cancer_mental',\n",
       "  'illness'],\n",
       " ['climate_change', 'increase_heat', 'wave', 'flood', 'epa'],\n",
       " ['plant', 'remain', 'an', 'effective_way', 'of', 'tackle', 'global_warming'],\n",
       " ['global_warming', 'kill', 'forest', 'in', 'colorado'],\n",
       " ['epa',\n",
       "  'confirms',\n",
       "  'climate',\n",
       "  'be',\n",
       "  'change',\n",
       "  'in',\n",
       "  'another',\n",
       "  'display',\n",
       "  'of',\n",
       "  'the',\n",
       "  'sea',\n",
       "  'change',\n",
       "  'that',\n",
       "  'have',\n",
       "  'occur',\n",
       "  'at',\n",
       "  'the',\n",
       "  'u',\n",
       "  'environmental'],\n",
       " ['must',\n",
       "  'see',\n",
       "  'place',\n",
       "  'before_they',\n",
       "  'disappear',\n",
       "  'europe',\n",
       "  'pic',\n",
       "  ']:',\n",
       "  'if',\n",
       "  'global_warming',\n",
       "  'prediction',\n",
       "  'prove',\n",
       "  'to',\n",
       "  'be',\n",
       "  'true',\n",
       "  'the',\n",
       "  'foll'],\n",
       " ['combat',\n",
       "  'climate_change',\n",
       "  'lesson_from',\n",
       "  'the',\n",
       "  'world',\n",
       "  'à_s',\n",
       "  'indigenous_people'],\n",
       " ['indigenous', 'tradition', 'use', 'to', 'fight', 'climate_change'],\n",
       " ['james_hansen',\n",
       "  'heather_rogers',\n",
       "  'green',\n",
       "  'go_wrong',\n",
       "  'false_hope',\n",
       "  'real_solution',\n",
       "  'to',\n",
       "  'climate_change',\n",
       "  '7pm',\n",
       "  '4/30'],\n",
       " ['climate_change',\n",
       "  'forest',\n",
       "  'not',\n",
       "  'for_absorb',\n",
       "  'carbon',\n",
       "  'say',\n",
       "  'activist'],\n",
       " ['climate_change',\n",
       "  'forest',\n",
       "  'not',\n",
       "  'for_absorb',\n",
       "  'carbon',\n",
       "  'say',\n",
       "  'activist',\n",
       "  'cleantech'],\n",
       " ['climate_change',\n",
       "  'melt',\n",
       "  'two',\n",
       "  'glacier',\n",
       "  'billing',\n",
       "  'mont',\n",
       "  'glacier_national',\n",
       "  'park',\n",
       "  'have',\n",
       "  'lose',\n",
       "  'two_more',\n",
       "  'of',\n",
       "  'it',\n",
       "  'namesake'],\n",
       " ['climate_change',\n",
       "  'forest',\n",
       "  'not',\n",
       "  'for_absorb',\n",
       "  'carbon',\n",
       "  'say',\n",
       "  'activist'],\n",
       " ['climate_change',\n",
       "  'forest',\n",
       "  'not',\n",
       "  'for_absorb',\n",
       "  'carbon',\n",
       "  'say',\n",
       "  'activist'],\n",
       " ['climate_change', 'forest', 'not', 'for_absorb', 'carbon'],\n",
       " ['climate_change',\n",
       "  'threatens',\n",
       "  \"japan's\",\n",
       "  'cherry',\n",
       "  'blossom',\n",
       "  'environment',\n",
       "  'if_you',\n",
       "  'be',\n",
       "  'not',\n",
       "  'familiar',\n",
       "  'with',\n",
       "  'the',\n",
       "  'culture',\n",
       "  'japan'],\n",
       " ['wed',\n",
       "  'podcast',\n",
       "  'mountain',\n",
       "  'valley',\n",
       "  'temp',\n",
       "  'stretch',\n",
       "  'apart',\n",
       "  'with',\n",
       "  'climate_change'],\n",
       " ['mountain', 'valley', 'temp', 'stretch', 'apart', 'with', 'climate_change'],\n",
       " ['climate_change',\n",
       "  'forest',\n",
       "  'not',\n",
       "  'for_absorb',\n",
       "  'carbon',\n",
       "  'say',\n",
       "  'activist',\n",
       "  'ipsamazon'],\n",
       " ['global_warming',\n",
       "  'report',\n",
       "  'urge',\n",
       "  'government',\n",
       "  'to',\n",
       "  'act',\n",
       "  'brussels',\n",
       "  'belgium',\n",
       "  'ap',\n",
       "  'the',\n",
       "  'world',\n",
       "  'face',\n",
       "  'increase',\n",
       "  'hunger',\n",
       "  'and'],\n",
       " ['arctic',\n",
       "  'rain_in',\n",
       "  'april',\n",
       "  'be',\n",
       "  'sign',\n",
       "  'of',\n",
       "  'global_warming',\n",
       "  'the',\n",
       "  'canadian',\n",
       "  'arctic',\n",
       "  'have',\n",
       "  'be',\n",
       "  'hit',\n",
       "  'by',\n",
       "  'rain_in',\n",
       "  'a',\n",
       "  'sign',\n",
       "  'that',\n",
       "  'the'],\n",
       " ['arctic',\n",
       "  'rain_in',\n",
       "  'april',\n",
       "  'be',\n",
       "  'sign',\n",
       "  'of',\n",
       "  'global_warming',\n",
       "  'the',\n",
       "  'canadian',\n",
       "  'arctic',\n",
       "  'have',\n",
       "  'be',\n",
       "  'hit',\n",
       "  'by',\n",
       "  'rain_in',\n",
       "  'a',\n",
       "  'sign',\n",
       "  'that',\n",
       "  'the'],\n",
       " ['microbe',\n",
       "  'contribute',\n",
       "  'less',\n",
       "  'to',\n",
       "  'global_warming',\n",
       "  'new',\n",
       "  'haven',\n",
       "  'conn',\n",
       "  '. ..'],\n",
       " ['microbe',\n",
       "  'contribute',\n",
       "  'less',\n",
       "  'to',\n",
       "  'global_warming',\n",
       "  'new',\n",
       "  'haven',\n",
       "  'conn',\n",
       "  '. ..'],\n",
       " ['south',\n",
       "  'asian',\n",
       "  'nation',\n",
       "  'to',\n",
       "  'fight',\n",
       "  'climate_change',\n",
       "  'foreign',\n",
       "  'minister',\n",
       "  'of',\n",
       "  'eight',\n",
       "  'south',\n",
       "  'asian',\n",
       "  'nation',\n",
       "  'met',\n",
       "  'in',\n",
       "  'this',\n",
       "  'seclude'],\n",
       " ['climate_change',\n",
       "  'increase_heat',\n",
       "  'wave',\n",
       "  'flood',\n",
       "  'washington_reuters',\n",
       "  'death',\n",
       "  'from',\n",
       "  'heat_wave',\n",
       "  'property',\n",
       "  'damage',\n",
       "  'from'],\n",
       " ['james_hansen',\n",
       "  'heather_rogers',\n",
       "  'green',\n",
       "  'go_wrong',\n",
       "  'false_hope',\n",
       "  'real_solution',\n",
       "  'to',\n",
       "  'climate_change',\n",
       "  '7pm',\n",
       "  '4/30'],\n",
       " ['i_love',\n",
       "  \"frog's\",\n",
       "  'leap',\n",
       "  'seriously',\n",
       "  'what',\n",
       "  'climate_change',\n",
       "  'mean',\n",
       "  'for',\n",
       "  'the',\n",
       "  'wine',\n",
       "  'industry',\n",
       "  'via'],\n",
       " ['report',\n",
       "  'save',\n",
       "  'the',\n",
       "  'whale',\n",
       "  'and',\n",
       "  'they_will',\n",
       "  'save',\n",
       "  'u',\n",
       "  'from',\n",
       "  'global_warming'],\n",
       " ['the',\n",
       "  'contribution',\n",
       "  'of',\n",
       "  'organic',\n",
       "  'agriculture',\n",
       "  'to',\n",
       "  'climate_change',\n",
       "  'mitigation'],\n",
       " ['arctic',\n",
       "  'beauty',\n",
       "  'in',\n",
       "  'black',\n",
       "  'and',\n",
       "  'white',\n",
       "  'alaska_before',\n",
       "  'the',\n",
       "  'effect_of',\n",
       "  'global_warming',\n",
       "  'slide',\n",
       "  'show',\n",
       "  ']:',\n",
       "  'toward',\n",
       "  'the',\n",
       "  'end',\n",
       "  'of',\n",
       "  'wor'],\n",
       " ['epa',\n",
       "  'report',\n",
       "  'document',\n",
       "  'very',\n",
       "  'real',\n",
       "  'impact',\n",
       "  'from',\n",
       "  'climate_change',\n",
       "  'in',\n",
       "  '22',\n",
       "  'of',\n",
       "  '24',\n",
       "  'indicator',\n",
       "  'study',\n",
       "  'energy',\n",
       "  'via'],\n",
       " ['canadian',\n",
       "  'ceo',\n",
       "  'more',\n",
       "  'keen',\n",
       "  'on',\n",
       "  'green',\n",
       "  'than',\n",
       "  'global',\n",
       "  'counterpart',\n",
       "  'prepare',\n",
       "  'for',\n",
       "  'impact',\n",
       "  'of',\n",
       "  'climate_change'],\n",
       " ['ask',\n",
       "  'the',\n",
       "  'g8',\n",
       "  'g20',\n",
       "  'to',\n",
       "  'support',\n",
       "  'biochar',\n",
       "  'fight',\n",
       "  'climate_change',\n",
       "  'food',\n",
       "  'shortage',\n",
       "  'check_this',\n",
       "  'huffpo',\n",
       "  'post'],\n",
       " ['whale',\n",
       "  'doodoo',\n",
       "  'could_help',\n",
       "  'fight',\n",
       "  'climate_change',\n",
       "  'sure',\n",
       "  'why',\n",
       "  'not',\n",
       "  'via'],\n",
       " ['global_warming',\n",
       "  'science',\n",
       "  'good_news',\n",
       "  'soil',\n",
       "  'release',\n",
       "  'less',\n",
       "  'carbon',\n",
       "  'than',\n",
       "  'though',\n",
       "  'a',\n",
       "  'world',\n",
       "  'warms'],\n",
       " ['high_temperature',\n",
       "  'sea_level',\n",
       "  'due_to',\n",
       "  'global_warming',\n",
       "  'kuala',\n",
       "  'lumpur',\n",
       "  \"malaysia's\",\n",
       "  'average',\n",
       "  'temperature',\n",
       "  'have',\n",
       "  'risen',\n",
       "  'by',\n",
       "  '1.1'],\n",
       " ['high_temperature',\n",
       "  'sea_level',\n",
       "  'due_to',\n",
       "  'global_warming',\n",
       "  'kuala',\n",
       "  'lumpur',\n",
       "  \"malaysia's\",\n",
       "  'average',\n",
       "  'temperature',\n",
       "  'have',\n",
       "  'risen',\n",
       "  'by',\n",
       "  '1.1'],\n",
       " ['west', 'mediterranean', 'country', 'unite', 'on', 'climate_change', 'afp'],\n",
       " ['cleaner_air',\n",
       "  'could_speed',\n",
       "  'global_warming',\n",
       "  'hugh',\n",
       "  'pickens',\n",
       "  'writes',\n",
       "  'scientist',\n",
       "  'estimate',\n",
       "  'that',\n",
       "  'the',\n",
       "  'u',\n",
       "  'clean',\n",
       "  'air',\n",
       "  'act',\n",
       "  'have',\n",
       "  'cut'],\n",
       " ['3,000_business', 'create_new', 'ad_for', 'climate_change', 'action'],\n",
       " ['alaska_before', 'the', 'effect_of', 'global_warming', 'pic', ']:'],\n",
       " ['new',\n",
       "  'blog_post',\n",
       "  'mandate',\n",
       "  'energy',\n",
       "  'benchmarking',\n",
       "  'the',\n",
       "  'next',\n",
       "  'step',\n",
       "  'for',\n",
       "  'city',\n",
       "  'in',\n",
       "  'address',\n",
       "  'climate_change'],\n",
       " ['how_much',\n",
       "  'trouble',\n",
       "  'do',\n",
       "  'global_warming',\n",
       "  'mean',\n",
       "  'for',\n",
       "  'agriculture',\n",
       "  'just_ask',\n",
       "  'the',\n",
       "  'wine',\n",
       "  'industry'],\n",
       " ['arctic',\n",
       "  'beauty',\n",
       "  'in',\n",
       "  'black',\n",
       "  'and',\n",
       "  'white',\n",
       "  'alaska_before',\n",
       "  'the',\n",
       "  'effect_of',\n",
       "  'global_warming',\n",
       "  'slide',\n",
       "  'show'],\n",
       " ['climate_change',\n",
       "  'from',\n",
       "  'paris',\n",
       "  'to',\n",
       "  'the',\n",
       "  'alp',\n",
       "  'european',\n",
       "  'place',\n",
       "  'in',\n",
       "  'peril',\n",
       "  'photo'],\n",
       " ['how',\n",
       "  'climate_change',\n",
       "  'will',\n",
       "  'change',\n",
       "  'the',\n",
       "  'electoral',\n",
       "  'map',\n",
       "  'the',\n",
       "  'national',\n",
       "  'oceanic',\n",
       "  'and',\n",
       "  'atmospheric',\n",
       "  'administration',\n",
       "  'be',\n",
       "  'not',\n",
       "  'know'],\n",
       " ['global_warming',\n",
       "  'be',\n",
       "  'a',\n",
       "  'threat',\n",
       "  'after',\n",
       "  'all',\n",
       "  'tim',\n",
       "  'blair',\n",
       "  'round',\n",
       "  'up',\n",
       "  'the',\n",
       "  'late',\n",
       "  'news',\n",
       "  'from',\n",
       "  'the',\n",
       "  'wild',\n",
       "  'frontier',\n",
       "  'of',\n",
       "  'global'],\n",
       " ['kuna',\n",
       "  'indian',\n",
       "  'prepare',\n",
       "  'for',\n",
       "  'relocation',\n",
       "  'a',\n",
       "  'traditional',\n",
       "  'home',\n",
       "  'sink',\n",
       "  'due_to',\n",
       "  'climate_change',\n",
       "  'by'],\n",
       " ['how',\n",
       "  'global_warming',\n",
       "  'be',\n",
       "  'kill',\n",
       "  \"california's\",\n",
       "  'wine',\n",
       "  'buzz',\n",
       "  'dr',\n",
       "  'kimberley',\n",
       "  'cahill',\n",
       "  'present',\n",
       "  'on',\n",
       "  'climate_change',\n",
       "  'in',\n",
       "  'califor'],\n",
       " ['uncajoe',\n",
       "  'plz_digg',\n",
       "  'climate',\n",
       "  'of',\n",
       "  'hate',\n",
       "  'the',\n",
       "  'politics',\n",
       "  'of',\n",
       "  'climate_change',\n",
       "  'denial',\n",
       "  'a',\n",
       "  'p2_du1',\n",
       "  'pgn'],\n",
       " ['global_warming',\n",
       "  'ocean_chemistry',\n",
       "  'be',\n",
       "  'change',\n",
       "  'faster_than',\n",
       "  'it',\n",
       "  'have',\n",
       "  'in',\n",
       "  '800,000',\n",
       "  'year',\n",
       "  'and',\n",
       "  'that',\n",
       "  'be',\n",
       "  'because',\n",
       "  'of',\n",
       "  'the',\n",
       "  'carbon'],\n",
       " ['global_warming',\n",
       "  'ocean_chemistry',\n",
       "  'be',\n",
       "  'change',\n",
       "  'faster_than',\n",
       "  'it',\n",
       "  'have',\n",
       "  'in',\n",
       "  '800,000',\n",
       "  'year',\n",
       "  'and',\n",
       "  'that',\n",
       "  'be',\n",
       "  'because',\n",
       "  'of',\n",
       "  'the',\n",
       "  'carbon'],\n",
       " ['good',\n",
       "  'go',\n",
       "  'douche',\n",
       "  \"i'm\",\n",
       "  'sure',\n",
       "  'there_be',\n",
       "  'no',\n",
       "  'climate_change',\n",
       "  'in',\n",
       "  'your',\n",
       "  'backass',\n",
       "  'world',\n",
       "  'graham',\n",
       "  'move_imperils',\n",
       "  'obama',\n",
       "  'agenda'],\n",
       " ['ski_resort',\n",
       "  'fight',\n",
       "  'global_warming',\n",
       "  'salt_lake',\n",
       "  'city',\n",
       "  'ap',\n",
       "  'ski_resort',\n",
       "  'across',\n",
       "  'the',\n",
       "  'u',\n",
       "  'be',\n",
       "  'use',\n",
       "  'this',\n",
       "  'thanksgiving'],\n",
       " ['ski_resort',\n",
       "  'fight',\n",
       "  'global_warming',\n",
       "  'salt_lake',\n",
       "  'city',\n",
       "  'ap',\n",
       "  'ski_resort',\n",
       "  'across',\n",
       "  'the',\n",
       "  'u',\n",
       "  'be',\n",
       "  'use',\n",
       "  'this',\n",
       "  'thanksgiving'],\n",
       " ['bat_bird',\n",
       "  'and_lizard',\n",
       "  'can_fight',\n",
       "  'climate_change',\n",
       "  'by',\n",
       "  'eat',\n",
       "  'insect',\n",
       "  'bird_bat',\n",
       "  'and_lizard',\n",
       "  'may_play',\n",
       "  'an_important'],\n",
       " ['make',\n",
       "  'it',\n",
       "  'green',\n",
       "  'cloud',\n",
       "  'compute',\n",
       "  'and',\n",
       "  'it',\n",
       "  'contribution',\n",
       "  'to',\n",
       "  'climate_change'],\n",
       " ['climate_change',\n",
       "  'favor',\n",
       "  'invasive_specie',\n",
       "  'over',\n",
       "  'indigenous',\n",
       "  'one',\n",
       "  '30',\n",
       "  'of',\n",
       "  'plant',\n",
       "  'thoreau',\n",
       "  'saw',\n",
       "  'be',\n",
       "  'now',\n",
       "  'extinct'],\n",
       " ['scary',\n",
       "  'climate_change',\n",
       "  'alter',\n",
       "  'u',\n",
       "  'season',\n",
       "  'spring',\n",
       "  '10',\n",
       "  'day',\n",
       "  'early',\n",
       "  'climate'],\n",
       " ['pres',\n",
       "  'evo_morale',\n",
       "  'in',\n",
       "  'climate_change',\n",
       "  'lesson_from',\n",
       "  'indigenous_people',\n",
       "  'cochabamba',\n",
       "  'cmpcc'],\n",
       " ['mediaglobal',\n",
       "  'report',\n",
       "  'on',\n",
       "  'special',\n",
       "  'tip',\n",
       "  'point',\n",
       "  'earth_day',\n",
       "  'event',\n",
       "  'science',\n",
       "  'and',\n",
       "  'art',\n",
       "  'mobilize',\n",
       "  'to',\n",
       "  'fight',\n",
       "  'climate_change'],\n",
       " ['a',\n",
       "  'review',\n",
       "  'of',\n",
       "  \"yesterday's\",\n",
       "  'discussion',\n",
       "  'science',\n",
       "  'and',\n",
       "  'art',\n",
       "  'mobilize',\n",
       "  'to',\n",
       "  'fight',\n",
       "  'climate_change',\n",
       "  'by',\n",
       "  'rebekah',\n",
       "  'mintzer'],\n",
       " ['global_warming', 'kill', 'forest', 'in', 'colorado'],\n",
       " ['combat',\n",
       "  'climate_change',\n",
       "  'lesson_from',\n",
       "  'the',\n",
       "  \"world's\",\n",
       "  'indigenous_people',\n",
       "  'when',\n",
       "  'i',\n",
       "  'arrive',\n",
       "  'at',\n",
       "  'the',\n",
       "  'united_nation',\n",
       "  'climat'],\n",
       " ['africa',\n",
       "  'meteorology',\n",
       "  'service',\n",
       "  'gear',\n",
       "  'up',\n",
       "  'for',\n",
       "  'climate_change',\n",
       "  'on',\n",
       "  'the',\n",
       "  'continent',\n",
       "  'most_vulnerable',\n",
       "  'to',\n",
       "  'climate',\n",
       "  'africa'],\n",
       " ['gecko',\n",
       "  '10_first',\n",
       "  'step',\n",
       "  'to',\n",
       "  'greener_living',\n",
       "  'it',\n",
       "  'all_seem',\n",
       "  'so_daunt',\n",
       "  'climate_change',\n",
       "  'carbon_credit',\n",
       "  'not',\n",
       "  'to',\n",
       "  'mention',\n",
       "  'gecko'],\n",
       " ['china',\n",
       "  'the',\n",
       "  'key',\n",
       "  'to',\n",
       "  'fix',\n",
       "  'global_warming',\n",
       "  'with',\n",
       "  'rapid',\n",
       "  'expansion',\n",
       "  'come',\n",
       "  'sizable',\n",
       "  'environmental',\n",
       "  'impact',\n",
       "  'so',\n",
       "  'the',\n",
       "  \"world's\"],\n",
       " ['china',\n",
       "  'the',\n",
       "  'key',\n",
       "  'to',\n",
       "  'fix',\n",
       "  'global_warming',\n",
       "  'with',\n",
       "  'rapid',\n",
       "  'expansion',\n",
       "  'come',\n",
       "  'sizable',\n",
       "  'environmental',\n",
       "  'impact',\n",
       "  'so',\n",
       "  'the',\n",
       "  \"world's\"],\n",
       " ['now',\n",
       "  'on',\n",
       "  'pb',\n",
       "  'go_green',\n",
       "  'new_york',\n",
       "  'examine',\n",
       "  'how',\n",
       "  'new',\n",
       "  'yorkers',\n",
       "  'be',\n",
       "  'confront',\n",
       "  'climate_change',\n",
       "  'check',\n",
       "  'local',\n",
       "  'listing'],\n",
       " ['official',\n",
       "  'nasa',\n",
       "  'report',\n",
       "  'sun',\n",
       "  'cause',\n",
       "  'climate_change',\n",
       "  'ftsn',\n",
       "  'social'],\n",
       " ['well',\n",
       "  'this',\n",
       "  'be',\n",
       "  'just',\n",
       "  'crazy',\n",
       "  'coal_ceo',\n",
       "  'call_mine',\n",
       "  'safety_rule',\n",
       "  'a_silly',\n",
       "  'a',\n",
       "  'global_warming'],\n",
       " ['impact', 'of', 'climate_change', 'extend', 'to', 'human_health'],\n",
       " ['impact', 'of', 'climate_change', 'extend', 'to', 'human_health'],\n",
       " ['the',\n",
       "  'good_news',\n",
       "  'about',\n",
       "  'the',\n",
       "  'very_bad',\n",
       "  'news',\n",
       "  'about',\n",
       "  'climate_change',\n",
       "  'by',\n",
       "  'rebecca',\n",
       "  'solnit'],\n",
       " ['alpha',\n",
       "  'phi',\n",
       "  'alpha',\n",
       "  'take',\n",
       "  'on',\n",
       "  'climate_change',\n",
       "  'and',\n",
       "  'energy',\n",
       "  'efficiency',\n",
       "  'climate'],\n",
       " ['gecko',\n",
       "  '10_first',\n",
       "  'step',\n",
       "  'to',\n",
       "  'greener_living',\n",
       "  'it',\n",
       "  'all_seem',\n",
       "  'so_daunt',\n",
       "  'climate_change',\n",
       "  'carbon_credit',\n",
       "  'not',\n",
       "  'to',\n",
       "  'mention',\n",
       "  'gecko'],\n",
       " ['natural',\n",
       "  'variability',\n",
       "  'do_not',\n",
       "  'explain',\n",
       "  'global_warming',\n",
       "  'climate',\n",
       "  'scientist',\n",
       "  'tell',\n",
       "  'popular',\n",
       "  'tv',\n",
       "  'meteorologist',\n",
       "  'climate',\n",
       "  'agw'],\n",
       " ['rebecca',\n",
       "  'solnit',\n",
       "  '350',\n",
       "  'degree',\n",
       "  'of',\n",
       "  'inseparability',\n",
       "  'the',\n",
       "  'good_news',\n",
       "  'about',\n",
       "  'the',\n",
       "  'very_bad',\n",
       "  'news',\n",
       "  'about',\n",
       "  'climate_change'],\n",
       " ['watch',\n",
       "  'video',\n",
       "  'climate_change',\n",
       "  'threatens',\n",
       "  'sacred',\n",
       "  'tibetan',\n",
       "  'mountain',\n",
       "  'include',\n",
       "  'land',\n",
       "  'know',\n",
       "  'a',\n",
       "  'shangri-la',\n",
       "  'earthday'],\n",
       " ['african',\n",
       "  'meteorology',\n",
       "  'service',\n",
       "  'gear',\n",
       "  'up',\n",
       "  'for',\n",
       "  'climate_change',\n",
       "  'america.gov',\n",
       "  'iri'],\n",
       " ['economist',\n",
       "  'say',\n",
       "  'climate_change',\n",
       "  'be',\n",
       "  'bad',\n",
       "  'for',\n",
       "  'economy',\n",
       "  'earthday'],\n",
       " ['economist',\n",
       "  'say',\n",
       "  'climate_change',\n",
       "  'be',\n",
       "  'bad',\n",
       "  'for',\n",
       "  'economy',\n",
       "  'earthday'],\n",
       " ['report',\n",
       "  'allergy_season',\n",
       "  'to',\n",
       "  'get_bad',\n",
       "  'with',\n",
       "  'climate_change',\n",
       "  'time.com'],\n",
       " ['don',\n",
       "  'à_t',\n",
       "  'kill',\n",
       "  'bill',\n",
       "  'à_',\n",
       "  'save',\n",
       "  'the',\n",
       "  'climate_change',\n",
       "  'accountability',\n",
       "  'act',\n",
       "  'via'],\n",
       " ['climate_change',\n",
       "  'make',\n",
       "  'farmer',\n",
       "  'pastoralists',\n",
       "  'in',\n",
       "  'ethiopia',\n",
       "  'increasingly',\n",
       "  'vulnerable',\n",
       "  'earthday'],\n",
       " ['denis',\n",
       "  'hayes',\n",
       "  'founder',\n",
       "  'of',\n",
       "  'earth_day',\n",
       "  'compare',\n",
       "  'global',\n",
       "  'climate_change',\n",
       "  'to',\n",
       "  'irish',\n",
       "  'famine',\n",
       "  'irishcentral',\n",
       "  'news',\n",
       "  'weather',\n",
       "  'politics'],\n",
       " ['climate_change',\n",
       "  'make',\n",
       "  'farmer',\n",
       "  'pastoralists',\n",
       "  'in',\n",
       "  'ethiopia',\n",
       "  'increasingly',\n",
       "  'vulnerable',\n",
       "  'earthday'],\n",
       " ['earth_day',\n",
       "  'ben',\n",
       "  'verwaayen',\n",
       "  'on',\n",
       "  'what',\n",
       "  'we',\n",
       "  'be',\n",
       "  'do',\n",
       "  'to_curb',\n",
       "  'climate_change',\n",
       "  'green',\n",
       "  'earthday',\n",
       "  'via'],\n",
       " ['health',\n",
       "  'u',\n",
       "  'and',\n",
       "  'other',\n",
       "  'industrial',\n",
       "  'nation',\n",
       "  'already',\n",
       "  'feel',\n",
       "  'impact',\n",
       "  'of',\n",
       "  'climate_change',\n",
       "  'report'],\n",
       " ['health',\n",
       "  'u',\n",
       "  'and',\n",
       "  'other',\n",
       "  'industrial',\n",
       "  'nation',\n",
       "  'already',\n",
       "  'feel',\n",
       "  'impact',\n",
       "  'of',\n",
       "  'climate_change',\n",
       "  'report'],\n",
       " ['health',\n",
       "  'u',\n",
       "  'and',\n",
       "  'other',\n",
       "  'industrial',\n",
       "  'nation',\n",
       "  'already',\n",
       "  'feel',\n",
       "  'impact',\n",
       "  'of',\n",
       "  'climate_change',\n",
       "  'report'],\n",
       " ['gecko',\n",
       "  '10_first',\n",
       "  'step',\n",
       "  'to',\n",
       "  'greener_living',\n",
       "  'it',\n",
       "  'all_seem',\n",
       "  'so_daunt',\n",
       "  'climate_change',\n",
       "  'carbon_credit',\n",
       "  'not',\n",
       "  'to',\n",
       "  'mention',\n",
       "  'gecko'],\n",
       " ['10_first',\n",
       "  'step',\n",
       "  'to',\n",
       "  'greener_living',\n",
       "  'it',\n",
       "  'all_seem',\n",
       "  'so_daunt',\n",
       "  'climate_change',\n",
       "  'carbon_credit',\n",
       "  'not',\n",
       "  'to',\n",
       "  'mention',\n",
       "  'biofuel'],\n",
       " ['climate_change', 'could_raise', 'cost_of', 'u', 'allergy', 'reuters'],\n",
       " ['treat',\n",
       "  'climate_change',\n",
       "  'a',\n",
       "  'a',\n",
       "  'curable_disease',\n",
       "  'bioethicists',\n",
       "  'and',\n",
       "  'international',\n",
       "  'law',\n",
       "  'expert',\n",
       "  'met',\n",
       "  'in',\n",
       "  'asilomar',\n",
       "  'later',\n",
       "  'la'],\n",
       " ['well',\n",
       "  'this',\n",
       "  'be',\n",
       "  'just',\n",
       "  'crazy',\n",
       "  'coal_ceo',\n",
       "  'call_mine',\n",
       "  'safety_rule',\n",
       "  'a_silly',\n",
       "  'a',\n",
       "  'global_warming'],\n",
       " ['military_lead', 'fight_against', 'climate_change', 'envnewsnet'],\n",
       " ['military_lead',\n",
       "  'fight_against',\n",
       "  'climate_change',\n",
       "  'the',\n",
       "  'u',\n",
       "  'military',\n",
       "  'the',\n",
       "  \"government's\",\n",
       "  'large',\n",
       "  'fuel',\n",
       "  'buyer',\n",
       "  'be',\n",
       "  'lead',\n",
       "  'th'],\n",
       " ['10_first',\n",
       "  'step',\n",
       "  'to',\n",
       "  'greener_living',\n",
       "  'it',\n",
       "  'all_seem',\n",
       "  'so_daunt',\n",
       "  'climate_change',\n",
       "  'carbon_credit',\n",
       "  'not',\n",
       "  'to',\n",
       "  'mention',\n",
       "  'biofuel'],\n",
       " ['swedish',\n",
       "  'expert',\n",
       "  'say',\n",
       "  'co2',\n",
       "  'be',\n",
       "  'not',\n",
       "  'the',\n",
       "  'main',\n",
       "  'cause',\n",
       "  'of',\n",
       "  'global_warming',\n",
       "  'swedish',\n",
       "  'climate',\n",
       "  'expert',\n",
       "  'dr',\n",
       "  'fred',\n",
       "  'goldberg',\n",
       "  'have',\n",
       "  'say'],\n",
       " ['fight', 'poverty_and', 'global_warming', 'in', 'africa', 'energy'],\n",
       " ['treat',\n",
       "  'climate_change',\n",
       "  'a',\n",
       "  'a',\n",
       "  'curable_disease',\n",
       "  'wire',\n",
       "  'science',\n",
       "  'wired.com',\n",
       "  'green',\n",
       "  'esg',\n",
       "  'sustainability'],\n",
       " ['it',\n",
       "  'be',\n",
       "  'time',\n",
       "  'to',\n",
       "  'tackle',\n",
       "  'climate_change',\n",
       "  'through',\n",
       "  'wind',\n",
       "  'energy'],\n",
       " ['thursday',\n",
       "  'on',\n",
       "  'pb',\n",
       "  'go_green',\n",
       "  'new_york',\n",
       "  'examine',\n",
       "  'how',\n",
       "  'new',\n",
       "  'yorkers',\n",
       "  'be',\n",
       "  'confront',\n",
       "  'climate_change',\n",
       "  'check',\n",
       "  'local',\n",
       "  'listing'],\n",
       " ['un',\n",
       "  'à_',\n",
       "  'only',\n",
       "  'global',\n",
       "  'cooperation',\n",
       "  'can',\n",
       "  'prevent',\n",
       "  'runaway',\n",
       "  'climate_change',\n",
       "  'secretary',\n",
       "  'à_',\n",
       "  'the',\n",
       "  'united_nation',\n",
       "  'seek',\n",
       "  'dialogue',\n",
       "  'i'],\n",
       " ['carbon_offset',\n",
       "  'how',\n",
       "  'a',\n",
       "  'vatican_forest',\n",
       "  'fail',\n",
       "  'to',\n",
       "  'reduce',\n",
       "  'global_warming'],\n",
       " ['most_important',\n",
       "  'event',\n",
       "  'in',\n",
       "  'struggle_against',\n",
       "  'climate_change',\n",
       "  'nigerian_environmentalist',\n",
       "  'nnimmo_bassey'],\n",
       " ['military_lead', 'fight_against', 'climate_change', 'pew'],\n",
       " ['report',\n",
       "  'identifies',\n",
       "  '11',\n",
       "  'disease',\n",
       "  'health',\n",
       "  'issue',\n",
       "  'affctd',\n",
       "  'by',\n",
       "  'climate_change',\n",
       "  'once',\n",
       "  'u',\n",
       "  'inclde',\n",
       "  'mental',\n",
       "  'health',\n",
       "  \"evrything's\",\n",
       "  'stake'],\n",
       " ['for', 'earth_day', 'resource', 'on', 'cop', 'with', 'climate_change'],\n",
       " ['ocean_saltiness',\n",
       "  'show',\n",
       "  'global_warming',\n",
       "  'be',\n",
       "  'intensify_our',\n",
       "  'water_cycle'],\n",
       " ['fedele',\n",
       "  'bauccio',\n",
       "  'combat',\n",
       "  'climate_change',\n",
       "  'one',\n",
       "  'meal',\n",
       "  'at',\n",
       "  'a',\n",
       "  'time',\n",
       "  'this_week',\n",
       "  'american',\n",
       "  'will',\n",
       "  'celebrate',\n",
       "  'the',\n",
       "  '40th',\n",
       "  'anniver'],\n",
       " ['i',\n",
       "  'support',\n",
       "  \"world_people's\",\n",
       "  'conf',\n",
       "  'on',\n",
       "  'climate_change',\n",
       "  'in',\n",
       "  'cochabamba',\n",
       "  'bolivia.watch',\n",
       "  'live'],\n",
       " ['topography',\n",
       "  'of',\n",
       "  'mountain',\n",
       "  'could',\n",
       "  'complicate',\n",
       "  'rate',\n",
       "  'of',\n",
       "  'global_warming'],\n",
       " ['i',\n",
       "  'support',\n",
       "  'the',\n",
       "  \"world_people's\",\n",
       "  'conference_on',\n",
       "  'climate_change',\n",
       "  'in',\n",
       "  'cochabamba',\n",
       "  'bolivia',\n",
       "  'watch',\n",
       "  'live',\n",
       "  'now',\n",
       "  'at'],\n",
       " ['bolivia',\n",
       "  'president',\n",
       "  'on',\n",
       "  'global_warming',\n",
       "  'main',\n",
       "  'cause',\n",
       "  'of',\n",
       "  'earth',\n",
       "  'destruction',\n",
       "  'be',\n",
       "  'capitalism',\n",
       "  'green',\n",
       "  'earthday'],\n",
       " ['boil',\n",
       "  'point',\n",
       "  'contain',\n",
       "  'the',\n",
       "  'spill',\n",
       "  'over',\n",
       "  'of',\n",
       "  'climate_change',\n",
       "  'in',\n",
       "  'the',\n",
       "  'indian',\n",
       "  'subcontinent',\n",
       "  'a',\n",
       "  'à_'],\n",
       " ['no',\n",
       "  'link',\n",
       "  'now',\n",
       "  'between',\n",
       "  'eyjafjallaj',\n",
       "  '__kull',\n",
       "  'and',\n",
       "  'climate_change',\n",
       "  'but',\n",
       "  'a',\n",
       "  'warming',\n",
       "  'world',\n",
       "  'could_trigger',\n",
       "  'earthquake',\n",
       "  'landslide'],\n",
       " ['uruguay_tool',\n",
       "  'need',\n",
       "  'for_those',\n",
       "  'most_vulnerable',\n",
       "  'to',\n",
       "  'climate_change',\n",
       "  'cleantech'],\n",
       " ['uruguay_tool',\n",
       "  'need',\n",
       "  'for_those',\n",
       "  'most_vulnerable',\n",
       "  'to',\n",
       "  'climate_change'],\n",
       " ['uruguay_tool',\n",
       "  'need',\n",
       "  'for_those',\n",
       "  'most_vulnerable',\n",
       "  'to',\n",
       "  'climate_change'],\n",
       " ['carbon_offset',\n",
       "  'how',\n",
       "  'a',\n",
       "  'vatican_forest',\n",
       "  'fail',\n",
       "  'to',\n",
       "  'reduce',\n",
       "  'global_warming'],\n",
       " ['carbon_offset',\n",
       "  'how',\n",
       "  'a',\n",
       "  'vatican_forest',\n",
       "  'fail',\n",
       "  'to',\n",
       "  'reduce',\n",
       "  'global_warming'],\n",
       " ['ethiopia',\n",
       "  'climate_change',\n",
       "  'increase',\n",
       "  'poverty_and',\n",
       "  'vulnerability',\n",
       "  'africa',\n",
       "  'solar'],\n",
       " ['ethiopia',\n",
       "  'climate_change',\n",
       "  'increase',\n",
       "  'poverty_and',\n",
       "  'vulnerability',\n",
       "  'small-scale',\n",
       "  'farmer',\n",
       "  'and',\n",
       "  'pastoralists',\n",
       "  'i',\n",
       "  'africa'],\n",
       " ['the',\n",
       "  'most_important',\n",
       "  'event',\n",
       "  'in',\n",
       "  'the',\n",
       "  'struggle_against',\n",
       "  'climate_change',\n",
       "  'nigerian_environmentalist',\n",
       "  'nnimmo_bassey',\n",
       "  'on',\n",
       "  'à_'],\n",
       " ['the',\n",
       "  'most_important',\n",
       "  'event',\n",
       "  'in',\n",
       "  'the',\n",
       "  'struggle_against',\n",
       "  'climate_change',\n",
       "  'nigerian_environmentalist',\n",
       "  'nnimmo_bassey',\n",
       "  'on',\n",
       "  'à_'],\n",
       " ['ocean_saltiness',\n",
       "  'show',\n",
       "  'global_warming',\n",
       "  'be',\n",
       "  'intensify_our',\n",
       "  'water_cycle'],\n",
       " ['backgrounder',\n",
       "  \"china's\",\n",
       "  'major',\n",
       "  'policy',\n",
       "  'to',\n",
       "  'tackle',\n",
       "  'climate_change',\n",
       "  'since',\n",
       "  'year',\n",
       "  '2000',\n",
       "  'chinagreen'],\n",
       " ['uw_biologist',\n",
       "  'link_early',\n",
       "  'bloom',\n",
       "  'to',\n",
       "  'global_warming',\n",
       "  'associate',\n",
       "  'press',\n",
       "  'april',\n",
       "  '21',\n",
       "  '2010',\n",
       "  '6:15',\n",
       "  'be',\n",
       "  'et',\n",
       "  'stevens',\n",
       "  'point'],\n",
       " ['uw_biologist',\n",
       "  'link_early',\n",
       "  'bloom',\n",
       "  'to',\n",
       "  'global_warming',\n",
       "  'associate',\n",
       "  'press',\n",
       "  'april',\n",
       "  '21',\n",
       "  '2010',\n",
       "  '6:15',\n",
       "  'be',\n",
       "  'et',\n",
       "  'stevens',\n",
       "  'point'],\n",
       " ['global_warming',\n",
       "  'evidence',\n",
       "  'all',\n",
       "  'around',\n",
       "  'u',\n",
       "  'a',\n",
       "  'message',\n",
       "  'to',\n",
       "  'global_warming',\n",
       "  'denier',\n",
       "  'and',\n",
       "  'doubter',\n",
       "  'just',\n",
       "  'look',\n",
       "  'around',\n",
       "  'our'],\n",
       " ['global_warming',\n",
       "  'evidence',\n",
       "  'all',\n",
       "  'around',\n",
       "  'u',\n",
       "  'a',\n",
       "  'message',\n",
       "  'to',\n",
       "  'global_warming',\n",
       "  'denier',\n",
       "  'and',\n",
       "  'doubter',\n",
       "  'just',\n",
       "  'look',\n",
       "  'around',\n",
       "  'our'],\n",
       " ['global_warming',\n",
       "  'evidence',\n",
       "  'all',\n",
       "  'around',\n",
       "  'u',\n",
       "  'a',\n",
       "  'message',\n",
       "  'to',\n",
       "  'global_warming',\n",
       "  'denier',\n",
       "  'and',\n",
       "  'doubter',\n",
       "  'just',\n",
       "  'look',\n",
       "  'around',\n",
       "  'our'],\n",
       " ['will',\n",
       "  'global_warming',\n",
       "  \"make_iceland's\",\n",
       "  'volcano_angry',\n",
       "  'melt_glacier',\n",
       "  'around',\n",
       "  'the',\n",
       "  'world',\n",
       "  'could_trigger',\n",
       "  'a',\n",
       "  'global'],\n",
       " ['will',\n",
       "  'global_warming',\n",
       "  \"make_iceland's\",\n",
       "  'volcano_angry',\n",
       "  'melt_glacier',\n",
       "  'around',\n",
       "  'the',\n",
       "  'world',\n",
       "  'could_trigger',\n",
       "  'a',\n",
       "  'global'],\n",
       " ['climate_change',\n",
       "  'could',\n",
       "  'nyc',\n",
       "  'get',\n",
       "  'katrina-like',\n",
       "  'flood',\n",
       "  'in',\n",
       "  'a',\n",
       "  'warmer',\n",
       "  'wetter',\n",
       "  'future',\n",
       "  'sea_level',\n",
       "  'rise',\n",
       "  'of',\n",
       "  '2_foot',\n",
       "  'in',\n",
       "  '70yrs'],\n",
       " ['climate_change',\n",
       "  'geologist',\n",
       "  'drill',\n",
       "  'into',\n",
       "  'antarctica',\n",
       "  'find',\n",
       "  'trouble',\n",
       "  'sign',\n",
       "  '4',\n",
       "  'ice',\n",
       "  'sheet',\n",
       "  'future',\n",
       "  'à_',\n",
       "  'melt',\n",
       "  'could',\n",
       "  'come',\n",
       "  'fast'],\n",
       " ['either',\n",
       "  'capitalism',\n",
       "  'dy',\n",
       "  'or',\n",
       "  'mother_earth',\n",
       "  'do',\n",
       "  'evo_morale',\n",
       "  'claim',\n",
       "  'in',\n",
       "  'the',\n",
       "  \"people's_world\",\n",
       "  'conference_on',\n",
       "  'climate_change'],\n",
       " ['yet',\n",
       "  'another',\n",
       "  'gift',\n",
       "  'from',\n",
       "  'global_warming',\n",
       "  'increase',\n",
       "  'allergy',\n",
       "  'attack',\n",
       "  'p2'],\n",
       " ['africa',\n",
       "  'time',\n",
       "  'bomb',\n",
       "  'await',\n",
       "  'africa',\n",
       "  'there_be',\n",
       "  'no',\n",
       "  'doubt',\n",
       "  'that',\n",
       "  'climate_change',\n",
       "  'a',\n",
       "  'an',\n",
       "  'environmental',\n",
       "  'issue',\n",
       "  'ha',\n",
       "  'africa'],\n",
       " ['buying',\n",
       "  'carbon_offset',\n",
       "  'may',\n",
       "  'ease',\n",
       "  'eco-guilt',\n",
       "  'but',\n",
       "  'not',\n",
       "  'global_warming'],\n",
       " ...]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tweet_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Pour les Tweets qui croient au réchauffement climatique : \n",
      " \n",
      "Global warming report urges governments to act|BRUSSELS, Belgium (AP) - The world faces increased hunger and .. \n",
      "Scores (pos/neg/neutre) : [0.0, 0.0, 1.0]\n",
      " \n",
      "Fighting poverty and global warming in Africa \n",
      "Scores (pos/neg/neutre) : [0.0, 0.0, 1.0]\n",
      " \n",
      "RT @sejorg: RT @JaymiHeimbuch: Ocean Saltiness Shows Global Warming Is Intensifying Our Water Cycle \n",
      "Scores (pos/neg/neutre) : [0.0, 0.0, 1.0]\n",
      " \n",
      "Global warming evidence all around us|A message to global warming deniers and doubters: Just look around our .. \n",
      "Scores (pos/neg/neutre) : [0.020833333333333332, 0.0, 0.9791666666666666]\n",
      " \n",
      "Migratory Birds' New Climate Change Strategy: Stay Home \n",
      "Scores (pos/neg/neutre) : [0.125, 0.05, 0.825]\n",
      " \n",
      "####################################################################################################\n",
      "####################################################################################################\n",
      " \n",
      " Pour les Tweets qui ne croient pas  au réchauffement climatique : \n",
      " \n",
      "Wait here's an idea: it's natural climate change, not human induced global warming. \n",
      "Scores (pos/neg/neutre) : [0.05357142857142857, 0.08928571428571429, 0.8571428571428571]\n",
      " \n",
      "@New_federalists  i have it on good auth tht global warming also causes toe fungus.  We R all fortunate tht thr IS no global warming! #tcot\n",
      "Scores (pos/neg/neutre) : [0.175, 0.05, 0.775]\n",
      " \n",
      "Illegal war and the myth of global warming|My main campaign platform for this election will be the illegal .. \n",
      "Scores (pos/neg/neutre) : [0.046875, 0.0, 0.953125]\n",
      " \n",
      "the scientific community was scamed by global green  gov warming scam.\n",
      "Scores (pos/neg/neutre) : [0.0, 0.125, 0.875]\n",
      " \n",
      "40 degrees in NYC. please urinate on next liberal global warming /climate change scum you see.\n",
      "Scores (pos/neg/neutre) : [0.175, 0.05, 0.775]\n",
      " \n"
     ]
    }
   ],
   "source": [
    "# Etude des résultats\n",
    "Base_SWN=pd.DataFrame(Base_SWN,columns=['Tweet','Scores','Label'])\n",
    "\n",
    "#############################################\n",
    "#############################################\n",
    "\n",
    "# Scores obtenus pour les Yes\n",
    "Base_SWN_yes=Base_SWN[(Base_SWN.Label=='Yes')&(Base_SWN.Scores!='pas de mots connus par SWN')]\n",
    "\n",
    "print(' Pour les Tweets qui croient au réchauffement climatique : ')\n",
    "print(' ')\n",
    "\n",
    "# Print des 5 premiers tweets de la base Yes\n",
    "for tweet_index in range(5):\n",
    "    print(list(Base_SWN_yes.Tweet)[tweet_index])\n",
    "    print('Scores (pos/neg/neutre) : '+str(list(Base_SWN_yes.Scores)[tweet_index]))\n",
    "    print(' ')\n",
    "#############################################\n",
    "#############################################\n",
    "\n",
    "\n",
    "print('#'*100)\n",
    "print('#'*100)\n",
    "print(' ')\n",
    "\n",
    "print(' Pour les Tweets qui ne croient pas  au réchauffement climatique : ')\n",
    "print(' ')\n",
    "# Scores obtenus pour les No\n",
    "Base_SWN_no=Base_SWN[(Base_SWN.Label=='No')&(Base_SWN.Scores!='pas de mots connus par SWN')]\n",
    "\n",
    "# Print des 5 premiers tweets de la base No\n",
    "for tweet_index in range(5):\n",
    "    print(list(Base_SWN_no.Tweet)[tweet_index])\n",
    "    print('Scores (pos/neg/neutre) : '+str(list(Base_SWN_no.Scores)[tweet_index]))\n",
    "    print(' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir de ces représentations, on peut étudier comment se répartissent les scors positifs dans les bases Yes et No ainsi que dans la base entière."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "Statistiques des scores obtenus sur les tweets de la base entière :\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score_pos</th>\n",
       "      <th>score_neg</th>\n",
       "      <th>score_neutre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>5435.000000</td>\n",
       "      <td>5435.000000</td>\n",
       "      <td>5435.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>0.038779</td>\n",
       "      <td>0.048963</td>\n",
       "      <td>0.912258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>0.061682</td>\n",
       "      <td>0.082293</td>\n",
       "      <td>0.106441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.862500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.944444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         score_pos    score_neg  score_neutre\n",
       "count  5435.000000  5435.000000   5435.000000\n",
       "mean      0.038779     0.048963      0.912258\n",
       "std       0.061682     0.082293      0.106441\n",
       "min       0.000000     0.000000      0.250000\n",
       "25%       0.000000     0.000000      0.862500\n",
       "50%       0.000000     0.000000      0.944444\n",
       "75%       0.062500     0.071429      1.000000\n",
       "max       0.625000     0.750000      1.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "############################################################\n",
      " \n",
      "Statistiques des scores obtenus sur les tweets des Yes :\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score_pos</th>\n",
       "      <th>score_neg</th>\n",
       "      <th>score_neutre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>2779.000000</td>\n",
       "      <td>2779.000000</td>\n",
       "      <td>2779.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>0.038137</td>\n",
       "      <td>0.049642</td>\n",
       "      <td>0.912221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>0.061173</td>\n",
       "      <td>0.086745</td>\n",
       "      <td>0.109528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.946429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         score_pos    score_neg  score_neutre\n",
       "count  2779.000000  2779.000000   2779.000000\n",
       "mean      0.038137     0.049642      0.912221\n",
       "std       0.061173     0.086745      0.109528\n",
       "min       0.000000     0.000000      0.250000\n",
       "25%       0.000000     0.000000      0.875000\n",
       "50%       0.000000     0.000000      0.946429\n",
       "75%       0.062500     0.071429      1.000000\n",
       "max       0.625000     0.750000      1.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "############################################################\n",
      " \n",
      "Statistiques des scores obtenus sur les tweets des No :\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score_pos</th>\n",
       "      <th>score_neg</th>\n",
       "      <th>score_neutre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>1014.000000</td>\n",
       "      <td>1014.000000</td>\n",
       "      <td>1014.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>0.047923</td>\n",
       "      <td>0.063173</td>\n",
       "      <td>0.888904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>0.067062</td>\n",
       "      <td>0.085786</td>\n",
       "      <td>0.111493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.906250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>0.075000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.986111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         score_pos    score_neg  score_neutre\n",
       "count  1014.000000  1014.000000   1014.000000\n",
       "mean      0.047923     0.063173      0.888904\n",
       "std       0.067062     0.085786      0.111493\n",
       "min       0.000000     0.000000      0.250000\n",
       "25%       0.000000     0.000000      0.833333\n",
       "50%       0.020833     0.031250      0.906250\n",
       "75%       0.075000     0.100000      0.986111\n",
       "max       0.625000     0.750000      1.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "############################################################\n",
      " \n"
     ]
    }
   ],
   "source": [
    "def stati_scores(base):\n",
    "    base=pd.DataFrame(list(base.Scores),columns=['score_pos','score_neg','score_neutre'])\n",
    "    display(base.describe())\n",
    "    \n",
    "print(' ')\n",
    "print('Statistiques des scores obtenus sur les tweets de la base entière :')\n",
    "stati_scores(Base_SWN[Base_SWN.Scores!='pas de mots connus par SWN'])\n",
    "print(' ')\n",
    "print('#'*60)\n",
    "print(' ')\n",
    "print('Statistiques des scores obtenus sur les tweets des Yes :')\n",
    "stati_scores(Base_SWN_yes)\n",
    "print(' ')\n",
    "print('#'*60)\n",
    "print(' ')\n",
    "print('Statistiques des scores obtenus sur les tweets des No :')\n",
    "stati_scores(Base_SWN_no)\n",
    "print(' ')\n",
    "print('#'*60)\n",
    "print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3dfZxWdZ3/8debAWbwnsJmV0WwRGOg1lbE/SnVICpWJj1+q6t0a4uwaExbdIM6m5Uta1hSu3iDEFlbOa66vy00CVydqdBuwNQEJg1vIbxJExWFkZvP749zruFiuGbmGpyZa64z7+fjcT3mOud8zzmf61zf6zPf8z13igjMzKz8DSh1AGZm1j2c0M3MMsIJ3cwsI5zQzcwywgndzCwjnNDNzDLCCd26jaSPSFrRwfR3S3q4l2J5QtKpvbGu/kLSWkm1HUxfJukTecP/Kul5Sc/0SoCGfB56+ZD0BFAN7AS2AD8DZkXElhLEMhJ4HBgUETvaKRPAqIhY34uh5db9BHBBRPxvb6+7P5D0FeDoiPhoO9OHA48AIyLiud6MrT9zC738fDAiDgCOA94FXNITK5FU0RPLtcKUyNLvcQTwgpN578pSBepXIuIZYDlJYgdAUqWkb0p6StKzkhZKGpJOq5W0UdKl6W7wE5I+kjfv9yRdJ+kOSa8CEyV9QNL9kl6WtCFtleX8Iv27WdIWSf9H0vmSVqbLy01/MJ1+bi6GvHWOltQkaXO6O39Wm3iukfRTSa9I+o2kt7W3PSR9TNKTkl6QVN9m2gBJF0t6NJ1+s6Q3pdOqJP0wHb9Z0ipJ1e2sY46kP6XxPCxpUjq+It2uj6bT7ktbqEg6KV3mS+nfk/KW1yRprqR7gNeAt0o6WNISSU+n6/rX3D9XSUdL+nm6rOcl/Vc7cY6UFJJmSNqULutzedMrJX07nbYpfV+ZThsm6fZ0W/xF0i9z/2jSOnOqpDOAS4Fz0+/2wbzPc4GSrq47gcPS6d/ryna2NyAi/CqTF/AEcGr6/gjgIeDf86Z/G1gKvAk4ELgNuCKdVgvsAOYDlcB7gVeBY9Pp3wNeAk4m+Udflc7zjnT4ncCzwIfS8iOBAAbmrf98YGXecJDslpMXw8b0/SBgPUliGAycArzSJp6/AOOBgcCPgJva2S41JF1Q70k/2/z0s+a21WeAX6fbrBK4HmhIp/1Tup32AyqA44GDCqzjWGADcFje539b+v4L6XdxLCDgb4A3p9/Di8DH0s8wNR1+czpfE/AUMCadPgj4cRrf/sBbgN8C/5SWbwDq876fCe1sj9x305Au5x3An/O2x+Xp9ngLcChwL/C1dNoVwMI0lkHAu9ndNftE3jK+AvywzXqbSLq59viuu7Kd/XpjL7fQy8+PJb1CklyeA74MyS47MB34bET8JSJeAf4NOK/N/F+KiJaI+DnwU+Af8qb9JCLuiYhdEbEtIpoi4qF0+PckCeK93fQ5/g44APh6RLweEXcDt5MkvZz/FxG/jaSP/kfk7Y20cTZwe0T8IiJagC8Bu/Km/xNQHxEb0+lfAc6WNBDYTpJ8j46InRFxX0S8XGAdO0n+GdRIGhQRT0TEo+m0C4B/iYiHI/FgRLwAfAD4Y0T8ICJ2REQD8Afgg3nL/V5ErE0/45uA9wGfiYhXI+mu+Ba7v8PtJF0Zh6Xfz8p2t27iq+lyHgJuYPe2/QhweUQ8FxF/Br5K8k8nt46/Jun73h4Rv4yI7jjQVux2tjfACb38fCgiDiRpAb0dGJaOP5Sk9XNfuku7meSg6aF5874YEa/mDT8JHJY3vCF/RZJOlNQo6c+SXgJm5q3vjToM2BAR+Yn3SeDwvOH8syNeI/kH0O6ycgPpZ3whb/oI4H/ytkszSYKuBn5A0nV1U9r9cKWkQW1XEMmB3c+Q/DN4TtJNknLbbjjwaNt50riebDOu7WfM3+YjSFrFT+fFej1JSxrgiyR7AL9Nu6j+seDWKLzs/O+6bVz5075Bsue0QtJjki7uZB3FKmo72xvjhF6m0hb294BvpqOeB7YCYyLikPR1cCQHUHOGSto/b/hIYFP+Ytus5kaSLpzhEXEwya642inbVZuA4drzQOCRwJ/2YVlPkyRVACTtR9IazNkAvC9vuxwSEVUR8ae0FfrViKgBTgLOBD5eaCURcWNETCBJvAHMy1t+of79TWnZfG0/Y/523AC0AMPy4jwoIsak638mIqZHxGEkex3XSjq6/c2ye5uw53fdNq7WaRHxSkR8LiLeSrInMTt3rKCNLn3/XdnOtu+c0Mvbt4HTJB2XtnQXA9+S9BYASYdLmtxmnq9KGizp3SQ/qls6WP6BwF8iYpuk8cCH86b9maRb460dzP9sB9N/Q9KH/0VJg5Sc3/xB4KYOlteeW4EzJU2QNJikjzi/bi8E5koaASDpUElT0vcTJb0jPfD4MknXwM62K5B0rKRT0oOH20j+eebKfQf4mqRRSrxT0puBO4BjJH1Y0kBJ55L0999e6ENExNPACuAqSQcpOZj7NknvTWM4R9IRafEXSZLqXrHm+ZKk/SSNAT4J5A6iNgD/km6HYcBlwA/TdZyZHnxVuj12trOOZ4GRKvLMnGK3s70xTuhlLO3//E+SPmOAOSS7y7+W9DLwvyQH6nKeIUkEm0j6pGdGxB86WMVFwOVpn/1lwM15634NmAvck3YP/F2B+b8CfD+dnt9XT0S8DpxF0mf8PHAt8PFO4ikoItYCnyLZo3g6/Ywb84r8O8mexor0s/waODGd9lck/xBeJumK+TlpcmujEvh6GuszJN0gl6bT5pNsmxXpcpYAQ9J+9DOBz5F0AX0RODMinu/g43yc5CDxuvRz3ErSpw1wAvAbSVvSz/PPEfF4B8v6OUl9uAv4ZkTkLvr6V2A18HuSg7m/S8cBjCKpN1uAXwHXRkRTgWXnGgIvSPpdBzHkFLud7Q3whUX9RNoC/mFEHNFZWStvKuKiL8smt9DNzDLCCd3MLCPc5WJmlhFuoZuZZcTAUq142LBhMXLkyFKtPnNeffVV9t9//84LmvUy183udd999z0fEYcWmlayhD5y5EhWr15dqtVnTlNTE7W1taUOw2wvrpvdS1Lbq49bucvFzCwjnNDNzDLCCd3MLCOc0M3MMsIJ3cwsI5zQzaxHNDQ0MHbsWCZNmsTYsWNpaGgodUiZV7LTFs0suxoaGqivr2fJkiXs3LmTiooKpk2bBsDUqVM7mdv2lVvoZtbt5s6dy5IlS5g4cSIDBw5k4sSJLFmyhLlz55Y6tExzQjezbtfc3MyECRP2GDdhwgSam5tLFFH/4IRuZt1u9OjRrFy55zOsV65cyejRo0sUUf/ghG5m3a6+vp5p06bR2NjIjh07aGxsZNq0adTX15c6tEzzQVEz63a5A591dXU0NzczevRo5s6d6wOiPcwJ3cx6xNSpU5k6dapvztWLin1i9xmSHpa0XtLF7ZT5B0nrJK2VdGP3hmlmZp3ptIUuqQK4BjiN5EnqqyQtjYh1eWVGAZcAJ0fEi5Le0lMBm5lZYcW00McD6yPisYh4HbgJmNKmzHTgmoh4ESAinuveMM3MrDPF9KEfDmzIG94InNimzDEAku4BKoCvRMTP2i5I0gxgBkB1dTVNTU37ELIVsmXLFm9P65NcN3tPMQldBca1fbL0QGAUUAscAfxS0tiI2LzHTBGLgEUA48aNCx8o6T4+8GR9letm7ymmy2UjMDxv+AhgU4EyP4mI7RHxOPAwSYI3M7NeUkxCXwWMknSUpMHAecDSNmV+DEwEkDSMpAvmse4M1MzMOtZpQo+IHcAsYDnQDNwcEWslXS7prLTYcuAFSeuARuALEfFCTwVtZmZ7K+rCooi4A7ijzbjL8t4HMDt9mZlZCfheLmZmGeGEbmaWEU7oZmYZ4YRuZpYRTuhmZhnhhG5mlhFO6GZmGeGEbmaWEU7oZmYZ4YRuZpYRTuhmZhnhhG5mlhFO6GZmGeGEbmaWEU7oZmYZ4YRuZpYRTuhmZhnhhG5mlhFO6GZmGeGEbmaWEU7oZmYZ4YRuZpYRTuhmZhlRVEKXdIakhyWtl3RxgennS/qzpAfS1wXdH6qZlZO6ujqqqqqYOHEiVVVV1NXVlTqkzBvYWQFJFcA1wGnARmCVpKURsa5N0f+KiFk9EKOZlZm6ujoWLlzIvHnzqKmpYd26dcyZMweABQsWlDi67CqmhT4eWB8Rj0XE68BNwJSeDcvMytnixYuZN28es2fPpqqqitmzZzNv3jwWL15c6tAyrdMWOnA4sCFveCNwYoFyfy/pPcAjwGcjYkPbApJmADMAqquraWpq6nLAVtiWLVu8Pa3PaGlpoaamhqampta6WVNTQ0tLi+tpDyomoavAuGgzfBvQEBEtkmYC3wdO2WumiEXAIoBx48ZFbW1t16K1djU1NeHtaX1FZWUl69atY/bs2a11c/78+VRWVrqe9qBiEvpGYHje8BHApvwCEfFC3uBiYN4bD83MytX06dNb+8xramqYP38+c+bMYebMmSWOLNuKSeirgFGSjgL+BJwHfDi/gKS/join08GzgOZujdLMykruwOell15KS0sLlZWVzJw50wdEe1inB0UjYgcwC1hOkqhvjoi1ki6XdFZa7NOS1kp6EPg0cH5PBWxm5WHBggVs27aNxsZGtm3b5mTeC4ppoRMRdwB3tBl3Wd77S4BLujc0MzPrCl8pamaWEU7oZmYZ4YRuZpYRTuhmZhnhhG5mlhFO6GZmGeGEbmaWEU7oZmYZ4YRuZpYRTuhmZhnhhG5mlhFO6GZmGeGEbmaWEU7oZmYZ4YRuZpYRTuhmZhnhhG5mlhFO6GZmGeGEbmaWEU7oZmYZ4YRuZpYRTuhmZhlRVEKXdIakhyWtl3RxB+XOlhSSxnVfiGZmVoxOE7qkCuAa4H1ADTBVUk2BcgcCnwZ+091BmplZ54ppoY8H1kfEYxHxOnATMKVAua8BVwLbujE+MzMr0sAiyhwObMgb3gicmF9A0ruA4RFxu6TPt7cgSTOAGQDV1dU0NTV1OWArbMuWLd6e1ie5bvaeYhK6CoyL1onSAOBbwPmdLSgiFgGLAMaNGxe1tbVFBWmda2pqwtvT+iLXzd5TTJfLRmB43vARwKa84QOBsUCTpCeAvwOW+sComVnvKiahrwJGSTpK0mDgPGBpbmJEvBQRwyJiZESMBH4NnBURq3skYjMzK6jThB4RO4BZwHKgGbg5ItZKulzSWT0doJmZFaeo89Aj4o6IOCYi3hYRc9Nxl0XE0gJla9067z0NDQ2MHTuWSZMmMXbsWBoaGkodkhngulkKxRwUtT6qoaGB+vp6lixZws6dO6moqGDatGkATJ06tcTRWX/mulkiEVGS1/HHHx/2xowZMybuvvvuiIhobGyMiIi77747xowZU8KozFw3exKwOtrJq76XSxlrbm5mwoQJe4ybMGECzc3NJYrILOG6WRpO6GVs9OjRrFy5co9xK1euZPTo0SWKyCzhulkaTuhlrL6+nmnTptHY2MiOHTtobGxk2rRp1NfXlzo06+dcN0vDB0XLWO7gUl1dHc3NzYwePZq5c+f6oJOVnOtmaSjpY+9948aNi9WrfXZjd/Hl1dZXuW52L0n3RUTBK/Hd5WJmlhFO6GZmGeGEbmaWEU7oZmYZ4YRuZpYRTuhlrq6ujqqqKiZOnEhVVRV1dXWlDskM8M25SsHnoZexuro6Fi5cyLx586ipqWHdunXMmTMHgAULFpQ4OuvPfHOuEmnvJi89/fLNud64ysrKuOqqqyJi9w2QrrrqqqisrCxhVGa+OVdPwjfnyqaWlhZmzpy5x7iZM2fS0tJSoojMEr45V2k4oZexyspKFi5cuMe4hQsXUllZWaKIzBK+OVdpuA+9jE2fPr21z7ympob58+czZ86cvVrtZr0td3OuXB967uZcc+fOLXVomeaEXsZyBz4vvfRSWlpaqKysZObMmT4gaiXnm3OVhm/OlRG+AZL1NZMnT+bOO+8kIpDEaaedxvLly0sdVtnzzbnMrFdNnjyZFStWMHPmTG677TZmzpzJihUrmDx5cqlDyzR3uZhZt7vzzju58MILufbaa2lqauLaa68F2OsgvnUvt9DNrNtFBFdcccUe46644gpK1cXbXxSV0CWdIelhSeslXVxg+kxJD0l6QNJKSTXdH6qZlQtJXHLJJXuMu+SSS5BUooj6h067XCRVANcApwEbgVWSlkbEurxiN0bEwrT8WcB84IweiNfMysBpp53GddddB8D73/9+LrroIq677jpOP/30EkeWbcX0oY8H1kfEYwCSbgKmAK0JPSJeziu/P+D9KrN+bPny5UyePJmFCxdy3XXXIYnTTz/dZ7n0sGIS+uHAhrzhjcCJbQtJ+hQwGxgMnFJoQZJmADMAqquraWpq6mK41p4tW7Z4e1qfMn78eB555BGeeuopjjzySMaPH+862sOKSeiFOr32aoFHxDXANZI+DPwL8IkCZRYBiyA5D93nTXcfn4dufUlDQwM/+tGP+O53v7vH3RZramp8cVEPKuag6EZgeN7wEcCmDsrfBHzojQRlZuVt7ty5LFmyhIkTJzJw4EAmTpzIkiVLfOl/Dysmoa8CRkk6StJg4DxgaX4BSaPyBj8A/LH7QjSzctPc3Mwtt9yyx8NXbrnlFt9tsYd12uUSETskzQKWAxXAdyNiraTLSe7LuxSYJelUYDvwIgW6W8ys/zjkkEO4/vrr+cY3vtH68JUvfOELHHLIIaUOLdN8L5cy19DQwNy5c1tvgFRfX+8+Siu5QYMGUVVVxbBhw3jyyScZMWIEzz//PNu2bWP79u2lDq+sdXQvF1/6X8b8mC/rq3bs2EFVVRVA68VEVVVVbNmypZRhZZ4v/S9jPvBkfZUkzjnnHB5//HHuuusuHn/8cc455xxfKdrD3EIvY37Ml/VVEcHixYs5+uijWx++snjxYt/LpYc5oZex3GO+Jk6c2DrOj/myvmDMmDGMGjVqj4evnHnmmfzxjz4Brie5y6WM5R7z1djYyI4dO1of81VfX1/q0Kyfq6+v58EHH2TZsmXceeedLFu2jAcffNB1s4e5hV7G/Jgv66tcN0vDpy1mhC/9t77KdbN7+bTFDBswYMAeB5oksWvXrhJGZJY48sgj2bBh9339hg8fzlNPPVXCiLLPfehlLJfMq6qquPrqq6mqqiIiGDDAX6uVVi6Zn3TSSdxyyy2cdNJJbNiwgSOPPLLUoWWaf/llLJfMt27dypgxY9i6dWtrUjcrpVwyv+eeexg2bBj33HNPa1K3nuOEXuba3l/a95u2vuLWW2/tcNi6nxN6mWt7sMkHn6yvOPvsszsctu7nhF7GJLFt2zaGDBnC2rVrGTJkCNu2bfPl1VZyw4cP59577+Xkk0/m+eef5+STT+bee+9l+PDhnc9s+8ynLZY5n+VifZXPcukZHZ226BZ6mdu1axcRQWNjIxHhZG59xlNPPbVH3XQy73lO6GbWIxoaGhg7diyTJk1i7NixNDQ0lDqkzPOFRWWurq6OxYsXt94Aafr06SxYsKDUYVk/53v1l4b70MtYXV0dV1999V7jZ82a5aRuJTV27FgeeeSRPZ5ONGjQII455hjWrFlTwsjKn/vQMyqXzPOvxssfb1Yqa9euZfv27VRXV3PDDTdQXV3N9u3bWbt2balDyzQn9DI3fvz4Pa7GGz9+fKlDMgNg6NChPPPMM4wcOZJnnnmGoUOHljqkzHMfepm7//779zjvfNCgQSWMxmy3l19+eY+6WVFRUcJo+ge30Mvc9u3bGTp0KIsXL2bo0KF+orr1GTt37mxtlQ8dOpSdO3eWOKLsc0LPgM2bNzN9+nQ2b95c6lDM9jB48GBuuOEGBg8eXOpQ+oWiErqkMyQ9LGm9pIsLTJ8taZ2k30u6S9KI7g/VCqmoqGi9UjQivFtrfcqzzz7LJz/5SZ599tlSh9IvdJrQJVUA1wDvA2qAqZJq2hS7HxgXEe8EbgWu7O5ArbCdO3dy4YUXctttt3HhhRd6t9asHyumhT4eWB8Rj0XE68BNwJT8AhHRGBGvpYO/Bo7o3jCtI8uWLWPz5s0sW7as1KGY7SF3kN4H63tHMWe5HA7k35V+I3BiB+WnAQUzi6QZwAyA6upq37u7G1RWVvLEE0/wsY99rHW4paXF29b6hNxB+vyD9a6bPaeYhF7oXqwFLy+V9FFgHPDeQtMjYhGwCJIrRX3v7jdGEi0tLXuMa2lpQZLvi24lN27cOFatWtX6kOgTTjiB1atXu272oGK6XDYC+TcxPgLY1LaQpFOBeuCsiGhpO926X+5gaEVFBfPnz289IOpH0FlfsHr1aqZMmcLmzZuZMmUKvtVHz+v0Xi6SBgKPAJOAPwGrgA9HxNq8Mu8iORh6RkT8sZgV+14ub5yk1vuhRwSSWu+H7qRupVRVVbXX3iMkXYLbtm0rQUTZ8Ybu5RIRO4BZwHKgGbg5ItZKulzSWWmxbwAHALdIekDS0m6K3TqxatUqdu3aRWNjI7t27WLVqlWlDsn6qVyDolBXYE6uSzD3su5V1HnoEXFHRBwTEW+LiLnpuMsiYmn6/tSIqI6I49LXWR0v0brLSSedtMc9p3M36DLrbbk9xdzrxhtvZMyYMaABjBkzhhtvvHGvMta9fKVoGcu1hB599FH+4z/+g0cffbS1BWRWalOnTmXNmjWM+OJS1qxZ4/ug9wIn9DJWU5Nc37Vt2zZmzZrV2jeZG29m/YsTehnL3Vs6/57T+ePNrH/x7XPL3IABA1rvl5Eb9oOizfont9DL3K5duxgyZAiSGDJkiJO5WT/mhJ4B1dXVSGrtcjGz/skJPQM2bNhARLBhw4bOC5tZZrkPPQNyt8z1rXPN+je30MtYe+eb+zx0s/7JCb2MtXelna/AM+ufnNAzwAdFzQyc0Mvefvvtx5AhQwAYMmQI++23X4kjMrNScUIvc6+9ljz5L9dvnhs2s/7HCT0Dtm7dypIlS9i6dWupQzGzEvJpixmQf+m/mfVfbqGbmWWEW+gZcPfdd7Nz504qKio45ZRTSh2OmZWIW+hl7oILLqCuro7JkydTV1fHBRdcUOqQzKxE3EIvc9/5zneICJqamqitrfVVomb9mFvoGSCJZcuWOZmb9XNO6GUs/xL/K6+8suB4M+s/nNDLXO7p6Y2NjX6Sulk/V1RCl3SGpIclrZd0cYHp75H0O0k7JJ3d/WGamVlnOj0oKqkCuAY4DdgIrJK0NCLW5RV7Cjgf+HxPBGmJfe0jd6vdrH8opoU+HlgfEY9FxOvATcCU/AIR8URE/B7wAy17UK5LpdBrxJzb251mZv1DMactHg7kP9tsI3DivqxM0gxgBiS3fG1qatqXxVg7vD2tr3Ld7B3FJPRC+/n71OyLiEXAIoBx48ZFbW3tvizGCvnZT/H2tD7JdbPXFNPlshEYnjd8BLCpZ8IxM7N9VUxCXwWMknSUpMHAecDSng3LzMy6qtOEHhE7gFnAcqAZuDki1kq6XNJZAJJOkLQROAe4XtLangzazMz2VtS9XCLiDuCONuMuy3u/iqQrxszMSsRXipqZZYQTuplZRvj2uWbWJX/z1RW8tHV7l+YZefFPu1T+4CGDePDLp3dpHnNCN7Muemnrdp74+geKLp+7V39XdPUfgCXc5WJmlhFO6GZmGeGEbmaWEU7oZmYZ4YRuZpYRTuhmZhnhhG5mlhE+D70P2pcLN6Br5+76wg2z7HFC74O6euEGdP3iDV+4YZY97nIxM8sIJ3Qzs4xwQjczywgndDOzjHBCNzPLCCd0M7OM8GmLZtYlB46+mHd8/+KuzfT9rq4DoGun7poTupl10SvNX/cDLvood7mYmWWEE7qZWUYUldAlnSHpYUnrJe3VeSapUtJ/pdN/I2lkdwdqZmYd6zShS6oArgHeB9QAUyXVtCk2DXgxIo4GvgXM6+5AzcysY8W00McD6yPisYh4HbgJmNKmzBR2H8e+FZgkSd0XppmZdaaYs1wOBzbkDW8ETmyvTETskPQS8Gbg+fxCkmYAMwCqq6tpamrat6gzbp9OC4MunRp24Ghoatq/6+swo/BZKE/OO7PLyxkx5/aC4/cfhPPDPigmoRdqacc+lCEiFgGLAMaNGxddPZWpv3iIh7o8z76cGma2L56obWfC1/f6yQOum72pmC6XjcDwvOEjgE3tlZE0EDgY+Et3BGhmZsUpJqGvAkZJOkrSYOA8YGmbMkuBT6TvzwbujojC/67NzKxHdNrlkvaJzwKWAxXAdyNiraTLgdURsRRYAvxA0nqSlvl5PRm0mZntrahL/yPiDuCONuMuy3u/DTine0MzM7Ou8JWiZmYZ4YRuZpYRTuhmZhnhhG5mlhEq1dmFkv4MPFmSlWfTMNpcmWvWR7hudq8REXFooQklS+jWvSStjohxpY7DrC3Xzd7jLhczs4xwQjczywgn9OxYVOoAzNrhutlL3IduZpYRbqGbmWWEE7qZWUY4ofcwSYdJujV9f5yk9+dNOyv30G1Jh6YP2L5f0rv3YT1bui/qvZZdK6nwo2W6ofy+kvQWSY9L+qu8cdcWepC5tc91tGel6wpJH8wbd7uk2u5eV6YTevqwjZKKiE0RcXY6eBzw/rxpSyPi6+ngJOAPEfGuiPhlb8dZjiLiOZIHkn8TQNLfAhOAq0oZV1e4jvYbG4H6Hl9LRPSZF7A/8FPgQWANcG46/gTg3nT8b4EDgSrgBuAh4H5gYlr2fOAW4DaSB20AfIHkQR2/B77a0braxNMEfDtd9xpgfDr+TcCP0+X9GnhnOv69wAPp6/40zpHpvIOBp4A/p9PPTWO9muRHlD9tf+B76XwPAZ8tENtRwK/Sz/U1YEs6/gDgLuB36bxT0vEjgWZgMbAWWAEMSad9GliXfp6bCqyrFrg9fT8+3R73p3+Pbaf8L4D/SZe7EBiQTrsOWJ3G8NW8eb6eF8M303GHAv+dfsZVwMkF1jUg3Q4T03jek44fCMwnqS+/By5Ixx8OrEy38xrgJNdR11F6to7WAreTPFPitHTc7UBt+n5SGutDwHeByn3OoaVM4AU++N8Di/OGD04r2WPACem4g0h+rJ8DbkjHvT2tbFVpBdwIvCmddjrJaX0d72MAAAT0SURBVFMi+fHfDryn0Lra+bEsTt+/B1iTvl8AfDl9fwrwQPr+ttwXmlbagWklzc13PnB13vJbh9u8Px64M6/cIQViWwp8PH3/KXb/WAYCB6XvhwHr088+EtgBHJdOuxn4aPp+U64StbOuWnb/WA4CBqbvTwX+u53y24C3kjwU5U7g7FyiSf9WpNv3nSTJ52F2n3V1SPr3RmBC+v5IoLmdenMcyYNVvpc37iLg4vR9JckP5khgDjAnL4YDXEddR+nBOsruhP5u4OfpuNvT8VXABuCYdPx/Ap/pSp3Mf/W1LpeHgFMlzZP07oh4CTgWeDoiVgFExMsRsYNk1/oH6bg/kNwX5ph0OXdGRO6Zpqenr/tJWgRvB0a1s65CGtJ1/AI4SNIhbdZ9N/BmSQcD9wDzJX2a5AvfsY/b4THgrZIWSDoDeLlAmZNzseViSQn4N0m/B/6XpEVanU57PCIeSN/fR/IDgqTF8SNJHyX5QXXkYOAWSWuAbwFj2in324h4LCJ2pnFOSMf/g6TfkXwfY4Ca9PNtA74j6f8Cr6VlTwWulvQASXI4SNKBbVeUfqY1wLV5o08HPpnO+xvgEJLvfRVwgaQvA2Mjoqv9uq6jCdfRRFF1FCDSbqo2xx+OTT/zI+nw90n+Me+TPpXQ0w91PElFvkLSZSRffqGT5dXBol5tU+6KiDgufR0dEUvaWVfBsAoMF1p3RNLXeAEwBPi1pLd3EGO7IuJF4G9IWgefAr5TZGwAHyHZDTw+Io4DniVpBQC05JXbye4nVn0AuIZke9zXSb/u14DGiBgLfDBv2Z3FFpKOAj4PTIqId5J0J1SlSWU8ya7rh4CfpfMMAP5P3nd3eES80s76dqWvHAEX5c17VETclSa3WuBpkgTxkQ4+694fynU0tyDX0URX6ijAXPbsS++ojnRZn0rokg4DXouIH5Ic6Ppb4A/AYZJOSMscmH6ZvyCpGEg6hmR35+ECi10O/KOkA9Kyh6dnRxRaVyHnpvNNAF5KW0n5664Fno+IlyW9LSIeioh5JH1wbX8sr5D0WXa2HYaR9Of9N/CldmK7h93Pbs1PSgcDz0XEdkkTgRGdrGsAMDwiGoEvkrRkD+hgloOBP6Xvz++g3Pj0weIDSLbhSpJd4VeBlyRVA+9LYziApDvhDuAzJF0okPShzsqL9TiKtxy4KPfDl3SspCGSRgDPRMQikj7gd3Vhma6ju7eD62iiS3U0IlYAQ0n+GUJSd0ZKOjod/hjw846W0ZGSH2Fv4x3ANyTtArYDF0bE65LOBRZIGgJsJdnNuRZYKOkhkl2w8yOiRdrzH15ErJA0GvhVOm0L8FHg6LbraiemFyXdS/JF/2M67ivADeku42vAJ9Lxn0kr6E6SgyfLgL/OW1YjcHG6e3ZFB9vh8HT5uX+4lxQo88/AjZL+maTVkPMj4DZJq0kOXv2hg/VA0k/4w3R3XMC3ImJzB+WvBL4vaTZwdwflfkVyEOkdpAefImKXpPtJDjY9RvKDhySB/ERSVRrDZ9PxnwauSbdzLkHO7OTz5FxPkkAfSL/354ApJAegZkvazu660BWuownX0cS+1NG5wE8geR6zpE+SdBENJOkSXNjJ/O3ypf8dkNQEfD4iVpc6FrNCXEctX5/qcjEzs33nFrqZWUa4hW5mlhFO6GZmGeGEbmaWEU7oZmYZ4YRuZpYR/x+n4zCIuBEihAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Boxplot des distributions des scores \n",
    "\n",
    "# Scores positifs des bases No et Yes  \n",
    "lis_pos_no=pd.DataFrame(list(Base_SWN_no.Scores),columns=['score_pos','score_neg','score_neutre'])['score_pos']\n",
    "lis_pos_yes=pd.DataFrame(list(Base_SWN_yes.Scores),columns=['score_pos','score_neg','score_neutre'])['score_pos']\n",
    "\n",
    "# Scores positifs des bases No et Yes  \n",
    "lis_neg_no=pd.DataFrame(list(Base_SWN_no.Scores),columns=['score_pos','score_neg','score_neutre'])['score_neg']\n",
    "lis_neg_yes=pd.DataFrame(list(Base_SWN_yes.Scores),columns=['score_pos','score_neg','score_neutre'])['score_neg']\n",
    "\n",
    "\n",
    "Base_pos=pd.DataFrame([[x,y] for (x,y) in zip(lis_pos_yes,lis_pos_no)],columns=['scores positifs dans la base Yes','scores positifs dans la base No'])\n",
    "Base_neg=pd.DataFrame([[x,y] for (x,y) in zip(lis_neg_yes,lis_neg_no)],columns=['scores negatifs dans la base Yes','scores négatifs dans la base No']) \n",
    "\n",
    "x=Base_pos.plot.box(grid='True',title='Repratition des scores positifs')\n",
    "x=Base_neg.plot.box(grid='True',title='Repratition des scores negatifs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\underline{Commentaires}$\n",
    "\n",
    "Concernant les scores positifs, la distribution de ces scores est sensiblement la même pour la base Yes et pour la base No.\n",
    "\n",
    "Concernant les scors négatifs, la distribution présente des différences. On observe que les tweets dans la base No sont scorés plus négativement. Par exemple, le 3ème quartile est des scores négatifs est de 0.10 pour la base No ; de 0.075 pourla base Yes. En observant les boxplots de ces distributions, on observe que la différence est assez significative. \n",
    "\n",
    "On peut faire la même remarque pour les scores positifs.\n",
    "\n",
    "S'ajoutant aux arguments différents entre les tweets No et Yes (voir partie II.a, II.b), la tonalité nous informe du caractère pessimiste/optimiste des tweets. Les personnes sceptiques semblent avoir un ton davantage incisif. C'est intéressant dans le sens où le 'pessimisme' supposé des tweets Yes (concernant le réchauffement climatique, hausse de température...) semble être dépassé par la 'négativité' tweets No(concernant les fraudes, les scandales, les mensonges). On peut notamment expliqué cela par le fait que les tweet No sont souvents accompagnés de mots plus forts et, à certains moments, d'insultes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour résumer les trois scores associés à un tweet, on peut déterminer si le score positif est supèrieur au score négatif. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "Sur toute la base (5435 tweets) : \n",
      " \n",
      "Le nombre de tweets jugés positifs est 1452 --> 26.72%\n",
      "Le nombre de tweets jugés négatifs est 1837 --> 33.8%\n",
      "Le nombre de tweets jugés neutres est 2146 --> 39.48%\n",
      " \n",
      "##############################\n",
      "##############################\n",
      " \n",
      " \n",
      "Sur la base composée des Yes (2779 tweets) : \n",
      " \n",
      "Le nombre de tweets jugés positifs est 740 --> 26.63%\n",
      "Le nombre de tweets jugés négatifs est 939 --> 33.79%\n",
      "Le nombre de tweets jugés neutres est 1100 --> 39.58%\n",
      " \n",
      "##############################\n",
      "##############################\n",
      " \n",
      " \n",
      "Sur la base composée des No (1014 tweets) : \n",
      " \n",
      "Le nombre de tweets jugés positifs est 297 --> 29.29%\n",
      "Le nombre de tweets jugés négatifs est 406 --> 40.04%\n",
      "Le nombre de tweets jugés neutres est 311 --> 30.67%\n",
      " \n",
      "##############################\n",
      "##############################\n",
      " \n"
     ]
    }
   ],
   "source": [
    "# On peut scorer un Tweet en faisant le classant positif si son score négatif est plus grand\n",
    "# que son score négatif ; et inversement. Si les deux scores sont égaux on le classe comme neutre\n",
    "\n",
    "def stati_scores_major(base):\n",
    "    base=pd.DataFrame(list(base.Scores),columns=['score_pos','score_neg','score_neutre'])\n",
    "    base['pos']=(base['score_pos']>base['score_neg'])*1\n",
    "    base['neg']=(base['score_neg']>base['score_pos'])*1\n",
    "    return([sum(base['pos']),sum(base['neg']),len(base)-(sum(base['neg'])+sum(base['pos']))])\n",
    "\n",
    "# Sur toute la base \n",
    "data=Base_SWN[Base_SWN.Scores!='pas de mots connus par SWN']\n",
    "results=stati_scores_major(data)\n",
    "print(' ')\n",
    "print('Sur toute la base ({} tweets) : '.format(len(data)))\n",
    "print(' ')\n",
    "print('Le nombre de tweets jugés positifs est {} --> {}%'.format(str(results[0]),str(round(100*results[0]/len(data),2))))\n",
    "print('Le nombre de tweets jugés négatifs est {} --> {}%'.format(str(results[1]),str(round(100*results[1]/len(data),2))))\n",
    "print('Le nombre de tweets jugés neutres est {} --> {}%'.format(str(results[2]),str(round(100*results[2]/len(data),2))))\n",
    "print(' ')\n",
    "print('#'*30)\n",
    "print('#'*30)\n",
    "print(' ')\n",
    "\n",
    "# Sur la bases composée des Yes  \n",
    "data=Base_SWN_yes\n",
    "results=stati_scores_major(data)\n",
    "print(' ')\n",
    "print('Sur la base composée des Yes ({} tweets) : '.format(len(data)))\n",
    "print(' ')\n",
    "print('Le nombre de tweets jugés positifs est {} --> {}%'.format(str(results[0]),str(round(100*results[0]/len(data),2))))\n",
    "print('Le nombre de tweets jugés négatifs est {} --> {}%'.format(str(results[1]),str(round(100*results[1]/len(data),2))))\n",
    "print('Le nombre de tweets jugés neutres est {} --> {}%'.format(str(results[2]),str(round(100*results[2]/len(data),2))))\n",
    "print(' ')\n",
    "print('#'*30)\n",
    "print('#'*30)\n",
    "print(' ')\n",
    "\n",
    "# Sur la bases composée des No \n",
    "data=Base_SWN_no\n",
    "results=stati_scores_major(data)\n",
    "print(' ')\n",
    "print('Sur la base composée des No ({} tweets) : '.format(len(data)))\n",
    "print(' ')\n",
    "print('Le nombre de tweets jugés positifs est {} --> {}%'.format(str(results[0]),str(round(100*results[0]/len(data),2))))\n",
    "print('Le nombre de tweets jugés négatifs est {} --> {}%'.format(str(results[1]),str(round(100*results[1]/len(data),2))))\n",
    "print('Le nombre de tweets jugés neutres est {} --> {}%'.format(str(results[2]),str(round(100*results[2]/len(data),2))))\n",
    "print(' ')\n",
    "print('#'*30)\n",
    "print('#'*30)\n",
    "print(' ')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\underline{Commentaires}$\n",
    "\n",
    "On observe que les tweets sont majoritarement à tonalité négative, qu'ils soient de la base Yes ou No. Néanmmoins, le pessimisme ou l'optimisme est davantage marqué chez les tweets des personnes sceptiques. Par exemple, les tweets scorés négatifs représent $40.04%$% de la base des No contre $533.79%$% pour les tweets Yes. On retrouve le caractère demonstratif des personnes climato-sceptiques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A titre d'exemples, voici les 5 tweets jugés le plus 'négativement' dans le base de No' :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "If Ensler & Behar represent liberal women, that's such a sad pathetic stmt. Global warming fanatics who yack about their vaginas. Pathetic!\n",
      "score négatif : 0.42857142857142855\n",
      " \n",
      "RT @gopevangelist: Global warming hysteria presumes 3 things: 1 it exists, 2 it is man-made, 3 it is bad. All 3 must be true. This winter may prove all 3 false\n",
      "score négatif : 0.3392857142857143\n",
      " \n"
     ]
    }
   ],
   "source": [
    "def stati_scores_tweets(base):\n",
    "    base_1=base.copy()\n",
    "    base=pd.DataFrame(list(base.Scores),columns=['score_pos','score_neg','score_neutre'])\n",
    "    base['Tweet']=base_1.Tweet\n",
    "    return(base)\n",
    "\n",
    "# Print des premiers tweets\n",
    "data=Base_SWN_no.reset_index()\n",
    "data=stati_scores_tweets(data)\n",
    "data=data.sort_values(by=['score_neg'],ascending=False).reset_index()\n",
    "print(' ')\n",
    "print(data.Tweet[4])\n",
    "print('score négatif : {}'.format(str(data.score_neg[4])))\n",
    "print(' ')\n",
    "print(data.Tweet[7])\n",
    "print('score négatif : {}'.format(str(data.score_neg[7])))\n",
    "print(' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les 10 mots les plus proches de change sont : \n",
      " \n",
      "ocean_chemistry\n",
      "always\n",
      "good_thing\n",
      "a\n",
      "our\n",
      "won\n",
      "800,000\n",
      "an\n",
      "evidence\n",
      "map\n",
      " \n",
      "##################################################\n",
      " \n",
      "Les 10 mots les plus proches de climate sont : \n",
      " \n",
      "landmark\n",
      "report\n",
      "environment\n",
      "news\n",
      "conduct\n",
      "defends_conclusion\n",
      "panel\n",
      "before_summit\n",
      "science\n",
      "on\n"
     ]
    }
   ],
   "source": [
    "# Cosinus similarité\n",
    "\n",
    "def closest_to(word,n_top_similar):\n",
    "    print('Les {} mots les plus proches de {} sont : '.format(n_top_similar,word))\n",
    "    print(' ')\n",
    "    for word in [w[0] for w in model_wv.most_similar(word,topn=n_top_similar)]:\n",
    "        print(word)\n",
    "        \n",
    "closest_to('change',10)\n",
    "print(' ')\n",
    "print('#'*50)\n",
    "print(' ')\n",
    "\n",
    "closest_to('climate',10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

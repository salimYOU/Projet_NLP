{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification des tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Modèles de prédictions et autres \n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "# Keras \n",
    "import keras\n",
    "from keras.datasets import imdb\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bases d'apprentissage\n",
    "\n",
    "bases_representations=[dt_tfidf_tweet] # Liste des bases d'apprentissage\n",
    "\n",
    "\n",
    "vecteurs=bases_representations[0].reset_index(drop=True).T\n",
    "labels=list(df.Existence)\n",
    "new_vecteurs=[]\n",
    "new_labels=[]\n",
    "array_vecteurs=np.array(vecteurs)\n",
    "for label_index in range(len(labels)):\n",
    "    if (labels[label_index]=='Yes')or(labels[label_index]=='No'):\n",
    "        new_vecteurs.append(array_vecteurs[label_index])\n",
    "        new_labels.append(labels[label_index])\n",
    "labels=new_labels\n",
    "labels=[(labels[tweet]=='Yes')*1 for tweet in range(len(labels))]\n",
    "vecteurs=pd.DataFrame(new_vecteurs)\n",
    "\n",
    "\n",
    "# labels=0 si 'No' \n",
    "# labels=1 si 'Yes'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Algorithmes de classifications classiques : XGboost, RandomForest, SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création des bases de train/test\n",
    "\n",
    "X_train, X_test, Y_train, Y_test= train_test_split(vecteurs,labels, test_size=0.5)\n",
    "X_train.reset_index(inplace=True)\n",
    "X_test.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apprentissage des modèles (5 min à runner)\n",
    "\n",
    "##RandomForest\n",
    "print('Apprentissage Random Forest ...')\n",
    "t=time.time()\n",
    "rfc = RandomForestClassifier(n_estimators=100)\n",
    "rfc.fit(X_train,Y_train)\n",
    "print('Apprentissage Random Forest done ({}s to learn)'.format(str(round(time.time()-t,0))))\n",
    "print(' ')\n",
    "\n",
    "##XgBoost Classifier\n",
    "print('Apprentissage XGBoost ...')\n",
    "t=time.time()\n",
    "clf = xgb.XGBClassifier()\n",
    "clf.fit(X_train,Y_train)\n",
    "print('Apprentissage XGBoost done ({}s to learn)'.format(str(round(time.time()-t,0))))\n",
    "print(' ')\n",
    "\n",
    "\n",
    "##SVM\n",
    "print('Apprentissage SVM ...')\n",
    "t=time.time()\n",
    "svm = SVC()#probability=True,C=2, kernel='rbf',max_iter=)\n",
    "svm.fit(X_train,Y_train)\n",
    "print('Apprentissage SVM done ({}s to learn)'.format(str(round(time.time()-t,0))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sauvegarde des modèles \n",
    "\n",
    "with open('RandomForest_model.p', 'wb') as fp:\n",
    "    pickle.dump(rfc, fp)\n",
    "with open('SVM_model.p', 'wb') as fp:\n",
    "    pickle.dump(svm, fp)\n",
    "with open('XGBoost_model.p', 'wb') as fp:\n",
    "    pickle.dump(clf, fp)\n",
    "    \n",
    "##############################################################################\n",
    "##############################################################################\n",
    "\n",
    "# Import des modèles \n",
    "\n",
    "path_XGBoost='XGBoost_model.p'\n",
    "path_RandomForest='RandomForest_model.p'\n",
    "path_SVM='SVM_model.p'\n",
    "\n",
    "#XgBoost\n",
    "with open(path_XGBoost, 'rb') as fp:\n",
    "    clf=pickle.load(fp)\n",
    "\n",
    "#RandomForest\n",
    "with open(path_RandomForest, 'rb') as fp:\n",
    "    rfc=pickle.load(fp)\n",
    "\n",
    "#SVM\n",
    "with open(path_SVM, 'rb') as fp:\n",
    "    svm=pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation des modèles \n",
    "\n",
    "# Prédiction et évaluation sur la base de test  \n",
    "\n",
    "print('Prédiction XGboost ...')\n",
    "pred_XGboost=clf.predict(X_test)\n",
    "print('DONE')\n",
    "print(' ')\n",
    "\n",
    "print('Matrice de confusion pour les prédictions XGboost :')\n",
    "display(confusion_matrix(Y_test, pred_XGboost))\n",
    "print('Précision score Yes (1) XGboost : '+str(precision_score(Y_test, pred_XGboost,average=None)[1]))\n",
    "print('Précision scoreNo (0) XGboost : '+str(precision_score(Y_test, pred_XGboost,average=None)[0]))\n",
    "print('Précision scoregénérale XGboost : '+str(precision_score(Y_test, pred_XGboost, average='macro')))\n",
    "print('F1 score Yes (1) XGboost : '+str(f1_score(Y_test, pred_XGboost,average=None)[1]))\n",
    "print('F1 score No (0) XGboost : '+str(f1_score(Y_test, pred_XGboost,average=None)[0]))\n",
    "print('F1 score générale XGboost : '+str(f1_score(Y_test, pred_XGboost, average='macro')))\n",
    "print(' ')\n",
    "print('#'*20)\n",
    "print(' ')\n",
    "\n",
    "\n",
    "####################################################################################\n",
    "####################################################################################\n",
    "\n",
    "print('Prédiction RandomForest ...')\n",
    "pred_rdf=rfc.predict(X_test)\n",
    "print('DONE')\n",
    "print(' ')\n",
    "\n",
    "print('Matrice de confusion pour les prédictions RandomForest :')\n",
    "display(confusion_matrix(Y_test, pred_rdf))\n",
    "print('Précision score Yes (1) RandomForest : '+str(precision_score(Y_test, pred_rdf,average=None)[1]))\n",
    "print('Précision score No (0) RandomForest : '+str(precision_score(Y_test, pred_rdf,average=None)[0]))\n",
    "print('Précision score générale RandomForest : '+str(precision_score(Y_test, pred_rdf, average='macro')))\n",
    "print('F1 score Yes (1) RandomForest : '+str(f1_score(Y_test, pred_rdf,average=None)[1]))\n",
    "print('F1 score No (0) RandomForest : '+str(f1_score(Y_test, pred_rdf,average=None)[0]))\n",
    "print('F1 score générale RandomForest : '+str(f1_score(Y_test, pred_rdf, average='macro')))\n",
    "print(' ')\n",
    "print('#'*20)\n",
    "print(' ')\n",
    "\n",
    "\n",
    "####################################################################################\n",
    "####################################################################################\n",
    "\n",
    "print('Prédiction SVM ...')\n",
    "pred_svm=svm.predict(X_test)\n",
    "print('DONE')\n",
    "print(' ')\n",
    "\n",
    "print('Matrice de confusion pour les prédictions SVM :')\n",
    "display(confusion_matrix(Y_test, pred_XGboost))\n",
    "print('Précision score Yes (1) SVM : '+str(precision_score(Y_test, pred_svm,average=None)[1]))\n",
    "print('Précision score No (0) SVM : '+str(precision_score(Y_test, pred_svm,average=None)[0]))\n",
    "print('Précision score générale SVM : '+str(precision_score(Y_test, pred_svm, average='macro')))\n",
    "print('F1 score Yes (1) SVM : '+str(f1_score(Y_test, pred_svm,average=None)[1]))\n",
    "print('F1 score No (0) SVM : '+str(f1_score(Y_test, pred_svm,average=None)[0]))\n",
    "print('F1 score générale SVM : '+str(f1_score(Y_test, pred_svm, average='macro')))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparamètres du réseau \n",
    "\n",
    "# Le maximum de mots à utiliserhe maximum number of words to be used. (most frequent)\n",
    "Max_nb_words= 50000\n",
    "# Longueur maximum du tweet \n",
    "Max_sequence_length = 30 # on a retenu en moyenne 14 mots par tweet\n",
    "Embedding_dim= 100\n",
    "tokenizer = keras.preprocessing.text.Tokenizer(num_words=Max_nb_words, filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~', lower=True)\n",
    "\n",
    "################################################################\n",
    "################################################################\n",
    "# Construction des bases en input\n",
    "\n",
    "# Tweets to convert\n",
    "corpus=clean_text_second(df.Tweet,threshold=2000)\n",
    "labels=list(df.Existence)\n",
    "corpus_new=[]\n",
    "for tweet in corpus: \n",
    "    tweet_sentence=''\n",
    "    for word in tweet:\n",
    "        tweet_sentence=tweet_sentence+' '+word\n",
    "    corpus_new.append(tweet_sentence)\n",
    "\n",
    "corpus=[]\n",
    "new_labels=[]\n",
    "for label_index in range(len(labels)):\n",
    "    if (labels[label_index]=='Yes')or(labels[label_index]=='No'):\n",
    "        corpus.append(corpus_new[label_index])\n",
    "        new_labels.append(labels[label_index])\n",
    "labels=new_labels\n",
    "labels=[(labels[tweet]=='Yes')*1 for tweet in range(len(labels))]\n",
    "\n",
    "    \n",
    "tokenizer.fit_on_texts(np.array(corpus))\n",
    "X = tokenizer.texts_to_sequences(np.array(corpus))\n",
    "X = sequence.pad_sequences(X, maxlen=Max_sequence_length) \n",
    "\n",
    "X_train, X_test, Y_train, Y_test= train_test_split(X,labels, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creation du modèle et entrainement \n",
    "\n",
    "embedding_vecor_length = 32\n",
    "model = Sequential()\n",
    "model.add(Embedding(Max_nb_words, Embedding_dim, input_length=Max_sequence_length))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "model.fit(X_train, Y_train, epochs=3, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation sur la base de test\n",
    "\n",
    "print('Prédiction LSTM ...')\n",
    "pred_LSTM=model.predict(X_test)\n",
    "pred_LSTM_new=[(float(pred_LSTM[pred])>=0.5)*1 for pred in range(len(pred_LSTM))]\n",
    "pred_LSTM=pred_LSTM_new\n",
    "print('DONE')\n",
    "print(' ')\n",
    "\n",
    "print('Matrice de confusion pour les prédictions LSTM :')\n",
    "display(confusion_matrix(Y_test, pred_LSTM))\n",
    "print('Précision score Yes (1) LSTM : '+str(precision_score(Y_test, pred_LSTM,average=None)[1]))\n",
    "print('Précision score No (0) LSTM : '+str(precision_score(Y_test, pred_LSTM,average=None)[0]))\n",
    "print('Précision score générale LSTM : '+str(precision_score(Y_test, pred_LSTM, average='macro')))\n",
    "print('F1 score Yes (1) LSTM : '+str(f1_score(Y_test, pred_LSTM,average=None)[1]))\n",
    "print('F1 score No (0) LSTM : '+str(f1_score(Y_test, pred_LSTM,average=None)[0]))\n",
    "print('F1 score générale LSTM : '+str(f1_score(Y_test, pred_LSTM, average='macro')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop la dernière couche pour avoir une représentation vectorielle des tweets\n",
    "# On le fait pour toute la base, pas que sur la base de train\n",
    "\n",
    "# Creation du modèle et entrainement sur toute la base \n",
    "\n",
    "embedding_vecor_length = 32\n",
    "model = Sequential()\n",
    "model.add(Embedding(Max_nb_words, Embedding_dim, input_length=Max_sequence_length))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "model.fit(X, labels, epochs=6, batch_size=64)\n",
    "\n",
    "# Enlever la dernière couche\n",
    "model.pop()\n",
    "model.summary()\n",
    "\n",
    "# Representation avec LSTM\n",
    "LTSM_representation=pd.DataFrame(model.predict(X)).T\n",
    "LTSM_representation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Idée : prédire des probas avec les modèles , prédire des featurs avec le LSTM, traiter les NAN, LSTM pré-entrainé."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

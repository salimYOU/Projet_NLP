{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import des constantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "#Tokenization \n",
    "import nltk\n",
    "from gensim.models.phrases import Phrases, Phraser\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from functools import reduce\n",
    "from operator import add\n",
    "import collections\n",
    "\n",
    "#Word2Vec\n",
    "from gensim.models import Word2Vec\n",
    "from multiprocessing import cpu_count\n",
    "\n",
    "#TF-IDF\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "#BERT\n",
    "import torch\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertModel, BertForMaskedLM\n",
    "\n",
    "#Clustering \n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import de la base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import de la base intiale \n",
    "f = open('1377884570_tweet_global_warming.txt', 'r',newline='', encoding='ISO-8859-1')\n",
    "content = f.read().split('\\r')\n",
    "\n",
    "content_new=[]\n",
    "for x in content : \n",
    "    if len(x)>0:\n",
    "        content_new.append(x)\n",
    "\n",
    "content_new=content_new[1:len(content_new)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "erreur\n",
      "erreur\n"
     ]
    }
   ],
   "source": [
    "# Création du dataframe\n",
    "\n",
    "col_tweet=[]\n",
    "col_existence=[]\n",
    "col_score=[]\n",
    "\n",
    "#Split tweet , Note\n",
    "\n",
    "for line in content_new:\n",
    "    if len(line.split('[link]'))==2:\n",
    "        (x,y)=line.split('[link]')\n",
    "        col_tweet.append(x)\n",
    "        col_existence.append(y)\n",
    "    else : \n",
    "        if len(line.split(',Yes,'))==2:\n",
    "            col_tweet.append(line.split(',Yes,')[0])\n",
    "            col_existence.append(',Yes,'+line.split(',Yes,')[1])\n",
    "        elif len(line.split(',No,'))==2:\n",
    "            col_tweet.append(line.split(',No,')[0])\n",
    "            col_existence.append(',No,'+line.split(',No,')[1])\n",
    "        elif len(line.split(',Y,'))==2:\n",
    "            col_tweet.append(line.split(',Y,')[0])\n",
    "            col_existence.append(',Yes,'+line.split(',Y,')[1])\n",
    "        elif len(line.split(',N/A,'))==2:\n",
    "            col_tweet.append(line.split(',N/A,')[0])\n",
    "            col_existence.append(',N/A,'+line.split(',N/A,')[1])\n",
    "        elif len(line.split(',NA,'))==2:\n",
    "            col_tweet.append(line.split(',NA,')[0])\n",
    "            col_existence.append(',NA,'+line.split(',NA,')[1])\n",
    "        elif len(line.split(',N,'))==2:\n",
    "            col_tweet.append(line.split(',N,')[0])\n",
    "            col_existence.append(',No,'+line.split(',N,')[1])\n",
    "        else : \n",
    "            print('erreur')\n",
    "            #print(line.split('[link]'))\n",
    "col_tweet.append('I truly  Fat ASS Gore should get the Scam Artist Award of the decade with his Global Warming and Energy Credits worth close to Billion')\n",
    "col_existence.append(' ,NA')\n",
    "col_tweet.append('Despite Climategate, LEFT investing heavily in global warming hysteria as new way 2 impose nat\\'l & international controls on human freedom.')\n",
    "col_existence.append(' ,NA')\n",
    "        \n",
    "# Split Existence/Note\n",
    "col_existence_new=[]\n",
    "\n",
    "for x in col_existence:\n",
    "    if len(x.split(','))==3:\n",
    "        col_existence_new.append(x.split(',')[1])\n",
    "        col_score.append(x.split(',')[2])\n",
    "    else:\n",
    "        col_existence_new.append('NA')\n",
    "        col_score.append('NA')\n",
    "        \n",
    "#Nettoyage existence\n",
    "for avis in range(len(col_existence_new)):\n",
    "    if col_existence_new[avis]=='NA' or col_existence_new[avis]=='N/A' or col_existence_new[avis]=='':\n",
    "        col_existence_new[avis]=np.nan\n",
    "        \n",
    "#Nettoyage score\n",
    "for score in range(len(col_score)):\n",
    "    if 'NA' not in col_score[score]:\n",
    "        col_score[score]=col_score[score].split('\\t')[0]\n",
    "        if len(col_score[score].split('\"'))>1:\n",
    "            col_score[score]=float(col_score[score].split('\"')[0])\n",
    "        else: \n",
    "            col_score[score]=float(col_score[score])\n",
    "            \n",
    "    else : \n",
    "        col_score[score]=np.nan\n",
    "\n",
    "#Creation du DataFrame\n",
    "dic={'Tweet':col_tweet,'Existence':col_existence_new,'Score':col_score}\n",
    "df=pd.DataFrame(dic)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(['Tweet'], inplace=True)\n",
    "df.reset_index(inplace=True,drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quelques statistiques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemples de tweets\n",
    "\n",
    "print('Exemples de tweets qui croient au réchauffement climatique : ')\n",
    "print(' ')\n",
    "for k in range(5):\n",
    "    print(df[df.Existence=='Yes'].reset_index().iloc[k]['Tweet'])\n",
    "    print(' ')\n",
    "    \n",
    "print('#'*50)\n",
    "print('#'*50)\n",
    "print(' ')\n",
    "print('Exemples de tweets qui doutent du réchauffement climatique : ')\n",
    "print(' ')\n",
    "for k in range(5):\n",
    "    print(df[df.Existence=='No'].reset_index().iloc[k]['Tweet'])\n",
    "    print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('On dispose de {} tweets.'.format(df.shape[0]))\n",
    "\n",
    "print(' ')\n",
    "print('On a {} données manquantes sur le label de l\\'avis du tweet (Yes, No) .'.format(str(df.isnull().sum()['Existence'])))\n",
    "print(' ')\n",
    "\n",
    "#Personnes convaincues du changement climatique \n",
    "print('On a {} tweets qui croit au Changement climatique.'.format(str(df[df.Existence=='Yes'].shape[0])))\n",
    "m=round(df[df.Existence=='Yes'].Score.describe()['mean'],2)\n",
    "std=round(df[df.Existence=='Yes'].Score.describe()['std'],2)\n",
    "print('Parmis ces personnes, le score est de {} en moyenne, avec un écart-type de {}.'.format(str(m),str(std)))\n",
    "print(' ')\n",
    "\n",
    "#Personnes qui doutent du changement climatique \n",
    "print('On a {} tweets qui remettent en doute le Changement climatique.'.format(str(df[df.Existence=='No'].shape[0])))\n",
    "m=round(df[df.Existence=='No'].Score.describe()['mean'],2)\n",
    "std=round(df[df.Existence=='No'].Score.describe()['std'],2)\n",
    "print('Parmis ces personnes, le score est de {} en moyenne, avec un écart-type de {}.'.format(str(m),str(std)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=plt.hist(list(df.Score))\n",
    "x=plt.title('Histogramme des scores de la base globale')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=plt.hist(list(df[df.Existence=='Yes'].Score))\n",
    "x=plt.title('Histogramme des scores pour les tweets qui croient au réchauffement climatique ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=plt.hist(list(df[df.Existence=='No'].Score))\n",
    "x=plt.title('Histogramme des scores pour les tweets qui ne croient pas au réchauffement climatique ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les scores sont des indicateurs sur la precision de la classification du tweet. Globalement, on a la même certitude sur cette précision pour les deux types de tweets (Yes et No)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenization des tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "En utilisant le séparateur ' ', on obtient 19602 mots dans l'ensemble des tweets\n"
     ]
    }
   ],
   "source": [
    "#Nombre de mots différents dans l'ensemble des articles \n",
    "\n",
    "##Récupération de tout les mots de tout les tweets\n",
    "arr=df.Tweet.apply(lambda x : x.split(' ')).array\n",
    "arr = reduce(add, arr)\n",
    "\n",
    "\n",
    "##Nombre de mots différents dans l'ensemble des articles \n",
    "print('En utilisant le séparateur \\' \\', on obtient {} mots dans l\\'ensemble des tweets'.format(len(set(arr))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "En utilisant le Tokenizer TweetTokenizer, on obtient un vocabulaire de 15804 mots.\n"
     ]
    }
   ],
   "source": [
    "# Tokenization en utilisant le Tokenizer Tweeter\n",
    "\n",
    "arr_tokens = df.Tweet.apply(lambda x: TweetTokenizer().tokenize(x)).array\n",
    "arr_tokens = reduce(add, arr_tokens)\n",
    "print('En utilisant le Tokenizer TweetTokenizer, on obtient un vocabulaire de {} mots.'.format(len(set(arr_tokens))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nettoyage des Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On prend toutes les phrases de touts les texts, et on les concatène dans une liste, en les traitant auparavant\n",
    "\n",
    "sent_detector = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "\n",
    "def remove_hashtags(tokens):\n",
    "    tokens= map(lambda x : x.replace('#',''),tokens) #map : parcours tout les tokens\n",
    "    return list(tokens)\n",
    "\n",
    "def remove_url(tokens): #pb pour https\n",
    "    tokens= filter(lambda x: \"http\" not in x, tokens) #filter : garde là où il y a True\n",
    "    return list(tokens)\n",
    "\n",
    "def remove_html(tokens):\n",
    "    tokens= filter(lambda x: x[0]+x[-1]!='<>',tokens)\n",
    "    return list(tokens)\n",
    "\n",
    "def remove_www(tokens):\n",
    "    tokens= filter(lambda x: \"www\" not in x, tokens) #filter : garde là où il y a True\n",
    "    return list(tokens)\n",
    "\n",
    "'''\n",
    "def remove_x95(clean_corpus):\n",
    "    for sentence_r in range(len(clean_corpus)):\n",
    "        sentence=clean_corpus[sentence_r]\n",
    "        for x in range(len(sentence)):\n",
    "            if '\\x95' in sentence[x]:\n",
    "                y=sentence[x].split('\\x95')\n",
    "                new_x=''\n",
    "                for part_x in y:\n",
    "                    new_x=new_x+part_x\n",
    "                sentence[x]=new_x\n",
    "        clean_corpus[sentence_r]=sentence\n",
    "    return(clean_corpus)\n",
    "'''\n",
    "\n",
    "def RepresentsInt(s):\n",
    "    try: \n",
    "        int(s)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "def clean_ponctuation(text_tokens): # Nettoyage de la ponctuation\n",
    "\n",
    "    list_word_clean_ponctuation=[]\n",
    "    for tweet in text_tokens:\n",
    "        list_tweet=[]\n",
    "        for word in tweet:\n",
    "            if len(word)<2:\n",
    "                if (word=='a') or (word=='i') or (word=='u'):\n",
    "                    list_tweet.append(word)\n",
    "                if RepresentsInt(word):\n",
    "                    list_tweet.append(word)\n",
    "            else :\n",
    "                if (word!='..') & (word!='...') & (word!='rt'):\n",
    "                    list_tweet.append(word)\n",
    "        list_word_clean_ponctuation.append(list_tweet)\n",
    "    \n",
    "    return(list_word_clean_ponctuation)\n",
    "\n",
    "def remove_arobase(text_tokens):\n",
    "    \n",
    "    list_new_tokens=[]\n",
    "    for tweet in text_tokens:\n",
    "        new_tweet=[]\n",
    "        for word in tweet: \n",
    "            if '@' not in word:\n",
    "                new_tweet.append(word)\n",
    "        list_new_tokens.append(new_tweet)\n",
    "    \n",
    "    return(list_new_tokens)\n",
    "\n",
    "###############################################################\n",
    "###############################################################\n",
    "###############################################################\n",
    "\n",
    "def clean_text_first(corpus):\n",
    "    \n",
    "    tok=TweetTokenizer()\n",
    "    tokens=[]\n",
    "    for sample in corpus:\n",
    "        token=tok.tokenize(sample) \n",
    "        token=remove_url(token)\n",
    "        token=remove_html(token)\n",
    "        token=remove_hashtags(token)\n",
    "        token=remove_www(token)\n",
    "        token=list(map(lambda x : x.lower(),token)) #.lower() : met les majuscules en minuscules\n",
    "        tokens.append(token) #ajout du token à l'ensemble des phrases\n",
    "    \n",
    "    #Nettoyage de la ponctuation\n",
    "    tokens=clean_ponctuation(tokens)\n",
    "    \n",
    "    #Nettoyage des arobase : pour la plupart, se sont des noms propres\n",
    "    tokens=remove_arobase(tokens)\n",
    "    \n",
    "    return tokens\n",
    "\n",
    "def clean_text_second(corpus,threshold): #On rajoute l'association des mots qui vont ensembles\n",
    "    \n",
    "    #clean les textes\n",
    "    tokens=clean_text_first(corpus)\n",
    "    \n",
    "    #associer les mots\n",
    "    phrases=Phrases(tokens,threshold=threshold) #On fait apprendre le modèle d'association sur tout les mots\n",
    "    phraser=Phraser(phrases) #Outil pour associer\n",
    "    \n",
    "    clean_tokens=[]\n",
    "    for token in tokens: #On parcours les phrases et on associe les mots\n",
    "        new_tokens=phraser[token]\n",
    "        clean_tokens.append(new_tokens)\n",
    "        \n",
    "    #tokens = remove_x95(tokens)\n",
    "    \n",
    "    return(clean_tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#clean_text_first(df.Tweet) #sans association de mots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_words=clean_text_second(df.Tweet,threshold=1000) #avec association de mots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les 10 mots qui apparaissent le plus sont (par ordre décroissant) :\n",
      " \n",
      "climate (3348) \n",
      "change (3027) \n",
      "global (2869) \n",
      "warming (2765) \n",
      "the (2275) \n",
      "to (1674) \n",
      "of (1440) \n",
      "on (1063) \n",
      "a (1056) \n",
      "in (998) \n"
     ]
    }
   ],
   "source": [
    "#Mots les plus fréquents après nettoyage des tokens\n",
    "\n",
    "counter=collections.Counter(reduce(add, list_words))\n",
    "\n",
    "#10 mots les plus fréquents \n",
    "number_word=10\n",
    "print('Les {} mots qui apparaissent le plus sont (par ordre décroissant) :'.format(number_word))\n",
    "print(' ')\n",
    "for word in counter.most_common(number_word):\n",
    "    print(word[0]+' ('+str(word[1])+') ') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "En moyenne, on a retenu 14.0 mots par tweet \n"
     ]
    }
   ],
   "source": [
    "# Taille moyenne des tweet : \n",
    "list_words\n",
    "mean=0\n",
    "for tweet in list_words:\n",
    "    mean=mean+len(tweet)\n",
    "    \n",
    "print('En moyenne, on a retenu {} mots par tweet '.format(str(round(mean/len(list_words),0))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Représentation des Tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avec Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On utilise tout d'abord l'algorithme Word2Vec pour représenter ces tweets. Chaque mot à une représentation vectorielle. Pour chaque tweet, on fait la moyenne des vecteurs (chaque mot) inclut dans ce tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleaning des tweets\n",
    "clean_text=clean_text_second(df.Tweet,threshold=1000)\n",
    "\n",
    "print(\"Entrainement du modèle Word2Vec ...\")\n",
    "model = Word2Vec(clean_text, size=100, window=5, min_count=3, workers=4) \n",
    "\n",
    "model.train(clean_text, total_examples=len(clean_text), epochs=10) #réseau de neuronne du Word2Vec\n",
    "model_wv = model.wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Représentation des tweets en moyennant les mots\n",
    "\n",
    "def tokens2vectors(tokenCorpus):\n",
    "    ''' transforms our X into a list of list of vec (2D array) '''\n",
    "    new_sample = list()\n",
    "    i=0\n",
    "    for sample in tokenCorpus:\n",
    "        tweetVecs = list()\n",
    "        for token in sample:\n",
    "            try : \n",
    "                tweetVecs.append(model_wv.get_vector(token)  )\n",
    "            except: \n",
    "                i=i+1\n",
    "                tweetVecs.append( np.zeros(100) ) \n",
    "        new_sample.append(np.mean(tweetVecs, axis=0))\n",
    "    \n",
    "    return np.array(new_sample)\n",
    "\n",
    "\n",
    "X= tokens2vectors(clean_text)\n",
    "\n",
    "Y=[]\n",
    "for x in list(X):\n",
    "    try: Y.append(list(x))\n",
    "    except : pass\n",
    "    \n",
    "df_representation_W2v= pd.DataFrame(Y).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_representation_W2v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Etude de cette représentation via la cosinus similarité\n",
    "\n",
    "def closest_to(word,n_top_similar):\n",
    "    print('Les {} mots les plus proches de {} sont : '.format(n_top_similar,word))\n",
    "    print(' ')\n",
    "    for word in [w[0] for w in model_wv.most_similar(word,topn=n_top_similar)]:\n",
    "        print(word)\n",
    "        \n",
    "closest_to('change',10)\n",
    "print(' ')\n",
    "print('#'*50)\n",
    "print(' ')\n",
    "\n",
    "closest_to('climate',10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Une approche naïve avec TF IDF\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour chaque mot, on a un vecteur le représentant. Pour réprésenter un tweet, on fait la moyenne des vecteurs correspondant à chacun de ces mots."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Représentation des mots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialisation des mots TF-IDF\n",
    "cv=CountVectorizer()\n",
    "tfidf_transformer=TfidfTransformer(smooth_idf=True,use_idf=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Formatage de la base pour la méthode TF-IDF\n",
    "corpus=clean_text_second(df.Tweet,threshold=2000)\n",
    "corpus_new=[]\n",
    "for tweet in corpus: \n",
    "    tweet_sentence=''\n",
    "    for word in tweet:\n",
    "        tweet_sentence=tweet_sentence+' '+word\n",
    "    corpus_new.append(tweet_sentence)\n",
    "    \n",
    "# Caclul des scores TF-IDF de chaque mot\n",
    "word_count_vector=cv.fit_transform(corpus_new)\n",
    "tfidf_transformer.fit(word_count_vector)\n",
    "\n",
    "count_vector=cv.transform(corpus_new)\n",
    "tf_idf_vector=tfidf_transformer.transform(count_vector)\n",
    "feature_names = cv.get_feature_names()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemple de représentation du premier tweet \n",
    "\n",
    "#get tfidf vector for first document\n",
    "first_document_vector=tf_idf_vector[0]\n",
    "\n",
    "#print du tweet\n",
    "print(' ')\n",
    "print('Tweet initial : '+df.iloc[0]['Tweet'])\n",
    "print(' ')\n",
    "\n",
    "#print du tweet nettoyé\n",
    "print('Tweet nettoyé : '+corpus_new[0])\n",
    "print(' ')\n",
    "print('Scores TF-IDF : ')\n",
    "#print des scores \n",
    "pd.DataFrame(first_document_vector.T.todense(), index=feature_names, columns=[\"first_tweet\"]).sort_values(by=[\"first_tweet\"],ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Représentation de tout les tweets \n",
    "\n",
    "dt_tfidf_tweet = pd.DataFrame(tf_idf_vector[0:2].T.todense(),index=feature_names)\n",
    "dt_tfidf_tweet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problématique : matrice très sparse (beaucoup de zéros)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Avec du clustering de mots d'après Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'idée est d'utiliser la représentation de Word2Vec des mots pour faire du clustering sur tout les mots contenus dans la base. On se place ensuite au niveau de chaque tweet et on le représente par un vecteur qui compte le nombre de mots contenu dans chaque cluster. Plus pour analyser quels sont les mots qui se rapproche le plus selon la distance euclidienne ? (plutot que la cos similarité)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Représentation Word2Vec de chaque mot \n",
    "\n",
    "clean_text=clean_text_second(df.Tweet,threshold=1000)\n",
    "\n",
    "print(\"Entrainement du modèle Word2Vec ...\")\n",
    "model = Word2Vec(clean_text, size=100, window=5, min_count=3, workers=4) \n",
    "\n",
    "model.train(clean_text, total_examples=len(clean_text), epochs=10) #réseau de neuronne du Word2Vec\n",
    "model_wv = model.wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Application du modèle W2v sur chaque token du corpus\n",
    "\n",
    "clean_text = reduce(add, clean_text)\n",
    "clean_text = set(clean_text)\n",
    "\n",
    "def Representation_W2v(tokenCorpus_unique):\n",
    "    new_sample = {}\n",
    "    number_not_in_vocab=0\n",
    "    for token in tokenCorpus_unique:\n",
    "            try : \n",
    "                new_sample[token]=list(model_wv.get_vector(token))\n",
    "            except: number_not_in_vocab=number_not_in_vocab+1\n",
    "    \n",
    "    print('{} mots sur {} ne sont pas dans le vocabulaire du modèle Word2Vec entrainé'.format(str(number_not_in_vocab),str(len(tokenCorpus_unique))))\n",
    "    return new_sample\n",
    "\n",
    "Representation_for_clustering=pd.DataFrame(Representation_W2v(clean_text)).T\n",
    "Representation_for_clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Representation_for_clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Application du clustering \n",
    "\n",
    "n_cluster = 5\n",
    "\n",
    "kmeans = KMeans(n_clusters=n_cluster) \n",
    "kmeans.fit(Representation_for_clustering)\n",
    "clusters=kmeans.predict(Representation_for_clustering).tolist()\n",
    "\n",
    "data=[]\n",
    "for x in range(len(clusters)):\n",
    "    data.append([Representation_for_clustering.index.tolist()[x],clusters[x]])\n",
    "    \n",
    "    \n",
    "results=pd.DataFrame(data= data , columns=['token','cluster'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(n_cluster):\n",
    "    print('Nombre de mots dans le cluster numéro {} : '.format(k)+str(len(results[results.cluster==k])))\n",
    "    print(' ')\n",
    "    print('#'*20)\n",
    "    print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Etude de chaque cluster spécifiquement\n",
    "cluster=2\n",
    "\n",
    "list_word=''\n",
    "for word_index in range(20):\n",
    "    word=list(results[results.cluster==cluster]['token'])[word_index]\n",
    "    list_word=list_word+' , '+word\n",
    "print('Parmis les mots du cluster {}, il y a : '.format(cluster)+list_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interprétation des clusters ? Refaire avec des modèles pré-entrainés ? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Représentation de tweet avec des modèles pré-entrainés : Fast2vec et Bert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fast2vec pre-trained"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bert pre-trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install pytorch-pretrained-bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_text=clean_text_second(df.Tweet,threshold=1000)\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "\n",
    "# Input formating for BERT\n",
    "\n",
    "#tokenization spécifique BERT\n",
    "def tokenization_BERT(tweet,tokenizer):\n",
    "    text=''\n",
    "    for word in tweet:\n",
    "        text=text+' '+word\n",
    "    tokenized_text='[CLS]'+text+' [SEP]'\n",
    "    tokenized_text = tokenizer.tokenize(tokenized_text)\n",
    "    indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "    segments_ids = [0] * len(tokenized_text)\n",
    "    \n",
    "    return(indexed_tokens,segments_ids)\n",
    "\n",
    "##########################################\n",
    "##########################################\n",
    "\n",
    "# Embedding du tweet\n",
    "def BERT_embedding(tweet,tokenizer):\n",
    "    \n",
    "    #tokenization et convertion des inputs en tensors\n",
    "    index, segments= tokenization_BERT(tweet,tokenizer)\n",
    "    \n",
    "    tokens_tensor = torch.tensor([index])\n",
    "    segments_tensors = torch.tensor([segments])\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        encoded_layers, _ = model(tokens_tensor, segments_tensors)\n",
    "\n",
    "    token_embeddings = torch.stack(encoded_layers, dim=0)\n",
    "    token_embeddings = torch.squeeze(token_embeddings, dim=1)\n",
    "    token_embeddings = token_embeddings.permute(1,0,2)\n",
    "    \n",
    "    token_vecs = encoded_layers[11][0]\n",
    "    sentence_embedding = torch.mean(token_vecs, dim=0)\n",
    "    \n",
    "    return(list(sentence_embedding.numpy())) #return le vecteur du tweet\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 407873900/407873900 [13:53<00:00, 489066.62B/s] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): BertLayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import du modèle\n",
    "\n",
    "# Load pre-trained model (weights)\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Put the model in \"evaluation\" mode, meaning feed-forward operation.\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet initial : Global warming report urges governments to act|BRUSSELS, Belgium (AP) - The world faces increased hunger and .. \n",
      " \n",
      "Tweet nettoyé :  global warming report urges governments to act brussels belgium ap the world faces increased hunger and\n",
      " \n",
      "10 premières valeurs de la représentation vectorielle : [-0.20707315, -0.1527531, 0.31561086, -0.102150574, -0.0494032, -0.15978688, 0.12970391, 0.61809164, -0.43857074, -0.18857116]\n",
      " \n",
      "####################\n",
      " \n",
      "Tweet initial : Fighting poverty and global warming in Africa \n",
      " \n",
      "Tweet nettoyé :  fighting poverty and global warming in africa\n",
      " \n",
      "10 premières valeurs de la représentation vectorielle : [-0.3177802, -0.19386752, -0.51339495, 0.08279662, 0.005352762, -0.3944389, 0.124147385, 0.6389174, -0.39283025, -0.5550124]\n",
      " \n",
      "####################\n",
      " \n",
      "Tweet initial : Carbon offsets: How a Vatican forest failed to reduce global warming \n",
      " \n",
      "Tweet nettoyé :  carbon offsets how a vatican forest failed to reduce global warming\n",
      " \n",
      "10 premières valeurs de la représentation vectorielle : [-0.11185432, -0.21433498, -0.17104717, 0.31577143, 0.13757117, -0.29026532, -0.00019155655, 0.4175995, -0.15806018, -0.09747195]\n",
      " \n",
      "####################\n",
      " \n",
      "Tweet initial : URUGUAY: Tools Needed for Those Most Vulnerable to Climate Change \n",
      " \n",
      "Tweet nettoyé :  uruguay tools needed for those most vulnerable to climate change\n",
      " \n",
      "10 premières valeurs de la représentation vectorielle : [-0.27096364, 0.050121903, -0.2203478, 0.3218468, 0.3050904, -0.21759973, 0.15318978, 0.48721266, -0.17184323, -0.06042658]\n",
      " \n",
      "####################\n",
      " \n",
      "Tweet initial : RT @sejorg: RT @JaymiHeimbuch: Ocean Saltiness Shows Global Warming Is Intensifying Our Water Cycle \n",
      " \n",
      "Tweet nettoyé :  rt rt ocean saltiness shows global warming is intensifying our water cycle\n",
      " \n",
      "10 premières valeurs de la représentation vectorielle : [-0.23678532, 0.08900328, 0.50781274, 0.06978822, 0.17861946, -0.27706355, 0.34692457, 0.466961, -0.3972774, -0.4910533]\n",
      " \n",
      "####################\n",
      " \n"
     ]
    }
   ],
   "source": [
    "# Représentation des 5 premiers tweets de la base\n",
    "\n",
    "for tweet_index in range(5):\n",
    "    print('Tweet initial : '+df.iloc[tweet_index]['Tweet'])\n",
    "    print(' ')\n",
    "    text=''\n",
    "    for word in clean_text[tweet_index]:\n",
    "        text=text+' '+word\n",
    "    print('Tweet nettoyé : '+text)\n",
    "    print(' ')\n",
    "    print('10 premières valeurs de la représentation vectorielle : '+str(BERT_embedding(clean_text[tweet_index],tokenizer)[0:10]))\n",
    "    print(' ')\n",
    "    print('#'*20)\n",
    "    print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5539/5539 [14:40<00:00,  6.29it/s]\n"
     ]
    }
   ],
   "source": [
    "# Représentation de la base entière par BERT\n",
    "\n",
    "dataframe={}\n",
    "for tweet_index in tqdm(range(len(clean_text))):\n",
    "    dataframe[tweet_index]=BERT_embedding(clean_text[tweet_index],tokenizer)\n",
    "df_BERT_embedding=pd.DataFrame(dataframe)\n",
    "\n",
    "df_BERT_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>5529</th>\n",
       "      <th>5530</th>\n",
       "      <th>5531</th>\n",
       "      <th>5532</th>\n",
       "      <th>5533</th>\n",
       "      <th>5534</th>\n",
       "      <th>5535</th>\n",
       "      <th>5536</th>\n",
       "      <th>5537</th>\n",
       "      <th>5538</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>-0.207073</td>\n",
       "      <td>-0.317780</td>\n",
       "      <td>-0.111854</td>\n",
       "      <td>-0.270964</td>\n",
       "      <td>-0.236785</td>\n",
       "      <td>0.393400</td>\n",
       "      <td>0.085322</td>\n",
       "      <td>-0.178012</td>\n",
       "      <td>-0.101252</td>\n",
       "      <td>-0.159416</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012333</td>\n",
       "      <td>-0.060874</td>\n",
       "      <td>-0.126322</td>\n",
       "      <td>-0.021645</td>\n",
       "      <td>-0.281184</td>\n",
       "      <td>-0.400154</td>\n",
       "      <td>0.051658</td>\n",
       "      <td>-0.010287</td>\n",
       "      <td>-0.018927</td>\n",
       "      <td>0.059379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>-0.152753</td>\n",
       "      <td>-0.193868</td>\n",
       "      <td>-0.214335</td>\n",
       "      <td>0.050122</td>\n",
       "      <td>0.089003</td>\n",
       "      <td>0.467884</td>\n",
       "      <td>-0.049446</td>\n",
       "      <td>-0.168504</td>\n",
       "      <td>-0.148704</td>\n",
       "      <td>0.046357</td>\n",
       "      <td>...</td>\n",
       "      <td>0.464100</td>\n",
       "      <td>0.068738</td>\n",
       "      <td>-0.085134</td>\n",
       "      <td>0.265985</td>\n",
       "      <td>0.009084</td>\n",
       "      <td>-0.256461</td>\n",
       "      <td>-0.054771</td>\n",
       "      <td>0.161429</td>\n",
       "      <td>0.158623</td>\n",
       "      <td>0.142215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.315611</td>\n",
       "      <td>-0.513395</td>\n",
       "      <td>-0.171047</td>\n",
       "      <td>-0.220348</td>\n",
       "      <td>0.507813</td>\n",
       "      <td>0.210394</td>\n",
       "      <td>0.098238</td>\n",
       "      <td>0.339805</td>\n",
       "      <td>-0.073870</td>\n",
       "      <td>-0.197705</td>\n",
       "      <td>...</td>\n",
       "      <td>0.088426</td>\n",
       "      <td>0.205937</td>\n",
       "      <td>-0.083525</td>\n",
       "      <td>0.493496</td>\n",
       "      <td>0.063933</td>\n",
       "      <td>-0.183564</td>\n",
       "      <td>0.298856</td>\n",
       "      <td>0.030481</td>\n",
       "      <td>0.391081</td>\n",
       "      <td>0.182608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>-0.102151</td>\n",
       "      <td>0.082797</td>\n",
       "      <td>0.315771</td>\n",
       "      <td>0.321847</td>\n",
       "      <td>0.069788</td>\n",
       "      <td>-0.083486</td>\n",
       "      <td>-0.287598</td>\n",
       "      <td>0.390049</td>\n",
       "      <td>-0.002181</td>\n",
       "      <td>0.123149</td>\n",
       "      <td>...</td>\n",
       "      <td>0.253761</td>\n",
       "      <td>0.301991</td>\n",
       "      <td>0.052356</td>\n",
       "      <td>-0.032803</td>\n",
       "      <td>-0.024530</td>\n",
       "      <td>0.033262</td>\n",
       "      <td>0.032705</td>\n",
       "      <td>-0.085691</td>\n",
       "      <td>0.183931</td>\n",
       "      <td>0.228363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>-0.049403</td>\n",
       "      <td>0.005353</td>\n",
       "      <td>0.137571</td>\n",
       "      <td>0.305090</td>\n",
       "      <td>0.178619</td>\n",
       "      <td>-0.151924</td>\n",
       "      <td>0.420903</td>\n",
       "      <td>0.448748</td>\n",
       "      <td>0.250639</td>\n",
       "      <td>0.046807</td>\n",
       "      <td>...</td>\n",
       "      <td>0.190971</td>\n",
       "      <td>0.264646</td>\n",
       "      <td>0.189702</td>\n",
       "      <td>-0.009137</td>\n",
       "      <td>-0.083970</td>\n",
       "      <td>0.159400</td>\n",
       "      <td>0.214817</td>\n",
       "      <td>0.177870</td>\n",
       "      <td>0.028438</td>\n",
       "      <td>0.027777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>763</td>\n",
       "      <td>-0.185915</td>\n",
       "      <td>-0.301050</td>\n",
       "      <td>-0.400634</td>\n",
       "      <td>-0.265072</td>\n",
       "      <td>-0.098970</td>\n",
       "      <td>-0.075689</td>\n",
       "      <td>-0.036328</td>\n",
       "      <td>-0.013185</td>\n",
       "      <td>-0.134336</td>\n",
       "      <td>-0.092333</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.330396</td>\n",
       "      <td>-0.570294</td>\n",
       "      <td>-0.547132</td>\n",
       "      <td>-0.065307</td>\n",
       "      <td>-0.157501</td>\n",
       "      <td>-0.436011</td>\n",
       "      <td>-0.042413</td>\n",
       "      <td>-0.412418</td>\n",
       "      <td>-0.248569</td>\n",
       "      <td>-0.000809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>764</td>\n",
       "      <td>0.117077</td>\n",
       "      <td>0.167589</td>\n",
       "      <td>0.102872</td>\n",
       "      <td>-0.133903</td>\n",
       "      <td>0.263657</td>\n",
       "      <td>0.123565</td>\n",
       "      <td>-0.013714</td>\n",
       "      <td>-0.358873</td>\n",
       "      <td>-0.198908</td>\n",
       "      <td>-0.091171</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.148618</td>\n",
       "      <td>0.399273</td>\n",
       "      <td>0.060670</td>\n",
       "      <td>0.016221</td>\n",
       "      <td>0.029190</td>\n",
       "      <td>-0.095360</td>\n",
       "      <td>-0.044953</td>\n",
       "      <td>-0.331940</td>\n",
       "      <td>0.103792</td>\n",
       "      <td>0.119760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>765</td>\n",
       "      <td>-0.721387</td>\n",
       "      <td>-0.430743</td>\n",
       "      <td>-0.392623</td>\n",
       "      <td>-0.531327</td>\n",
       "      <td>-0.353686</td>\n",
       "      <td>-0.185703</td>\n",
       "      <td>-0.366322</td>\n",
       "      <td>-0.413659</td>\n",
       "      <td>-0.478867</td>\n",
       "      <td>-0.323900</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.505612</td>\n",
       "      <td>-0.060666</td>\n",
       "      <td>0.036509</td>\n",
       "      <td>-0.288299</td>\n",
       "      <td>-0.223615</td>\n",
       "      <td>-0.296756</td>\n",
       "      <td>-0.381793</td>\n",
       "      <td>-0.071939</td>\n",
       "      <td>-0.125099</td>\n",
       "      <td>-0.096072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>766</td>\n",
       "      <td>-0.034098</td>\n",
       "      <td>-0.192657</td>\n",
       "      <td>-0.079638</td>\n",
       "      <td>-0.279678</td>\n",
       "      <td>0.036645</td>\n",
       "      <td>0.247101</td>\n",
       "      <td>-0.196660</td>\n",
       "      <td>-0.090664</td>\n",
       "      <td>-0.095181</td>\n",
       "      <td>0.272903</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.194793</td>\n",
       "      <td>0.411907</td>\n",
       "      <td>0.265059</td>\n",
       "      <td>0.317590</td>\n",
       "      <td>0.174986</td>\n",
       "      <td>0.257059</td>\n",
       "      <td>0.155324</td>\n",
       "      <td>0.001736</td>\n",
       "      <td>0.281513</td>\n",
       "      <td>0.467625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>767</td>\n",
       "      <td>-0.397592</td>\n",
       "      <td>-0.311446</td>\n",
       "      <td>-0.073035</td>\n",
       "      <td>-0.462800</td>\n",
       "      <td>0.062536</td>\n",
       "      <td>-0.264021</td>\n",
       "      <td>-0.284723</td>\n",
       "      <td>-0.488933</td>\n",
       "      <td>-0.508842</td>\n",
       "      <td>0.052635</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.325583</td>\n",
       "      <td>-0.106872</td>\n",
       "      <td>0.151327</td>\n",
       "      <td>-0.023796</td>\n",
       "      <td>0.137110</td>\n",
       "      <td>-0.234672</td>\n",
       "      <td>-0.293402</td>\n",
       "      <td>-0.254345</td>\n",
       "      <td>0.205877</td>\n",
       "      <td>-0.219986</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows × 5539 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6     \\\n",
       "0   -0.207073 -0.317780 -0.111854 -0.270964 -0.236785  0.393400  0.085322   \n",
       "1   -0.152753 -0.193868 -0.214335  0.050122  0.089003  0.467884 -0.049446   \n",
       "2    0.315611 -0.513395 -0.171047 -0.220348  0.507813  0.210394  0.098238   \n",
       "3   -0.102151  0.082797  0.315771  0.321847  0.069788 -0.083486 -0.287598   \n",
       "4   -0.049403  0.005353  0.137571  0.305090  0.178619 -0.151924  0.420903   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "763 -0.185915 -0.301050 -0.400634 -0.265072 -0.098970 -0.075689 -0.036328   \n",
       "764  0.117077  0.167589  0.102872 -0.133903  0.263657  0.123565 -0.013714   \n",
       "765 -0.721387 -0.430743 -0.392623 -0.531327 -0.353686 -0.185703 -0.366322   \n",
       "766 -0.034098 -0.192657 -0.079638 -0.279678  0.036645  0.247101 -0.196660   \n",
       "767 -0.397592 -0.311446 -0.073035 -0.462800  0.062536 -0.264021 -0.284723   \n",
       "\n",
       "         7         8         9     ...      5529      5530      5531  \\\n",
       "0   -0.178012 -0.101252 -0.159416  ...  0.012333 -0.060874 -0.126322   \n",
       "1   -0.168504 -0.148704  0.046357  ...  0.464100  0.068738 -0.085134   \n",
       "2    0.339805 -0.073870 -0.197705  ...  0.088426  0.205937 -0.083525   \n",
       "3    0.390049 -0.002181  0.123149  ...  0.253761  0.301991  0.052356   \n",
       "4    0.448748  0.250639  0.046807  ...  0.190971  0.264646  0.189702   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "763 -0.013185 -0.134336 -0.092333  ... -0.330396 -0.570294 -0.547132   \n",
       "764 -0.358873 -0.198908 -0.091171  ... -0.148618  0.399273  0.060670   \n",
       "765 -0.413659 -0.478867 -0.323900  ... -0.505612 -0.060666  0.036509   \n",
       "766 -0.090664 -0.095181  0.272903  ... -0.194793  0.411907  0.265059   \n",
       "767 -0.488933 -0.508842  0.052635  ... -0.325583 -0.106872  0.151327   \n",
       "\n",
       "         5532      5533      5534      5535      5536      5537      5538  \n",
       "0   -0.021645 -0.281184 -0.400154  0.051658 -0.010287 -0.018927  0.059379  \n",
       "1    0.265985  0.009084 -0.256461 -0.054771  0.161429  0.158623  0.142215  \n",
       "2    0.493496  0.063933 -0.183564  0.298856  0.030481  0.391081  0.182608  \n",
       "3   -0.032803 -0.024530  0.033262  0.032705 -0.085691  0.183931  0.228363  \n",
       "4   -0.009137 -0.083970  0.159400  0.214817  0.177870  0.028438  0.027777  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "763 -0.065307 -0.157501 -0.436011 -0.042413 -0.412418 -0.248569 -0.000809  \n",
       "764  0.016221  0.029190 -0.095360 -0.044953 -0.331940  0.103792  0.119760  \n",
       "765 -0.288299 -0.223615 -0.296756 -0.381793 -0.071939 -0.125099 -0.096072  \n",
       "766  0.317590  0.174986  0.257059  0.155324  0.001736  0.281513  0.467625  \n",
       "767 -0.023796  0.137110 -0.234672 -0.293402 -0.254345  0.205877 -0.219986  \n",
       "\n",
       "[768 rows x 5539 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_BERT_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import des constantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "#Tokenization \n",
    "import nltk\n",
    "from gensim.models.phrases import Phrases, Phraser\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from functools import reduce\n",
    "from operator import add\n",
    "import collections\n",
    "\n",
    "#Word2Vec\n",
    "from gensim.models import Word2Vec\n",
    "from multiprocessing import cpu_count\n",
    "\n",
    "#TF-IDF\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "#Clustering \n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import de la base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import de la base intiale \n",
    "f = open('1377884570_tweet_global_warming.txt', 'r',newline='', encoding='ISO-8859-1')\n",
    "content = f.read().split('\\r')\n",
    "\n",
    "content_new=[]\n",
    "for x in content : \n",
    "    if len(x)>0:\n",
    "        content_new.append(x)\n",
    "\n",
    "content_new=content_new[1:len(content_new)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "erreur\n",
      "erreur\n"
     ]
    }
   ],
   "source": [
    "# Création du dataframe\n",
    "\n",
    "col_tweet=[]\n",
    "col_existence=[]\n",
    "col_score=[]\n",
    "\n",
    "#Split tweet , Note\n",
    "\n",
    "for line in content_new:\n",
    "    if len(line.split('[link]'))==2:\n",
    "        (x,y)=line.split('[link]')\n",
    "        col_tweet.append(x)\n",
    "        col_existence.append(y)\n",
    "    else : \n",
    "        if len(line.split(',Yes,'))==2:\n",
    "            col_tweet.append(line.split(',Yes,')[0])\n",
    "            col_existence.append(',Yes,'+line.split(',Yes,')[1])\n",
    "        elif len(line.split(',No,'))==2:\n",
    "            col_tweet.append(line.split(',No,')[0])\n",
    "            col_existence.append(',No,'+line.split(',No,')[1])\n",
    "        elif len(line.split(',Y,'))==2:\n",
    "            col_tweet.append(line.split(',Y,')[0])\n",
    "            col_existence.append(',Yes,'+line.split(',Y,')[1])\n",
    "        elif len(line.split(',N/A,'))==2:\n",
    "            col_tweet.append(line.split(',N/A,')[0])\n",
    "            col_existence.append(',N/A,'+line.split(',N/A,')[1])\n",
    "        elif len(line.split(',NA,'))==2:\n",
    "            col_tweet.append(line.split(',NA,')[0])\n",
    "            col_existence.append(',NA,'+line.split(',NA,')[1])\n",
    "        elif len(line.split(',N,'))==2:\n",
    "            col_tweet.append(line.split(',N,')[0])\n",
    "            col_existence.append(',No,'+line.split(',N,')[1])\n",
    "        else : \n",
    "            print('erreur')\n",
    "            #print(line.split('[link]'))\n",
    "col_tweet.append('I truly  Fat ASS Gore should get the Scam Artist Award of the decade with his Global Warming and Energy Credits worth close to Billion')\n",
    "col_existence.append(' ,NA')\n",
    "col_tweet.append('Despite Climategate, LEFT investing heavily in global warming hysteria as new way 2 impose nat\\'l & international controls on human freedom.')\n",
    "col_existence.append(' ,NA')\n",
    "        \n",
    "# Split Existence/Note\n",
    "col_existence_new=[]\n",
    "\n",
    "for x in col_existence:\n",
    "    if len(x.split(','))==3:\n",
    "        col_existence_new.append(x.split(',')[1])\n",
    "        col_score.append(x.split(',')[2])\n",
    "    else:\n",
    "        col_existence_new.append('NA')\n",
    "        col_score.append('NA')\n",
    "        \n",
    "#Nettoyage existence\n",
    "for avis in range(len(col_existence_new)):\n",
    "    if col_existence_new[avis]=='NA' or col_existence_new[avis]=='N/A' or col_existence_new[avis]=='':\n",
    "        col_existence_new[avis]=np.nan\n",
    "        \n",
    "#Nettoyage score\n",
    "for score in range(len(col_score)):\n",
    "    if 'NA' not in col_score[score]:\n",
    "        col_score[score]=col_score[score].split('\\t')[0]\n",
    "        if len(col_score[score].split('\"'))>1:\n",
    "            col_score[score]=float(col_score[score].split('\"')[0])\n",
    "        else: \n",
    "            col_score[score]=float(col_score[score])\n",
    "            \n",
    "    else : \n",
    "        col_score[score]=np.nan\n",
    "\n",
    "#Creation du DataFrame\n",
    "dic={'Tweet':col_tweet,'Existence':col_existence_new,'Score':col_score}\n",
    "df=pd.DataFrame(dic)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(['Tweet'], inplace=True)\n",
    "df.reset_index(inplace=True,drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quelques statistiques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exemples de tweets qui croient au réchauffement climatique : \n",
      " \n",
      "Global warming report urges governments to act|BRUSSELS, Belgium (AP) - The world faces increased hunger and .. \n",
      " \n",
      "Fighting poverty and global warming in Africa \n",
      " \n",
      "Carbon offsets: How a Vatican forest failed to reduce global warming \n",
      " \n",
      "URUGUAY: Tools Needed for Those Most Vulnerable to Climate Change \n",
      " \n",
      "RT @sejorg: RT @JaymiHeimbuch: Ocean Saltiness Shows Global Warming Is Intensifying Our Water Cycle \n",
      " \n",
      "##################################################\n",
      "##################################################\n",
      " \n",
      "Exemples de tweets qui doutent du réchauffement climatique : \n",
      " \n",
      "Wait here's an idea: it's natural climate change, not human induced global warming. \n",
      " \n",
      "@New_federalists  i have it on good auth tht global warming also causes toe fungus.  We R all fortunate tht thr IS no global warming! #tcot\n",
      " \n",
      "Illegal war and the myth of global warming|My main campaign platform for this election will be the illegal .. \n",
      " \n",
      "the scientific community was scamed by global green  gov warming scam.\n",
      " \n",
      "40 degrees in NYC. please urinate on next liberal global warming /climate change scum you see.\n",
      " \n"
     ]
    }
   ],
   "source": [
    "# Exemples de tweets\n",
    "\n",
    "print('Exemples de tweets qui croient au réchauffement climatique : ')\n",
    "print(' ')\n",
    "for k in range(5):\n",
    "    print(df[df.Existence=='Yes'].reset_index().iloc[k]['Tweet'])\n",
    "    print(' ')\n",
    "    \n",
    "print('#'*50)\n",
    "print('#'*50)\n",
    "print(' ')\n",
    "print('Exemples de tweets qui doutent du réchauffement climatique : ')\n",
    "print(' ')\n",
    "for k in range(5):\n",
    "    print(df[df.Existence=='No'].reset_index().iloc[k]['Tweet'])\n",
    "    print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On dispose de 5539 tweets.\n",
      " \n",
      "On a 1683 données manquantes sur le label de l'avis du tweet (Yes, No) .\n",
      " \n",
      "On a 2821 tweets qui croit au Changement climatique.\n",
      "Parmis ces personnes, le score est de 0.82 en moyenne, avec un écart-type de 0.18.\n",
      " \n",
      "On a 1035 tweets qui remettent en doute le Changement climatique.\n",
      "Parmis ces personnes, le score est de 0.76 en moyenne, avec un écart-type de 0.19.\n"
     ]
    }
   ],
   "source": [
    "print('On dispose de {} tweets.'.format(df.shape[0]))\n",
    "\n",
    "print(' ')\n",
    "print('On a {} données manquantes sur le label de l\\'avis du tweet (Yes, No) .'.format(str(df.isnull().sum()['Existence'])))\n",
    "print(' ')\n",
    "\n",
    "#Personnes convaincues du changement climatique \n",
    "print('On a {} tweets qui croit au Changement climatique.'.format(str(df[df.Existence=='Yes'].shape[0])))\n",
    "m=round(df[df.Existence=='Yes'].Score.describe()['mean'],2)\n",
    "std=round(df[df.Existence=='Yes'].Score.describe()['std'],2)\n",
    "print('Parmis ces personnes, le score est de {} en moyenne, avec un écart-type de {}.'.format(str(m),str(std)))\n",
    "print(' ')\n",
    "\n",
    "#Personnes qui doutent du changement climatique \n",
    "print('On a {} tweets qui remettent en doute le Changement climatique.'.format(str(df[df.Existence=='No'].shape[0])))\n",
    "m=round(df[df.Existence=='No'].Score.describe()['mean'],2)\n",
    "std=round(df[df.Existence=='No'].Score.describe()['std'],2)\n",
    "print('Parmis ces personnes, le score est de {} en moyenne, avec un écart-type de {}.'.format(str(m),str(std)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/salimyoussfi/opt/anaconda3/lib/python3.7/site-packages/numpy/lib/histograms.py:829: RuntimeWarning: invalid value encountered in greater_equal\n",
      "  keep = (tmp_a >= first_edge)\n",
      "/Users/salimyoussfi/opt/anaconda3/lib/python3.7/site-packages/numpy/lib/histograms.py:830: RuntimeWarning: invalid value encountered in less_equal\n",
      "  keep &= (tmp_a <= last_edge)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x=plt.hist(list(df.Score))\n",
    "x=plt.title('Histogramme des scores de la base globale')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x=plt.hist(list(df[df.Existence=='Yes'].Score))\n",
    "x=plt.title('Histogramme des scores pour les tweets qui croient au réchauffement climatique ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x=plt.hist(list(df[df.Existence=='No'].Score))\n",
    "x=plt.title('Histogramme des scores pour les tweets qui ne croient pas au réchauffement climatique ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les scores sont des indicateurs sur la precision de la classification du tweet. Globalement, on a la même certitude sur cette précision pour les deux types de tweets (Yes et No)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenization des tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "En utilisant le séparateur ' ', on obtient 19602 mots dans l'ensemble des tweets\n"
     ]
    }
   ],
   "source": [
    "#Nombre de mots différents dans l'ensemble des articles \n",
    "\n",
    "##Récupération de tout les mots de tout les tweets\n",
    "arr=df.Tweet.apply(lambda x : x.split(' ')).array\n",
    "arr = reduce(add, arr)\n",
    "\n",
    "\n",
    "##Nombre de mots différents dans l'ensemble des articles \n",
    "print('En utilisant le séparateur \\' \\', on obtient {} mots dans l\\'ensemble des tweets'.format(len(set(arr))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "En utilisant le Tokenizer TweetTokenizer, on obtient un vocabulaire de 15804 mots.\n"
     ]
    }
   ],
   "source": [
    "# Tokenization en utilisant le Tokenizer Tweeter\n",
    "\n",
    "arr_tokens = df.Tweet.apply(lambda x: TweetTokenizer().tokenize(x)).array\n",
    "arr_tokens = reduce(add, arr_tokens)\n",
    "print('En utilisant le Tokenizer TweetTokenizer, on obtient un vocabulaire de {} mots.'.format(len(set(arr_tokens))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nettoyage des Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On prend toutes les phrases de touts les texts, et on les concatène dans une liste, en les traitant auparavant\n",
    "\n",
    "sent_detector = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "\n",
    "def remove_hashtags(tokens):\n",
    "    tokens= map(lambda x : x.replace('#',''),tokens) #map : parcours tout les tokens\n",
    "    return list(tokens)\n",
    "\n",
    "def remove_url(tokens): #pb pour https\n",
    "    tokens= filter(lambda x: \"http\" not in x, tokens) #filter : garde là où il y a True\n",
    "    return list(tokens)\n",
    "\n",
    "def remove_html(tokens):\n",
    "    tokens= filter(lambda x: x[0]+x[-1]!='<>',tokens)\n",
    "    return list(tokens)\n",
    "\n",
    "def remove_www(tokens):\n",
    "    tokens= filter(lambda x: \"www\" not in x, tokens) #filter : garde là où il y a True\n",
    "    return list(tokens)\n",
    "\n",
    "'''\n",
    "def remove_x95(clean_corpus):\n",
    "    for sentence_r in range(len(clean_corpus)):\n",
    "        sentence=clean_corpus[sentence_r]\n",
    "        for x in range(len(sentence)):\n",
    "            if '\\x95' in sentence[x]:\n",
    "                y=sentence[x].split('\\x95')\n",
    "                new_x=''\n",
    "                for part_x in y:\n",
    "                    new_x=new_x+part_x\n",
    "                sentence[x]=new_x\n",
    "        clean_corpus[sentence_r]=sentence\n",
    "    return(clean_corpus)\n",
    "'''\n",
    "\n",
    "def RepresentsInt(s):\n",
    "    try: \n",
    "        int(s)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "def clean_ponctuation(text_tokens): # Nettoyage de la ponctuation\n",
    "\n",
    "    list_word_clean_ponctuation=[]\n",
    "    for tweet in text_tokens:\n",
    "        list_tweet=[]\n",
    "        for word in tweet:\n",
    "            if len(word)<2:\n",
    "                if (word=='a') or (word=='i') or (word=='u'):\n",
    "                    list_tweet.append(word)\n",
    "                if RepresentsInt(word):\n",
    "                    list_tweet.append(word)\n",
    "            else :\n",
    "                if (word!='..') & (word!='...'):\n",
    "                    list_tweet.append(word)\n",
    "        list_word_clean_ponctuation.append(list_tweet)\n",
    "    \n",
    "    return(list_word_clean_ponctuation)\n",
    "\n",
    "def remove_arobase(text_tokens):\n",
    "    \n",
    "    list_new_tokens=[]\n",
    "    for tweet in text_tokens:\n",
    "        new_tweet=[]\n",
    "        for word in tweet: \n",
    "            if '@' not in word:\n",
    "                new_tweet.append(word)\n",
    "        list_new_tokens.append(new_tweet)\n",
    "    \n",
    "    return(list_new_tokens)\n",
    "\n",
    "###############################################################\n",
    "###############################################################\n",
    "###############################################################\n",
    "\n",
    "def clean_text_first(corpus):\n",
    "    \n",
    "    tok=TweetTokenizer()\n",
    "    tokens=[]\n",
    "    for sample in corpus:\n",
    "        token=tok.tokenize(sample) \n",
    "        token=remove_url(token)\n",
    "        token=remove_html(token)\n",
    "        token=remove_hashtags(token)\n",
    "        token=remove_www(token)\n",
    "        token=list(map(lambda x : x.lower(),token)) #.lower() : met les majuscules en minuscules\n",
    "        tokens.append(token) #ajout du token à l'ensemble des phrases\n",
    "    \n",
    "    #Nettoyage de la ponctuation\n",
    "    tokens=clean_ponctuation(tokens)\n",
    "    \n",
    "    #Nettoyage des arobase : pour la plupart, se sont des noms propres\n",
    "    tokens=remove_arobase(tokens)\n",
    "    \n",
    "    return tokens\n",
    "\n",
    "def clean_text_second(corpus,threshold): #On rajoute l'association des mots qui vont ensembles\n",
    "    \n",
    "    #clean les textes\n",
    "    tokens=clean_text_first(corpus)\n",
    "    \n",
    "    #associer les mots\n",
    "    phrases=Phrases(tokens,threshold=threshold) #On fait apprendre le modèle d'association sur tout les mots\n",
    "    phraser=Phraser(phrases) #Outil pour associer\n",
    "    \n",
    "    clean_tokens=[]\n",
    "    for token in tokens: #On parcours les phrases et on associe les mots\n",
    "        new_tokens=phraser[token]\n",
    "        clean_tokens.append(new_tokens)\n",
    "        \n",
    "    #tokens = remove_x95(tokens)\n",
    "    \n",
    "    return(clean_tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#clean_text_first(df.Tweet) #sans association de mots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_words=clean_text_second(df.Tweet,threshold=1000) #avec association de mots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les 10 mots qui apparaissent le plus sont (par ordre décroissant) :\n",
      " \n",
      "climate (3348) \n",
      "change (3027) \n",
      "global (2869) \n",
      "warming (2765) \n",
      "the (2275) \n",
      "to (1674) \n",
      "of (1440) \n",
      "on (1063) \n",
      "a (1056) \n",
      "in (998) \n"
     ]
    }
   ],
   "source": [
    "#Mots les plus fréquents après nettoyage des tokens\n",
    "\n",
    "counter=collections.Counter(reduce(add, list_words))\n",
    "\n",
    "#10 mots les plus fréquents \n",
    "number_word=10\n",
    "print('Les {} mots qui apparaissent le plus sont (par ordre décroissant) :'.format(number_word))\n",
    "print(' ')\n",
    "for word in counter.most_common(number_word):\n",
    "    print(word[0]+' ('+str(word[1])+') ') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "En moyenne, on a retenu 14.0 mots par tweet \n"
     ]
    }
   ],
   "source": [
    "# Taille moyenne des tweet : \n",
    "list_words\n",
    "mean=0\n",
    "for tweet in list_words:\n",
    "    mean=mean+len(tweet)\n",
    "    \n",
    "print('En moyenne, on a retenu {} mots par tweet '.format(str(round(mean/len(list_words),0))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Représentation des Tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avec Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On utilise tout d'abord l'algorithme Word2Vec pour représenter ces tweets. Chaque mot à une représentation vectorielle. Pour chaque tweet, on fait la moyenne des vecteurs (chaque mot) inclut dans ce tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrainement du modèle Word2Vec ...\n"
     ]
    }
   ],
   "source": [
    "#Cleaning des tweets\n",
    "clean_text=clean_text_second(df.Tweet,threshold=1000)\n",
    "\n",
    "print(\"Entrainement du modèle Word2Vec ...\")\n",
    "model = Word2Vec(clean_text, size=100, window=5, min_count=3, workers=4) \n",
    "\n",
    "model.train(clean_text, total_examples=len(clean_text), epochs=10) #réseau de neuronne du Word2Vec\n",
    "model_wv = model.wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/salimyoussfi/opt/anaconda3/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3257: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/Users/salimyoussfi/opt/anaconda3/lib/python3.7/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6978\n"
     ]
    }
   ],
   "source": [
    "# Représentation des tweets en moyennant les mots\n",
    "\n",
    "def tokens2vectors(tokenCorpus):\n",
    "    ''' transforms our X into a list of list of vec (2D array) '''\n",
    "    new_sample = list()\n",
    "    i=0\n",
    "    for sample in tokenCorpus:\n",
    "        tweetVecs = list()\n",
    "        for token in sample:\n",
    "            try : \n",
    "                tweetVecs.append(model_wv.get_vector(token)  )\n",
    "            except: \n",
    "                i=i+1\n",
    "                tweetVecs.append( np.zeros(100) ) \n",
    "        new_sample.append(np.mean(tweetVecs, axis=0))\n",
    "    \n",
    "    return np.array(new_sample)\n",
    "\n",
    "\n",
    "X= tokens2vectors(clean_text)\n",
    "\n",
    "Y=[]\n",
    "for x in list(X):\n",
    "    try: Y.append(list(x))\n",
    "    except : pass\n",
    "    \n",
    "df_representation_W2v= pd.DataFrame(Y).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>5527</th>\n",
       "      <th>5528</th>\n",
       "      <th>5529</th>\n",
       "      <th>5530</th>\n",
       "      <th>5531</th>\n",
       "      <th>5532</th>\n",
       "      <th>5533</th>\n",
       "      <th>5534</th>\n",
       "      <th>5535</th>\n",
       "      <th>5536</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.231585</td>\n",
       "      <td>0.151163</td>\n",
       "      <td>0.073116</td>\n",
       "      <td>0.142370</td>\n",
       "      <td>0.103849</td>\n",
       "      <td>-0.006454</td>\n",
       "      <td>0.356444</td>\n",
       "      <td>0.110716</td>\n",
       "      <td>0.102889</td>\n",
       "      <td>-0.245600</td>\n",
       "      <td>...</td>\n",
       "      <td>0.136608</td>\n",
       "      <td>0.100538</td>\n",
       "      <td>0.156224</td>\n",
       "      <td>0.017823</td>\n",
       "      <td>0.097291</td>\n",
       "      <td>0.193199</td>\n",
       "      <td>-0.142301</td>\n",
       "      <td>-0.035692</td>\n",
       "      <td>0.053435</td>\n",
       "      <td>-0.008556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.234641</td>\n",
       "      <td>0.272158</td>\n",
       "      <td>0.358477</td>\n",
       "      <td>0.161240</td>\n",
       "      <td>0.265180</td>\n",
       "      <td>0.266771</td>\n",
       "      <td>0.147805</td>\n",
       "      <td>0.138410</td>\n",
       "      <td>0.231763</td>\n",
       "      <td>0.377306</td>\n",
       "      <td>...</td>\n",
       "      <td>0.131544</td>\n",
       "      <td>0.215738</td>\n",
       "      <td>0.104093</td>\n",
       "      <td>0.173507</td>\n",
       "      <td>0.198876</td>\n",
       "      <td>0.366641</td>\n",
       "      <td>0.239651</td>\n",
       "      <td>0.170668</td>\n",
       "      <td>0.245517</td>\n",
       "      <td>0.225361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.251932</td>\n",
       "      <td>0.409688</td>\n",
       "      <td>0.368279</td>\n",
       "      <td>0.141289</td>\n",
       "      <td>0.364655</td>\n",
       "      <td>0.423418</td>\n",
       "      <td>-0.046299</td>\n",
       "      <td>0.121733</td>\n",
       "      <td>0.269102</td>\n",
       "      <td>0.622014</td>\n",
       "      <td>...</td>\n",
       "      <td>0.103441</td>\n",
       "      <td>0.308851</td>\n",
       "      <td>0.143387</td>\n",
       "      <td>0.301402</td>\n",
       "      <td>0.293130</td>\n",
       "      <td>0.398373</td>\n",
       "      <td>0.395591</td>\n",
       "      <td>0.315253</td>\n",
       "      <td>0.326125</td>\n",
       "      <td>0.321966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>-0.041058</td>\n",
       "      <td>-0.012350</td>\n",
       "      <td>-0.078078</td>\n",
       "      <td>-0.186405</td>\n",
       "      <td>-0.109355</td>\n",
       "      <td>-0.110934</td>\n",
       "      <td>-0.155026</td>\n",
       "      <td>-0.147576</td>\n",
       "      <td>-0.098623</td>\n",
       "      <td>-0.277977</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.227338</td>\n",
       "      <td>-0.047307</td>\n",
       "      <td>-0.134986</td>\n",
       "      <td>-0.079196</td>\n",
       "      <td>-0.081337</td>\n",
       "      <td>0.015762</td>\n",
       "      <td>-0.160332</td>\n",
       "      <td>-0.061306</td>\n",
       "      <td>-0.047760</td>\n",
       "      <td>-0.098994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.196058</td>\n",
       "      <td>0.193707</td>\n",
       "      <td>0.046136</td>\n",
       "      <td>0.308916</td>\n",
       "      <td>0.110850</td>\n",
       "      <td>0.109412</td>\n",
       "      <td>0.391374</td>\n",
       "      <td>0.255873</td>\n",
       "      <td>0.215590</td>\n",
       "      <td>-0.100335</td>\n",
       "      <td>...</td>\n",
       "      <td>0.335335</td>\n",
       "      <td>0.117763</td>\n",
       "      <td>0.292548</td>\n",
       "      <td>0.163065</td>\n",
       "      <td>0.201584</td>\n",
       "      <td>0.104444</td>\n",
       "      <td>0.054773</td>\n",
       "      <td>0.077808</td>\n",
       "      <td>0.115127</td>\n",
       "      <td>0.165373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>-0.338004</td>\n",
       "      <td>-0.448492</td>\n",
       "      <td>-0.407415</td>\n",
       "      <td>-0.334126</td>\n",
       "      <td>-0.362681</td>\n",
       "      <td>-0.410135</td>\n",
       "      <td>-0.265093</td>\n",
       "      <td>-0.290675</td>\n",
       "      <td>-0.372448</td>\n",
       "      <td>-0.532854</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.413611</td>\n",
       "      <td>-0.351949</td>\n",
       "      <td>-0.298367</td>\n",
       "      <td>-0.352100</td>\n",
       "      <td>-0.313564</td>\n",
       "      <td>-0.415174</td>\n",
       "      <td>-0.427682</td>\n",
       "      <td>-0.296633</td>\n",
       "      <td>-0.323871</td>\n",
       "      <td>-0.403244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>-0.260541</td>\n",
       "      <td>-0.317578</td>\n",
       "      <td>-0.358566</td>\n",
       "      <td>-0.402495</td>\n",
       "      <td>-0.317551</td>\n",
       "      <td>-0.331603</td>\n",
       "      <td>-0.328416</td>\n",
       "      <td>-0.329614</td>\n",
       "      <td>-0.354142</td>\n",
       "      <td>-0.477308</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.435722</td>\n",
       "      <td>-0.298772</td>\n",
       "      <td>-0.339823</td>\n",
       "      <td>-0.312367</td>\n",
       "      <td>-0.252384</td>\n",
       "      <td>-0.252861</td>\n",
       "      <td>-0.417251</td>\n",
       "      <td>-0.259335</td>\n",
       "      <td>-0.278924</td>\n",
       "      <td>-0.379769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>97</td>\n",
       "      <td>-0.091331</td>\n",
       "      <td>-0.048536</td>\n",
       "      <td>-0.171515</td>\n",
       "      <td>-0.248557</td>\n",
       "      <td>-0.138849</td>\n",
       "      <td>-0.173732</td>\n",
       "      <td>-0.270104</td>\n",
       "      <td>-0.209832</td>\n",
       "      <td>-0.156161</td>\n",
       "      <td>-0.328426</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.289519</td>\n",
       "      <td>-0.045965</td>\n",
       "      <td>-0.195670</td>\n",
       "      <td>-0.094860</td>\n",
       "      <td>-0.133596</td>\n",
       "      <td>-0.061210</td>\n",
       "      <td>-0.285379</td>\n",
       "      <td>-0.098825</td>\n",
       "      <td>-0.098370</td>\n",
       "      <td>-0.148948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98</td>\n",
       "      <td>0.475029</td>\n",
       "      <td>0.616331</td>\n",
       "      <td>0.295438</td>\n",
       "      <td>0.449078</td>\n",
       "      <td>0.429179</td>\n",
       "      <td>0.476891</td>\n",
       "      <td>0.434953</td>\n",
       "      <td>0.379936</td>\n",
       "      <td>0.429556</td>\n",
       "      <td>0.301831</td>\n",
       "      <td>...</td>\n",
       "      <td>0.487893</td>\n",
       "      <td>0.371047</td>\n",
       "      <td>0.454772</td>\n",
       "      <td>0.391740</td>\n",
       "      <td>0.476402</td>\n",
       "      <td>0.453732</td>\n",
       "      <td>0.372838</td>\n",
       "      <td>0.326981</td>\n",
       "      <td>0.377145</td>\n",
       "      <td>0.413909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99</td>\n",
       "      <td>-0.267994</td>\n",
       "      <td>-0.307027</td>\n",
       "      <td>-0.128380</td>\n",
       "      <td>-0.309421</td>\n",
       "      <td>-0.252040</td>\n",
       "      <td>-0.225712</td>\n",
       "      <td>-0.429682</td>\n",
       "      <td>-0.244619</td>\n",
       "      <td>-0.256639</td>\n",
       "      <td>-0.057134</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.369123</td>\n",
       "      <td>-0.205620</td>\n",
       "      <td>-0.372858</td>\n",
       "      <td>-0.230378</td>\n",
       "      <td>-0.293506</td>\n",
       "      <td>-0.161806</td>\n",
       "      <td>-0.097667</td>\n",
       "      <td>-0.169446</td>\n",
       "      <td>-0.188974</td>\n",
       "      <td>-0.201229</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5537 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6     \\\n",
       "0   0.231585  0.151163  0.073116  0.142370  0.103849 -0.006454  0.356444   \n",
       "1   0.234641  0.272158  0.358477  0.161240  0.265180  0.266771  0.147805   \n",
       "2   0.251932  0.409688  0.368279  0.141289  0.364655  0.423418 -0.046299   \n",
       "3  -0.041058 -0.012350 -0.078078 -0.186405 -0.109355 -0.110934 -0.155026   \n",
       "4   0.196058  0.193707  0.046136  0.308916  0.110850  0.109412  0.391374   \n",
       "..       ...       ...       ...       ...       ...       ...       ...   \n",
       "95 -0.338004 -0.448492 -0.407415 -0.334126 -0.362681 -0.410135 -0.265093   \n",
       "96 -0.260541 -0.317578 -0.358566 -0.402495 -0.317551 -0.331603 -0.328416   \n",
       "97 -0.091331 -0.048536 -0.171515 -0.248557 -0.138849 -0.173732 -0.270104   \n",
       "98  0.475029  0.616331  0.295438  0.449078  0.429179  0.476891  0.434953   \n",
       "99 -0.267994 -0.307027 -0.128380 -0.309421 -0.252040 -0.225712 -0.429682   \n",
       "\n",
       "        7         8         9     ...      5527      5528      5529      5530  \\\n",
       "0   0.110716  0.102889 -0.245600  ...  0.136608  0.100538  0.156224  0.017823   \n",
       "1   0.138410  0.231763  0.377306  ...  0.131544  0.215738  0.104093  0.173507   \n",
       "2   0.121733  0.269102  0.622014  ...  0.103441  0.308851  0.143387  0.301402   \n",
       "3  -0.147576 -0.098623 -0.277977  ... -0.227338 -0.047307 -0.134986 -0.079196   \n",
       "4   0.255873  0.215590 -0.100335  ...  0.335335  0.117763  0.292548  0.163065   \n",
       "..       ...       ...       ...  ...       ...       ...       ...       ...   \n",
       "95 -0.290675 -0.372448 -0.532854  ... -0.413611 -0.351949 -0.298367 -0.352100   \n",
       "96 -0.329614 -0.354142 -0.477308  ... -0.435722 -0.298772 -0.339823 -0.312367   \n",
       "97 -0.209832 -0.156161 -0.328426  ... -0.289519 -0.045965 -0.195670 -0.094860   \n",
       "98  0.379936  0.429556  0.301831  ...  0.487893  0.371047  0.454772  0.391740   \n",
       "99 -0.244619 -0.256639 -0.057134  ... -0.369123 -0.205620 -0.372858 -0.230378   \n",
       "\n",
       "        5531      5532      5533      5534      5535      5536  \n",
       "0   0.097291  0.193199 -0.142301 -0.035692  0.053435 -0.008556  \n",
       "1   0.198876  0.366641  0.239651  0.170668  0.245517  0.225361  \n",
       "2   0.293130  0.398373  0.395591  0.315253  0.326125  0.321966  \n",
       "3  -0.081337  0.015762 -0.160332 -0.061306 -0.047760 -0.098994  \n",
       "4   0.201584  0.104444  0.054773  0.077808  0.115127  0.165373  \n",
       "..       ...       ...       ...       ...       ...       ...  \n",
       "95 -0.313564 -0.415174 -0.427682 -0.296633 -0.323871 -0.403244  \n",
       "96 -0.252384 -0.252861 -0.417251 -0.259335 -0.278924 -0.379769  \n",
       "97 -0.133596 -0.061210 -0.285379 -0.098825 -0.098370 -0.148948  \n",
       "98  0.476402  0.453732  0.372838  0.326981  0.377145  0.413909  \n",
       "99 -0.293506 -0.161806 -0.097667 -0.169446 -0.188974 -0.201229  \n",
       "\n",
       "[100 rows x 5537 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_representation_W2v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les 10 mots les plus proches de change sont : \n",
      " \n",
      "qdr\n",
      "align\n",
      "bank\n",
      "immigration\n",
      "reform\n",
      "ch\n",
      "legislation\n",
      "arizona's\n",
      "powers\n",
      "limbo\n",
      " \n",
      "##################################################\n",
      " \n",
      "Les 10 mots les plus proches de climate sont : \n",
      " \n",
      "legislation\n",
      "immigration\n",
      "legisl\n",
      "tale\n",
      "extend\n",
      "reveal_further\n",
      "panel\n",
      "sidelining\n",
      "powers\n",
      "reform\n"
     ]
    }
   ],
   "source": [
    "# Etude de cette représentation via la cosinus similarité\n",
    "\n",
    "def closest_to(word,n_top_similar):\n",
    "    print('Les {} mots les plus proches de {} sont : '.format(n_top_similar,word))\n",
    "    print(' ')\n",
    "    for word in [w[0] for w in model_wv.most_similar(word,topn=n_top_similar)]:\n",
    "        print(word)\n",
    "        \n",
    "closest_to('change',10)\n",
    "print(' ')\n",
    "print('#'*50)\n",
    "print(' ')\n",
    "\n",
    "closest_to('climate',10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Une approche naïve avec TF IDF\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour chaque mot, on a un vecteur le représentant. Pour réprésenter un tweet, on fait la moyenne des vecteurs correspondant à chacun de ces mots."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Représentation des mots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialisation des mots TF-IDF\n",
    "cv=CountVectorizer()\n",
    "tfidf_transformer=TfidfTransformer(smooth_idf=True,use_idf=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Formatage de la base pour la méthode TF-IDF\n",
    "corpus=clean_text_second(df.Tweet,threshold=2000)\n",
    "corpus_new=[]\n",
    "for tweet in corpus: \n",
    "    tweet_sentence=''\n",
    "    for word in tweet:\n",
    "        tweet_sentence=tweet_sentence+' '+word\n",
    "    corpus_new.append(tweet_sentence)\n",
    "    \n",
    "# Caclul des scores TF-IDF de chaque mot\n",
    "word_count_vector=cv.fit_transform(corpus_new)\n",
    "tfidf_transformer.fit(word_count_vector)\n",
    "\n",
    "count_vector=cv.transform(corpus_new)\n",
    "tf_idf_vector=tfidf_transformer.transform(count_vector)\n",
    "feature_names = cv.get_feature_names()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "Tweet initial : Global warming report urges governments to act|BRUSSELS, Belgium (AP) - The world faces increased hunger and .. \n",
      " \n",
      "Tweet nettoyé :  global warming report urges governments to act brussels belgium ap the world faces increased hunger and\n",
      " \n",
      "Scores TF-IDF : \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>brussels</td>\n",
       "      <td>0.358888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>belgium</td>\n",
       "      <td>0.358888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>hunger</td>\n",
       "      <td>0.337373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>urges</td>\n",
       "      <td>0.323202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>governments</td>\n",
       "      <td>0.312617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>explain</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>experts</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>expert</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>experiments</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>à_the</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8167 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             first_tweet\n",
       "brussels        0.358888\n",
       "belgium         0.358888\n",
       "hunger          0.337373\n",
       "urges           0.323202\n",
       "governments     0.312617\n",
       "...                  ...\n",
       "explain         0.000000\n",
       "experts         0.000000\n",
       "expert          0.000000\n",
       "experiments     0.000000\n",
       "à_the           0.000000\n",
       "\n",
       "[8167 rows x 1 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exemple de représentation du premier tweet \n",
    "\n",
    "#get tfidf vector for first document\n",
    "first_document_vector=tf_idf_vector[0]\n",
    "\n",
    "#print du tweet\n",
    "print(' ')\n",
    "print('Tweet initial : '+df.iloc[0]['Tweet'])\n",
    "print(' ')\n",
    "\n",
    "#print du tweet nettoyé\n",
    "print('Tweet nettoyé : '+corpus_new[0])\n",
    "print(' ')\n",
    "print('Scores TF-IDF : ')\n",
    "#print des scores \n",
    "pd.DataFrame(first_document_vector.T.todense(), index=feature_names, columns=[\"first_tweet\"]).sort_values(by=[\"first_tweet\"],ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>062</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>à_only</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>à_poisoning</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>à_s</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>à_t</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>à_the</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8167 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0    1\n",
       "00           0.0  0.0\n",
       "000          0.0  0.0\n",
       "02           0.0  0.0\n",
       "04           0.0  0.0\n",
       "062          0.0  0.0\n",
       "...          ...  ...\n",
       "à_only       0.0  0.0\n",
       "à_poisoning  0.0  0.0\n",
       "à_s          0.0  0.0\n",
       "à_t          0.0  0.0\n",
       "à_the        0.0  0.0\n",
       "\n",
       "[8167 rows x 2 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Représentation de tout les tweets \n",
    "\n",
    "dt_tfidf_tweet = pd.DataFrame(tf_idf_vector[0:2].T.todense(),index=feature_names)\n",
    "dt_tfidf_tweet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problématique : matrice très sparse (beaucoup de zéros)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Avec du clustering de mots d'après Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'idée est d'utiliser la représentation de Word2Vec des mots pour faire du clustering sur tout les mots contenus dans la base. On se place ensuite au niveau de chaque tweet et on le représente par un vecteur qui compte le nombre de mots contenu dans chaque cluster. Plus pour analyser quels sont les mots qui se rapproche le plus selon la distance euclidienne ? (plutot que la cos similarité)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrainement du modèle Word2Vec ...\n"
     ]
    }
   ],
   "source": [
    "# Représentation Word2Vec de chaque mot \n",
    "\n",
    "clean_text=clean_text_second(df.Tweet,threshold=1000)\n",
    "\n",
    "print(\"Entrainement du modèle Word2Vec ...\")\n",
    "model = Word2Vec(clean_text, size=100, window=5, min_count=3, workers=4) \n",
    "\n",
    "model.train(clean_text, total_examples=len(clean_text), epochs=10) #réseau de neuronne du Word2Vec\n",
    "model_wv = model.wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5305 sur 8595 ne sont pas dans le vocabulaire du modèle Word2Vec entrainé\n"
     ]
    }
   ],
   "source": [
    "# Application du modèle W2v sur chaque token du corpus\n",
    "\n",
    "clean_text = reduce(add, clean_text)\n",
    "clean_text = set(clean_text)\n",
    "\n",
    "def Representation_W2v(tokenCorpus_unique):\n",
    "    new_sample = {}\n",
    "    number_not_in_vocab=0\n",
    "    for token in tokenCorpus_unique:\n",
    "            try : \n",
    "                new_sample[token]=list(model_wv.get_vector(token))\n",
    "            except: number_not_in_vocab=number_not_in_vocab+1\n",
    "    \n",
    "    print('{} mots sur {} ne sont pas dans le vocabulaire du modèle Word2Vec entrainé'.format(str(number_not_in_vocab),str(len(tokenCorpus_unique))))\n",
    "    return new_sample\n",
    "\n",
    "Representation_for_clustering=pd.DataFrame(Representation_W2v(clean_text)).T\n",
    "Representation_for_clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>goes</td>\n",
       "      <td>0.122800</td>\n",
       "      <td>0.144504</td>\n",
       "      <td>0.140187</td>\n",
       "      <td>-0.067737</td>\n",
       "      <td>0.175853</td>\n",
       "      <td>-0.098972</td>\n",
       "      <td>0.038210</td>\n",
       "      <td>-0.323761</td>\n",
       "      <td>0.157308</td>\n",
       "      <td>0.004284</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.152768</td>\n",
       "      <td>-0.073552</td>\n",
       "      <td>-0.008023</td>\n",
       "      <td>0.198721</td>\n",
       "      <td>0.225388</td>\n",
       "      <td>-0.244660</td>\n",
       "      <td>-0.288455</td>\n",
       "      <td>-0.128753</td>\n",
       "      <td>0.292307</td>\n",
       "      <td>-0.222587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>kids</td>\n",
       "      <td>-0.005635</td>\n",
       "      <td>0.107130</td>\n",
       "      <td>0.144896</td>\n",
       "      <td>-0.049324</td>\n",
       "      <td>0.048938</td>\n",
       "      <td>-0.110232</td>\n",
       "      <td>0.098668</td>\n",
       "      <td>-0.317000</td>\n",
       "      <td>0.089937</td>\n",
       "      <td>0.075107</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.133693</td>\n",
       "      <td>-0.075549</td>\n",
       "      <td>0.014891</td>\n",
       "      <td>0.164881</td>\n",
       "      <td>0.169205</td>\n",
       "      <td>-0.168924</td>\n",
       "      <td>-0.172270</td>\n",
       "      <td>-0.079434</td>\n",
       "      <td>0.204529</td>\n",
       "      <td>-0.110598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>way</td>\n",
       "      <td>0.003344</td>\n",
       "      <td>0.223247</td>\n",
       "      <td>0.313947</td>\n",
       "      <td>-0.128078</td>\n",
       "      <td>0.121334</td>\n",
       "      <td>-0.211594</td>\n",
       "      <td>0.211394</td>\n",
       "      <td>-0.748043</td>\n",
       "      <td>0.228341</td>\n",
       "      <td>0.171735</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.271408</td>\n",
       "      <td>-0.178806</td>\n",
       "      <td>-0.013306</td>\n",
       "      <td>0.363037</td>\n",
       "      <td>0.394783</td>\n",
       "      <td>-0.420372</td>\n",
       "      <td>-0.355643</td>\n",
       "      <td>-0.230895</td>\n",
       "      <td>0.387712</td>\n",
       "      <td>-0.223542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>cause</td>\n",
       "      <td>0.074173</td>\n",
       "      <td>0.386671</td>\n",
       "      <td>0.482558</td>\n",
       "      <td>-0.038281</td>\n",
       "      <td>-0.133846</td>\n",
       "      <td>-0.315780</td>\n",
       "      <td>0.439500</td>\n",
       "      <td>-0.871008</td>\n",
       "      <td>0.207984</td>\n",
       "      <td>0.241556</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.246951</td>\n",
       "      <td>-0.240948</td>\n",
       "      <td>-0.145416</td>\n",
       "      <td>0.416895</td>\n",
       "      <td>0.349004</td>\n",
       "      <td>-0.441297</td>\n",
       "      <td>-0.262328</td>\n",
       "      <td>-0.172549</td>\n",
       "      <td>0.349467</td>\n",
       "      <td>-0.148784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>reminding</td>\n",
       "      <td>-0.003189</td>\n",
       "      <td>0.056232</td>\n",
       "      <td>0.065434</td>\n",
       "      <td>-0.057459</td>\n",
       "      <td>0.007311</td>\n",
       "      <td>-0.048342</td>\n",
       "      <td>0.065785</td>\n",
       "      <td>-0.161821</td>\n",
       "      <td>0.004852</td>\n",
       "      <td>0.019016</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.067688</td>\n",
       "      <td>-0.033220</td>\n",
       "      <td>0.047907</td>\n",
       "      <td>0.050937</td>\n",
       "      <td>0.096906</td>\n",
       "      <td>-0.056147</td>\n",
       "      <td>-0.090628</td>\n",
       "      <td>-0.050083</td>\n",
       "      <td>0.059451</td>\n",
       "      <td>-0.031128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>belief</td>\n",
       "      <td>0.049002</td>\n",
       "      <td>0.138154</td>\n",
       "      <td>0.168448</td>\n",
       "      <td>-0.091389</td>\n",
       "      <td>0.125838</td>\n",
       "      <td>-0.118271</td>\n",
       "      <td>0.099431</td>\n",
       "      <td>-0.396778</td>\n",
       "      <td>0.133435</td>\n",
       "      <td>0.045762</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.157462</td>\n",
       "      <td>-0.050805</td>\n",
       "      <td>-0.005014</td>\n",
       "      <td>0.216999</td>\n",
       "      <td>0.214113</td>\n",
       "      <td>-0.205685</td>\n",
       "      <td>-0.231601</td>\n",
       "      <td>-0.121349</td>\n",
       "      <td>0.275925</td>\n",
       "      <td>-0.195891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ok</td>\n",
       "      <td>-0.050264</td>\n",
       "      <td>0.090456</td>\n",
       "      <td>0.176545</td>\n",
       "      <td>-0.116576</td>\n",
       "      <td>0.103199</td>\n",
       "      <td>-0.156815</td>\n",
       "      <td>0.155655</td>\n",
       "      <td>-0.451350</td>\n",
       "      <td>0.097688</td>\n",
       "      <td>0.106334</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.157814</td>\n",
       "      <td>-0.068910</td>\n",
       "      <td>0.068837</td>\n",
       "      <td>0.254995</td>\n",
       "      <td>0.241713</td>\n",
       "      <td>-0.220757</td>\n",
       "      <td>-0.250343</td>\n",
       "      <td>-0.161370</td>\n",
       "      <td>0.264842</td>\n",
       "      <td>-0.139815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>iceland</td>\n",
       "      <td>-0.077911</td>\n",
       "      <td>0.186505</td>\n",
       "      <td>0.392422</td>\n",
       "      <td>-0.127865</td>\n",
       "      <td>0.132483</td>\n",
       "      <td>-0.229768</td>\n",
       "      <td>0.285382</td>\n",
       "      <td>-0.742903</td>\n",
       "      <td>0.178304</td>\n",
       "      <td>0.194057</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.246844</td>\n",
       "      <td>-0.167081</td>\n",
       "      <td>-0.071641</td>\n",
       "      <td>0.428722</td>\n",
       "      <td>0.406804</td>\n",
       "      <td>-0.446940</td>\n",
       "      <td>-0.366821</td>\n",
       "      <td>-0.164390</td>\n",
       "      <td>0.456962</td>\n",
       "      <td>-0.238140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ruse</td>\n",
       "      <td>0.021283</td>\n",
       "      <td>0.037299</td>\n",
       "      <td>0.037412</td>\n",
       "      <td>-0.026468</td>\n",
       "      <td>0.055175</td>\n",
       "      <td>-0.032279</td>\n",
       "      <td>0.029146</td>\n",
       "      <td>-0.126785</td>\n",
       "      <td>0.036809</td>\n",
       "      <td>0.016773</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.046990</td>\n",
       "      <td>-0.030422</td>\n",
       "      <td>0.006864</td>\n",
       "      <td>0.072238</td>\n",
       "      <td>0.069490</td>\n",
       "      <td>-0.071309</td>\n",
       "      <td>-0.082006</td>\n",
       "      <td>-0.053621</td>\n",
       "      <td>0.081575</td>\n",
       "      <td>-0.052474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>about</td>\n",
       "      <td>-0.347457</td>\n",
       "      <td>0.104362</td>\n",
       "      <td>0.607938</td>\n",
       "      <td>0.101850</td>\n",
       "      <td>0.035738</td>\n",
       "      <td>-0.390447</td>\n",
       "      <td>0.261178</td>\n",
       "      <td>-1.435874</td>\n",
       "      <td>0.264164</td>\n",
       "      <td>0.587478</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.563034</td>\n",
       "      <td>-0.429308</td>\n",
       "      <td>-0.110377</td>\n",
       "      <td>0.526160</td>\n",
       "      <td>0.269138</td>\n",
       "      <td>-0.483008</td>\n",
       "      <td>-0.305909</td>\n",
       "      <td>-0.315252</td>\n",
       "      <td>0.328023</td>\n",
       "      <td>-0.027998</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3290 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0         1         2         3         4         5   \\\n",
       "goes       0.122800  0.144504  0.140187 -0.067737  0.175853 -0.098972   \n",
       "kids      -0.005635  0.107130  0.144896 -0.049324  0.048938 -0.110232   \n",
       "way        0.003344  0.223247  0.313947 -0.128078  0.121334 -0.211594   \n",
       "cause      0.074173  0.386671  0.482558 -0.038281 -0.133846 -0.315780   \n",
       "reminding -0.003189  0.056232  0.065434 -0.057459  0.007311 -0.048342   \n",
       "...             ...       ...       ...       ...       ...       ...   \n",
       "belief     0.049002  0.138154  0.168448 -0.091389  0.125838 -0.118271   \n",
       "ok        -0.050264  0.090456  0.176545 -0.116576  0.103199 -0.156815   \n",
       "iceland   -0.077911  0.186505  0.392422 -0.127865  0.132483 -0.229768   \n",
       "ruse       0.021283  0.037299  0.037412 -0.026468  0.055175 -0.032279   \n",
       "about     -0.347457  0.104362  0.607938  0.101850  0.035738 -0.390447   \n",
       "\n",
       "                 6         7         8         9   ...        90        91  \\\n",
       "goes       0.038210 -0.323761  0.157308  0.004284  ... -0.152768 -0.073552   \n",
       "kids       0.098668 -0.317000  0.089937  0.075107  ... -0.133693 -0.075549   \n",
       "way        0.211394 -0.748043  0.228341  0.171735  ... -0.271408 -0.178806   \n",
       "cause      0.439500 -0.871008  0.207984  0.241556  ... -0.246951 -0.240948   \n",
       "reminding  0.065785 -0.161821  0.004852  0.019016  ... -0.067688 -0.033220   \n",
       "...             ...       ...       ...       ...  ...       ...       ...   \n",
       "belief     0.099431 -0.396778  0.133435  0.045762  ... -0.157462 -0.050805   \n",
       "ok         0.155655 -0.451350  0.097688  0.106334  ... -0.157814 -0.068910   \n",
       "iceland    0.285382 -0.742903  0.178304  0.194057  ... -0.246844 -0.167081   \n",
       "ruse       0.029146 -0.126785  0.036809  0.016773  ... -0.046990 -0.030422   \n",
       "about      0.261178 -1.435874  0.264164  0.587478  ... -0.563034 -0.429308   \n",
       "\n",
       "                 92        93        94        95        96        97  \\\n",
       "goes      -0.008023  0.198721  0.225388 -0.244660 -0.288455 -0.128753   \n",
       "kids       0.014891  0.164881  0.169205 -0.168924 -0.172270 -0.079434   \n",
       "way       -0.013306  0.363037  0.394783 -0.420372 -0.355643 -0.230895   \n",
       "cause     -0.145416  0.416895  0.349004 -0.441297 -0.262328 -0.172549   \n",
       "reminding  0.047907  0.050937  0.096906 -0.056147 -0.090628 -0.050083   \n",
       "...             ...       ...       ...       ...       ...       ...   \n",
       "belief    -0.005014  0.216999  0.214113 -0.205685 -0.231601 -0.121349   \n",
       "ok         0.068837  0.254995  0.241713 -0.220757 -0.250343 -0.161370   \n",
       "iceland   -0.071641  0.428722  0.406804 -0.446940 -0.366821 -0.164390   \n",
       "ruse       0.006864  0.072238  0.069490 -0.071309 -0.082006 -0.053621   \n",
       "about     -0.110377  0.526160  0.269138 -0.483008 -0.305909 -0.315252   \n",
       "\n",
       "                 98        99  \n",
       "goes       0.292307 -0.222587  \n",
       "kids       0.204529 -0.110598  \n",
       "way        0.387712 -0.223542  \n",
       "cause      0.349467 -0.148784  \n",
       "reminding  0.059451 -0.031128  \n",
       "...             ...       ...  \n",
       "belief     0.275925 -0.195891  \n",
       "ok         0.264842 -0.139815  \n",
       "iceland    0.456962 -0.238140  \n",
       "ruse       0.081575 -0.052474  \n",
       "about      0.328023 -0.027998  \n",
       "\n",
       "[3290 rows x 100 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Representation_for_clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Application du clustering \n",
    "\n",
    "n_cluster = 5\n",
    "\n",
    "kmeans = KMeans(n_clusters=n_cluster) \n",
    "kmeans.fit(Representation_for_clustering)\n",
    "clusters=kmeans.predict(Representation_for_clustering).tolist()\n",
    "\n",
    "data=[]\n",
    "for x in range(len(clusters)):\n",
    "    data.append([Representation_for_clustering.index.tolist()[x],clusters[x]])\n",
    "    \n",
    "    \n",
    "results=pd.DataFrame(data= data , columns=['token','cluster'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de mots dans le cluster numéro 0 : 482\n",
      " \n",
      "####################\n",
      " \n",
      "Nombre de mots dans le cluster numéro 1 : 1024\n",
      " \n",
      "####################\n",
      " \n",
      "Nombre de mots dans le cluster numéro 2 : 126\n",
      " \n",
      "####################\n",
      " \n",
      "Nombre de mots dans le cluster numéro 3 : 103\n",
      " \n",
      "####################\n",
      " \n",
      "Nombre de mots dans le cluster numéro 4 : 1555\n",
      " \n",
      "####################\n",
      " \n"
     ]
    }
   ],
   "source": [
    "for k in range(n_cluster):\n",
    "    print('Nombre de mots dans le cluster numéro {} : '.format(k)+str(len(results[results.cluster==k])))\n",
    "    print(' ')\n",
    "    print('#'*20)\n",
    "    print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parmis les mots du cluster 2, il y a :  , says , body , plan , copenhagen , health , experts , sec , humanitarian , climate , ad , limbo , move , summit , art , à_o , forming , head , issues , bill , agency\n"
     ]
    }
   ],
   "source": [
    "# Etude de chaque cluster spécifiquement\n",
    "cluster=2\n",
    "\n",
    "list_word=''\n",
    "for word_index in range(20):\n",
    "    word=list(results[results.cluster==cluster]['token'])[word_index]\n",
    "    list_word=list_word+' , '+word\n",
    "print('Parmis les mots du cluster {}, il y a : '.format(cluster)+list_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interprétation des clusters ? Refaire avec des modèles pré-entrainés ? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Représentation de tweet avec des modèles pré-entrainés : Fast2vec, Word2vec et Bert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilisation en mode pré-entrainé"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
